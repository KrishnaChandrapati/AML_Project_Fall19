{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ECG200_notebook.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R1S9dLpyZJWT",
        "colab_type": "text"
      },
      "source": [
        "#This notebook uses ECG200 data and perform classification using two different methods: Recurrence plots(RP) and Gramian Angular Field (GAF).\n",
        "\n",
        "Same notebook can be slightly modified to run for 50words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gOqStzn6ZL81",
        "colab_type": "code",
        "outputId": "09d03ee1-8d12-4749-9396-bb5dac6a73f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0THxT7wNbw2M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import sys,os\n",
        "from mpl_toolkits.axes_grid1 import make_axes_locatable"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pQHJ0ucybQ8h",
        "colab_type": "text"
      },
      "source": [
        "#series2RP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hxf6BAqxnBtN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#unthresholded recurrence plot\n",
        "def r_plot(data,delay=0):\n",
        "    transformed=np.zeros([2,len(data)-delay])\n",
        "    transformed[0,:]=data[0:len(data)-delay]\n",
        "    transformed[1,:]=data[delay:len(data)]\n",
        "    rp=np.zeros([len(data)-delay,len(data)-delay])\n",
        "    for i in range(len(rp)):\n",
        "        for j in range(len(rp)):\n",
        "            rp[i,j]=np.linalg.norm(transformed[:,i]-transformed[:,j])\n",
        "    return np.array(rp.flatten())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T7-aj2qYGux6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "d88ff166-74a0-41bd-bc3e-7f054047703a"
      },
      "source": [
        "def paa(series, now, opw):\n",
        "    if now == None:\n",
        "        now = int(len(series) / opw)\n",
        "    if opw == None:\n",
        "        opw = int(len(series) / now)\n",
        "    return [sum(series[i * opw : (i + 1) * opw]) / float(opw) for i in range(now)]\n",
        "datafiles = ['ECG200_TRAIN', 'ECG200_TEST',] # Data file name\n",
        "rplot = [[],[]]\n",
        "labels = [[],[]]\n",
        "phase_space_vector = [0,0]\n",
        "size=[31]\n",
        "for i in range(len(datafiles)):\n",
        "    fn = datafiles[i]\n",
        "    for s in size:  \n",
        "        print('read file: {}, size: {}'.format(datafiles[i], s))\n",
        "        #read data\n",
        "        raw = open('/content/drive/Shared drives/AML Project Fall 2019/ECG200/'+fn+'.tsv').readlines()\n",
        "        raw = [list(map(float, each.strip().split('\\t'))) for each in raw]\n",
        "\n",
        "        for each in raw:\n",
        "            labels[i].append(each[0])\n",
        "            paa_data = np.array(paa(each[1:],s,None))\n",
        "            smt= r_plot(paa_data)\n",
        "            rplot[i].append(smt)\n",
        "        phase_space_vector[i] = (np.asarray(rplot[i]),labels[i]) \n",
        "\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "read file: ECG200_TRAIN, size: 31\n",
            "read file: ECG200_TEST, size: 31\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c61m4FWBGu1C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ECG200_TRAIN_phasespace= phase_space_vector[0]\n",
        "ECG200_TEST_phasespace= phase_space_vector[1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OaFpdz68GuvH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_img= ECG200_TRAIN_phasespace[0]\n",
        "test_img= ECG200_TEST_phasespace[0]\n",
        "train_labels= ECG200_TRAIN_phasespace[1]\n",
        "test_labels= ECG200_TEST_phasespace[1]\n",
        "for i in range(ECG200_TRAIN_phasespace[0].shape[0]):\n",
        "  if train_labels[i] == -1:\n",
        "    train_labels[i]=0\n",
        "for i in range(ECG200_TEST_phasespace[0].shape[0]):\n",
        "  if test_labels[i] == -1:\n",
        "    test_labels[i]=0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hbr6Z4oAYJvR",
        "colab_type": "code",
        "outputId": "efff22a7-bd55-4894-d6a6-7cbfdab90086",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from __future__ import print_function\n",
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras import backend as K\n",
        "from keras.utils import plot_model\n",
        "from keras import optimizers\n",
        "batch_size =10\n",
        "num_classes = 2\n",
        "epochs = 500\n",
        "\n",
        "# input image dimensions\n",
        "img_rows, img_cols = 31,31\n",
        "# the data, split between train and test sets\n",
        "(x_train, y_train), (x_test, y_test) = (train_img, train_labels), (test_img, test_labels)\n",
        "x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
        "x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
        "input_shape = (img_rows, img_cols, 1)\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "def labeling(y,num_classes):\n",
        "  from sklearn.preprocessing import LabelEncoder\n",
        "  encoder = LabelEncoder()\n",
        "  encoder.fit(y)\n",
        "  encoded_Y = encoder.transform(y)\n",
        "  # convert integers to dummy variables (i.e. one hot encoded)\n",
        "  dummy_y = keras.utils.np_utils.to_categorical(encoded_Y,num_classes)\n",
        "  return(dummy_y)\n",
        "\n",
        "#from keras.utils.np_utils import to_categorical\n",
        "#one-hot encode target column\n",
        "y_train = labeling(y_train, num_classes)\n",
        "y_test = labeling(y_test, num_classes)\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, kernel_size=(3,3),\n",
        "                 activation='relu',\n",
        "                 input_shape=input_shape))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Conv2D(32, kernel_size=(3,3), \n",
        "                 activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "              optimizer=keras.optimizers.Adam(),\n",
        "              metrics=['accuracy'])\n",
        "history=model.fit(x_train, y_train,\n",
        "          batch_size,\n",
        "          epochs,\n",
        "          verbose=1,\n",
        "          validation_data=(x_test, y_test))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "x_train shape: (100, 31, 31, 1)\n",
            "100 train samples\n",
            "100 test samples\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Train on 100 samples, validate on 100 samples\n",
            "Epoch 1/500\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.6752 - acc: 0.6300 - val_loss: 0.6662 - val_acc: 0.6400\n",
            "Epoch 2/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.6257 - acc: 0.6900 - val_loss: 0.6629 - val_acc: 0.6400\n",
            "Epoch 3/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.6373 - acc: 0.6900 - val_loss: 0.6502 - val_acc: 0.6400\n",
            "Epoch 4/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.6204 - acc: 0.6900 - val_loss: 0.6550 - val_acc: 0.6400\n",
            "Epoch 5/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.6389 - acc: 0.6900 - val_loss: 0.6485 - val_acc: 0.6400\n",
            "Epoch 6/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.6044 - acc: 0.6900 - val_loss: 0.6461 - val_acc: 0.6400\n",
            "Epoch 7/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.6110 - acc: 0.6900 - val_loss: 0.6631 - val_acc: 0.6400\n",
            "Epoch 8/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.6050 - acc: 0.6900 - val_loss: 0.6385 - val_acc: 0.6400\n",
            "Epoch 9/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.6176 - acc: 0.6900 - val_loss: 0.6320 - val_acc: 0.6400\n",
            "Epoch 10/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.6037 - acc: 0.6900 - val_loss: 0.6215 - val_acc: 0.6400\n",
            "Epoch 11/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.5802 - acc: 0.6900 - val_loss: 0.6047 - val_acc: 0.6400\n",
            "Epoch 12/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.5613 - acc: 0.6900 - val_loss: 0.5826 - val_acc: 0.6400\n",
            "Epoch 13/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.5554 - acc: 0.6900 - val_loss: 0.5616 - val_acc: 0.6400\n",
            "Epoch 14/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.5338 - acc: 0.6900 - val_loss: 0.5388 - val_acc: 0.6400\n",
            "Epoch 15/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.4942 - acc: 0.7000 - val_loss: 0.5151 - val_acc: 0.6900\n",
            "Epoch 16/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.4820 - acc: 0.7500 - val_loss: 0.4869 - val_acc: 0.7700\n",
            "Epoch 17/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.4483 - acc: 0.7700 - val_loss: 0.4587 - val_acc: 0.8300\n",
            "Epoch 18/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.4623 - acc: 0.7800 - val_loss: 0.4483 - val_acc: 0.8200\n",
            "Epoch 19/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.4570 - acc: 0.8000 - val_loss: 0.4344 - val_acc: 0.8000\n",
            "Epoch 20/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.4296 - acc: 0.8100 - val_loss: 0.4294 - val_acc: 0.8000\n",
            "Epoch 21/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.4130 - acc: 0.8100 - val_loss: 0.4237 - val_acc: 0.8100\n",
            "Epoch 22/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.4486 - acc: 0.7900 - val_loss: 0.4238 - val_acc: 0.8100\n",
            "Epoch 23/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.3926 - acc: 0.8200 - val_loss: 0.4178 - val_acc: 0.8200\n",
            "Epoch 24/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.4066 - acc: 0.7800 - val_loss: 0.4090 - val_acc: 0.8100\n",
            "Epoch 25/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.3902 - acc: 0.8100 - val_loss: 0.4042 - val_acc: 0.8100\n",
            "Epoch 26/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.3967 - acc: 0.8000 - val_loss: 0.4020 - val_acc: 0.7900\n",
            "Epoch 27/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.4013 - acc: 0.8100 - val_loss: 0.4062 - val_acc: 0.8000\n",
            "Epoch 28/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.4251 - acc: 0.8000 - val_loss: 0.4054 - val_acc: 0.8000\n",
            "Epoch 29/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.3902 - acc: 0.8100 - val_loss: 0.4051 - val_acc: 0.8000\n",
            "Epoch 30/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.3761 - acc: 0.8300 - val_loss: 0.4027 - val_acc: 0.8000\n",
            "Epoch 31/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.4149 - acc: 0.7900 - val_loss: 0.3963 - val_acc: 0.8000\n",
            "Epoch 32/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.3923 - acc: 0.8300 - val_loss: 0.3984 - val_acc: 0.8100\n",
            "Epoch 33/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.3807 - acc: 0.8200 - val_loss: 0.4004 - val_acc: 0.8100\n",
            "Epoch 34/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.3986 - acc: 0.8200 - val_loss: 0.3967 - val_acc: 0.8100\n",
            "Epoch 35/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.3757 - acc: 0.8200 - val_loss: 0.3928 - val_acc: 0.8100\n",
            "Epoch 36/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.3922 - acc: 0.8300 - val_loss: 0.3860 - val_acc: 0.8200\n",
            "Epoch 37/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.3816 - acc: 0.7800 - val_loss: 0.3829 - val_acc: 0.8000\n",
            "Epoch 38/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.3801 - acc: 0.7900 - val_loss: 0.3823 - val_acc: 0.8200\n",
            "Epoch 39/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.3537 - acc: 0.8000 - val_loss: 0.3806 - val_acc: 0.8000\n",
            "Epoch 40/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.3408 - acc: 0.8600 - val_loss: 0.3810 - val_acc: 0.8100\n",
            "Epoch 41/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.3347 - acc: 0.8300 - val_loss: 0.3744 - val_acc: 0.8200\n",
            "Epoch 42/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.3808 - acc: 0.7900 - val_loss: 0.3683 - val_acc: 0.8200\n",
            "Epoch 43/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.3608 - acc: 0.8100 - val_loss: 0.3702 - val_acc: 0.8100\n",
            "Epoch 44/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.3698 - acc: 0.8200 - val_loss: 0.3713 - val_acc: 0.8200\n",
            "Epoch 45/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.3443 - acc: 0.8300 - val_loss: 0.3670 - val_acc: 0.8200\n",
            "Epoch 46/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.3513 - acc: 0.8200 - val_loss: 0.3631 - val_acc: 0.8200\n",
            "Epoch 47/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.3435 - acc: 0.8300 - val_loss: 0.3603 - val_acc: 0.8100\n",
            "Epoch 48/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.3155 - acc: 0.8300 - val_loss: 0.3633 - val_acc: 0.8300\n",
            "Epoch 49/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.3713 - acc: 0.8400 - val_loss: 0.3542 - val_acc: 0.8300\n",
            "Epoch 50/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.3471 - acc: 0.8500 - val_loss: 0.3607 - val_acc: 0.8000\n",
            "Epoch 51/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.3604 - acc: 0.8200 - val_loss: 0.3650 - val_acc: 0.8200\n",
            "Epoch 52/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.3282 - acc: 0.8400 - val_loss: 0.3565 - val_acc: 0.8400\n",
            "Epoch 53/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.3199 - acc: 0.8500 - val_loss: 0.3470 - val_acc: 0.8200\n",
            "Epoch 54/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.3587 - acc: 0.8000 - val_loss: 0.3492 - val_acc: 0.8100\n",
            "Epoch 55/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.3208 - acc: 0.8500 - val_loss: 0.3401 - val_acc: 0.8400\n",
            "Epoch 56/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.3390 - acc: 0.8100 - val_loss: 0.3415 - val_acc: 0.8300\n",
            "Epoch 57/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.3524 - acc: 0.8100 - val_loss: 0.3473 - val_acc: 0.8100\n",
            "Epoch 58/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.3137 - acc: 0.8800 - val_loss: 0.3444 - val_acc: 0.8300\n",
            "Epoch 59/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.3054 - acc: 0.8300 - val_loss: 0.3414 - val_acc: 0.8500\n",
            "Epoch 60/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.3069 - acc: 0.9000 - val_loss: 0.3290 - val_acc: 0.8300\n",
            "Epoch 61/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.3342 - acc: 0.8600 - val_loss: 0.3297 - val_acc: 0.8300\n",
            "Epoch 62/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.3082 - acc: 0.8400 - val_loss: 0.3276 - val_acc: 0.8300\n",
            "Epoch 63/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.2929 - acc: 0.8300 - val_loss: 0.3319 - val_acc: 0.8200\n",
            "Epoch 64/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.3129 - acc: 0.8700 - val_loss: 0.3225 - val_acc: 0.8200\n",
            "Epoch 65/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.2859 - acc: 0.8800 - val_loss: 0.3313 - val_acc: 0.8400\n",
            "Epoch 66/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.3226 - acc: 0.8400 - val_loss: 0.3285 - val_acc: 0.8600\n",
            "Epoch 67/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.2811 - acc: 0.8500 - val_loss: 0.3201 - val_acc: 0.8200\n",
            "Epoch 68/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.3111 - acc: 0.8400 - val_loss: 0.3183 - val_acc: 0.8300\n",
            "Epoch 69/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.2899 - acc: 0.8400 - val_loss: 0.3158 - val_acc: 0.8800\n",
            "Epoch 70/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.2980 - acc: 0.8600 - val_loss: 0.3178 - val_acc: 0.8200\n",
            "Epoch 71/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.2999 - acc: 0.8400 - val_loss: 0.3125 - val_acc: 0.8500\n",
            "Epoch 72/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.2706 - acc: 0.9000 - val_loss: 0.3098 - val_acc: 0.8600\n",
            "Epoch 73/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.2960 - acc: 0.8700 - val_loss: 0.3344 - val_acc: 0.8700\n",
            "Epoch 74/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.2860 - acc: 0.8600 - val_loss: 0.3145 - val_acc: 0.8500\n",
            "Epoch 75/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.2679 - acc: 0.8700 - val_loss: 0.3067 - val_acc: 0.8600\n",
            "Epoch 76/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.2408 - acc: 0.8900 - val_loss: 0.3153 - val_acc: 0.8700\n",
            "Epoch 77/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.2882 - acc: 0.8600 - val_loss: 0.3115 - val_acc: 0.8600\n",
            "Epoch 78/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.2713 - acc: 0.8700 - val_loss: 0.3055 - val_acc: 0.8500\n",
            "Epoch 79/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.2580 - acc: 0.8800 - val_loss: 0.3057 - val_acc: 0.8700\n",
            "Epoch 80/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.2914 - acc: 0.8700 - val_loss: 0.2991 - val_acc: 0.8700\n",
            "Epoch 81/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.2559 - acc: 0.9000 - val_loss: 0.3107 - val_acc: 0.8500\n",
            "Epoch 82/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.2778 - acc: 0.8500 - val_loss: 0.3019 - val_acc: 0.8700\n",
            "Epoch 83/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.2610 - acc: 0.8800 - val_loss: 0.3061 - val_acc: 0.8700\n",
            "Epoch 84/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.2692 - acc: 0.8800 - val_loss: 0.3001 - val_acc: 0.8600\n",
            "Epoch 85/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.2756 - acc: 0.8500 - val_loss: 0.3031 - val_acc: 0.8500\n",
            "Epoch 86/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.2690 - acc: 0.9000 - val_loss: 0.3076 - val_acc: 0.8700\n",
            "Epoch 87/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.2423 - acc: 0.9000 - val_loss: 0.3095 - val_acc: 0.8800\n",
            "Epoch 88/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.2600 - acc: 0.9100 - val_loss: 0.3082 - val_acc: 0.8700\n",
            "Epoch 89/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.2637 - acc: 0.9200 - val_loss: 0.3071 - val_acc: 0.8800\n",
            "Epoch 90/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.2746 - acc: 0.8900 - val_loss: 0.3101 - val_acc: 0.8700\n",
            "Epoch 91/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.2594 - acc: 0.8800 - val_loss: 0.2933 - val_acc: 0.9000\n",
            "Epoch 92/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.2509 - acc: 0.9200 - val_loss: 0.2846 - val_acc: 0.8900\n",
            "Epoch 93/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.2344 - acc: 0.9300 - val_loss: 0.2978 - val_acc: 0.8700\n",
            "Epoch 94/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.2646 - acc: 0.8700 - val_loss: 0.3128 - val_acc: 0.8900\n",
            "Epoch 95/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.2307 - acc: 0.9300 - val_loss: 0.2839 - val_acc: 0.9000\n",
            "Epoch 96/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.2450 - acc: 0.8800 - val_loss: 0.2790 - val_acc: 0.9000\n",
            "Epoch 97/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.2356 - acc: 0.9200 - val_loss: 0.2864 - val_acc: 0.9000\n",
            "Epoch 98/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.2145 - acc: 0.9000 - val_loss: 0.2835 - val_acc: 0.9000\n",
            "Epoch 99/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.2538 - acc: 0.8900 - val_loss: 0.2800 - val_acc: 0.9100\n",
            "Epoch 100/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.2529 - acc: 0.8900 - val_loss: 0.2735 - val_acc: 0.9100\n",
            "Epoch 101/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.2294 - acc: 0.9100 - val_loss: 0.2818 - val_acc: 0.9000\n",
            "Epoch 102/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.2008 - acc: 0.9200 - val_loss: 0.2911 - val_acc: 0.9100\n",
            "Epoch 103/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.2306 - acc: 0.9200 - val_loss: 0.2901 - val_acc: 0.9000\n",
            "Epoch 104/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.2028 - acc: 0.9300 - val_loss: 0.2785 - val_acc: 0.8900\n",
            "Epoch 105/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.2608 - acc: 0.8700 - val_loss: 0.2840 - val_acc: 0.9100\n",
            "Epoch 106/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.2259 - acc: 0.9100 - val_loss: 0.3043 - val_acc: 0.8800\n",
            "Epoch 107/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.2192 - acc: 0.9200 - val_loss: 0.2935 - val_acc: 0.8900\n",
            "Epoch 108/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.2422 - acc: 0.8800 - val_loss: 0.3038 - val_acc: 0.8900\n",
            "Epoch 109/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.2259 - acc: 0.8900 - val_loss: 0.2945 - val_acc: 0.9100\n",
            "Epoch 110/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.2069 - acc: 0.8900 - val_loss: 0.2833 - val_acc: 0.8900\n",
            "Epoch 111/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.2498 - acc: 0.9000 - val_loss: 0.2682 - val_acc: 0.9200\n",
            "Epoch 112/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.2521 - acc: 0.9300 - val_loss: 0.2979 - val_acc: 0.9000\n",
            "Epoch 113/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.2189 - acc: 0.9100 - val_loss: 0.2933 - val_acc: 0.9000\n",
            "Epoch 114/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.2655 - acc: 0.8700 - val_loss: 0.2912 - val_acc: 0.9000\n",
            "Epoch 115/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.2531 - acc: 0.9000 - val_loss: 0.2807 - val_acc: 0.9200\n",
            "Epoch 116/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.1793 - acc: 0.9100 - val_loss: 0.2775 - val_acc: 0.9200\n",
            "Epoch 117/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.2803 - acc: 0.8800 - val_loss: 0.2842 - val_acc: 0.9100\n",
            "Epoch 118/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.2097 - acc: 0.9000 - val_loss: 0.2740 - val_acc: 0.9100\n",
            "Epoch 119/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.2132 - acc: 0.9200 - val_loss: 0.2671 - val_acc: 0.9000\n",
            "Epoch 120/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.2737 - acc: 0.8500 - val_loss: 0.2980 - val_acc: 0.8800\n",
            "Epoch 121/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.2050 - acc: 0.9000 - val_loss: 0.2948 - val_acc: 0.8900\n",
            "Epoch 122/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.1918 - acc: 0.9200 - val_loss: 0.2927 - val_acc: 0.8900\n",
            "Epoch 123/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.2335 - acc: 0.8700 - val_loss: 0.2667 - val_acc: 0.9100\n",
            "Epoch 124/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.2241 - acc: 0.8800 - val_loss: 0.2894 - val_acc: 0.9000\n",
            "Epoch 125/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.2216 - acc: 0.9200 - val_loss: 0.2959 - val_acc: 0.9000\n",
            "Epoch 126/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.2235 - acc: 0.9000 - val_loss: 0.2813 - val_acc: 0.9100\n",
            "Epoch 127/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.2194 - acc: 0.9200 - val_loss: 0.3168 - val_acc: 0.8900\n",
            "Epoch 128/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.2017 - acc: 0.9200 - val_loss: 0.2871 - val_acc: 0.9000\n",
            "Epoch 129/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.2187 - acc: 0.9000 - val_loss: 0.2845 - val_acc: 0.9000\n",
            "Epoch 130/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.2590 - acc: 0.9200 - val_loss: 0.3051 - val_acc: 0.9200\n",
            "Epoch 131/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.1672 - acc: 0.9300 - val_loss: 0.2929 - val_acc: 0.9000\n",
            "Epoch 132/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.2030 - acc: 0.8900 - val_loss: 0.2896 - val_acc: 0.9100\n",
            "Epoch 133/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.1763 - acc: 0.9300 - val_loss: 0.2856 - val_acc: 0.9100\n",
            "Epoch 134/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.2086 - acc: 0.9100 - val_loss: 0.2898 - val_acc: 0.9100\n",
            "Epoch 135/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.1836 - acc: 0.9300 - val_loss: 0.3068 - val_acc: 0.9100\n",
            "Epoch 136/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.1837 - acc: 0.9300 - val_loss: 0.3040 - val_acc: 0.9100\n",
            "Epoch 137/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.2081 - acc: 0.9300 - val_loss: 0.2906 - val_acc: 0.9000\n",
            "Epoch 138/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.1709 - acc: 0.9400 - val_loss: 0.3151 - val_acc: 0.9200\n",
            "Epoch 139/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.2138 - acc: 0.9300 - val_loss: 0.2843 - val_acc: 0.9000\n",
            "Epoch 140/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.1865 - acc: 0.9100 - val_loss: 0.2890 - val_acc: 0.9200\n",
            "Epoch 141/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.2235 - acc: 0.9100 - val_loss: 0.2972 - val_acc: 0.9300\n",
            "Epoch 142/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.1706 - acc: 0.9400 - val_loss: 0.2915 - val_acc: 0.9300\n",
            "Epoch 143/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.1760 - acc: 0.9400 - val_loss: 0.2807 - val_acc: 0.9200\n",
            "Epoch 144/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.1872 - acc: 0.9100 - val_loss: 0.2823 - val_acc: 0.9200\n",
            "Epoch 145/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.1645 - acc: 0.9300 - val_loss: 0.3229 - val_acc: 0.9000\n",
            "Epoch 146/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.1871 - acc: 0.9000 - val_loss: 0.3000 - val_acc: 0.9300\n",
            "Epoch 147/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.1698 - acc: 0.9600 - val_loss: 0.2931 - val_acc: 0.9000\n",
            "Epoch 148/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.1542 - acc: 0.9400 - val_loss: 0.3485 - val_acc: 0.8700\n",
            "Epoch 149/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.1671 - acc: 0.9300 - val_loss: 0.3309 - val_acc: 0.9100\n",
            "Epoch 150/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.2171 - acc: 0.8900 - val_loss: 0.2780 - val_acc: 0.9000\n",
            "Epoch 151/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.1977 - acc: 0.9000 - val_loss: 0.2791 - val_acc: 0.9000\n",
            "Epoch 152/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.1727 - acc: 0.9300 - val_loss: 0.3089 - val_acc: 0.9100\n",
            "Epoch 153/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.1975 - acc: 0.9400 - val_loss: 0.2956 - val_acc: 0.9400\n",
            "Epoch 154/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.1680 - acc: 0.9400 - val_loss: 0.2790 - val_acc: 0.9200\n",
            "Epoch 155/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.2103 - acc: 0.9100 - val_loss: 0.3002 - val_acc: 0.9100\n",
            "Epoch 156/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.1766 - acc: 0.9200 - val_loss: 0.2829 - val_acc: 0.9200\n",
            "Epoch 157/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.1714 - acc: 0.9200 - val_loss: 0.2930 - val_acc: 0.9200\n",
            "Epoch 158/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.1705 - acc: 0.9300 - val_loss: 0.3270 - val_acc: 0.9100\n",
            "Epoch 159/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.1980 - acc: 0.9300 - val_loss: 0.3115 - val_acc: 0.9200\n",
            "Epoch 160/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.1547 - acc: 0.9400 - val_loss: 0.3169 - val_acc: 0.9200\n",
            "Epoch 161/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.1539 - acc: 0.9400 - val_loss: 0.3170 - val_acc: 0.9400\n",
            "Epoch 162/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.1750 - acc: 0.9100 - val_loss: 0.2932 - val_acc: 0.9300\n",
            "Epoch 163/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.1515 - acc: 0.9400 - val_loss: 0.3067 - val_acc: 0.9400\n",
            "Epoch 164/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.1720 - acc: 0.9200 - val_loss: 0.3119 - val_acc: 0.9300\n",
            "Epoch 165/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.1304 - acc: 0.9600 - val_loss: 0.2992 - val_acc: 0.9400\n",
            "Epoch 166/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.1515 - acc: 0.9400 - val_loss: 0.3168 - val_acc: 0.9300\n",
            "Epoch 167/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.1561 - acc: 0.9300 - val_loss: 0.3088 - val_acc: 0.9500\n",
            "Epoch 168/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.1265 - acc: 0.9700 - val_loss: 0.2961 - val_acc: 0.9200\n",
            "Epoch 169/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.1502 - acc: 0.9400 - val_loss: 0.3537 - val_acc: 0.9000\n",
            "Epoch 170/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.2014 - acc: 0.8700 - val_loss: 0.3157 - val_acc: 0.9300\n",
            "Epoch 171/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.1816 - acc: 0.9100 - val_loss: 0.3175 - val_acc: 0.9100\n",
            "Epoch 172/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.2214 - acc: 0.8900 - val_loss: 0.2986 - val_acc: 0.9400\n",
            "Epoch 173/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.2538 - acc: 0.8900 - val_loss: 0.2787 - val_acc: 0.9000\n",
            "Epoch 174/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.1827 - acc: 0.9200 - val_loss: 0.3172 - val_acc: 0.9300\n",
            "Epoch 175/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1698 - acc: 0.9200 - val_loss: 0.3104 - val_acc: 0.9000\n",
            "Epoch 176/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.1531 - acc: 0.9600 - val_loss: 0.3118 - val_acc: 0.9100\n",
            "Epoch 177/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.1697 - acc: 0.9400 - val_loss: 0.3021 - val_acc: 0.9400\n",
            "Epoch 178/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.1435 - acc: 0.9600 - val_loss: 0.3132 - val_acc: 0.9200\n",
            "Epoch 179/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.1160 - acc: 0.9600 - val_loss: 0.3107 - val_acc: 0.9300\n",
            "Epoch 180/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.1082 - acc: 0.9500 - val_loss: 0.3204 - val_acc: 0.9200\n",
            "Epoch 181/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.1172 - acc: 0.9400 - val_loss: 0.3397 - val_acc: 0.9100\n",
            "Epoch 182/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.1242 - acc: 0.9700 - val_loss: 0.3364 - val_acc: 0.9300\n",
            "Epoch 183/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.1441 - acc: 0.9200 - val_loss: 0.3595 - val_acc: 0.9100\n",
            "Epoch 184/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.1389 - acc: 0.9600 - val_loss: 0.3651 - val_acc: 0.9100\n",
            "Epoch 185/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.1522 - acc: 0.9400 - val_loss: 0.3520 - val_acc: 0.9400\n",
            "Epoch 186/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.1090 - acc: 0.9500 - val_loss: 0.3427 - val_acc: 0.9200\n",
            "Epoch 187/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.1478 - acc: 0.9100 - val_loss: 0.3162 - val_acc: 0.9300\n",
            "Epoch 188/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.1132 - acc: 0.9500 - val_loss: 0.3516 - val_acc: 0.9200\n",
            "Epoch 189/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.1984 - acc: 0.9100 - val_loss: 0.3203 - val_acc: 0.9200\n",
            "Epoch 190/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.1216 - acc: 0.9500 - val_loss: 0.3322 - val_acc: 0.9200\n",
            "Epoch 191/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.1607 - acc: 0.8900 - val_loss: 0.3305 - val_acc: 0.9200\n",
            "Epoch 192/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.1432 - acc: 0.9600 - val_loss: 0.3147 - val_acc: 0.9200\n",
            "Epoch 193/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.1183 - acc: 0.9600 - val_loss: 0.3067 - val_acc: 0.9300\n",
            "Epoch 194/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.1321 - acc: 0.9400 - val_loss: 0.3331 - val_acc: 0.9200\n",
            "Epoch 195/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.2139 - acc: 0.9200 - val_loss: 0.3156 - val_acc: 0.9400\n",
            "Epoch 196/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.1352 - acc: 0.9300 - val_loss: 0.3087 - val_acc: 0.9400\n",
            "Epoch 197/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.1075 - acc: 0.9700 - val_loss: 0.3232 - val_acc: 0.9300\n",
            "Epoch 198/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.1260 - acc: 0.9500 - val_loss: 0.3504 - val_acc: 0.9200\n",
            "Epoch 199/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.1414 - acc: 0.9200 - val_loss: 0.3321 - val_acc: 0.9200\n",
            "Epoch 200/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.1038 - acc: 0.9400 - val_loss: 0.3129 - val_acc: 0.9400\n",
            "Epoch 201/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.2007 - acc: 0.9000 - val_loss: 0.3185 - val_acc: 0.9300\n",
            "Epoch 202/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.1197 - acc: 0.9500 - val_loss: 0.3183 - val_acc: 0.9200\n",
            "Epoch 203/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.1391 - acc: 0.9500 - val_loss: 0.3277 - val_acc: 0.9300\n",
            "Epoch 204/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.1103 - acc: 0.9500 - val_loss: 0.3110 - val_acc: 0.9300\n",
            "Epoch 205/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.1739 - acc: 0.9300 - val_loss: 0.3166 - val_acc: 0.9300\n",
            "Epoch 206/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.1501 - acc: 0.9100 - val_loss: 0.3821 - val_acc: 0.9200\n",
            "Epoch 207/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.1665 - acc: 0.9200 - val_loss: 0.3208 - val_acc: 0.9200\n",
            "Epoch 208/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.1083 - acc: 0.9500 - val_loss: 0.3225 - val_acc: 0.9100\n",
            "Epoch 209/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.1283 - acc: 0.9600 - val_loss: 0.3620 - val_acc: 0.9100\n",
            "Epoch 210/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.1603 - acc: 0.9200 - val_loss: 0.3309 - val_acc: 0.9400\n",
            "Epoch 211/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.1369 - acc: 0.9400 - val_loss: 0.3700 - val_acc: 0.9100\n",
            "Epoch 212/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.1235 - acc: 0.9400 - val_loss: 0.3818 - val_acc: 0.9100\n",
            "Epoch 213/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.1311 - acc: 0.9500 - val_loss: 0.3831 - val_acc: 0.9100\n",
            "Epoch 214/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.1455 - acc: 0.9300 - val_loss: 0.3624 - val_acc: 0.9200\n",
            "Epoch 215/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.0938 - acc: 0.9600 - val_loss: 0.3266 - val_acc: 0.9300\n",
            "Epoch 216/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.1863 - acc: 0.9400 - val_loss: 0.3410 - val_acc: 0.9300\n",
            "Epoch 217/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.1336 - acc: 0.9400 - val_loss: 0.3527 - val_acc: 0.9100\n",
            "Epoch 218/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.1047 - acc: 0.9700 - val_loss: 0.3489 - val_acc: 0.9300\n",
            "Epoch 219/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.1548 - acc: 0.9100 - val_loss: 0.3477 - val_acc: 0.9100\n",
            "Epoch 220/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0907 - acc: 0.9600 - val_loss: 0.3695 - val_acc: 0.9100\n",
            "Epoch 221/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.1166 - acc: 0.9600 - val_loss: 0.3708 - val_acc: 0.9100\n",
            "Epoch 222/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.1401 - acc: 0.9300 - val_loss: 0.3544 - val_acc: 0.9200\n",
            "Epoch 223/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.1484 - acc: 0.9300 - val_loss: 0.3497 - val_acc: 0.9300\n",
            "Epoch 224/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.1123 - acc: 0.9600 - val_loss: 0.3617 - val_acc: 0.9200\n",
            "Epoch 225/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.1329 - acc: 0.9400 - val_loss: 0.4319 - val_acc: 0.8800\n",
            "Epoch 226/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.1159 - acc: 0.9400 - val_loss: 0.4049 - val_acc: 0.9100\n",
            "Epoch 227/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.1427 - acc: 0.9100 - val_loss: 0.3529 - val_acc: 0.9300\n",
            "Epoch 228/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.1242 - acc: 0.9600 - val_loss: 0.3564 - val_acc: 0.9100\n",
            "Epoch 229/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.1435 - acc: 0.9200 - val_loss: 0.3548 - val_acc: 0.9100\n",
            "Epoch 230/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.1928 - acc: 0.9100 - val_loss: 0.3188 - val_acc: 0.9200\n",
            "Epoch 231/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0952 - acc: 0.9600 - val_loss: 0.3122 - val_acc: 0.9200\n",
            "Epoch 232/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.1426 - acc: 0.9400 - val_loss: 0.3104 - val_acc: 0.9200\n",
            "Epoch 233/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.1476 - acc: 0.9400 - val_loss: 0.3606 - val_acc: 0.9000\n",
            "Epoch 234/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.1504 - acc: 0.9000 - val_loss: 0.3893 - val_acc: 0.9000\n",
            "Epoch 235/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.1052 - acc: 0.9500 - val_loss: 0.3799 - val_acc: 0.9100\n",
            "Epoch 236/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.1117 - acc: 0.9600 - val_loss: 0.3432 - val_acc: 0.9200\n",
            "Epoch 237/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.1874 - acc: 0.9400 - val_loss: 0.3881 - val_acc: 0.9000\n",
            "Epoch 238/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0928 - acc: 0.9600 - val_loss: 0.3893 - val_acc: 0.9200\n",
            "Epoch 239/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.1007 - acc: 0.9600 - val_loss: 0.3807 - val_acc: 0.9200\n",
            "Epoch 240/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0867 - acc: 0.9600 - val_loss: 0.4023 - val_acc: 0.9100\n",
            "Epoch 241/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.1247 - acc: 0.9400 - val_loss: 0.4115 - val_acc: 0.9100\n",
            "Epoch 242/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.1011 - acc: 0.9500 - val_loss: 0.3970 - val_acc: 0.9200\n",
            "Epoch 243/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.1120 - acc: 0.9500 - val_loss: 0.3975 - val_acc: 0.9100\n",
            "Epoch 244/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.1248 - acc: 0.9500 - val_loss: 0.3629 - val_acc: 0.9200\n",
            "Epoch 245/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0993 - acc: 0.9400 - val_loss: 0.3486 - val_acc: 0.9200\n",
            "Epoch 246/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.1026 - acc: 0.9700 - val_loss: 0.4266 - val_acc: 0.9100\n",
            "Epoch 247/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.1240 - acc: 0.9200 - val_loss: 0.3741 - val_acc: 0.9300\n",
            "Epoch 248/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0850 - acc: 0.9700 - val_loss: 0.3892 - val_acc: 0.9100\n",
            "Epoch 249/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0899 - acc: 0.9900 - val_loss: 0.4756 - val_acc: 0.9100\n",
            "Epoch 250/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.1498 - acc: 0.9200 - val_loss: 0.4180 - val_acc: 0.9000\n",
            "Epoch 251/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.1436 - acc: 0.9300 - val_loss: 0.3801 - val_acc: 0.9300\n",
            "Epoch 252/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.1384 - acc: 0.9300 - val_loss: 0.3946 - val_acc: 0.9000\n",
            "Epoch 253/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.1361 - acc: 0.9500 - val_loss: 0.3512 - val_acc: 0.9200\n",
            "Epoch 254/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.1253 - acc: 0.9500 - val_loss: 0.3755 - val_acc: 0.9200\n",
            "Epoch 255/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0981 - acc: 0.9700 - val_loss: 0.4449 - val_acc: 0.9100\n",
            "Epoch 256/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.1787 - acc: 0.9200 - val_loss: 0.3843 - val_acc: 0.9200\n",
            "Epoch 257/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.1013 - acc: 0.9600 - val_loss: 0.3647 - val_acc: 0.9100\n",
            "Epoch 258/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.1048 - acc: 0.9600 - val_loss: 0.3679 - val_acc: 0.9100\n",
            "Epoch 259/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.1394 - acc: 0.9500 - val_loss: 0.3274 - val_acc: 0.9200\n",
            "Epoch 260/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.1165 - acc: 0.9500 - val_loss: 0.3304 - val_acc: 0.9200\n",
            "Epoch 261/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.1189 - acc: 0.9500 - val_loss: 0.3745 - val_acc: 0.9200\n",
            "Epoch 262/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0941 - acc: 0.9600 - val_loss: 0.3705 - val_acc: 0.9200\n",
            "Epoch 263/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0914 - acc: 0.9800 - val_loss: 0.3570 - val_acc: 0.9200\n",
            "Epoch 264/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0753 - acc: 0.9700 - val_loss: 0.3467 - val_acc: 0.9300\n",
            "Epoch 265/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.1556 - acc: 0.9300 - val_loss: 0.3885 - val_acc: 0.9200\n",
            "Epoch 266/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.1193 - acc: 0.9500 - val_loss: 0.4353 - val_acc: 0.9100\n",
            "Epoch 267/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0986 - acc: 0.9700 - val_loss: 0.4169 - val_acc: 0.9200\n",
            "Epoch 268/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0909 - acc: 0.9500 - val_loss: 0.4005 - val_acc: 0.9100\n",
            "Epoch 269/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0986 - acc: 0.9400 - val_loss: 0.4076 - val_acc: 0.9100\n",
            "Epoch 270/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.1232 - acc: 0.9400 - val_loss: 0.4191 - val_acc: 0.9100\n",
            "Epoch 271/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0958 - acc: 0.9400 - val_loss: 0.4050 - val_acc: 0.9100\n",
            "Epoch 272/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0737 - acc: 0.9700 - val_loss: 0.3954 - val_acc: 0.9200\n",
            "Epoch 273/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.1002 - acc: 0.9500 - val_loss: 0.3815 - val_acc: 0.9200\n",
            "Epoch 274/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1032 - acc: 0.9700 - val_loss: 0.4118 - val_acc: 0.9100\n",
            "Epoch 275/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1024 - acc: 0.9700 - val_loss: 0.4149 - val_acc: 0.9100\n",
            "Epoch 276/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.1024 - acc: 0.9700 - val_loss: 0.3745 - val_acc: 0.9100\n",
            "Epoch 277/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0854 - acc: 0.9500 - val_loss: 0.3483 - val_acc: 0.9200\n",
            "Epoch 278/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1203 - acc: 0.9600 - val_loss: 0.3764 - val_acc: 0.9000\n",
            "Epoch 279/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0567 - acc: 0.9900 - val_loss: 0.3856 - val_acc: 0.9000\n",
            "Epoch 280/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.1024 - acc: 0.9700 - val_loss: 0.4009 - val_acc: 0.9000\n",
            "Epoch 281/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0822 - acc: 0.9700 - val_loss: 0.4252 - val_acc: 0.9100\n",
            "Epoch 282/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0926 - acc: 0.9600 - val_loss: 0.4418 - val_acc: 0.9100\n",
            "Epoch 283/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0882 - acc: 0.9700 - val_loss: 0.4270 - val_acc: 0.9200\n",
            "Epoch 284/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.1136 - acc: 0.9200 - val_loss: 0.4480 - val_acc: 0.9200\n",
            "Epoch 285/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.0759 - acc: 0.9700 - val_loss: 0.4485 - val_acc: 0.9100\n",
            "Epoch 286/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1236 - acc: 0.9400 - val_loss: 0.4797 - val_acc: 0.9100\n",
            "Epoch 287/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0923 - acc: 0.9600 - val_loss: 0.5173 - val_acc: 0.9100\n",
            "Epoch 288/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0799 - acc: 0.9700 - val_loss: 0.4553 - val_acc: 0.9100\n",
            "Epoch 289/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.1041 - acc: 0.9400 - val_loss: 0.3854 - val_acc: 0.9300\n",
            "Epoch 290/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.1639 - acc: 0.9200 - val_loss: 0.3957 - val_acc: 0.9100\n",
            "Epoch 291/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.1064 - acc: 0.9500 - val_loss: 0.4225 - val_acc: 0.9100\n",
            "Epoch 292/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.1392 - acc: 0.9300 - val_loss: 0.4175 - val_acc: 0.9100\n",
            "Epoch 293/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.1090 - acc: 0.9400 - val_loss: 0.4541 - val_acc: 0.9100\n",
            "Epoch 294/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0894 - acc: 0.9700 - val_loss: 0.4554 - val_acc: 0.9100\n",
            "Epoch 295/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0604 - acc: 0.9800 - val_loss: 0.4635 - val_acc: 0.9100\n",
            "Epoch 296/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.1225 - acc: 0.9500 - val_loss: 0.4027 - val_acc: 0.9100\n",
            "Epoch 297/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0903 - acc: 0.9500 - val_loss: 0.3737 - val_acc: 0.9100\n",
            "Epoch 298/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.1199 - acc: 0.9400 - val_loss: 0.4633 - val_acc: 0.9100\n",
            "Epoch 299/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.1038 - acc: 0.9600 - val_loss: 0.4181 - val_acc: 0.9100\n",
            "Epoch 300/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.1591 - acc: 0.9400 - val_loss: 0.4264 - val_acc: 0.9100\n",
            "Epoch 301/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.1123 - acc: 0.9400 - val_loss: 0.4018 - val_acc: 0.9100\n",
            "Epoch 302/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0910 - acc: 0.9700 - val_loss: 0.3955 - val_acc: 0.9000\n",
            "Epoch 303/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0766 - acc: 0.9500 - val_loss: 0.4172 - val_acc: 0.9000\n",
            "Epoch 304/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0830 - acc: 0.9700 - val_loss: 0.4173 - val_acc: 0.9000\n",
            "Epoch 305/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.1206 - acc: 0.9600 - val_loss: 0.4228 - val_acc: 0.9100\n",
            "Epoch 306/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0723 - acc: 0.9700 - val_loss: 0.4344 - val_acc: 0.9000\n",
            "Epoch 307/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0776 - acc: 0.9800 - val_loss: 0.4393 - val_acc: 0.9100\n",
            "Epoch 308/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.1022 - acc: 0.9500 - val_loss: 0.4363 - val_acc: 0.9100\n",
            "Epoch 309/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0607 - acc: 0.9800 - val_loss: 0.4394 - val_acc: 0.9100\n",
            "Epoch 310/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0632 - acc: 0.9800 - val_loss: 0.4248 - val_acc: 0.9000\n",
            "Epoch 311/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0901 - acc: 0.9600 - val_loss: 0.4737 - val_acc: 0.9100\n",
            "Epoch 312/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.1064 - acc: 0.9400 - val_loss: 0.5031 - val_acc: 0.9100\n",
            "Epoch 313/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0944 - acc: 0.9400 - val_loss: 0.4224 - val_acc: 0.9100\n",
            "Epoch 314/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.1117 - acc: 0.9500 - val_loss: 0.4443 - val_acc: 0.9000\n",
            "Epoch 315/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0857 - acc: 0.9600 - val_loss: 0.4982 - val_acc: 0.9100\n",
            "Epoch 316/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0814 - acc: 0.9500 - val_loss: 0.4506 - val_acc: 0.9100\n",
            "Epoch 317/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.1246 - acc: 0.9300 - val_loss: 0.4474 - val_acc: 0.9200\n",
            "Epoch 318/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0961 - acc: 0.9400 - val_loss: 0.4008 - val_acc: 0.9200\n",
            "Epoch 319/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.1111 - acc: 0.9400 - val_loss: 0.4020 - val_acc: 0.9100\n",
            "Epoch 320/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.1012 - acc: 0.9600 - val_loss: 0.5249 - val_acc: 0.9100\n",
            "Epoch 321/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0934 - acc: 0.9600 - val_loss: 0.4647 - val_acc: 0.9100\n",
            "Epoch 322/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0663 - acc: 0.9600 - val_loss: 0.4289 - val_acc: 0.9100\n",
            "Epoch 323/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0599 - acc: 1.0000 - val_loss: 0.4181 - val_acc: 0.9100\n",
            "Epoch 324/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0899 - acc: 0.9800 - val_loss: 0.3908 - val_acc: 0.9200\n",
            "Epoch 325/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.1678 - acc: 0.9300 - val_loss: 0.4182 - val_acc: 0.9100\n",
            "Epoch 326/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0764 - acc: 0.9600 - val_loss: 0.4127 - val_acc: 0.9100\n",
            "Epoch 327/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0976 - acc: 0.9600 - val_loss: 0.4114 - val_acc: 0.9000\n",
            "Epoch 328/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0910 - acc: 0.9500 - val_loss: 0.4477 - val_acc: 0.9200\n",
            "Epoch 329/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0994 - acc: 0.9500 - val_loss: 0.4817 - val_acc: 0.9100\n",
            "Epoch 330/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.1129 - acc: 0.9700 - val_loss: 0.4363 - val_acc: 0.9100\n",
            "Epoch 331/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0902 - acc: 0.9700 - val_loss: 0.4172 - val_acc: 0.9100\n",
            "Epoch 332/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0955 - acc: 0.9400 - val_loss: 0.4644 - val_acc: 0.9000\n",
            "Epoch 333/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0893 - acc: 0.9500 - val_loss: 0.4490 - val_acc: 0.9200\n",
            "Epoch 334/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0997 - acc: 0.9600 - val_loss: 0.4314 - val_acc: 0.9200\n",
            "Epoch 335/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.1143 - acc: 0.9600 - val_loss: 0.4315 - val_acc: 0.9200\n",
            "Epoch 336/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0788 - acc: 0.9500 - val_loss: 0.4432 - val_acc: 0.9100\n",
            "Epoch 337/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0869 - acc: 0.9600 - val_loss: 0.4854 - val_acc: 0.9100\n",
            "Epoch 338/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0737 - acc: 0.9900 - val_loss: 0.4706 - val_acc: 0.9100\n",
            "Epoch 339/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0690 - acc: 0.9700 - val_loss: 0.4434 - val_acc: 0.9200\n",
            "Epoch 340/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0735 - acc: 0.9700 - val_loss: 0.4475 - val_acc: 0.9100\n",
            "Epoch 341/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0484 - acc: 0.9900 - val_loss: 0.4624 - val_acc: 0.9200\n",
            "Epoch 342/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0974 - acc: 0.9700 - val_loss: 0.4776 - val_acc: 0.9100\n",
            "Epoch 343/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0809 - acc: 0.9600 - val_loss: 0.5647 - val_acc: 0.9100\n",
            "Epoch 344/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0721 - acc: 0.9800 - val_loss: 0.4746 - val_acc: 0.9200\n",
            "Epoch 345/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.1246 - acc: 0.9500 - val_loss: 0.4804 - val_acc: 0.9000\n",
            "Epoch 346/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0611 - acc: 0.9800 - val_loss: 0.5070 - val_acc: 0.9000\n",
            "Epoch 347/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.1099 - acc: 0.9600 - val_loss: 0.4437 - val_acc: 0.9100\n",
            "Epoch 348/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0641 - acc: 0.9800 - val_loss: 0.4669 - val_acc: 0.9100\n",
            "Epoch 349/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0823 - acc: 0.9600 - val_loss: 0.5375 - val_acc: 0.9100\n",
            "Epoch 350/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.1514 - acc: 0.9300 - val_loss: 0.5292 - val_acc: 0.9100\n",
            "Epoch 351/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0787 - acc: 0.9500 - val_loss: 0.4479 - val_acc: 0.9100\n",
            "Epoch 352/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0643 - acc: 0.9700 - val_loss: 0.4428 - val_acc: 0.9200\n",
            "Epoch 353/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0710 - acc: 0.9800 - val_loss: 0.4280 - val_acc: 0.9300\n",
            "Epoch 354/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.1139 - acc: 0.9500 - val_loss: 0.4518 - val_acc: 0.9300\n",
            "Epoch 355/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0696 - acc: 0.9700 - val_loss: 0.5440 - val_acc: 0.9100\n",
            "Epoch 356/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.1024 - acc: 0.9600 - val_loss: 0.4884 - val_acc: 0.9000\n",
            "Epoch 357/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.1266 - acc: 0.9400 - val_loss: 0.4196 - val_acc: 0.9000\n",
            "Epoch 358/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0660 - acc: 0.9900 - val_loss: 0.4104 - val_acc: 0.9100\n",
            "Epoch 359/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0850 - acc: 0.9800 - val_loss: 0.4558 - val_acc: 0.9100\n",
            "Epoch 360/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0410 - acc: 1.0000 - val_loss: 0.4556 - val_acc: 0.9000\n",
            "Epoch 361/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0607 - acc: 0.9700 - val_loss: 0.4881 - val_acc: 0.9100\n",
            "Epoch 362/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0708 - acc: 0.9600 - val_loss: 0.5293 - val_acc: 0.9100\n",
            "Epoch 363/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0746 - acc: 0.9800 - val_loss: 0.4909 - val_acc: 0.9000\n",
            "Epoch 364/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0806 - acc: 0.9500 - val_loss: 0.4880 - val_acc: 0.9100\n",
            "Epoch 365/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0551 - acc: 0.9700 - val_loss: 0.5227 - val_acc: 0.9100\n",
            "Epoch 366/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0528 - acc: 0.9800 - val_loss: 0.5314 - val_acc: 0.9100\n",
            "Epoch 367/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0569 - acc: 0.9800 - val_loss: 0.5009 - val_acc: 0.9000\n",
            "Epoch 368/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.1036 - acc: 0.9500 - val_loss: 0.5512 - val_acc: 0.9100\n",
            "Epoch 369/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0963 - acc: 0.9600 - val_loss: 0.5565 - val_acc: 0.9100\n",
            "Epoch 370/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0764 - acc: 0.9600 - val_loss: 0.4624 - val_acc: 0.9200\n",
            "Epoch 371/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.1243 - acc: 0.9700 - val_loss: 0.4326 - val_acc: 0.9200\n",
            "Epoch 372/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0720 - acc: 0.9700 - val_loss: 0.5027 - val_acc: 0.9100\n",
            "Epoch 373/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0808 - acc: 0.9500 - val_loss: 0.5235 - val_acc: 0.9100\n",
            "Epoch 374/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.1032 - acc: 0.9300 - val_loss: 0.5060 - val_acc: 0.9100\n",
            "Epoch 375/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0726 - acc: 0.9800 - val_loss: 0.4978 - val_acc: 0.9100\n",
            "Epoch 376/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0899 - acc: 0.9600 - val_loss: 0.4916 - val_acc: 0.9100\n",
            "Epoch 377/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0630 - acc: 0.9800 - val_loss: 0.4423 - val_acc: 0.9100\n",
            "Epoch 378/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0604 - acc: 0.9800 - val_loss: 0.4672 - val_acc: 0.9100\n",
            "Epoch 379/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0435 - acc: 1.0000 - val_loss: 0.4742 - val_acc: 0.9100\n",
            "Epoch 380/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0528 - acc: 0.9800 - val_loss: 0.4906 - val_acc: 0.9000\n",
            "Epoch 381/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.0780 - acc: 0.9900 - val_loss: 0.5526 - val_acc: 0.9100\n",
            "Epoch 382/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0796 - acc: 0.9700 - val_loss: 0.5711 - val_acc: 0.9100\n",
            "Epoch 383/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0449 - acc: 0.9800 - val_loss: 0.5444 - val_acc: 0.9100\n",
            "Epoch 384/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0359 - acc: 1.0000 - val_loss: 0.5343 - val_acc: 0.9100\n",
            "Epoch 385/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0716 - acc: 0.9700 - val_loss: 0.5340 - val_acc: 0.9100\n",
            "Epoch 386/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0618 - acc: 0.9800 - val_loss: 0.5085 - val_acc: 0.9100\n",
            "Epoch 387/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.0589 - acc: 0.9800 - val_loss: 0.5379 - val_acc: 0.9100\n",
            "Epoch 388/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.0606 - acc: 0.9700 - val_loss: 0.6220 - val_acc: 0.9100\n",
            "Epoch 389/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.0476 - acc: 0.9900 - val_loss: 0.6693 - val_acc: 0.9100\n",
            "Epoch 390/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.0369 - acc: 0.9900 - val_loss: 0.6117 - val_acc: 0.9100\n",
            "Epoch 391/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0534 - acc: 0.9800 - val_loss: 0.5877 - val_acc: 0.9100\n",
            "Epoch 392/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.1045 - acc: 0.9600 - val_loss: 0.5117 - val_acc: 0.9000\n",
            "Epoch 393/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0503 - acc: 0.9700 - val_loss: 0.5252 - val_acc: 0.9100\n",
            "Epoch 394/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.1122 - acc: 0.9600 - val_loss: 0.4515 - val_acc: 0.9200\n",
            "Epoch 395/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0743 - acc: 0.9800 - val_loss: 0.4506 - val_acc: 0.9100\n",
            "Epoch 396/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0905 - acc: 0.9500 - val_loss: 0.4586 - val_acc: 0.9000\n",
            "Epoch 397/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0479 - acc: 0.9900 - val_loss: 0.4621 - val_acc: 0.9200\n",
            "Epoch 398/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0570 - acc: 0.9700 - val_loss: 0.4879 - val_acc: 0.9200\n",
            "Epoch 399/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0450 - acc: 0.9900 - val_loss: 0.5233 - val_acc: 0.9100\n",
            "Epoch 400/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.1359 - acc: 0.9600 - val_loss: 0.6430 - val_acc: 0.9000\n",
            "Epoch 401/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.1273 - acc: 0.9700 - val_loss: 0.5865 - val_acc: 0.9100\n",
            "Epoch 402/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.0545 - acc: 0.9800 - val_loss: 0.4980 - val_acc: 0.9000\n",
            "Epoch 403/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0850 - acc: 0.9600 - val_loss: 0.5331 - val_acc: 0.9100\n",
            "Epoch 404/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0844 - acc: 0.9500 - val_loss: 0.4763 - val_acc: 0.9100\n",
            "Epoch 405/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0646 - acc: 0.9700 - val_loss: 0.4212 - val_acc: 0.9200\n",
            "Epoch 406/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.1443 - acc: 0.9500 - val_loss: 0.5127 - val_acc: 0.9000\n",
            "Epoch 407/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0820 - acc: 0.9700 - val_loss: 0.6277 - val_acc: 0.9100\n",
            "Epoch 408/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.1078 - acc: 0.9700 - val_loss: 0.5067 - val_acc: 0.9000\n",
            "Epoch 409/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.0491 - acc: 0.9800 - val_loss: 0.4712 - val_acc: 0.9200\n",
            "Epoch 410/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.1176 - acc: 0.9600 - val_loss: 0.4624 - val_acc: 0.9300\n",
            "Epoch 411/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.1239 - acc: 0.9400 - val_loss: 0.5216 - val_acc: 0.9100\n",
            "Epoch 412/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0672 - acc: 0.9900 - val_loss: 0.6283 - val_acc: 0.9000\n",
            "Epoch 413/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0870 - acc: 0.9700 - val_loss: 0.5770 - val_acc: 0.9100\n",
            "Epoch 414/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0988 - acc: 0.9500 - val_loss: 0.4737 - val_acc: 0.9200\n",
            "Epoch 415/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0997 - acc: 0.9700 - val_loss: 0.4623 - val_acc: 0.9000\n",
            "Epoch 416/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.0953 - acc: 0.9600 - val_loss: 0.4939 - val_acc: 0.8800\n",
            "Epoch 417/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0887 - acc: 0.9400 - val_loss: 0.4830 - val_acc: 0.9100\n",
            "Epoch 418/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.1052 - acc: 0.9500 - val_loss: 0.4768 - val_acc: 0.9200\n",
            "Epoch 419/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0699 - acc: 0.9900 - val_loss: 0.4975 - val_acc: 0.9000\n",
            "Epoch 420/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0855 - acc: 0.9600 - val_loss: 0.5064 - val_acc: 0.9000\n",
            "Epoch 421/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0393 - acc: 1.0000 - val_loss: 0.4995 - val_acc: 0.9000\n",
            "Epoch 422/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.1083 - acc: 0.9500 - val_loss: 0.4629 - val_acc: 0.9100\n",
            "Epoch 423/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0857 - acc: 0.9700 - val_loss: 0.5664 - val_acc: 0.9000\n",
            "Epoch 424/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.0762 - acc: 0.9700 - val_loss: 0.5476 - val_acc: 0.9000\n",
            "Epoch 425/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0570 - acc: 0.9800 - val_loss: 0.4791 - val_acc: 0.9000\n",
            "Epoch 426/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0614 - acc: 0.9700 - val_loss: 0.5199 - val_acc: 0.9100\n",
            "Epoch 427/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0427 - acc: 0.9900 - val_loss: 0.5326 - val_acc: 0.9100\n",
            "Epoch 428/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0652 - acc: 0.9700 - val_loss: 0.5247 - val_acc: 0.9100\n",
            "Epoch 429/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0467 - acc: 0.9800 - val_loss: 0.5151 - val_acc: 0.9100\n",
            "Epoch 430/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0574 - acc: 0.9900 - val_loss: 0.4992 - val_acc: 0.9200\n",
            "Epoch 431/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0837 - acc: 0.9700 - val_loss: 0.5198 - val_acc: 0.9100\n",
            "Epoch 432/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0748 - acc: 0.9600 - val_loss: 0.5610 - val_acc: 0.9100\n",
            "Epoch 433/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.1116 - acc: 0.9600 - val_loss: 0.5148 - val_acc: 0.9100\n",
            "Epoch 434/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0582 - acc: 0.9800 - val_loss: 0.6055 - val_acc: 0.9100\n",
            "Epoch 435/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0624 - acc: 0.9600 - val_loss: 0.6668 - val_acc: 0.9100\n",
            "Epoch 436/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0534 - acc: 0.9700 - val_loss: 0.5972 - val_acc: 0.9100\n",
            "Epoch 437/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0643 - acc: 0.9700 - val_loss: 0.5874 - val_acc: 0.9100\n",
            "Epoch 438/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0727 - acc: 0.9600 - val_loss: 0.5427 - val_acc: 0.8900\n",
            "Epoch 439/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0509 - acc: 0.9800 - val_loss: 0.5161 - val_acc: 0.9000\n",
            "Epoch 440/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0667 - acc: 0.9800 - val_loss: 0.5635 - val_acc: 0.9100\n",
            "Epoch 441/500\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.0757 - acc: 0.9800 - val_loss: 0.5440 - val_acc: 0.9100\n",
            "Epoch 442/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.1003 - acc: 0.9600 - val_loss: 0.5612 - val_acc: 0.9100\n",
            "Epoch 443/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0382 - acc: 1.0000 - val_loss: 0.5692 - val_acc: 0.9100\n",
            "Epoch 444/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0745 - acc: 0.9700 - val_loss: 0.6172 - val_acc: 0.9100\n",
            "Epoch 445/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0741 - acc: 0.9600 - val_loss: 0.5759 - val_acc: 0.9100\n",
            "Epoch 446/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0454 - acc: 0.9800 - val_loss: 0.5210 - val_acc: 0.9100\n",
            "Epoch 447/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0739 - acc: 0.9700 - val_loss: 0.5537 - val_acc: 0.9100\n",
            "Epoch 448/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.1140 - acc: 0.9500 - val_loss: 0.6338 - val_acc: 0.9100\n",
            "Epoch 449/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0475 - acc: 0.9900 - val_loss: 0.6228 - val_acc: 0.9100\n",
            "Epoch 450/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0442 - acc: 0.9800 - val_loss: 0.5940 - val_acc: 0.9100\n",
            "Epoch 451/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0543 - acc: 0.9900 - val_loss: 0.5671 - val_acc: 0.9000\n",
            "Epoch 452/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0457 - acc: 0.9900 - val_loss: 0.5996 - val_acc: 0.9100\n",
            "Epoch 453/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0432 - acc: 0.9700 - val_loss: 0.6020 - val_acc: 0.9100\n",
            "Epoch 454/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0363 - acc: 0.9900 - val_loss: 0.5974 - val_acc: 0.9100\n",
            "Epoch 455/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0849 - acc: 0.9600 - val_loss: 0.6324 - val_acc: 0.9100\n",
            "Epoch 456/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0467 - acc: 0.9800 - val_loss: 0.5913 - val_acc: 0.9100\n",
            "Epoch 457/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0948 - acc: 0.9600 - val_loss: 0.6844 - val_acc: 0.9000\n",
            "Epoch 458/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0519 - acc: 0.9900 - val_loss: 0.6912 - val_acc: 0.9000\n",
            "Epoch 459/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0529 - acc: 0.9800 - val_loss: 0.5925 - val_acc: 0.9100\n",
            "Epoch 460/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0872 - acc: 0.9700 - val_loss: 0.5404 - val_acc: 0.9100\n",
            "Epoch 461/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0393 - acc: 0.9900 - val_loss: 0.5751 - val_acc: 0.9100\n",
            "Epoch 462/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0374 - acc: 1.0000 - val_loss: 0.6138 - val_acc: 0.9100\n",
            "Epoch 463/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0629 - acc: 0.9700 - val_loss: 0.5504 - val_acc: 0.9100\n",
            "Epoch 464/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0689 - acc: 0.9600 - val_loss: 0.5162 - val_acc: 0.9300\n",
            "Epoch 465/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0985 - acc: 0.9600 - val_loss: 0.5442 - val_acc: 0.9100\n",
            "Epoch 466/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.1436 - acc: 0.9700 - val_loss: 0.5432 - val_acc: 0.9100\n",
            "Epoch 467/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0789 - acc: 0.9700 - val_loss: 0.4972 - val_acc: 0.9100\n",
            "Epoch 468/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0461 - acc: 0.9900 - val_loss: 0.5100 - val_acc: 0.9200\n",
            "Epoch 469/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0881 - acc: 0.9500 - val_loss: 0.5198 - val_acc: 0.9100\n",
            "Epoch 470/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0634 - acc: 0.9800 - val_loss: 0.5145 - val_acc: 0.9100\n",
            "Epoch 471/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0544 - acc: 0.9800 - val_loss: 0.5517 - val_acc: 0.9100\n",
            "Epoch 472/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0233 - acc: 1.0000 - val_loss: 0.5835 - val_acc: 0.9100\n",
            "Epoch 473/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0335 - acc: 1.0000 - val_loss: 0.5765 - val_acc: 0.9100\n",
            "Epoch 474/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0459 - acc: 0.9800 - val_loss: 0.5662 - val_acc: 0.9100\n",
            "Epoch 475/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0354 - acc: 0.9900 - val_loss: 0.5555 - val_acc: 0.9200\n",
            "Epoch 476/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0465 - acc: 0.9800 - val_loss: 0.5799 - val_acc: 0.9100\n",
            "Epoch 477/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0440 - acc: 0.9800 - val_loss: 0.5816 - val_acc: 0.9100\n",
            "Epoch 478/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0418 - acc: 0.9900 - val_loss: 0.5662 - val_acc: 0.9200\n",
            "Epoch 479/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0461 - acc: 0.9900 - val_loss: 0.6674 - val_acc: 0.9100\n",
            "Epoch 480/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0525 - acc: 0.9900 - val_loss: 0.6535 - val_acc: 0.9000\n",
            "Epoch 481/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0432 - acc: 0.9800 - val_loss: 0.6428 - val_acc: 0.9000\n",
            "Epoch 482/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.1239 - acc: 0.9500 - val_loss: 0.7520 - val_acc: 0.8900\n",
            "Epoch 483/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0947 - acc: 0.9400 - val_loss: 0.6978 - val_acc: 0.9100\n",
            "Epoch 484/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0792 - acc: 0.9500 - val_loss: 0.6354 - val_acc: 0.9100\n",
            "Epoch 485/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0581 - acc: 0.9700 - val_loss: 0.6387 - val_acc: 0.9100\n",
            "Epoch 486/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.1016 - acc: 0.9700 - val_loss: 0.6331 - val_acc: 0.9000\n",
            "Epoch 487/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0398 - acc: 0.9700 - val_loss: 0.5976 - val_acc: 0.9100\n",
            "Epoch 488/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0597 - acc: 0.9700 - val_loss: 0.5988 - val_acc: 0.9100\n",
            "Epoch 489/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0264 - acc: 1.0000 - val_loss: 0.6018 - val_acc: 0.9100\n",
            "Epoch 490/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.1128 - acc: 0.9600 - val_loss: 0.5326 - val_acc: 0.9000\n",
            "Epoch 491/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0565 - acc: 0.9700 - val_loss: 0.5461 - val_acc: 0.8900\n",
            "Epoch 492/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0278 - acc: 1.0000 - val_loss: 0.5511 - val_acc: 0.9000\n",
            "Epoch 493/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0171 - acc: 1.0000 - val_loss: 0.5546 - val_acc: 0.9000\n",
            "Epoch 494/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0272 - acc: 0.9900 - val_loss: 0.5651 - val_acc: 0.9000\n",
            "Epoch 495/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0486 - acc: 0.9700 - val_loss: 0.5688 - val_acc: 0.9000\n",
            "Epoch 496/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0392 - acc: 0.9900 - val_loss: 0.5534 - val_acc: 0.9000\n",
            "Epoch 497/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0591 - acc: 0.9700 - val_loss: 0.5802 - val_acc: 0.9000\n",
            "Epoch 498/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0482 - acc: 0.9900 - val_loss: 0.6343 - val_acc: 0.9100\n",
            "Epoch 499/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0576 - acc: 0.9700 - val_loss: 0.6397 - val_acc: 0.9100\n",
            "Epoch 500/500\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0270 - acc: 1.0000 - val_loss: 0.6751 - val_acc: 0.9100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sJKwraSfVug8",
        "colab_type": "text"
      },
      "source": [
        "#RP 31x31"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PAeu_tBxVgz5",
        "colab_type": "code",
        "outputId": "48b539e6-6a10-4763-c817-4a27ff513b41",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "print(max(history.history['val_acc']))\n",
        "print(max(history.history['acc']))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.95\n",
            "1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NatB9qkQVg4G",
        "colab_type": "code",
        "outputId": "3ffe41df-f031-4991-f568-10d79651fbb4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nUZIcFQSKoihJjgoCRVGUJOf/AVlbT0IKlYn7AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SetcEz4CVgw-",
        "colab_type": "code",
        "outputId": "f0867335-16c1-42bb-e437-16bbcdf0600d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "plt.title('Model Accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nMzPr6P8BcUvqlClhXokAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hJNfStj6bOBy",
        "colab_type": "text"
      },
      "source": [
        "# seires2GAF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rTsPuhUAcABI",
        "colab_type": "code",
        "outputId": "1df9a84c-eff5-42ba-b094-26d8d79c0fb8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\n",
        "#PAA function -- dimensionality reduction\n",
        "def paa(series, now, opw):\n",
        "    if now == None:\n",
        "        now = int(len(series) / opw)\n",
        "    if opw == None:\n",
        "        opw = int(len(series) / now)\n",
        "    return [sum(series[i * opw : (i + 1) * opw]) / float(opw) for i in range(now)]\n",
        "\n",
        "#Rescale data into [0,1]\n",
        "def rescale(serie):\n",
        "    maxval = max(serie)\n",
        "    minval = min(serie)\n",
        "    gap = float(maxval-minval)\n",
        "    return [(each-minval)/gap for each in serie]\n",
        "#Rescale data into [-1,1]    \n",
        "def rescaleminus(serie):\n",
        "    maxval = max(serie)\n",
        "    minval = min(serie)\n",
        "    gap = float(maxval-minval)\n",
        "    return [(each-minval)/gap*2-1 for each in serie]\n",
        "\n",
        "    \n",
        "#################################\n",
        "###Define the parameters here####\n",
        "#################################\n",
        "\n",
        "datafiles = ['ECG200_TRAIN', 'ECG200_TEST',] # Data file name\n",
        "size = [31]  # PAA size\n",
        "GAF_type = 'GADF' # GAF type: GASF, GADF\n",
        "save_PAA = True # Save the GAF with or without dimension reduction by PAA: True, False\n",
        "rescale_type = 'Zero' # Rescale the data into [0,1] or [-1,1]: Zero, Minusone \n",
        "polarvectors= [0,0]\n",
        "\n",
        "\n",
        "for i in range(len(datafiles)):\n",
        "    fn = datafiles[i]\n",
        "    for s in size:  \n",
        "        print('read file: {}, size: {}, GAF type: {}, rescale_type: {}'.format(datafiles[i], s, GAF_type, rescale_type))\n",
        "        #read data\n",
        "        raw = open('/content/drive/Shared drives/AML Project Fall 2019/ECG200/'+fn+'.tsv').readlines()\n",
        "        raw = [list(map(float, each.strip().split('\\t'))) for each in raw]\n",
        "        length = len(raw[0])-1\n",
        "        \n",
        "        print('format data')\n",
        "        label = []\n",
        "        image = []\n",
        "        paaimage = []\n",
        "        #patchimage = []\n",
        "        matmatrix = []\n",
        "        fullmatrix = []\n",
        "        data1 =[]  #time series data collection\n",
        "        paadata1 = [] #after paa time series data collection\n",
        "        for each in raw:\n",
        "            label.append(each[0])\n",
        "            if rescale_type == 'Zero':\n",
        "                std_data = rescale(each[1:])\n",
        "            elif rescale_type == 'Minusone':\n",
        "                std_data = rescaleminus(each[1:])\n",
        "            else:\n",
        "                sys.exit('Unknown rescaling type!')\n",
        "            paalistcos = paa(std_data,s,None)            \n",
        "            datacos = np.array(std_data)\n",
        "            data1.append(datacos)\n",
        "            datasin = np.sqrt(1-np.array(std_data)**2)\n",
        "\n",
        "            paalistcos = np.array(paalistcos)\n",
        "            paadata1.append(paalistcos)\n",
        "            paalistsin = np.sqrt(1-paalistcos**2)\n",
        "            \n",
        "            datacos = np.matrix(datacos)\n",
        "            datasin = np.matrix(datasin)            \n",
        "            \n",
        "            paalistcos = np.matrix(paalistcos)\n",
        "            paalistsin = np.matrix(paalistsin)            \n",
        "            if GAF_type == 'GASF':\n",
        "                paamatrix = paalistcos.T*paalistcos-paalistsin.T*paalistsin\n",
        "                matrix = np.array(datacos.T*datacos-datasin.T*datasin)\n",
        "            elif GAF_type == 'GADF':\n",
        "                paamatrix = paalistsin.T*paalistcos-paalistcos.T*paalistsin\n",
        "                matrix = np.array(datasin.T*datacos - datacos.T*datasin)\n",
        "            else:\n",
        "                sys.exit('Unknown GAF type!')\n",
        "            paamatrix = np.array(paamatrix)\n",
        "            image.append(matrix)\n",
        "            paaimage.append(np.array(paamatrix))\n",
        "            matmatrix.append(paamatrix.flatten())\n",
        "            fullmatrix.append(matrix.flatten())\n",
        "    \n",
        "        label = np.asarray(label)\n",
        "        image = np.asarray(image)\n",
        "        paaimage = np.asarray(paaimage)\n",
        "        matmatrix = np.asarray(matmatrix)\n",
        "        fullmatrix = np.asarray(fullmatrix)\n",
        "\n",
        "        if save_PAA == True:        \n",
        "            finalmatrix = matmatrix\n",
        "        else:\n",
        "            finalmatrix = fullmatrix\n",
        "        polarvectors[i]= (finalmatrix, label)\n",
        "\n",
        "k=0\n",
        "fig = plt.figure()\n",
        "ax = plt.axes()\n",
        "ax.plot(data1[k]);\n",
        "\n",
        "fig = plt.figure()\n",
        "ax = plt.axes()\n",
        "ax.plot(paadata1[k]);\n",
        "\n",
        "# polar coordinates\n",
        "k=0;r = np.array(range(1,length+1));r=r/100.0;theta = np.array(rescale(raw[k][1:]))*2*np.pi;plt.figure();ax = plt.subplot(polar=True);ax.set_title('Polar Coordinate',y=1.08);ax.plot(theta, r, color='r', linewidth=3);plt.show()\n",
        "## draw large image and paa image\n",
        "k = 0;plt.figure();plt.suptitle(datafiles[i]+'_index_'+str(k)+'_label_'+str(label[k]));ax1 = plt.subplot(121);plt.title(GAF_type + 'without PAA');plt.imshow(image[k]);divider = make_axes_locatable(ax1);cax = divider.append_axes(\"right\", size=\"5%\", pad=0.2);plt.colorbar(cax = cax);ax2 = plt.subplot(122);plt.title(GAF_type + 'with PAA');plt.imshow(paaimage[k]);divider = make_axes_locatable(ax2);cax = divider.append_axes(\"right\", size=\"5%\", pad=0.2);plt.colorbar(cax = cax);plt.tight_layout()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "read file: ECG200_TRAIN, size: 31, GAF type: GADF, rescale_type: Zero\n",
            "format data\n",
            "read file: ECG200_TEST, size: 31, GAF type: GADF, rescale_type: Zero\n",
            "format data\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nhAZ0pZSyiP8PYbYHCM0Jx9MAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nUiHi/wMZYImoc7q3wwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAARUAAAEcCAYAAADp4SAqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAADoCAYAAAC6nXAYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nKtE2qIaGhoaGU4n/DwDTl9mt817sAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 4 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZsJ8Fajjc_N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ECG200_TRAIN_polar=polarvectors[0]\n",
        "ECG200_TEST_polar=polarvectors[1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ExdHtKsYgZ9o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_img= ECG200_TRAIN_polar[0]\n",
        "test_img= ECG200_TEST_polar[0]\n",
        "train_labels= ECG200_TRAIN_polar[1]\n",
        "test_labels= ECG200_TEST_polar[1]\n",
        "for i in range(ECG200_TRAIN_polar[0].shape[0]):\n",
        "  if train_labels[i] == -1:\n",
        "    train_labels[i]=0\n",
        "for i in range(ECG200_TEST_polar[0].shape[0]):\n",
        "  if test_labels[i] == -1:\n",
        "    test_labels[i]=0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-CCzdmb0hX9G",
        "colab_type": "code",
        "outputId": "49edf740-67c8-46f3-abf8-6bff78bca1f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#Convolution Neural Network\n",
        "\n",
        "from __future__ import print_function\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras import backend as K\n",
        "from keras.utils import plot_model\n",
        "from keras import optimizers\n",
        "\n",
        "size= 32\n",
        "batch_size =10\n",
        "num_classes = 2\n",
        "epochs = 4500\n",
        "\n",
        "# input image dimensions\n",
        "img_rows, img_cols = size-1, size-1\n",
        "(x_train, y_train), (x_test, y_test) = (train_img, train_labels), (test_img, test_labels)\n",
        "if K.image_data_format() == 'channels_first':\n",
        "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
        "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
        "    input_shape = (1, img_rows, img_cols)\n",
        "else:\n",
        "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
        "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
        "    input_shape = (img_rows, img_cols, 1)\n",
        "  \n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "\n",
        "# convert class vectors to binary class matrices\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, kernel_size=(3, 3),\n",
        "                 activation='relu',\n",
        "                 input_shape=input_shape))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "sgd = optimizers.SGD(lr=0.001, decay=1e-6, momentum=0.9, nesterov=True)\n",
        "model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "              optimizer=sgd,\n",
        "              metrics=['accuracy'])\n",
        "train_loss = []\n",
        "test_loss = []\n",
        "for i in range(1):\n",
        "  history=model.fit(x_train, y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          verbose=1,\n",
        "          validation_data=(x_test, y_test))\n",
        "  score_train=model.evaluate(x_train,y_train,verbose=0)\n",
        "  score = model.evaluate(x_test, y_test, verbose=0)\n",
        "  train_loss.append(score_train[0])\n",
        "  #print(score_train[0])\n",
        "  test_loss.append(score[0])\n",
        "  #print(score[0])\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "x_train shape: (100, 31, 31, 1)\n",
            "100 train samples\n",
            "100 test samples\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Train on 100 samples, validate on 100 samples\n",
            "Epoch 1/4500\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "100/100 [==============================] - 8s 75ms/step - loss: 0.6890 - acc: 0.6200 - val_loss: 0.6846 - val_acc: 0.6400\n",
            "Epoch 2/4500\n",
            "100/100 [==============================] - 0s 540us/step - loss: 0.6738 - acc: 0.6900 - val_loss: 0.6707 - val_acc: 0.6400\n",
            "Epoch 3/4500\n",
            "100/100 [==============================] - 0s 521us/step - loss: 0.6550 - acc: 0.6900 - val_loss: 0.6589 - val_acc: 0.6400\n",
            "Epoch 4/4500\n",
            "100/100 [==============================] - 0s 569us/step - loss: 0.6355 - acc: 0.6900 - val_loss: 0.6537 - val_acc: 0.6400\n",
            "Epoch 5/4500\n",
            "100/100 [==============================] - 0s 570us/step - loss: 0.6253 - acc: 0.6900 - val_loss: 0.6545 - val_acc: 0.6400\n",
            "Epoch 6/4500\n",
            "100/100 [==============================] - 0s 553us/step - loss: 0.6209 - acc: 0.6900 - val_loss: 0.6579 - val_acc: 0.6400\n",
            "Epoch 7/4500\n",
            "100/100 [==============================] - 0s 515us/step - loss: 0.6198 - acc: 0.6900 - val_loss: 0.6582 - val_acc: 0.6400\n",
            "Epoch 8/4500\n",
            "100/100 [==============================] - 0s 502us/step - loss: 0.6191 - acc: 0.6900 - val_loss: 0.6596 - val_acc: 0.6400\n",
            "Epoch 9/4500\n",
            "100/100 [==============================] - 0s 501us/step - loss: 0.6223 - acc: 0.6900 - val_loss: 0.6630 - val_acc: 0.6400\n",
            "Epoch 10/4500\n",
            "100/100 [==============================] - 0s 503us/step - loss: 0.6211 - acc: 0.6900 - val_loss: 0.6583 - val_acc: 0.6400\n",
            "Epoch 11/4500\n",
            "100/100 [==============================] - 0s 532us/step - loss: 0.6210 - acc: 0.6900 - val_loss: 0.6570 - val_acc: 0.6400\n",
            "Epoch 12/4500\n",
            "100/100 [==============================] - 0s 500us/step - loss: 0.6203 - acc: 0.6900 - val_loss: 0.6593 - val_acc: 0.6400\n",
            "Epoch 13/4500\n",
            "100/100 [==============================] - 0s 508us/step - loss: 0.6217 - acc: 0.6900 - val_loss: 0.6570 - val_acc: 0.6400\n",
            "Epoch 14/4500\n",
            "100/100 [==============================] - 0s 495us/step - loss: 0.6193 - acc: 0.6900 - val_loss: 0.6593 - val_acc: 0.6400\n",
            "Epoch 15/4500\n",
            "100/100 [==============================] - 0s 633us/step - loss: 0.6207 - acc: 0.6900 - val_loss: 0.6583 - val_acc: 0.6400\n",
            "Epoch 16/4500\n",
            "100/100 [==============================] - 0s 516us/step - loss: 0.6198 - acc: 0.6900 - val_loss: 0.6592 - val_acc: 0.6400\n",
            "Epoch 17/4500\n",
            "100/100 [==============================] - 0s 589us/step - loss: 0.6211 - acc: 0.6900 - val_loss: 0.6620 - val_acc: 0.6400\n",
            "Epoch 18/4500\n",
            "100/100 [==============================] - 0s 586us/step - loss: 0.6199 - acc: 0.6900 - val_loss: 0.6596 - val_acc: 0.6400\n",
            "Epoch 19/4500\n",
            "100/100 [==============================] - 0s 531us/step - loss: 0.6211 - acc: 0.6900 - val_loss: 0.6570 - val_acc: 0.6400\n",
            "Epoch 20/4500\n",
            "100/100 [==============================] - 0s 608us/step - loss: 0.6200 - acc: 0.6900 - val_loss: 0.6574 - val_acc: 0.6400\n",
            "Epoch 21/4500\n",
            "100/100 [==============================] - 0s 555us/step - loss: 0.6216 - acc: 0.6900 - val_loss: 0.6610 - val_acc: 0.6400\n",
            "Epoch 22/4500\n",
            "100/100 [==============================] - 0s 525us/step - loss: 0.6215 - acc: 0.6900 - val_loss: 0.6590 - val_acc: 0.6400\n",
            "Epoch 23/4500\n",
            "100/100 [==============================] - 0s 524us/step - loss: 0.6217 - acc: 0.6900 - val_loss: 0.6600 - val_acc: 0.6400\n",
            "Epoch 24/4500\n",
            "100/100 [==============================] - 0s 540us/step - loss: 0.6205 - acc: 0.6900 - val_loss: 0.6569 - val_acc: 0.6400\n",
            "Epoch 25/4500\n",
            "100/100 [==============================] - 0s 567us/step - loss: 0.6197 - acc: 0.6900 - val_loss: 0.6576 - val_acc: 0.6400\n",
            "Epoch 26/4500\n",
            "100/100 [==============================] - 0s 496us/step - loss: 0.6221 - acc: 0.6900 - val_loss: 0.6602 - val_acc: 0.6400\n",
            "Epoch 27/4500\n",
            "100/100 [==============================] - 0s 505us/step - loss: 0.6194 - acc: 0.6900 - val_loss: 0.6579 - val_acc: 0.6400\n",
            "Epoch 28/4500\n",
            "100/100 [==============================] - 0s 484us/step - loss: 0.6199 - acc: 0.6900 - val_loss: 0.6574 - val_acc: 0.6400\n",
            "Epoch 29/4500\n",
            "100/100 [==============================] - 0s 551us/step - loss: 0.6198 - acc: 0.6900 - val_loss: 0.6588 - val_acc: 0.6400\n",
            "Epoch 30/4500\n",
            "100/100 [==============================] - 0s 541us/step - loss: 0.6195 - acc: 0.6900 - val_loss: 0.6583 - val_acc: 0.6400\n",
            "Epoch 31/4500\n",
            "100/100 [==============================] - 0s 508us/step - loss: 0.6212 - acc: 0.6900 - val_loss: 0.6607 - val_acc: 0.6400\n",
            "Epoch 32/4500\n",
            "100/100 [==============================] - 0s 598us/step - loss: 0.6212 - acc: 0.6900 - val_loss: 0.6574 - val_acc: 0.6400\n",
            "Epoch 33/4500\n",
            "100/100 [==============================] - 0s 624us/step - loss: 0.6203 - acc: 0.6900 - val_loss: 0.6575 - val_acc: 0.6400\n",
            "Epoch 34/4500\n",
            "100/100 [==============================] - 0s 520us/step - loss: 0.6199 - acc: 0.6900 - val_loss: 0.6593 - val_acc: 0.6400\n",
            "Epoch 35/4500\n",
            "100/100 [==============================] - 0s 506us/step - loss: 0.6203 - acc: 0.6900 - val_loss: 0.6586 - val_acc: 0.6400\n",
            "Epoch 36/4500\n",
            "100/100 [==============================] - 0s 533us/step - loss: 0.6198 - acc: 0.6900 - val_loss: 0.6583 - val_acc: 0.6400\n",
            "Epoch 37/4500\n",
            "100/100 [==============================] - 0s 538us/step - loss: 0.6199 - acc: 0.6900 - val_loss: 0.6583 - val_acc: 0.6400\n",
            "Epoch 38/4500\n",
            "100/100 [==============================] - 0s 547us/step - loss: 0.6222 - acc: 0.6900 - val_loss: 0.6621 - val_acc: 0.6400\n",
            "Epoch 39/4500\n",
            "100/100 [==============================] - 0s 565us/step - loss: 0.6200 - acc: 0.6900 - val_loss: 0.6592 - val_acc: 0.6400\n",
            "Epoch 40/4500\n",
            "100/100 [==============================] - 0s 497us/step - loss: 0.6198 - acc: 0.6900 - val_loss: 0.6577 - val_acc: 0.6400\n",
            "Epoch 41/4500\n",
            "100/100 [==============================] - 0s 504us/step - loss: 0.6206 - acc: 0.6900 - val_loss: 0.6584 - val_acc: 0.6400\n",
            "Epoch 42/4500\n",
            "100/100 [==============================] - 0s 509us/step - loss: 0.6197 - acc: 0.6900 - val_loss: 0.6581 - val_acc: 0.6400\n",
            "Epoch 43/4500\n",
            "100/100 [==============================] - 0s 519us/step - loss: 0.6198 - acc: 0.6900 - val_loss: 0.6587 - val_acc: 0.6400\n",
            "Epoch 44/4500\n",
            "100/100 [==============================] - 0s 527us/step - loss: 0.6199 - acc: 0.6900 - val_loss: 0.6583 - val_acc: 0.6400\n",
            "Epoch 45/4500\n",
            "100/100 [==============================] - 0s 514us/step - loss: 0.6204 - acc: 0.6900 - val_loss: 0.6590 - val_acc: 0.6400\n",
            "Epoch 46/4500\n",
            "100/100 [==============================] - 0s 523us/step - loss: 0.6201 - acc: 0.6900 - val_loss: 0.6589 - val_acc: 0.6400\n",
            "Epoch 47/4500\n",
            "100/100 [==============================] - 0s 512us/step - loss: 0.6206 - acc: 0.6900 - val_loss: 0.6575 - val_acc: 0.6400\n",
            "Epoch 48/4500\n",
            "100/100 [==============================] - 0s 515us/step - loss: 0.6201 - acc: 0.6900 - val_loss: 0.6574 - val_acc: 0.6400\n",
            "Epoch 49/4500\n",
            "100/100 [==============================] - 0s 530us/step - loss: 0.6195 - acc: 0.6900 - val_loss: 0.6602 - val_acc: 0.6400\n",
            "Epoch 50/4500\n",
            "100/100 [==============================] - 0s 509us/step - loss: 0.6198 - acc: 0.6900 - val_loss: 0.6602 - val_acc: 0.6400\n",
            "Epoch 51/4500\n",
            "100/100 [==============================] - 0s 536us/step - loss: 0.6215 - acc: 0.6900 - val_loss: 0.6580 - val_acc: 0.6400\n",
            "Epoch 52/4500\n",
            "100/100 [==============================] - 0s 573us/step - loss: 0.6200 - acc: 0.6900 - val_loss: 0.6597 - val_acc: 0.6400\n",
            "Epoch 53/4500\n",
            "100/100 [==============================] - 0s 534us/step - loss: 0.6200 - acc: 0.6900 - val_loss: 0.6591 - val_acc: 0.6400\n",
            "Epoch 54/4500\n",
            "100/100 [==============================] - 0s 634us/step - loss: 0.6202 - acc: 0.6900 - val_loss: 0.6592 - val_acc: 0.6400\n",
            "Epoch 55/4500\n",
            "100/100 [==============================] - 0s 587us/step - loss: 0.6197 - acc: 0.6900 - val_loss: 0.6601 - val_acc: 0.6400\n",
            "Epoch 56/4500\n",
            "100/100 [==============================] - 0s 534us/step - loss: 0.6207 - acc: 0.6900 - val_loss: 0.6579 - val_acc: 0.6400\n",
            "Epoch 57/4500\n",
            "100/100 [==============================] - 0s 516us/step - loss: 0.6201 - acc: 0.6900 - val_loss: 0.6597 - val_acc: 0.6400\n",
            "Epoch 58/4500\n",
            "100/100 [==============================] - 0s 518us/step - loss: 0.6208 - acc: 0.6900 - val_loss: 0.6578 - val_acc: 0.6400\n",
            "Epoch 59/4500\n",
            "100/100 [==============================] - 0s 531us/step - loss: 0.6193 - acc: 0.6900 - val_loss: 0.6586 - val_acc: 0.6400\n",
            "Epoch 60/4500\n",
            "100/100 [==============================] - 0s 537us/step - loss: 0.6207 - acc: 0.6900 - val_loss: 0.6595 - val_acc: 0.6400\n",
            "Epoch 61/4500\n",
            "100/100 [==============================] - 0s 522us/step - loss: 0.6200 - acc: 0.6900 - val_loss: 0.6584 - val_acc: 0.6400\n",
            "Epoch 62/4500\n",
            "100/100 [==============================] - 0s 548us/step - loss: 0.6207 - acc: 0.6900 - val_loss: 0.6570 - val_acc: 0.6400\n",
            "Epoch 63/4500\n",
            "100/100 [==============================] - 0s 592us/step - loss: 0.6195 - acc: 0.6900 - val_loss: 0.6586 - val_acc: 0.6400\n",
            "Epoch 64/4500\n",
            "100/100 [==============================] - 0s 569us/step - loss: 0.6198 - acc: 0.6900 - val_loss: 0.6610 - val_acc: 0.6400\n",
            "Epoch 65/4500\n",
            "100/100 [==============================] - 0s 569us/step - loss: 0.6198 - acc: 0.6900 - val_loss: 0.6596 - val_acc: 0.6400\n",
            "Epoch 66/4500\n",
            "100/100 [==============================] - 0s 555us/step - loss: 0.6206 - acc: 0.6900 - val_loss: 0.6580 - val_acc: 0.6400\n",
            "Epoch 67/4500\n",
            "100/100 [==============================] - 0s 480us/step - loss: 0.6194 - acc: 0.6900 - val_loss: 0.6586 - val_acc: 0.6400\n",
            "Epoch 68/4500\n",
            "100/100 [==============================] - 0s 532us/step - loss: 0.6200 - acc: 0.6900 - val_loss: 0.6598 - val_acc: 0.6400\n",
            "Epoch 69/4500\n",
            "100/100 [==============================] - 0s 532us/step - loss: 0.6207 - acc: 0.6900 - val_loss: 0.6575 - val_acc: 0.6400\n",
            "Epoch 70/4500\n",
            "100/100 [==============================] - 0s 497us/step - loss: 0.6241 - acc: 0.6900 - val_loss: 0.6618 - val_acc: 0.6400\n",
            "Epoch 71/4500\n",
            "100/100 [==============================] - 0s 571us/step - loss: 0.6213 - acc: 0.6900 - val_loss: 0.6573 - val_acc: 0.6400\n",
            "Epoch 72/4500\n",
            "100/100 [==============================] - 0s 507us/step - loss: 0.6196 - acc: 0.6900 - val_loss: 0.6573 - val_acc: 0.6400\n",
            "Epoch 73/4500\n",
            "100/100 [==============================] - 0s 500us/step - loss: 0.6200 - acc: 0.6900 - val_loss: 0.6592 - val_acc: 0.6400\n",
            "Epoch 74/4500\n",
            "100/100 [==============================] - 0s 488us/step - loss: 0.6197 - acc: 0.6900 - val_loss: 0.6580 - val_acc: 0.6400\n",
            "Epoch 75/4500\n",
            "100/100 [==============================] - 0s 517us/step - loss: 0.6198 - acc: 0.6900 - val_loss: 0.6578 - val_acc: 0.6400\n",
            "Epoch 76/4500\n",
            "100/100 [==============================] - 0s 502us/step - loss: 0.6207 - acc: 0.6900 - val_loss: 0.6578 - val_acc: 0.6400\n",
            "Epoch 77/4500\n",
            "100/100 [==============================] - 0s 498us/step - loss: 0.6198 - acc: 0.6900 - val_loss: 0.6591 - val_acc: 0.6400\n",
            "Epoch 78/4500\n",
            "100/100 [==============================] - 0s 547us/step - loss: 0.6216 - acc: 0.6900 - val_loss: 0.6617 - val_acc: 0.6400\n",
            "Epoch 79/4500\n",
            "100/100 [==============================] - 0s 535us/step - loss: 0.6192 - acc: 0.6900 - val_loss: 0.6592 - val_acc: 0.6400\n",
            "Epoch 80/4500\n",
            "100/100 [==============================] - 0s 540us/step - loss: 0.6200 - acc: 0.6900 - val_loss: 0.6578 - val_acc: 0.6400\n",
            "Epoch 81/4500\n",
            "100/100 [==============================] - 0s 547us/step - loss: 0.6214 - acc: 0.6900 - val_loss: 0.6596 - val_acc: 0.6400\n",
            "Epoch 82/4500\n",
            "100/100 [==============================] - 0s 514us/step - loss: 0.6197 - acc: 0.6900 - val_loss: 0.6574 - val_acc: 0.6400\n",
            "Epoch 83/4500\n",
            "100/100 [==============================] - 0s 535us/step - loss: 0.6199 - acc: 0.6900 - val_loss: 0.6578 - val_acc: 0.6400\n",
            "Epoch 84/4500\n",
            "100/100 [==============================] - 0s 553us/step - loss: 0.6191 - acc: 0.6900 - val_loss: 0.6587 - val_acc: 0.6400\n",
            "Epoch 85/4500\n",
            "100/100 [==============================] - 0s 497us/step - loss: 0.6202 - acc: 0.6900 - val_loss: 0.6605 - val_acc: 0.6400\n",
            "Epoch 86/4500\n",
            "100/100 [==============================] - 0s 510us/step - loss: 0.6204 - acc: 0.6900 - val_loss: 0.6577 - val_acc: 0.6400\n",
            "Epoch 87/4500\n",
            "100/100 [==============================] - 0s 524us/step - loss: 0.6204 - acc: 0.6900 - val_loss: 0.6580 - val_acc: 0.6400\n",
            "Epoch 88/4500\n",
            "100/100 [==============================] - 0s 519us/step - loss: 0.6195 - acc: 0.6900 - val_loss: 0.6594 - val_acc: 0.6400\n",
            "Epoch 89/4500\n",
            "100/100 [==============================] - 0s 521us/step - loss: 0.6198 - acc: 0.6900 - val_loss: 0.6602 - val_acc: 0.6400\n",
            "Epoch 90/4500\n",
            "100/100 [==============================] - 0s 586us/step - loss: 0.6204 - acc: 0.6900 - val_loss: 0.6578 - val_acc: 0.6400\n",
            "Epoch 91/4500\n",
            "100/100 [==============================] - 0s 514us/step - loss: 0.6198 - acc: 0.6900 - val_loss: 0.6588 - val_acc: 0.6400\n",
            "Epoch 92/4500\n",
            "100/100 [==============================] - 0s 501us/step - loss: 0.6192 - acc: 0.6900 - val_loss: 0.6591 - val_acc: 0.6400\n",
            "Epoch 93/4500\n",
            "100/100 [==============================] - 0s 511us/step - loss: 0.6202 - acc: 0.6900 - val_loss: 0.6597 - val_acc: 0.6400\n",
            "Epoch 94/4500\n",
            "100/100 [==============================] - 0s 469us/step - loss: 0.6195 - acc: 0.6900 - val_loss: 0.6587 - val_acc: 0.6400\n",
            "Epoch 95/4500\n",
            "100/100 [==============================] - 0s 500us/step - loss: 0.6202 - acc: 0.6900 - val_loss: 0.6571 - val_acc: 0.6400\n",
            "Epoch 96/4500\n",
            "100/100 [==============================] - 0s 501us/step - loss: 0.6196 - acc: 0.6900 - val_loss: 0.6576 - val_acc: 0.6400\n",
            "Epoch 97/4500\n",
            "100/100 [==============================] - 0s 500us/step - loss: 0.6198 - acc: 0.6900 - val_loss: 0.6601 - val_acc: 0.6400\n",
            "Epoch 98/4500\n",
            "100/100 [==============================] - 0s 612us/step - loss: 0.6206 - acc: 0.6900 - val_loss: 0.6580 - val_acc: 0.6400\n",
            "Epoch 99/4500\n",
            "100/100 [==============================] - 0s 511us/step - loss: 0.6202 - acc: 0.6900 - val_loss: 0.6595 - val_acc: 0.6400\n",
            "Epoch 100/4500\n",
            "100/100 [==============================] - 0s 490us/step - loss: 0.6198 - acc: 0.6900 - val_loss: 0.6597 - val_acc: 0.6400\n",
            "Epoch 101/4500\n",
            "100/100 [==============================] - 0s 499us/step - loss: 0.6217 - acc: 0.6900 - val_loss: 0.6577 - val_acc: 0.6400\n",
            "Epoch 102/4500\n",
            "100/100 [==============================] - 0s 549us/step - loss: 0.6196 - acc: 0.6900 - val_loss: 0.6588 - val_acc: 0.6400\n",
            "Epoch 103/4500\n",
            "100/100 [==============================] - 0s 587us/step - loss: 0.6201 - acc: 0.6900 - val_loss: 0.6597 - val_acc: 0.6400\n",
            "Epoch 104/4500\n",
            "100/100 [==============================] - 0s 502us/step - loss: 0.6204 - acc: 0.6900 - val_loss: 0.6605 - val_acc: 0.6400\n",
            "Epoch 105/4500\n",
            "100/100 [==============================] - 0s 518us/step - loss: 0.6197 - acc: 0.6900 - val_loss: 0.6593 - val_acc: 0.6400\n",
            "Epoch 106/4500\n",
            "100/100 [==============================] - 0s 603us/step - loss: 0.6213 - acc: 0.6900 - val_loss: 0.6588 - val_acc: 0.6400\n",
            "Epoch 107/4500\n",
            "100/100 [==============================] - 0s 532us/step - loss: 0.6205 - acc: 0.6900 - val_loss: 0.6581 - val_acc: 0.6400\n",
            "Epoch 108/4500\n",
            "100/100 [==============================] - 0s 499us/step - loss: 0.6198 - acc: 0.6900 - val_loss: 0.6569 - val_acc: 0.6400\n",
            "Epoch 109/4500\n",
            "100/100 [==============================] - 0s 603us/step - loss: 0.6200 - acc: 0.6900 - val_loss: 0.6567 - val_acc: 0.6400\n",
            "Epoch 110/4500\n",
            "100/100 [==============================] - 0s 513us/step - loss: 0.6196 - acc: 0.6900 - val_loss: 0.6584 - val_acc: 0.6400\n",
            "Epoch 111/4500\n",
            "100/100 [==============================] - 0s 562us/step - loss: 0.6199 - acc: 0.6900 - val_loss: 0.6588 - val_acc: 0.6400\n",
            "Epoch 112/4500\n",
            "100/100 [==============================] - 0s 498us/step - loss: 0.6216 - acc: 0.6900 - val_loss: 0.6605 - val_acc: 0.6400\n",
            "Epoch 113/4500\n",
            "100/100 [==============================] - 0s 531us/step - loss: 0.6202 - acc: 0.6900 - val_loss: 0.6582 - val_acc: 0.6400\n",
            "Epoch 114/4500\n",
            "100/100 [==============================] - 0s 566us/step - loss: 0.6195 - acc: 0.6900 - val_loss: 0.6586 - val_acc: 0.6400\n",
            "Epoch 115/4500\n",
            "100/100 [==============================] - 0s 498us/step - loss: 0.6199 - acc: 0.6900 - val_loss: 0.6574 - val_acc: 0.6400\n",
            "Epoch 116/4500\n",
            "100/100 [==============================] - 0s 612us/step - loss: 0.6197 - acc: 0.6900 - val_loss: 0.6588 - val_acc: 0.6400\n",
            "Epoch 117/4500\n",
            "100/100 [==============================] - 0s 530us/step - loss: 0.6191 - acc: 0.6900 - val_loss: 0.6592 - val_acc: 0.6400\n",
            "Epoch 118/4500\n",
            "100/100 [==============================] - 0s 541us/step - loss: 0.6197 - acc: 0.6900 - val_loss: 0.6600 - val_acc: 0.6400\n",
            "Epoch 119/4500\n",
            "100/100 [==============================] - 0s 500us/step - loss: 0.6200 - acc: 0.6900 - val_loss: 0.6583 - val_acc: 0.6400\n",
            "Epoch 120/4500\n",
            "100/100 [==============================] - 0s 501us/step - loss: 0.6197 - acc: 0.6900 - val_loss: 0.6589 - val_acc: 0.6400\n",
            "Epoch 121/4500\n",
            "100/100 [==============================] - 0s 575us/step - loss: 0.6197 - acc: 0.6900 - val_loss: 0.6596 - val_acc: 0.6400\n",
            "Epoch 122/4500\n",
            "100/100 [==============================] - 0s 658us/step - loss: 0.6200 - acc: 0.6900 - val_loss: 0.6581 - val_acc: 0.6400\n",
            "Epoch 123/4500\n",
            "100/100 [==============================] - 0s 534us/step - loss: 0.6201 - acc: 0.6900 - val_loss: 0.6584 - val_acc: 0.6400\n",
            "Epoch 124/4500\n",
            "100/100 [==============================] - 0s 508us/step - loss: 0.6210 - acc: 0.6900 - val_loss: 0.6574 - val_acc: 0.6400\n",
            "Epoch 125/4500\n",
            "100/100 [==============================] - 0s 518us/step - loss: 0.6206 - acc: 0.6900 - val_loss: 0.6602 - val_acc: 0.6400\n",
            "Epoch 126/4500\n",
            "100/100 [==============================] - 0s 490us/step - loss: 0.6211 - acc: 0.6900 - val_loss: 0.6585 - val_acc: 0.6400\n",
            "Epoch 127/4500\n",
            "100/100 [==============================] - 0s 620us/step - loss: 0.6194 - acc: 0.6900 - val_loss: 0.6588 - val_acc: 0.6400\n",
            "Epoch 128/4500\n",
            "100/100 [==============================] - 0s 601us/step - loss: 0.6200 - acc: 0.6900 - val_loss: 0.6587 - val_acc: 0.6400\n",
            "Epoch 129/4500\n",
            "100/100 [==============================] - 0s 523us/step - loss: 0.6196 - acc: 0.6900 - val_loss: 0.6586 - val_acc: 0.6400\n",
            "Epoch 130/4500\n",
            "100/100 [==============================] - 0s 511us/step - loss: 0.6196 - acc: 0.6900 - val_loss: 0.6584 - val_acc: 0.6400\n",
            "Epoch 131/4500\n",
            "100/100 [==============================] - 0s 490us/step - loss: 0.6195 - acc: 0.6900 - val_loss: 0.6584 - val_acc: 0.6400\n",
            "Epoch 132/4500\n",
            "100/100 [==============================] - 0s 496us/step - loss: 0.6198 - acc: 0.6900 - val_loss: 0.6579 - val_acc: 0.6400\n",
            "Epoch 133/4500\n",
            "100/100 [==============================] - 0s 494us/step - loss: 0.6204 - acc: 0.6900 - val_loss: 0.6576 - val_acc: 0.6400\n",
            "Epoch 134/4500\n",
            "100/100 [==============================] - 0s 523us/step - loss: 0.6215 - acc: 0.6900 - val_loss: 0.6606 - val_acc: 0.6400\n",
            "Epoch 135/4500\n",
            "100/100 [==============================] - 0s 593us/step - loss: 0.6197 - acc: 0.6900 - val_loss: 0.6588 - val_acc: 0.6400\n",
            "Epoch 136/4500\n",
            "100/100 [==============================] - 0s 539us/step - loss: 0.6235 - acc: 0.6900 - val_loss: 0.6611 - val_acc: 0.6400\n",
            "Epoch 137/4500\n",
            "100/100 [==============================] - 0s 591us/step - loss: 0.6187 - acc: 0.6900 - val_loss: 0.6587 - val_acc: 0.6400\n",
            "Epoch 138/4500\n",
            "100/100 [==============================] - 0s 624us/step - loss: 0.6196 - acc: 0.6900 - val_loss: 0.6570 - val_acc: 0.6400\n",
            "Epoch 139/4500\n",
            "100/100 [==============================] - 0s 605us/step - loss: 0.6200 - acc: 0.6900 - val_loss: 0.6562 - val_acc: 0.6400\n",
            "Epoch 140/4500\n",
            "100/100 [==============================] - 0s 510us/step - loss: 0.6199 - acc: 0.6900 - val_loss: 0.6577 - val_acc: 0.6400\n",
            "Epoch 141/4500\n",
            "100/100 [==============================] - 0s 564us/step - loss: 0.6209 - acc: 0.6900 - val_loss: 0.6593 - val_acc: 0.6400\n",
            "Epoch 142/4500\n",
            "100/100 [==============================] - 0s 584us/step - loss: 0.6217 - acc: 0.6900 - val_loss: 0.6611 - val_acc: 0.6400\n",
            "Epoch 143/4500\n",
            "100/100 [==============================] - 0s 533us/step - loss: 0.6199 - acc: 0.6900 - val_loss: 0.6580 - val_acc: 0.6400\n",
            "Epoch 144/4500\n",
            "100/100 [==============================] - 0s 531us/step - loss: 0.6206 - acc: 0.6900 - val_loss: 0.6566 - val_acc: 0.6400\n",
            "Epoch 145/4500\n",
            "100/100 [==============================] - 0s 660us/step - loss: 0.6195 - acc: 0.6900 - val_loss: 0.6578 - val_acc: 0.6400\n",
            "Epoch 146/4500\n",
            "100/100 [==============================] - 0s 572us/step - loss: 0.6210 - acc: 0.6900 - val_loss: 0.6582 - val_acc: 0.6400\n",
            "Epoch 147/4500\n",
            "100/100 [==============================] - 0s 522us/step - loss: 0.6205 - acc: 0.6900 - val_loss: 0.6598 - val_acc: 0.6400\n",
            "Epoch 148/4500\n",
            "100/100 [==============================] - 0s 549us/step - loss: 0.6199 - acc: 0.6900 - val_loss: 0.6597 - val_acc: 0.6400\n",
            "Epoch 149/4500\n",
            "100/100 [==============================] - 0s 537us/step - loss: 0.6196 - acc: 0.6900 - val_loss: 0.6585 - val_acc: 0.6400\n",
            "Epoch 150/4500\n",
            "100/100 [==============================] - 0s 536us/step - loss: 0.6193 - acc: 0.6900 - val_loss: 0.6585 - val_acc: 0.6400\n",
            "Epoch 151/4500\n",
            "100/100 [==============================] - 0s 554us/step - loss: 0.6194 - acc: 0.6900 - val_loss: 0.6588 - val_acc: 0.6400\n",
            "Epoch 152/4500\n",
            "100/100 [==============================] - 0s 567us/step - loss: 0.6221 - acc: 0.6900 - val_loss: 0.6579 - val_acc: 0.6400\n",
            "Epoch 153/4500\n",
            "100/100 [==============================] - 0s 527us/step - loss: 0.6196 - acc: 0.6900 - val_loss: 0.6576 - val_acc: 0.6400\n",
            "Epoch 154/4500\n",
            "100/100 [==============================] - 0s 524us/step - loss: 0.6215 - acc: 0.6900 - val_loss: 0.6607 - val_acc: 0.6400\n",
            "Epoch 155/4500\n",
            "100/100 [==============================] - 0s 535us/step - loss: 0.6207 - acc: 0.6900 - val_loss: 0.6579 - val_acc: 0.6400\n",
            "Epoch 156/4500\n",
            "100/100 [==============================] - 0s 561us/step - loss: 0.6194 - acc: 0.6900 - val_loss: 0.6586 - val_acc: 0.6400\n",
            "Epoch 157/4500\n",
            "100/100 [==============================] - 0s 499us/step - loss: 0.6195 - acc: 0.6900 - val_loss: 0.6587 - val_acc: 0.6400\n",
            "Epoch 158/4500\n",
            "100/100 [==============================] - 0s 596us/step - loss: 0.6220 - acc: 0.6900 - val_loss: 0.6605 - val_acc: 0.6400\n",
            "Epoch 159/4500\n",
            "100/100 [==============================] - 0s 563us/step - loss: 0.6202 - acc: 0.6900 - val_loss: 0.6580 - val_acc: 0.6400\n",
            "Epoch 160/4500\n",
            "100/100 [==============================] - 0s 555us/step - loss: 0.6193 - acc: 0.6900 - val_loss: 0.6582 - val_acc: 0.6400\n",
            "Epoch 161/4500\n",
            "100/100 [==============================] - 0s 532us/step - loss: 0.6204 - acc: 0.6900 - val_loss: 0.6575 - val_acc: 0.6400\n",
            "Epoch 162/4500\n",
            "100/100 [==============================] - 0s 540us/step - loss: 0.6195 - acc: 0.6900 - val_loss: 0.6592 - val_acc: 0.6400\n",
            "Epoch 163/4500\n",
            "100/100 [==============================] - 0s 704us/step - loss: 0.6207 - acc: 0.6900 - val_loss: 0.6589 - val_acc: 0.6400\n",
            "Epoch 164/4500\n",
            "100/100 [==============================] - 0s 526us/step - loss: 0.6198 - acc: 0.6900 - val_loss: 0.6593 - val_acc: 0.6400\n",
            "Epoch 165/4500\n",
            "100/100 [==============================] - 0s 516us/step - loss: 0.6199 - acc: 0.6900 - val_loss: 0.6588 - val_acc: 0.6400\n",
            "Epoch 166/4500\n",
            "100/100 [==============================] - 0s 539us/step - loss: 0.6233 - acc: 0.6900 - val_loss: 0.6620 - val_acc: 0.6400\n",
            "Epoch 167/4500\n",
            "100/100 [==============================] - 0s 514us/step - loss: 0.6198 - acc: 0.6900 - val_loss: 0.6591 - val_acc: 0.6400\n",
            "Epoch 168/4500\n",
            "100/100 [==============================] - 0s 578us/step - loss: 0.6207 - acc: 0.6900 - val_loss: 0.6565 - val_acc: 0.6400\n",
            "Epoch 169/4500\n",
            "100/100 [==============================] - 0s 551us/step - loss: 0.6197 - acc: 0.6900 - val_loss: 0.6580 - val_acc: 0.6400\n",
            "Epoch 170/4500\n",
            "100/100 [==============================] - 0s 545us/step - loss: 0.6197 - acc: 0.6900 - val_loss: 0.6576 - val_acc: 0.6400\n",
            "Epoch 171/4500\n",
            "100/100 [==============================] - 0s 575us/step - loss: 0.6191 - acc: 0.6900 - val_loss: 0.6585 - val_acc: 0.6400\n",
            "Epoch 172/4500\n",
            "100/100 [==============================] - 0s 677us/step - loss: 0.6201 - acc: 0.6900 - val_loss: 0.6599 - val_acc: 0.6400\n",
            "Epoch 173/4500\n",
            "100/100 [==============================] - 0s 559us/step - loss: 0.6209 - acc: 0.6900 - val_loss: 0.6577 - val_acc: 0.6400\n",
            "Epoch 174/4500\n",
            "100/100 [==============================] - 0s 624us/step - loss: 0.6193 - acc: 0.6900 - val_loss: 0.6582 - val_acc: 0.6400\n",
            "Epoch 175/4500\n",
            "100/100 [==============================] - 0s 515us/step - loss: 0.6200 - acc: 0.6900 - val_loss: 0.6593 - val_acc: 0.6400\n",
            "Epoch 176/4500\n",
            "100/100 [==============================] - 0s 532us/step - loss: 0.6201 - acc: 0.6900 - val_loss: 0.6586 - val_acc: 0.6400\n",
            "Epoch 177/4500\n",
            "100/100 [==============================] - 0s 518us/step - loss: 0.6211 - acc: 0.6900 - val_loss: 0.6585 - val_acc: 0.6400\n",
            "Epoch 178/4500\n",
            "100/100 [==============================] - 0s 571us/step - loss: 0.6195 - acc: 0.6900 - val_loss: 0.6593 - val_acc: 0.6400\n",
            "Epoch 179/4500\n",
            "100/100 [==============================] - 0s 583us/step - loss: 0.6193 - acc: 0.6900 - val_loss: 0.6594 - val_acc: 0.6400\n",
            "Epoch 180/4500\n",
            "100/100 [==============================] - 0s 522us/step - loss: 0.6215 - acc: 0.6900 - val_loss: 0.6616 - val_acc: 0.6400\n",
            "Epoch 181/4500\n",
            "100/100 [==============================] - 0s 609us/step - loss: 0.6202 - acc: 0.6900 - val_loss: 0.6579 - val_acc: 0.6400\n",
            "Epoch 182/4500\n",
            "100/100 [==============================] - 0s 565us/step - loss: 0.6197 - acc: 0.6900 - val_loss: 0.6577 - val_acc: 0.6400\n",
            "Epoch 183/4500\n",
            "100/100 [==============================] - 0s 530us/step - loss: 0.6223 - acc: 0.6900 - val_loss: 0.6563 - val_acc: 0.6400\n",
            "Epoch 184/4500\n",
            "100/100 [==============================] - 0s 623us/step - loss: 0.6201 - acc: 0.6900 - val_loss: 0.6571 - val_acc: 0.6400\n",
            "Epoch 185/4500\n",
            "100/100 [==============================] - 0s 547us/step - loss: 0.6217 - acc: 0.6900 - val_loss: 0.6615 - val_acc: 0.6400\n",
            "Epoch 186/4500\n",
            "100/100 [==============================] - 0s 511us/step - loss: 0.6215 - acc: 0.6900 - val_loss: 0.6627 - val_acc: 0.6400\n",
            "Epoch 187/4500\n",
            "100/100 [==============================] - 0s 527us/step - loss: 0.6190 - acc: 0.6900 - val_loss: 0.6588 - val_acc: 0.6400\n",
            "Epoch 188/4500\n",
            "100/100 [==============================] - 0s 555us/step - loss: 0.6203 - acc: 0.6900 - val_loss: 0.6591 - val_acc: 0.6400\n",
            "Epoch 189/4500\n",
            "100/100 [==============================] - 0s 522us/step - loss: 0.6194 - acc: 0.6900 - val_loss: 0.6574 - val_acc: 0.6400\n",
            "Epoch 190/4500\n",
            "100/100 [==============================] - 0s 537us/step - loss: 0.6195 - acc: 0.6900 - val_loss: 0.6571 - val_acc: 0.6400\n",
            "Epoch 191/4500\n",
            "100/100 [==============================] - 0s 549us/step - loss: 0.6207 - acc: 0.6900 - val_loss: 0.6567 - val_acc: 0.6400\n",
            "Epoch 192/4500\n",
            "100/100 [==============================] - 0s 588us/step - loss: 0.6204 - acc: 0.6900 - val_loss: 0.6587 - val_acc: 0.6400\n",
            "Epoch 193/4500\n",
            "100/100 [==============================] - 0s 560us/step - loss: 0.6198 - acc: 0.6900 - val_loss: 0.6594 - val_acc: 0.6400\n",
            "Epoch 194/4500\n",
            "100/100 [==============================] - 0s 527us/step - loss: 0.6205 - acc: 0.6900 - val_loss: 0.6605 - val_acc: 0.6400\n",
            "Epoch 195/4500\n",
            "100/100 [==============================] - 0s 522us/step - loss: 0.6205 - acc: 0.6900 - val_loss: 0.6573 - val_acc: 0.6400\n",
            "Epoch 196/4500\n",
            "100/100 [==============================] - 0s 556us/step - loss: 0.6199 - acc: 0.6900 - val_loss: 0.6572 - val_acc: 0.6400\n",
            "Epoch 197/4500\n",
            "100/100 [==============================] - 0s 668us/step - loss: 0.6202 - acc: 0.6900 - val_loss: 0.6596 - val_acc: 0.6400\n",
            "Epoch 198/4500\n",
            "100/100 [==============================] - 0s 572us/step - loss: 0.6211 - acc: 0.6900 - val_loss: 0.6582 - val_acc: 0.6400\n",
            "Epoch 199/4500\n",
            "100/100 [==============================] - 0s 619us/step - loss: 0.6197 - acc: 0.6900 - val_loss: 0.6594 - val_acc: 0.6400\n",
            "Epoch 200/4500\n",
            "100/100 [==============================] - 0s 549us/step - loss: 0.6244 - acc: 0.6900 - val_loss: 0.6627 - val_acc: 0.6400\n",
            "Epoch 201/4500\n",
            "100/100 [==============================] - 0s 538us/step - loss: 0.6195 - acc: 0.6900 - val_loss: 0.6583 - val_acc: 0.6400\n",
            "Epoch 202/4500\n",
            "100/100 [==============================] - 0s 520us/step - loss: 0.6191 - acc: 0.6900 - val_loss: 0.6571 - val_acc: 0.6400\n",
            "Epoch 203/4500\n",
            "100/100 [==============================] - 0s 514us/step - loss: 0.6195 - acc: 0.6900 - val_loss: 0.6573 - val_acc: 0.6400\n",
            "Epoch 204/4500\n",
            "100/100 [==============================] - 0s 522us/step - loss: 0.6198 - acc: 0.6900 - val_loss: 0.6576 - val_acc: 0.6400\n",
            "Epoch 205/4500\n",
            "100/100 [==============================] - 0s 542us/step - loss: 0.6201 - acc: 0.6900 - val_loss: 0.6573 - val_acc: 0.6400\n",
            "Epoch 206/4500\n",
            "100/100 [==============================] - 0s 550us/step - loss: 0.6208 - acc: 0.6900 - val_loss: 0.6587 - val_acc: 0.6400\n",
            "Epoch 207/4500\n",
            "100/100 [==============================] - 0s 549us/step - loss: 0.6216 - acc: 0.6900 - val_loss: 0.6573 - val_acc: 0.6400\n",
            "Epoch 208/4500\n",
            "100/100 [==============================] - 0s 523us/step - loss: 0.6193 - acc: 0.6900 - val_loss: 0.6576 - val_acc: 0.6400\n",
            "Epoch 209/4500\n",
            "100/100 [==============================] - 0s 579us/step - loss: 0.6196 - acc: 0.6900 - val_loss: 0.6601 - val_acc: 0.6400\n",
            "Epoch 210/4500\n",
            "100/100 [==============================] - 0s 539us/step - loss: 0.6195 - acc: 0.6900 - val_loss: 0.6603 - val_acc: 0.6400\n",
            "Epoch 211/4500\n",
            "100/100 [==============================] - 0s 612us/step - loss: 0.6202 - acc: 0.6900 - val_loss: 0.6590 - val_acc: 0.6400\n",
            "Epoch 212/4500\n",
            "100/100 [==============================] - 0s 629us/step - loss: 0.6202 - acc: 0.6900 - val_loss: 0.6605 - val_acc: 0.6400\n",
            "Epoch 213/4500\n",
            "100/100 [==============================] - 0s 619us/step - loss: 0.6192 - acc: 0.6900 - val_loss: 0.6597 - val_acc: 0.6400\n",
            "Epoch 214/4500\n",
            "100/100 [==============================] - 0s 568us/step - loss: 0.6198 - acc: 0.6900 - val_loss: 0.6598 - val_acc: 0.6400\n",
            "Epoch 215/4500\n",
            "100/100 [==============================] - 0s 566us/step - loss: 0.6197 - acc: 0.6900 - val_loss: 0.6577 - val_acc: 0.6400\n",
            "Epoch 216/4500\n",
            "100/100 [==============================] - 0s 563us/step - loss: 0.6205 - acc: 0.6900 - val_loss: 0.6564 - val_acc: 0.6400\n",
            "Epoch 217/4500\n",
            "100/100 [==============================] - 0s 630us/step - loss: 0.6193 - acc: 0.6900 - val_loss: 0.6580 - val_acc: 0.6400\n",
            "Epoch 218/4500\n",
            "100/100 [==============================] - 0s 514us/step - loss: 0.6194 - acc: 0.6900 - val_loss: 0.6586 - val_acc: 0.6400\n",
            "Epoch 219/4500\n",
            "100/100 [==============================] - 0s 527us/step - loss: 0.6214 - acc: 0.6900 - val_loss: 0.6589 - val_acc: 0.6400\n",
            "Epoch 220/4500\n",
            "100/100 [==============================] - 0s 509us/step - loss: 0.6203 - acc: 0.6900 - val_loss: 0.6575 - val_acc: 0.6400\n",
            "Epoch 221/4500\n",
            "100/100 [==============================] - 0s 501us/step - loss: 0.6198 - acc: 0.6900 - val_loss: 0.6584 - val_acc: 0.6400\n",
            "Epoch 222/4500\n",
            "100/100 [==============================] - 0s 588us/step - loss: 0.6193 - acc: 0.6900 - val_loss: 0.6583 - val_acc: 0.6400\n",
            "Epoch 223/4500\n",
            "100/100 [==============================] - 0s 583us/step - loss: 0.6195 - acc: 0.6900 - val_loss: 0.6603 - val_acc: 0.6400\n",
            "Epoch 224/4500\n",
            "100/100 [==============================] - 0s 538us/step - loss: 0.6206 - acc: 0.6900 - val_loss: 0.6615 - val_acc: 0.6400\n",
            "Epoch 225/4500\n",
            "100/100 [==============================] - 0s 512us/step - loss: 0.6196 - acc: 0.6900 - val_loss: 0.6593 - val_acc: 0.6400\n",
            "Epoch 226/4500\n",
            "100/100 [==============================] - 0s 570us/step - loss: 0.6194 - acc: 0.6900 - val_loss: 0.6591 - val_acc: 0.6400\n",
            "Epoch 227/4500\n",
            "100/100 [==============================] - 0s 523us/step - loss: 0.6192 - acc: 0.6900 - val_loss: 0.6586 - val_acc: 0.6400\n",
            "Epoch 228/4500\n",
            "100/100 [==============================] - 0s 519us/step - loss: 0.6191 - acc: 0.6900 - val_loss: 0.6579 - val_acc: 0.6400\n",
            "Epoch 229/4500\n",
            "100/100 [==============================] - 0s 499us/step - loss: 0.6209 - acc: 0.6900 - val_loss: 0.6570 - val_acc: 0.6400\n",
            "Epoch 230/4500\n",
            "100/100 [==============================] - 0s 641us/step - loss: 0.6194 - acc: 0.6900 - val_loss: 0.6581 - val_acc: 0.6400\n",
            "Epoch 231/4500\n",
            "100/100 [==============================] - 0s 585us/step - loss: 0.6201 - acc: 0.6900 - val_loss: 0.6599 - val_acc: 0.6400\n",
            "Epoch 232/4500\n",
            "100/100 [==============================] - 0s 562us/step - loss: 0.6203 - acc: 0.6900 - val_loss: 0.6585 - val_acc: 0.6400\n",
            "Epoch 233/4500\n",
            "100/100 [==============================] - 0s 602us/step - loss: 0.6202 - acc: 0.6900 - val_loss: 0.6579 - val_acc: 0.6400\n",
            "Epoch 234/4500\n",
            "100/100 [==============================] - 0s 585us/step - loss: 0.6209 - acc: 0.6900 - val_loss: 0.6598 - val_acc: 0.6400\n",
            "Epoch 235/4500\n",
            "100/100 [==============================] - 0s 684us/step - loss: 0.6231 - acc: 0.6900 - val_loss: 0.6566 - val_acc: 0.6400\n",
            "Epoch 236/4500\n",
            "100/100 [==============================] - 0s 544us/step - loss: 0.6194 - acc: 0.6900 - val_loss: 0.6584 - val_acc: 0.6400\n",
            "Epoch 237/4500\n",
            "100/100 [==============================] - 0s 569us/step - loss: 0.6191 - acc: 0.6900 - val_loss: 0.6589 - val_acc: 0.6400\n",
            "Epoch 238/4500\n",
            "100/100 [==============================] - 0s 591us/step - loss: 0.6194 - acc: 0.6900 - val_loss: 0.6602 - val_acc: 0.6400\n",
            "Epoch 239/4500\n",
            "100/100 [==============================] - 0s 587us/step - loss: 0.6199 - acc: 0.6900 - val_loss: 0.6600 - val_acc: 0.6400\n",
            "Epoch 240/4500\n",
            "100/100 [==============================] - 0s 539us/step - loss: 0.6197 - acc: 0.6900 - val_loss: 0.6586 - val_acc: 0.6400\n",
            "Epoch 241/4500\n",
            "100/100 [==============================] - 0s 542us/step - loss: 0.6193 - acc: 0.6900 - val_loss: 0.6591 - val_acc: 0.6400\n",
            "Epoch 242/4500\n",
            "100/100 [==============================] - 0s 599us/step - loss: 0.6196 - acc: 0.6900 - val_loss: 0.6591 - val_acc: 0.6400\n",
            "Epoch 243/4500\n",
            "100/100 [==============================] - 0s 554us/step - loss: 0.6196 - acc: 0.6900 - val_loss: 0.6589 - val_acc: 0.6400\n",
            "Epoch 244/4500\n",
            "100/100 [==============================] - 0s 531us/step - loss: 0.6199 - acc: 0.6900 - val_loss: 0.6599 - val_acc: 0.6400\n",
            "Epoch 245/4500\n",
            "100/100 [==============================] - 0s 519us/step - loss: 0.6195 - acc: 0.6900 - val_loss: 0.6596 - val_acc: 0.6400\n",
            "Epoch 246/4500\n",
            "100/100 [==============================] - 0s 515us/step - loss: 0.6203 - acc: 0.6900 - val_loss: 0.6571 - val_acc: 0.6400\n",
            "Epoch 247/4500\n",
            "100/100 [==============================] - 0s 532us/step - loss: 0.6194 - acc: 0.6900 - val_loss: 0.6568 - val_acc: 0.6400\n",
            "Epoch 248/4500\n",
            "100/100 [==============================] - 0s 598us/step - loss: 0.6191 - acc: 0.6900 - val_loss: 0.6581 - val_acc: 0.6400\n",
            "Epoch 249/4500\n",
            "100/100 [==============================] - 0s 529us/step - loss: 0.6199 - acc: 0.6900 - val_loss: 0.6580 - val_acc: 0.6400\n",
            "Epoch 250/4500\n",
            "100/100 [==============================] - 0s 533us/step - loss: 0.6200 - acc: 0.6900 - val_loss: 0.6595 - val_acc: 0.6400\n",
            "Epoch 251/4500\n",
            "100/100 [==============================] - 0s 593us/step - loss: 0.6223 - acc: 0.6900 - val_loss: 0.6614 - val_acc: 0.6400\n",
            "Epoch 252/4500\n",
            "100/100 [==============================] - 0s 601us/step - loss: 0.6204 - acc: 0.6900 - val_loss: 0.6576 - val_acc: 0.6400\n",
            "Epoch 253/4500\n",
            "100/100 [==============================] - 0s 661us/step - loss: 0.6192 - acc: 0.6900 - val_loss: 0.6580 - val_acc: 0.6400\n",
            "Epoch 254/4500\n",
            "100/100 [==============================] - 0s 543us/step - loss: 0.6207 - acc: 0.6900 - val_loss: 0.6570 - val_acc: 0.6400\n",
            "Epoch 255/4500\n",
            "100/100 [==============================] - 0s 547us/step - loss: 0.6194 - acc: 0.6900 - val_loss: 0.6587 - val_acc: 0.6400\n",
            "Epoch 256/4500\n",
            "100/100 [==============================] - 0s 550us/step - loss: 0.6198 - acc: 0.6900 - val_loss: 0.6595 - val_acc: 0.6400\n",
            "Epoch 257/4500\n",
            "100/100 [==============================] - 0s 563us/step - loss: 0.6196 - acc: 0.6900 - val_loss: 0.6589 - val_acc: 0.6400\n",
            "Epoch 258/4500\n",
            "100/100 [==============================] - 0s 572us/step - loss: 0.6213 - acc: 0.6900 - val_loss: 0.6573 - val_acc: 0.6400\n",
            "Epoch 259/4500\n",
            "100/100 [==============================] - 0s 534us/step - loss: 0.6207 - acc: 0.6900 - val_loss: 0.6570 - val_acc: 0.6400\n",
            "Epoch 260/4500\n",
            "100/100 [==============================] - 0s 526us/step - loss: 0.6191 - acc: 0.6900 - val_loss: 0.6585 - val_acc: 0.6400\n",
            "Epoch 261/4500\n",
            "100/100 [==============================] - 0s 528us/step - loss: 0.6191 - acc: 0.6900 - val_loss: 0.6596 - val_acc: 0.6400\n",
            "Epoch 262/4500\n",
            "100/100 [==============================] - 0s 534us/step - loss: 0.6192 - acc: 0.6900 - val_loss: 0.6599 - val_acc: 0.6400\n",
            "Epoch 263/4500\n",
            "100/100 [==============================] - 0s 533us/step - loss: 0.6194 - acc: 0.6900 - val_loss: 0.6600 - val_acc: 0.6400\n",
            "Epoch 264/4500\n",
            "100/100 [==============================] - 0s 544us/step - loss: 0.6196 - acc: 0.6900 - val_loss: 0.6591 - val_acc: 0.6400\n",
            "Epoch 265/4500\n",
            "100/100 [==============================] - 0s 534us/step - loss: 0.6191 - acc: 0.6900 - val_loss: 0.6588 - val_acc: 0.6400\n",
            "Epoch 266/4500\n",
            "100/100 [==============================] - 0s 540us/step - loss: 0.6196 - acc: 0.6900 - val_loss: 0.6596 - val_acc: 0.6400\n",
            "Epoch 267/4500\n",
            "100/100 [==============================] - 0s 648us/step - loss: 0.6193 - acc: 0.6900 - val_loss: 0.6596 - val_acc: 0.6400\n",
            "Epoch 268/4500\n",
            "100/100 [==============================] - 0s 578us/step - loss: 0.6199 - acc: 0.6900 - val_loss: 0.6579 - val_acc: 0.6400\n",
            "Epoch 269/4500\n",
            "100/100 [==============================] - 0s 541us/step - loss: 0.6192 - acc: 0.6900 - val_loss: 0.6580 - val_acc: 0.6400\n",
            "Epoch 270/4500\n",
            "100/100 [==============================] - 0s 544us/step - loss: 0.6192 - acc: 0.6900 - val_loss: 0.6587 - val_acc: 0.6400\n",
            "Epoch 271/4500\n",
            "100/100 [==============================] - 0s 643us/step - loss: 0.6209 - acc: 0.6900 - val_loss: 0.6569 - val_acc: 0.6400\n",
            "Epoch 272/4500\n",
            "100/100 [==============================] - 0s 538us/step - loss: 0.6198 - acc: 0.6900 - val_loss: 0.6586 - val_acc: 0.6400\n",
            "Epoch 273/4500\n",
            "100/100 [==============================] - 0s 534us/step - loss: 0.6202 - acc: 0.6900 - val_loss: 0.6598 - val_acc: 0.6400\n",
            "Epoch 274/4500\n",
            "100/100 [==============================] - 0s 528us/step - loss: 0.6200 - acc: 0.6900 - val_loss: 0.6589 - val_acc: 0.6400\n",
            "Epoch 275/4500\n",
            "100/100 [==============================] - 0s 530us/step - loss: 0.6200 - acc: 0.6900 - val_loss: 0.6594 - val_acc: 0.6400\n",
            "Epoch 276/4500\n",
            "100/100 [==============================] - 0s 547us/step - loss: 0.6199 - acc: 0.6900 - val_loss: 0.6579 - val_acc: 0.6400\n",
            "Epoch 277/4500\n",
            "100/100 [==============================] - 0s 574us/step - loss: 0.6211 - acc: 0.6900 - val_loss: 0.6569 - val_acc: 0.6400\n",
            "Epoch 278/4500\n",
            "100/100 [==============================] - 0s 606us/step - loss: 0.6191 - acc: 0.6900 - val_loss: 0.6578 - val_acc: 0.6400\n",
            "Epoch 279/4500\n",
            "100/100 [==============================] - 0s 562us/step - loss: 0.6198 - acc: 0.6900 - val_loss: 0.6594 - val_acc: 0.6400\n",
            "Epoch 280/4500\n",
            "100/100 [==============================] - 0s 532us/step - loss: 0.6193 - acc: 0.6900 - val_loss: 0.6590 - val_acc: 0.6400\n",
            "Epoch 281/4500\n",
            "100/100 [==============================] - 0s 529us/step - loss: 0.6201 - acc: 0.6900 - val_loss: 0.6577 - val_acc: 0.6400\n",
            "Epoch 282/4500\n",
            "100/100 [==============================] - 0s 531us/step - loss: 0.6195 - acc: 0.6900 - val_loss: 0.6581 - val_acc: 0.6400\n",
            "Epoch 283/4500\n",
            "100/100 [==============================] - 0s 517us/step - loss: 0.6191 - acc: 0.6900 - val_loss: 0.6595 - val_acc: 0.6400\n",
            "Epoch 284/4500\n",
            "100/100 [==============================] - 0s 567us/step - loss: 0.6197 - acc: 0.6900 - val_loss: 0.6601 - val_acc: 0.6400\n",
            "Epoch 285/4500\n",
            "100/100 [==============================] - 0s 562us/step - loss: 0.6199 - acc: 0.6900 - val_loss: 0.6605 - val_acc: 0.6400\n",
            "Epoch 286/4500\n",
            "100/100 [==============================] - 0s 540us/step - loss: 0.6205 - acc: 0.6900 - val_loss: 0.6588 - val_acc: 0.6400\n",
            "Epoch 287/4500\n",
            "100/100 [==============================] - 0s 571us/step - loss: 0.6200 - acc: 0.6900 - val_loss: 0.6595 - val_acc: 0.6400\n",
            "Epoch 288/4500\n",
            "100/100 [==============================] - 0s 544us/step - loss: 0.6200 - acc: 0.6900 - val_loss: 0.6572 - val_acc: 0.6400\n",
            "Epoch 289/4500\n",
            "100/100 [==============================] - 0s 605us/step - loss: 0.6194 - acc: 0.6900 - val_loss: 0.6575 - val_acc: 0.6400\n",
            "Epoch 290/4500\n",
            "100/100 [==============================] - 0s 500us/step - loss: 0.6204 - acc: 0.6900 - val_loss: 0.6588 - val_acc: 0.6400\n",
            "Epoch 291/4500\n",
            "100/100 [==============================] - 0s 540us/step - loss: 0.6191 - acc: 0.6900 - val_loss: 0.6584 - val_acc: 0.6400\n",
            "Epoch 292/4500\n",
            "100/100 [==============================] - 0s 533us/step - loss: 0.6191 - acc: 0.6900 - val_loss: 0.6582 - val_acc: 0.6400\n",
            "Epoch 293/4500\n",
            "100/100 [==============================] - 0s 536us/step - loss: 0.6192 - acc: 0.6900 - val_loss: 0.6587 - val_acc: 0.6400\n",
            "Epoch 294/4500\n",
            "100/100 [==============================] - 0s 550us/step - loss: 0.6197 - acc: 0.6900 - val_loss: 0.6580 - val_acc: 0.6400\n",
            "Epoch 295/4500\n",
            "100/100 [==============================] - 0s 586us/step - loss: 0.6192 - acc: 0.6900 - val_loss: 0.6581 - val_acc: 0.6400\n",
            "Epoch 296/4500\n",
            "100/100 [==============================] - 0s 601us/step - loss: 0.6195 - acc: 0.6900 - val_loss: 0.6582 - val_acc: 0.6400\n",
            "Epoch 297/4500\n",
            "100/100 [==============================] - 0s 533us/step - loss: 0.6198 - acc: 0.6900 - val_loss: 0.6598 - val_acc: 0.6400\n",
            "Epoch 298/4500\n",
            "100/100 [==============================] - 0s 542us/step - loss: 0.6194 - acc: 0.6900 - val_loss: 0.6589 - val_acc: 0.6400\n",
            "Epoch 299/4500\n",
            "100/100 [==============================] - 0s 518us/step - loss: 0.6195 - acc: 0.6900 - val_loss: 0.6583 - val_acc: 0.6400\n",
            "Epoch 300/4500\n",
            "100/100 [==============================] - 0s 519us/step - loss: 0.6210 - acc: 0.6900 - val_loss: 0.6584 - val_acc: 0.6400\n",
            "Epoch 301/4500\n",
            "100/100 [==============================] - 0s 604us/step - loss: 0.6197 - acc: 0.6900 - val_loss: 0.6593 - val_acc: 0.6400\n",
            "Epoch 302/4500\n",
            "100/100 [==============================] - 0s 646us/step - loss: 0.6198 - acc: 0.6900 - val_loss: 0.6594 - val_acc: 0.6400\n",
            "Epoch 303/4500\n",
            "100/100 [==============================] - 0s 590us/step - loss: 0.6193 - acc: 0.6900 - val_loss: 0.6589 - val_acc: 0.6400\n",
            "Epoch 304/4500\n",
            "100/100 [==============================] - 0s 557us/step - loss: 0.6195 - acc: 0.6900 - val_loss: 0.6591 - val_acc: 0.6400\n",
            "Epoch 305/4500\n",
            "100/100 [==============================] - 0s 536us/step - loss: 0.6195 - acc: 0.6900 - val_loss: 0.6582 - val_acc: 0.6400\n",
            "Epoch 306/4500\n",
            "100/100 [==============================] - 0s 603us/step - loss: 0.6195 - acc: 0.6900 - val_loss: 0.6585 - val_acc: 0.6400\n",
            "Epoch 307/4500\n",
            "100/100 [==============================] - 0s 566us/step - loss: 0.6192 - acc: 0.6900 - val_loss: 0.6578 - val_acc: 0.6400\n",
            "Epoch 308/4500\n",
            "100/100 [==============================] - 0s 554us/step - loss: 0.6205 - acc: 0.6900 - val_loss: 0.6578 - val_acc: 0.6400\n",
            "Epoch 309/4500\n",
            "100/100 [==============================] - 0s 527us/step - loss: 0.6198 - acc: 0.6900 - val_loss: 0.6589 - val_acc: 0.6400\n",
            "Epoch 310/4500\n",
            "100/100 [==============================] - 0s 495us/step - loss: 0.6193 - acc: 0.6900 - val_loss: 0.6590 - val_acc: 0.6400\n",
            "Epoch 311/4500\n",
            "100/100 [==============================] - 0s 537us/step - loss: 0.6198 - acc: 0.6900 - val_loss: 0.6598 - val_acc: 0.6400\n",
            "Epoch 312/4500\n",
            "100/100 [==============================] - 0s 574us/step - loss: 0.6195 - acc: 0.6900 - val_loss: 0.6588 - val_acc: 0.6400\n",
            "Epoch 313/4500\n",
            "100/100 [==============================] - 0s 542us/step - loss: 0.6193 - acc: 0.6900 - val_loss: 0.6579 - val_acc: 0.6400\n",
            "Epoch 314/4500\n",
            "100/100 [==============================] - 0s 714us/step - loss: 0.6204 - acc: 0.6900 - val_loss: 0.6567 - val_acc: 0.6400\n",
            "Epoch 315/4500\n",
            "100/100 [==============================] - 0s 591us/step - loss: 0.6205 - acc: 0.6900 - val_loss: 0.6589 - val_acc: 0.6400\n",
            "Epoch 316/4500\n",
            "100/100 [==============================] - 0s 567us/step - loss: 0.6197 - acc: 0.6900 - val_loss: 0.6580 - val_acc: 0.6400\n",
            "Epoch 317/4500\n",
            "100/100 [==============================] - 0s 555us/step - loss: 0.6194 - acc: 0.6900 - val_loss: 0.6593 - val_acc: 0.6400\n",
            "Epoch 318/4500\n",
            "100/100 [==============================] - 0s 501us/step - loss: 0.6193 - acc: 0.6900 - val_loss: 0.6584 - val_acc: 0.6400\n",
            "Epoch 319/4500\n",
            "100/100 [==============================] - 0s 535us/step - loss: 0.6197 - acc: 0.6900 - val_loss: 0.6597 - val_acc: 0.6400\n",
            "Epoch 320/4500\n",
            "100/100 [==============================] - 0s 509us/step - loss: 0.6197 - acc: 0.6900 - val_loss: 0.6586 - val_acc: 0.6400\n",
            "Epoch 321/4500\n",
            "100/100 [==============================] - 0s 525us/step - loss: 0.6199 - acc: 0.6900 - val_loss: 0.6582 - val_acc: 0.6400\n",
            "Epoch 322/4500\n",
            "100/100 [==============================] - 0s 542us/step - loss: 0.6194 - acc: 0.6900 - val_loss: 0.6578 - val_acc: 0.6400\n",
            "Epoch 323/4500\n",
            "100/100 [==============================] - 0s 566us/step - loss: 0.6191 - acc: 0.6900 - val_loss: 0.6582 - val_acc: 0.6400\n",
            "Epoch 324/4500\n",
            "100/100 [==============================] - 0s 658us/step - loss: 0.6198 - acc: 0.6900 - val_loss: 0.6584 - val_acc: 0.6400\n",
            "Epoch 325/4500\n",
            "100/100 [==============================] - 0s 569us/step - loss: 0.6192 - acc: 0.6900 - val_loss: 0.6591 - val_acc: 0.6400\n",
            "Epoch 326/4500\n",
            "100/100 [==============================] - 0s 596us/step - loss: 0.6193 - acc: 0.6900 - val_loss: 0.6582 - val_acc: 0.6400\n",
            "Epoch 327/4500\n",
            "100/100 [==============================] - 0s 630us/step - loss: 0.6197 - acc: 0.6900 - val_loss: 0.6586 - val_acc: 0.6400\n",
            "Epoch 328/4500\n",
            "100/100 [==============================] - 0s 587us/step - loss: 0.6205 - acc: 0.6900 - val_loss: 0.6594 - val_acc: 0.6400\n",
            "Epoch 329/4500\n",
            "100/100 [==============================] - 0s 605us/step - loss: 0.6191 - acc: 0.6900 - val_loss: 0.6588 - val_acc: 0.6400\n",
            "Epoch 330/4500\n",
            "100/100 [==============================] - 0s 573us/step - loss: 0.6192 - acc: 0.6900 - val_loss: 0.6579 - val_acc: 0.6400\n",
            "Epoch 331/4500\n",
            "100/100 [==============================] - 0s 666us/step - loss: 0.6197 - acc: 0.6900 - val_loss: 0.6574 - val_acc: 0.6400\n",
            "Epoch 332/4500\n",
            "100/100 [==============================] - 0s 605us/step - loss: 0.6199 - acc: 0.6900 - val_loss: 0.6591 - val_acc: 0.6400\n",
            "Epoch 333/4500\n",
            "100/100 [==============================] - 0s 555us/step - loss: 0.6200 - acc: 0.6900 - val_loss: 0.6589 - val_acc: 0.6400\n",
            "Epoch 334/4500\n",
            "100/100 [==============================] - 0s 516us/step - loss: 0.6193 - acc: 0.6900 - val_loss: 0.6577 - val_acc: 0.6400\n",
            "Epoch 335/4500\n",
            "100/100 [==============================] - 0s 494us/step - loss: 0.6207 - acc: 0.6900 - val_loss: 0.6591 - val_acc: 0.6400\n",
            "Epoch 336/4500\n",
            "100/100 [==============================] - 0s 520us/step - loss: 0.6191 - acc: 0.6900 - val_loss: 0.6578 - val_acc: 0.6400\n",
            "Epoch 337/4500\n",
            "100/100 [==============================] - 0s 537us/step - loss: 0.6199 - acc: 0.6900 - val_loss: 0.6588 - val_acc: 0.6400\n",
            "Epoch 338/4500\n",
            "100/100 [==============================] - 0s 523us/step - loss: 0.6213 - acc: 0.6900 - val_loss: 0.6567 - val_acc: 0.6400\n",
            "Epoch 339/4500\n",
            "100/100 [==============================] - 0s 549us/step - loss: 0.6205 - acc: 0.6900 - val_loss: 0.6563 - val_acc: 0.6400\n",
            "Epoch 340/4500\n",
            "100/100 [==============================] - 0s 627us/step - loss: 0.6196 - acc: 0.6900 - val_loss: 0.6588 - val_acc: 0.6400\n",
            "Epoch 341/4500\n",
            "100/100 [==============================] - 0s 647us/step - loss: 0.6195 - acc: 0.6900 - val_loss: 0.6591 - val_acc: 0.6400\n",
            "Epoch 342/4500\n",
            "100/100 [==============================] - 0s 644us/step - loss: 0.6196 - acc: 0.6900 - val_loss: 0.6588 - val_acc: 0.6400\n",
            "Epoch 343/4500\n",
            "100/100 [==============================] - 0s 604us/step - loss: 0.6193 - acc: 0.6900 - val_loss: 0.6592 - val_acc: 0.6400\n",
            "Epoch 344/4500\n",
            "100/100 [==============================] - 0s 558us/step - loss: 0.6199 - acc: 0.6900 - val_loss: 0.6594 - val_acc: 0.6400\n",
            "Epoch 345/4500\n",
            "100/100 [==============================] - 0s 569us/step - loss: 0.6206 - acc: 0.6900 - val_loss: 0.6603 - val_acc: 0.6400\n",
            "Epoch 346/4500\n",
            "100/100 [==============================] - 0s 601us/step - loss: 0.6197 - acc: 0.6900 - val_loss: 0.6588 - val_acc: 0.6400\n",
            "Epoch 347/4500\n",
            "100/100 [==============================] - 0s 564us/step - loss: 0.6201 - acc: 0.6900 - val_loss: 0.6569 - val_acc: 0.6400\n",
            "Epoch 348/4500\n",
            "100/100 [==============================] - 0s 585us/step - loss: 0.6204 - acc: 0.6900 - val_loss: 0.6580 - val_acc: 0.6400\n",
            "Epoch 349/4500\n",
            "100/100 [==============================] - 0s 565us/step - loss: 0.6198 - acc: 0.6900 - val_loss: 0.6583 - val_acc: 0.6400\n",
            "Epoch 350/4500\n",
            "100/100 [==============================] - 0s 690us/step - loss: 0.6199 - acc: 0.6900 - val_loss: 0.6571 - val_acc: 0.6400\n",
            "Epoch 351/4500\n",
            "100/100 [==============================] - 0s 557us/step - loss: 0.6193 - acc: 0.6900 - val_loss: 0.6579 - val_acc: 0.6400\n",
            "Epoch 352/4500\n",
            "100/100 [==============================] - 0s 584us/step - loss: 0.6207 - acc: 0.6900 - val_loss: 0.6565 - val_acc: 0.6400\n",
            "Epoch 353/4500\n",
            "100/100 [==============================] - 0s 579us/step - loss: 0.6194 - acc: 0.6900 - val_loss: 0.6583 - val_acc: 0.6400\n",
            "Epoch 354/4500\n",
            "100/100 [==============================] - 0s 536us/step - loss: 0.6198 - acc: 0.6900 - val_loss: 0.6582 - val_acc: 0.6400\n",
            "Epoch 355/4500\n",
            "100/100 [==============================] - 0s 602us/step - loss: 0.6198 - acc: 0.6900 - val_loss: 0.6595 - val_acc: 0.6400\n",
            "Epoch 356/4500\n",
            "100/100 [==============================] - 0s 536us/step - loss: 0.6204 - acc: 0.6900 - val_loss: 0.6606 - val_acc: 0.6400\n",
            "Epoch 357/4500\n",
            "100/100 [==============================] - 0s 522us/step - loss: 0.6201 - acc: 0.6900 - val_loss: 0.6580 - val_acc: 0.6400\n",
            "Epoch 358/4500\n",
            "100/100 [==============================] - 0s 515us/step - loss: 0.6211 - acc: 0.6900 - val_loss: 0.6598 - val_acc: 0.6400\n",
            "Epoch 359/4500\n",
            "100/100 [==============================] - 0s 608us/step - loss: 0.6198 - acc: 0.6900 - val_loss: 0.6585 - val_acc: 0.6400\n",
            "Epoch 360/4500\n",
            "100/100 [==============================] - 0s 615us/step - loss: 0.6207 - acc: 0.6900 - val_loss: 0.6566 - val_acc: 0.6400\n",
            "Epoch 361/4500\n",
            "100/100 [==============================] - 0s 503us/step - loss: 0.6199 - acc: 0.6900 - val_loss: 0.6577 - val_acc: 0.6400\n",
            "Epoch 362/4500\n",
            "100/100 [==============================] - 0s 518us/step - loss: 0.6196 - acc: 0.6900 - val_loss: 0.6590 - val_acc: 0.6400\n",
            "Epoch 363/4500\n",
            "100/100 [==============================] - 0s 492us/step - loss: 0.6216 - acc: 0.6900 - val_loss: 0.6572 - val_acc: 0.6400\n",
            "Epoch 364/4500\n",
            "100/100 [==============================] - 0s 517us/step - loss: 0.6193 - acc: 0.6900 - val_loss: 0.6586 - val_acc: 0.6400\n",
            "Epoch 365/4500\n",
            "100/100 [==============================] - 0s 510us/step - loss: 0.6195 - acc: 0.6900 - val_loss: 0.6591 - val_acc: 0.6400\n",
            "Epoch 366/4500\n",
            "100/100 [==============================] - 0s 540us/step - loss: 0.6195 - acc: 0.6900 - val_loss: 0.6582 - val_acc: 0.6400\n",
            "Epoch 367/4500\n",
            "100/100 [==============================] - 0s 501us/step - loss: 0.6204 - acc: 0.6900 - val_loss: 0.6577 - val_acc: 0.6400\n",
            "Epoch 368/4500\n",
            "100/100 [==============================] - 0s 510us/step - loss: 0.6195 - acc: 0.6900 - val_loss: 0.6593 - val_acc: 0.6400\n",
            "Epoch 369/4500\n",
            "100/100 [==============================] - 0s 502us/step - loss: 0.6193 - acc: 0.6900 - val_loss: 0.6588 - val_acc: 0.6400\n",
            "Epoch 370/4500\n",
            "100/100 [==============================] - 0s 530us/step - loss: 0.6196 - acc: 0.6900 - val_loss: 0.6598 - val_acc: 0.6400\n",
            "Epoch 371/4500\n",
            "100/100 [==============================] - 0s 554us/step - loss: 0.6194 - acc: 0.6900 - val_loss: 0.6599 - val_acc: 0.6400\n",
            "Epoch 372/4500\n",
            "100/100 [==============================] - 0s 520us/step - loss: 0.6204 - acc: 0.6900 - val_loss: 0.6574 - val_acc: 0.6400\n",
            "Epoch 373/4500\n",
            "100/100 [==============================] - 0s 610us/step - loss: 0.6194 - acc: 0.6900 - val_loss: 0.6578 - val_acc: 0.6400\n",
            "Epoch 374/4500\n",
            "100/100 [==============================] - 0s 554us/step - loss: 0.6199 - acc: 0.6900 - val_loss: 0.6576 - val_acc: 0.6400\n",
            "Epoch 375/4500\n",
            "100/100 [==============================] - 0s 524us/step - loss: 0.6209 - acc: 0.6900 - val_loss: 0.6600 - val_acc: 0.6400\n",
            "Epoch 376/4500\n",
            "100/100 [==============================] - 0s 548us/step - loss: 0.6195 - acc: 0.6900 - val_loss: 0.6583 - val_acc: 0.6400\n",
            "Epoch 377/4500\n",
            "100/100 [==============================] - 0s 541us/step - loss: 0.6190 - acc: 0.6900 - val_loss: 0.6587 - val_acc: 0.6400\n",
            "Epoch 378/4500\n",
            "100/100 [==============================] - 0s 526us/step - loss: 0.6191 - acc: 0.6900 - val_loss: 0.6584 - val_acc: 0.6400\n",
            "Epoch 379/4500\n",
            "100/100 [==============================] - 0s 488us/step - loss: 0.6191 - acc: 0.6900 - val_loss: 0.6584 - val_acc: 0.6400\n",
            "Epoch 380/4500\n",
            "100/100 [==============================] - 0s 508us/step - loss: 0.6192 - acc: 0.6900 - val_loss: 0.6589 - val_acc: 0.6400\n",
            "Epoch 381/4500\n",
            "100/100 [==============================] - 0s 498us/step - loss: 0.6190 - acc: 0.6900 - val_loss: 0.6584 - val_acc: 0.6400\n",
            "Epoch 382/4500\n",
            "100/100 [==============================] - 0s 496us/step - loss: 0.6194 - acc: 0.6900 - val_loss: 0.6581 - val_acc: 0.6400\n",
            "Epoch 383/4500\n",
            "100/100 [==============================] - 0s 519us/step - loss: 0.6191 - acc: 0.6900 - val_loss: 0.6580 - val_acc: 0.6400\n",
            "Epoch 384/4500\n",
            "100/100 [==============================] - 0s 488us/step - loss: 0.6198 - acc: 0.6900 - val_loss: 0.6596 - val_acc: 0.6400\n",
            "Epoch 385/4500\n",
            "100/100 [==============================] - 0s 493us/step - loss: 0.6193 - acc: 0.6900 - val_loss: 0.6598 - val_acc: 0.6400\n",
            "Epoch 386/4500\n",
            "100/100 [==============================] - 0s 527us/step - loss: 0.6192 - acc: 0.6900 - val_loss: 0.6586 - val_acc: 0.6400\n",
            "Epoch 387/4500\n",
            "100/100 [==============================] - 0s 519us/step - loss: 0.6190 - acc: 0.6900 - val_loss: 0.6577 - val_acc: 0.6400\n",
            "Epoch 388/4500\n",
            "100/100 [==============================] - 0s 535us/step - loss: 0.6202 - acc: 0.6900 - val_loss: 0.6587 - val_acc: 0.6400\n",
            "Epoch 389/4500\n",
            "100/100 [==============================] - 0s 525us/step - loss: 0.6193 - acc: 0.6900 - val_loss: 0.6588 - val_acc: 0.6400\n",
            "Epoch 390/4500\n",
            "100/100 [==============================] - 0s 515us/step - loss: 0.6198 - acc: 0.6900 - val_loss: 0.6573 - val_acc: 0.6400\n",
            "Epoch 391/4500\n",
            "100/100 [==============================] - 0s 500us/step - loss: 0.6194 - acc: 0.6900 - val_loss: 0.6572 - val_acc: 0.6400\n",
            "Epoch 392/4500\n",
            "100/100 [==============================] - 0s 519us/step - loss: 0.6191 - acc: 0.6900 - val_loss: 0.6586 - val_acc: 0.6400\n",
            "Epoch 393/4500\n",
            "100/100 [==============================] - 0s 581us/step - loss: 0.6199 - acc: 0.6900 - val_loss: 0.6580 - val_acc: 0.6400\n",
            "Epoch 394/4500\n",
            "100/100 [==============================] - 0s 498us/step - loss: 0.6194 - acc: 0.6900 - val_loss: 0.6587 - val_acc: 0.6400\n",
            "Epoch 395/4500\n",
            "100/100 [==============================] - 0s 558us/step - loss: 0.6191 - acc: 0.6900 - val_loss: 0.6592 - val_acc: 0.6400\n",
            "Epoch 396/4500\n",
            "100/100 [==============================] - 0s 491us/step - loss: 0.6191 - acc: 0.6900 - val_loss: 0.6585 - val_acc: 0.6400\n",
            "Epoch 397/4500\n",
            "100/100 [==============================] - 0s 597us/step - loss: 0.6196 - acc: 0.6900 - val_loss: 0.6591 - val_acc: 0.6400\n",
            "Epoch 398/4500\n",
            "100/100 [==============================] - 0s 517us/step - loss: 0.6198 - acc: 0.6900 - val_loss: 0.6583 - val_acc: 0.6400\n",
            "Epoch 399/4500\n",
            "100/100 [==============================] - 0s 509us/step - loss: 0.6194 - acc: 0.6900 - val_loss: 0.6585 - val_acc: 0.6400\n",
            "Epoch 400/4500\n",
            "100/100 [==============================] - 0s 489us/step - loss: 0.6201 - acc: 0.6900 - val_loss: 0.6576 - val_acc: 0.6400\n",
            "Epoch 401/4500\n",
            "100/100 [==============================] - 0s 530us/step - loss: 0.6194 - acc: 0.6900 - val_loss: 0.6581 - val_acc: 0.6400\n",
            "Epoch 402/4500\n",
            "100/100 [==============================] - 0s 519us/step - loss: 0.6196 - acc: 0.6900 - val_loss: 0.6578 - val_acc: 0.6400\n",
            "Epoch 403/4500\n",
            "100/100 [==============================] - 0s 514us/step - loss: 0.6191 - acc: 0.6900 - val_loss: 0.6598 - val_acc: 0.6400\n",
            "Epoch 404/4500\n",
            "100/100 [==============================] - 0s 494us/step - loss: 0.6189 - acc: 0.6900 - val_loss: 0.6599 - val_acc: 0.6400\n",
            "Epoch 405/4500\n",
            "100/100 [==============================] - 0s 519us/step - loss: 0.6192 - acc: 0.6900 - val_loss: 0.6591 - val_acc: 0.6400\n",
            "Epoch 406/4500\n",
            "100/100 [==============================] - 0s 520us/step - loss: 0.6193 - acc: 0.6900 - val_loss: 0.6582 - val_acc: 0.6400\n",
            "Epoch 407/4500\n",
            "100/100 [==============================] - 0s 630us/step - loss: 0.6190 - acc: 0.6900 - val_loss: 0.6582 - val_acc: 0.6400\n",
            "Epoch 408/4500\n",
            "100/100 [==============================] - 0s 588us/step - loss: 0.6199 - acc: 0.6900 - val_loss: 0.6579 - val_acc: 0.6400\n",
            "Epoch 409/4500\n",
            "100/100 [==============================] - 0s 561us/step - loss: 0.6189 - acc: 0.6900 - val_loss: 0.6592 - val_acc: 0.6400\n",
            "Epoch 410/4500\n",
            "100/100 [==============================] - 0s 517us/step - loss: 0.6198 - acc: 0.6900 - val_loss: 0.6603 - val_acc: 0.6400\n",
            "Epoch 411/4500\n",
            "100/100 [==============================] - 0s 533us/step - loss: 0.6188 - acc: 0.6900 - val_loss: 0.6597 - val_acc: 0.6400\n",
            "Epoch 412/4500\n",
            "100/100 [==============================] - 0s 506us/step - loss: 0.6193 - acc: 0.6900 - val_loss: 0.6585 - val_acc: 0.6400\n",
            "Epoch 413/4500\n",
            "100/100 [==============================] - 0s 491us/step - loss: 0.6192 - acc: 0.6900 - val_loss: 0.6588 - val_acc: 0.6400\n",
            "Epoch 414/4500\n",
            "100/100 [==============================] - 0s 550us/step - loss: 0.6197 - acc: 0.6900 - val_loss: 0.6578 - val_acc: 0.6400\n",
            "Epoch 415/4500\n",
            "100/100 [==============================] - 0s 558us/step - loss: 0.6189 - acc: 0.6900 - val_loss: 0.6584 - val_acc: 0.6400\n",
            "Epoch 416/4500\n",
            "100/100 [==============================] - 0s 529us/step - loss: 0.6207 - acc: 0.6900 - val_loss: 0.6603 - val_acc: 0.6400\n",
            "Epoch 417/4500\n",
            "100/100 [==============================] - 0s 507us/step - loss: 0.6194 - acc: 0.6900 - val_loss: 0.6585 - val_acc: 0.6400\n",
            "Epoch 418/4500\n",
            "100/100 [==============================] - 0s 503us/step - loss: 0.6196 - acc: 0.6900 - val_loss: 0.6590 - val_acc: 0.6400\n",
            "Epoch 419/4500\n",
            "100/100 [==============================] - 0s 549us/step - loss: 0.6197 - acc: 0.6900 - val_loss: 0.6576 - val_acc: 0.6400\n",
            "Epoch 420/4500\n",
            "100/100 [==============================] - 0s 498us/step - loss: 0.6195 - acc: 0.6900 - val_loss: 0.6571 - val_acc: 0.6400\n",
            "Epoch 421/4500\n",
            "100/100 [==============================] - 0s 493us/step - loss: 0.6198 - acc: 0.6900 - val_loss: 0.6589 - val_acc: 0.6400\n",
            "Epoch 422/4500\n",
            "100/100 [==============================] - 0s 496us/step - loss: 0.6192 - acc: 0.6900 - val_loss: 0.6580 - val_acc: 0.6400\n",
            "Epoch 423/4500\n",
            "100/100 [==============================] - 0s 550us/step - loss: 0.6198 - acc: 0.6900 - val_loss: 0.6587 - val_acc: 0.6400\n",
            "Epoch 424/4500\n",
            "100/100 [==============================] - 0s 485us/step - loss: 0.6191 - acc: 0.6900 - val_loss: 0.6589 - val_acc: 0.6400\n",
            "Epoch 425/4500\n",
            "100/100 [==============================] - 0s 509us/step - loss: 0.6198 - acc: 0.6900 - val_loss: 0.6596 - val_acc: 0.6400\n",
            "Epoch 426/4500\n",
            "100/100 [==============================] - 0s 596us/step - loss: 0.6195 - acc: 0.6900 - val_loss: 0.6577 - val_acc: 0.6400\n",
            "Epoch 427/4500\n",
            "100/100 [==============================] - 0s 489us/step - loss: 0.6209 - acc: 0.6900 - val_loss: 0.6593 - val_acc: 0.6400\n",
            "Epoch 428/4500\n",
            "100/100 [==============================] - 0s 494us/step - loss: 0.6190 - acc: 0.6900 - val_loss: 0.6584 - val_acc: 0.6400\n",
            "Epoch 429/4500\n",
            "100/100 [==============================] - 0s 497us/step - loss: 0.6199 - acc: 0.6900 - val_loss: 0.6577 - val_acc: 0.6400\n",
            "Epoch 430/4500\n",
            "100/100 [==============================] - 0s 520us/step - loss: 0.6195 - acc: 0.6900 - val_loss: 0.6571 - val_acc: 0.6400\n",
            "Epoch 431/4500\n",
            "100/100 [==============================] - 0s 537us/step - loss: 0.6192 - acc: 0.6900 - val_loss: 0.6579 - val_acc: 0.6400\n",
            "Epoch 432/4500\n",
            "100/100 [==============================] - 0s 516us/step - loss: 0.6196 - acc: 0.6900 - val_loss: 0.6594 - val_acc: 0.6400\n",
            "Epoch 433/4500\n",
            "100/100 [==============================] - 0s 533us/step - loss: 0.6203 - acc: 0.6900 - val_loss: 0.6573 - val_acc: 0.6400\n",
            "Epoch 434/4500\n",
            "100/100 [==============================] - 0s 556us/step - loss: 0.6198 - acc: 0.6900 - val_loss: 0.6572 - val_acc: 0.6400\n",
            "Epoch 435/4500\n",
            "100/100 [==============================] - 0s 611us/step - loss: 0.6194 - acc: 0.6900 - val_loss: 0.6580 - val_acc: 0.6400\n",
            "Epoch 436/4500\n",
            "100/100 [==============================] - 0s 550us/step - loss: 0.6193 - acc: 0.6900 - val_loss: 0.6593 - val_acc: 0.6400\n",
            "Epoch 437/4500\n",
            "100/100 [==============================] - 0s 536us/step - loss: 0.6190 - acc: 0.6900 - val_loss: 0.6588 - val_acc: 0.6400\n",
            "Epoch 438/4500\n",
            "100/100 [==============================] - 0s 518us/step - loss: 0.6195 - acc: 0.6900 - val_loss: 0.6589 - val_acc: 0.6400\n",
            "Epoch 439/4500\n",
            "100/100 [==============================] - 0s 590us/step - loss: 0.6191 - acc: 0.6900 - val_loss: 0.6590 - val_acc: 0.6400\n",
            "Epoch 440/4500\n",
            "100/100 [==============================] - 0s 594us/step - loss: 0.6190 - acc: 0.6900 - val_loss: 0.6589 - val_acc: 0.6400\n",
            "Epoch 441/4500\n",
            "100/100 [==============================] - 0s 545us/step - loss: 0.6190 - acc: 0.6900 - val_loss: 0.6592 - val_acc: 0.6400\n",
            "Epoch 442/4500\n",
            "100/100 [==============================] - 0s 508us/step - loss: 0.6190 - acc: 0.6900 - val_loss: 0.6584 - val_acc: 0.6400\n",
            "Epoch 443/4500\n",
            "100/100 [==============================] - 0s 558us/step - loss: 0.6200 - acc: 0.6900 - val_loss: 0.6579 - val_acc: 0.6400\n",
            "Epoch 444/4500\n",
            "100/100 [==============================] - 0s 605us/step - loss: 0.6192 - acc: 0.6900 - val_loss: 0.6591 - val_acc: 0.6400\n",
            "Epoch 445/4500\n",
            "100/100 [==============================] - 0s 597us/step - loss: 0.6195 - acc: 0.6900 - val_loss: 0.6600 - val_acc: 0.6400\n",
            "Epoch 446/4500\n",
            "100/100 [==============================] - 0s 606us/step - loss: 0.6198 - acc: 0.6900 - val_loss: 0.6594 - val_acc: 0.6400\n",
            "Epoch 447/4500\n",
            "100/100 [==============================] - 0s 533us/step - loss: 0.6197 - acc: 0.6900 - val_loss: 0.6592 - val_acc: 0.6400\n",
            "Epoch 448/4500\n",
            "100/100 [==============================] - 0s 530us/step - loss: 0.6188 - acc: 0.6900 - val_loss: 0.6578 - val_acc: 0.6400\n",
            "Epoch 449/4500\n",
            "100/100 [==============================] - 0s 516us/step - loss: 0.6192 - acc: 0.6900 - val_loss: 0.6572 - val_acc: 0.6400\n",
            "Epoch 450/4500\n",
            "100/100 [==============================] - 0s 525us/step - loss: 0.6192 - acc: 0.6900 - val_loss: 0.6576 - val_acc: 0.6400\n",
            "Epoch 451/4500\n",
            "100/100 [==============================] - 0s 496us/step - loss: 0.6191 - acc: 0.6900 - val_loss: 0.6580 - val_acc: 0.6400\n",
            "Epoch 452/4500\n",
            "100/100 [==============================] - 0s 519us/step - loss: 0.6203 - acc: 0.6900 - val_loss: 0.6569 - val_acc: 0.6400\n",
            "Epoch 453/4500\n",
            "100/100 [==============================] - 0s 636us/step - loss: 0.6189 - acc: 0.6900 - val_loss: 0.6580 - val_acc: 0.6400\n",
            "Epoch 454/4500\n",
            "100/100 [==============================] - 0s 547us/step - loss: 0.6196 - acc: 0.6900 - val_loss: 0.6598 - val_acc: 0.6400\n",
            "Epoch 455/4500\n",
            "100/100 [==============================] - 0s 511us/step - loss: 0.6190 - acc: 0.6900 - val_loss: 0.6591 - val_acc: 0.6400\n",
            "Epoch 456/4500\n",
            "100/100 [==============================] - 0s 517us/step - loss: 0.6195 - acc: 0.6900 - val_loss: 0.6583 - val_acc: 0.6400\n",
            "Epoch 457/4500\n",
            "100/100 [==============================] - 0s 512us/step - loss: 0.6195 - acc: 0.6900 - val_loss: 0.6590 - val_acc: 0.6400\n",
            "Epoch 458/4500\n",
            "100/100 [==============================] - 0s 508us/step - loss: 0.6189 - acc: 0.6900 - val_loss: 0.6593 - val_acc: 0.6400\n",
            "Epoch 459/4500\n",
            "100/100 [==============================] - 0s 508us/step - loss: 0.6204 - acc: 0.6900 - val_loss: 0.6576 - val_acc: 0.6400\n",
            "Epoch 460/4500\n",
            "100/100 [==============================] - 0s 517us/step - loss: 0.6195 - acc: 0.6900 - val_loss: 0.6590 - val_acc: 0.6400\n",
            "Epoch 461/4500\n",
            "100/100 [==============================] - 0s 520us/step - loss: 0.6191 - acc: 0.6900 - val_loss: 0.6584 - val_acc: 0.6400\n",
            "Epoch 462/4500\n",
            "100/100 [==============================] - 0s 523us/step - loss: 0.6199 - acc: 0.6900 - val_loss: 0.6580 - val_acc: 0.6400\n",
            "Epoch 463/4500\n",
            "100/100 [==============================] - 0s 512us/step - loss: 0.6195 - acc: 0.6900 - val_loss: 0.6590 - val_acc: 0.6400\n",
            "Epoch 464/4500\n",
            "100/100 [==============================] - 0s 554us/step - loss: 0.6203 - acc: 0.6900 - val_loss: 0.6575 - val_acc: 0.6400\n",
            "Epoch 465/4500\n",
            "100/100 [==============================] - 0s 549us/step - loss: 0.6188 - acc: 0.6900 - val_loss: 0.6580 - val_acc: 0.6400\n",
            "Epoch 466/4500\n",
            "100/100 [==============================] - 0s 508us/step - loss: 0.6192 - acc: 0.6900 - val_loss: 0.6586 - val_acc: 0.6400\n",
            "Epoch 467/4500\n",
            "100/100 [==============================] - 0s 507us/step - loss: 0.6196 - acc: 0.6900 - val_loss: 0.6589 - val_acc: 0.6400\n",
            "Epoch 468/4500\n",
            "100/100 [==============================] - 0s 516us/step - loss: 0.6193 - acc: 0.6900 - val_loss: 0.6583 - val_acc: 0.6400\n",
            "Epoch 469/4500\n",
            "100/100 [==============================] - 0s 536us/step - loss: 0.6188 - acc: 0.6900 - val_loss: 0.6587 - val_acc: 0.6400\n",
            "Epoch 470/4500\n",
            "100/100 [==============================] - 0s 502us/step - loss: 0.6192 - acc: 0.6900 - val_loss: 0.6586 - val_acc: 0.6400\n",
            "Epoch 471/4500\n",
            "100/100 [==============================] - 0s 492us/step - loss: 0.6206 - acc: 0.6900 - val_loss: 0.6571 - val_acc: 0.6400\n",
            "Epoch 472/4500\n",
            "100/100 [==============================] - 0s 608us/step - loss: 0.6206 - acc: 0.6900 - val_loss: 0.6589 - val_acc: 0.6400\n",
            "Epoch 473/4500\n",
            "100/100 [==============================] - 0s 595us/step - loss: 0.6197 - acc: 0.6900 - val_loss: 0.6580 - val_acc: 0.6400\n",
            "Epoch 474/4500\n",
            "100/100 [==============================] - 0s 534us/step - loss: 0.6192 - acc: 0.6900 - val_loss: 0.6589 - val_acc: 0.6400\n",
            "Epoch 475/4500\n",
            "100/100 [==============================] - 0s 509us/step - loss: 0.6192 - acc: 0.6900 - val_loss: 0.6588 - val_acc: 0.6400\n",
            "Epoch 476/4500\n",
            "100/100 [==============================] - 0s 512us/step - loss: 0.6192 - acc: 0.6900 - val_loss: 0.6582 - val_acc: 0.6400\n",
            "Epoch 477/4500\n",
            "100/100 [==============================] - 0s 504us/step - loss: 0.6228 - acc: 0.6900 - val_loss: 0.6606 - val_acc: 0.6400\n",
            "Epoch 478/4500\n",
            "100/100 [==============================] - 0s 521us/step - loss: 0.6186 - acc: 0.6900 - val_loss: 0.6589 - val_acc: 0.6400\n",
            "Epoch 479/4500\n",
            "100/100 [==============================] - 0s 510us/step - loss: 0.6197 - acc: 0.6900 - val_loss: 0.6570 - val_acc: 0.6400\n",
            "Epoch 480/4500\n",
            "100/100 [==============================] - 0s 504us/step - loss: 0.6191 - acc: 0.6900 - val_loss: 0.6568 - val_acc: 0.6400\n",
            "Epoch 481/4500\n",
            "100/100 [==============================] - 0s 496us/step - loss: 0.6194 - acc: 0.6900 - val_loss: 0.6569 - val_acc: 0.6400\n",
            "Epoch 482/4500\n",
            "100/100 [==============================] - 0s 585us/step - loss: 0.6195 - acc: 0.6900 - val_loss: 0.6586 - val_acc: 0.6400\n",
            "Epoch 483/4500\n",
            "100/100 [==============================] - 0s 588us/step - loss: 0.6191 - acc: 0.6900 - val_loss: 0.6591 - val_acc: 0.6400\n",
            "Epoch 484/4500\n",
            "100/100 [==============================] - 0s 558us/step - loss: 0.6192 - acc: 0.6900 - val_loss: 0.6586 - val_acc: 0.6400\n",
            "Epoch 485/4500\n",
            "100/100 [==============================] - 0s 509us/step - loss: 0.6191 - acc: 0.6900 - val_loss: 0.6590 - val_acc: 0.6400\n",
            "Epoch 486/4500\n",
            "100/100 [==============================] - 0s 515us/step - loss: 0.6191 - acc: 0.6900 - val_loss: 0.6584 - val_acc: 0.6400\n",
            "Epoch 487/4500\n",
            "100/100 [==============================] - 0s 495us/step - loss: 0.6195 - acc: 0.6900 - val_loss: 0.6593 - val_acc: 0.6400\n",
            "Epoch 488/4500\n",
            "100/100 [==============================] - 0s 494us/step - loss: 0.6207 - acc: 0.6900 - val_loss: 0.6571 - val_acc: 0.6400\n",
            "Epoch 489/4500\n",
            "100/100 [==============================] - 0s 529us/step - loss: 0.6192 - acc: 0.6900 - val_loss: 0.6573 - val_acc: 0.6400\n",
            "Epoch 490/4500\n",
            "100/100 [==============================] - 0s 636us/step - loss: 0.6217 - acc: 0.6900 - val_loss: 0.6604 - val_acc: 0.6400\n",
            "Epoch 491/4500\n",
            "100/100 [==============================] - 0s 703us/step - loss: 0.6188 - acc: 0.6900 - val_loss: 0.6592 - val_acc: 0.6400\n",
            "Epoch 492/4500\n",
            "100/100 [==============================] - 0s 572us/step - loss: 0.6190 - acc: 0.6900 - val_loss: 0.6582 - val_acc: 0.6400\n",
            "Epoch 493/4500\n",
            "100/100 [==============================] - 0s 521us/step - loss: 0.6191 - acc: 0.6900 - val_loss: 0.6576 - val_acc: 0.6400\n",
            "Epoch 494/4500\n",
            "100/100 [==============================] - 0s 508us/step - loss: 0.6189 - acc: 0.6900 - val_loss: 0.6575 - val_acc: 0.6400\n",
            "Epoch 495/4500\n",
            "100/100 [==============================] - 0s 553us/step - loss: 0.6199 - acc: 0.6900 - val_loss: 0.6579 - val_acc: 0.6400\n",
            "Epoch 496/4500\n",
            "100/100 [==============================] - 0s 554us/step - loss: 0.6193 - acc: 0.6900 - val_loss: 0.6586 - val_acc: 0.6400\n",
            "Epoch 497/4500\n",
            "100/100 [==============================] - 0s 530us/step - loss: 0.6193 - acc: 0.6900 - val_loss: 0.6596 - val_acc: 0.6400\n",
            "Epoch 498/4500\n",
            "100/100 [==============================] - 0s 504us/step - loss: 0.6190 - acc: 0.6900 - val_loss: 0.6588 - val_acc: 0.6400\n",
            "Epoch 499/4500\n",
            "100/100 [==============================] - 0s 512us/step - loss: 0.6194 - acc: 0.6900 - val_loss: 0.6584 - val_acc: 0.6400\n",
            "Epoch 500/4500\n",
            "100/100 [==============================] - 0s 598us/step - loss: 0.6191 - acc: 0.6900 - val_loss: 0.6576 - val_acc: 0.6400\n",
            "Epoch 501/4500\n",
            "100/100 [==============================] - 0s 572us/step - loss: 0.6193 - acc: 0.6900 - val_loss: 0.6587 - val_acc: 0.6400\n",
            "Epoch 502/4500\n",
            "100/100 [==============================] - 0s 534us/step - loss: 0.6196 - acc: 0.6900 - val_loss: 0.6591 - val_acc: 0.6400\n",
            "Epoch 503/4500\n",
            "100/100 [==============================] - 0s 557us/step - loss: 0.6208 - acc: 0.6900 - val_loss: 0.6571 - val_acc: 0.6400\n",
            "Epoch 504/4500\n",
            "100/100 [==============================] - 0s 592us/step - loss: 0.6194 - acc: 0.6900 - val_loss: 0.6578 - val_acc: 0.6400\n",
            "Epoch 505/4500\n",
            "100/100 [==============================] - 0s 542us/step - loss: 0.6194 - acc: 0.6900 - val_loss: 0.6582 - val_acc: 0.6400\n",
            "Epoch 506/4500\n",
            "100/100 [==============================] - 0s 505us/step - loss: 0.6193 - acc: 0.6900 - val_loss: 0.6589 - val_acc: 0.6400\n",
            "Epoch 507/4500\n",
            "100/100 [==============================] - 0s 505us/step - loss: 0.6190 - acc: 0.6900 - val_loss: 0.6585 - val_acc: 0.6400\n",
            "Epoch 508/4500\n",
            "100/100 [==============================] - 0s 502us/step - loss: 0.6193 - acc: 0.6900 - val_loss: 0.6578 - val_acc: 0.6400\n",
            "Epoch 509/4500\n",
            "100/100 [==============================] - 0s 588us/step - loss: 0.6189 - acc: 0.6900 - val_loss: 0.6581 - val_acc: 0.6400\n",
            "Epoch 510/4500\n",
            "100/100 [==============================] - 0s 538us/step - loss: 0.6192 - acc: 0.6900 - val_loss: 0.6587 - val_acc: 0.6400\n",
            "Epoch 511/4500\n",
            "100/100 [==============================] - 0s 604us/step - loss: 0.6203 - acc: 0.6900 - val_loss: 0.6594 - val_acc: 0.6400\n",
            "Epoch 512/4500\n",
            "100/100 [==============================] - 0s 535us/step - loss: 0.6192 - acc: 0.6900 - val_loss: 0.6592 - val_acc: 0.6400\n",
            "Epoch 513/4500\n",
            "100/100 [==============================] - 0s 523us/step - loss: 0.6203 - acc: 0.6900 - val_loss: 0.6592 - val_acc: 0.6400\n",
            "Epoch 514/4500\n",
            "100/100 [==============================] - 0s 505us/step - loss: 0.6187 - acc: 0.6900 - val_loss: 0.6576 - val_acc: 0.6400\n",
            "Epoch 515/4500\n",
            "100/100 [==============================] - 0s 538us/step - loss: 0.6190 - acc: 0.6900 - val_loss: 0.6569 - val_acc: 0.6400\n",
            "Epoch 516/4500\n",
            "100/100 [==============================] - 0s 554us/step - loss: 0.6189 - acc: 0.6900 - val_loss: 0.6571 - val_acc: 0.6400\n",
            "Epoch 517/4500\n",
            "100/100 [==============================] - 0s 673us/step - loss: 0.6190 - acc: 0.6900 - val_loss: 0.6574 - val_acc: 0.6400\n",
            "Epoch 518/4500\n",
            "100/100 [==============================] - 0s 636us/step - loss: 0.6195 - acc: 0.6900 - val_loss: 0.6586 - val_acc: 0.6400\n",
            "Epoch 519/4500\n",
            "100/100 [==============================] - 0s 560us/step - loss: 0.6190 - acc: 0.6900 - val_loss: 0.6585 - val_acc: 0.6400\n",
            "Epoch 520/4500\n",
            "100/100 [==============================] - 0s 538us/step - loss: 0.6189 - acc: 0.6900 - val_loss: 0.6580 - val_acc: 0.6400\n",
            "Epoch 521/4500\n",
            "100/100 [==============================] - 0s 535us/step - loss: 0.6191 - acc: 0.6900 - val_loss: 0.6576 - val_acc: 0.6400\n",
            "Epoch 522/4500\n",
            "100/100 [==============================] - 0s 585us/step - loss: 0.6188 - acc: 0.6900 - val_loss: 0.6584 - val_acc: 0.6400\n",
            "Epoch 523/4500\n",
            "100/100 [==============================] - 0s 500us/step - loss: 0.6191 - acc: 0.6900 - val_loss: 0.6580 - val_acc: 0.6400\n",
            "Epoch 524/4500\n",
            "100/100 [==============================] - 0s 524us/step - loss: 0.6196 - acc: 0.6900 - val_loss: 0.6574 - val_acc: 0.6400\n",
            "Epoch 525/4500\n",
            "100/100 [==============================] - 0s 518us/step - loss: 0.6192 - acc: 0.6900 - val_loss: 0.6579 - val_acc: 0.6400\n",
            "Epoch 526/4500\n",
            "100/100 [==============================] - 0s 558us/step - loss: 0.6189 - acc: 0.6900 - val_loss: 0.6585 - val_acc: 0.6400\n",
            "Epoch 527/4500\n",
            "100/100 [==============================] - 0s 543us/step - loss: 0.6197 - acc: 0.6900 - val_loss: 0.6606 - val_acc: 0.6400\n",
            "Epoch 528/4500\n",
            "100/100 [==============================] - 0s 529us/step - loss: 0.6194 - acc: 0.6900 - val_loss: 0.6608 - val_acc: 0.6400\n",
            "Epoch 529/4500\n",
            "100/100 [==============================] - 0s 498us/step - loss: 0.6192 - acc: 0.6900 - val_loss: 0.6592 - val_acc: 0.6400\n",
            "Epoch 530/4500\n",
            "100/100 [==============================] - 0s 591us/step - loss: 0.6198 - acc: 0.6900 - val_loss: 0.6576 - val_acc: 0.6400\n",
            "Epoch 531/4500\n",
            "100/100 [==============================] - 0s 514us/step - loss: 0.6189 - acc: 0.6900 - val_loss: 0.6580 - val_acc: 0.6400\n",
            "Epoch 532/4500\n",
            "100/100 [==============================] - 0s 534us/step - loss: 0.6191 - acc: 0.6900 - val_loss: 0.6583 - val_acc: 0.6400\n",
            "Epoch 533/4500\n",
            "100/100 [==============================] - 0s 530us/step - loss: 0.6190 - acc: 0.6900 - val_loss: 0.6577 - val_acc: 0.6400\n",
            "Epoch 534/4500\n",
            "100/100 [==============================] - 0s 526us/step - loss: 0.6193 - acc: 0.6900 - val_loss: 0.6581 - val_acc: 0.6400\n",
            "Epoch 535/4500\n",
            "100/100 [==============================] - 0s 504us/step - loss: 0.6191 - acc: 0.6900 - val_loss: 0.6590 - val_acc: 0.6400\n",
            "Epoch 536/4500\n",
            "100/100 [==============================] - 0s 489us/step - loss: 0.6190 - acc: 0.6900 - val_loss: 0.6589 - val_acc: 0.6400\n",
            "Epoch 537/4500\n",
            "100/100 [==============================] - 0s 577us/step - loss: 0.6192 - acc: 0.6900 - val_loss: 0.6588 - val_acc: 0.6400\n",
            "Epoch 538/4500\n",
            "100/100 [==============================] - 0s 597us/step - loss: 0.6188 - acc: 0.6900 - val_loss: 0.6587 - val_acc: 0.6400\n",
            "Epoch 539/4500\n",
            "100/100 [==============================] - 0s 546us/step - loss: 0.6191 - acc: 0.6900 - val_loss: 0.6590 - val_acc: 0.6400\n",
            "Epoch 540/4500\n",
            "100/100 [==============================] - 0s 504us/step - loss: 0.6191 - acc: 0.6900 - val_loss: 0.6580 - val_acc: 0.6400\n",
            "Epoch 541/4500\n",
            "100/100 [==============================] - 0s 576us/step - loss: 0.6199 - acc: 0.6900 - val_loss: 0.6585 - val_acc: 0.6400\n",
            "Epoch 542/4500\n",
            "100/100 [==============================] - 0s 547us/step - loss: 0.6198 - acc: 0.6900 - val_loss: 0.6571 - val_acc: 0.6400\n",
            "Epoch 543/4500\n",
            "100/100 [==============================] - 0s 514us/step - loss: 0.6198 - acc: 0.6900 - val_loss: 0.6569 - val_acc: 0.6400\n",
            "Epoch 544/4500\n",
            "100/100 [==============================] - 0s 516us/step - loss: 0.6197 - acc: 0.6900 - val_loss: 0.6587 - val_acc: 0.6400\n",
            "Epoch 545/4500\n",
            "100/100 [==============================] - 0s 507us/step - loss: 0.6192 - acc: 0.6900 - val_loss: 0.6586 - val_acc: 0.6400\n",
            "Epoch 546/4500\n",
            "100/100 [==============================] - 0s 557us/step - loss: 0.6195 - acc: 0.6900 - val_loss: 0.6591 - val_acc: 0.6400\n",
            "Epoch 547/4500\n",
            "100/100 [==============================] - 0s 511us/step - loss: 0.6188 - acc: 0.6900 - val_loss: 0.6582 - val_acc: 0.6400\n",
            "Epoch 548/4500\n",
            "100/100 [==============================] - 0s 504us/step - loss: 0.6190 - acc: 0.6900 - val_loss: 0.6579 - val_acc: 0.6400\n",
            "Epoch 549/4500\n",
            "100/100 [==============================] - 0s 540us/step - loss: 0.6193 - acc: 0.6900 - val_loss: 0.6588 - val_acc: 0.6400\n",
            "Epoch 550/4500\n",
            "100/100 [==============================] - 0s 508us/step - loss: 0.6193 - acc: 0.6900 - val_loss: 0.6577 - val_acc: 0.6400\n",
            "Epoch 551/4500\n",
            "100/100 [==============================] - 0s 508us/step - loss: 0.6188 - acc: 0.6900 - val_loss: 0.6576 - val_acc: 0.6400\n",
            "Epoch 552/4500\n",
            "100/100 [==============================] - 0s 510us/step - loss: 0.6190 - acc: 0.6900 - val_loss: 0.6584 - val_acc: 0.6400\n",
            "Epoch 553/4500\n",
            "100/100 [==============================] - 0s 494us/step - loss: 0.6194 - acc: 0.6900 - val_loss: 0.6575 - val_acc: 0.6400\n",
            "Epoch 554/4500\n",
            "100/100 [==============================] - 0s 555us/step - loss: 0.6188 - acc: 0.6900 - val_loss: 0.6580 - val_acc: 0.6400\n",
            "Epoch 555/4500\n",
            "100/100 [==============================] - 0s 510us/step - loss: 0.6187 - acc: 0.6900 - val_loss: 0.6587 - val_acc: 0.6400\n",
            "Epoch 556/4500\n",
            "100/100 [==============================] - 0s 632us/step - loss: 0.6191 - acc: 0.6900 - val_loss: 0.6582 - val_acc: 0.6400\n",
            "Epoch 557/4500\n",
            "100/100 [==============================] - 0s 525us/step - loss: 0.6193 - acc: 0.6900 - val_loss: 0.6581 - val_acc: 0.6400\n",
            "Epoch 558/4500\n",
            "100/100 [==============================] - 0s 523us/step - loss: 0.6192 - acc: 0.6900 - val_loss: 0.6582 - val_acc: 0.6400\n",
            "Epoch 559/4500\n",
            "100/100 [==============================] - 0s 548us/step - loss: 0.6191 - acc: 0.6900 - val_loss: 0.6582 - val_acc: 0.6400\n",
            "Epoch 560/4500\n",
            "100/100 [==============================] - 0s 624us/step - loss: 0.6190 - acc: 0.6900 - val_loss: 0.6594 - val_acc: 0.6400\n",
            "Epoch 561/4500\n",
            "100/100 [==============================] - 0s 555us/step - loss: 0.6190 - acc: 0.6900 - val_loss: 0.6589 - val_acc: 0.6400\n",
            "Epoch 562/4500\n",
            "100/100 [==============================] - 0s 509us/step - loss: 0.6189 - acc: 0.6900 - val_loss: 0.6593 - val_acc: 0.6400\n",
            "Epoch 563/4500\n",
            "100/100 [==============================] - 0s 516us/step - loss: 0.6190 - acc: 0.6900 - val_loss: 0.6588 - val_acc: 0.6400\n",
            "Epoch 564/4500\n",
            "100/100 [==============================] - 0s 586us/step - loss: 0.6190 - acc: 0.6900 - val_loss: 0.6587 - val_acc: 0.6400\n",
            "Epoch 565/4500\n",
            "100/100 [==============================] - 0s 507us/step - loss: 0.6193 - acc: 0.6900 - val_loss: 0.6590 - val_acc: 0.6400\n",
            "Epoch 566/4500\n",
            "100/100 [==============================] - 0s 509us/step - loss: 0.6195 - acc: 0.6900 - val_loss: 0.6595 - val_acc: 0.6400\n",
            "Epoch 567/4500\n",
            "100/100 [==============================] - 0s 505us/step - loss: 0.6202 - acc: 0.6900 - val_loss: 0.6569 - val_acc: 0.6400\n",
            "Epoch 568/4500\n",
            "100/100 [==============================] - 0s 514us/step - loss: 0.6188 - acc: 0.6900 - val_loss: 0.6573 - val_acc: 0.6400\n",
            "Epoch 569/4500\n",
            "100/100 [==============================] - 0s 526us/step - loss: 0.6190 - acc: 0.6900 - val_loss: 0.6576 - val_acc: 0.6400\n",
            "Epoch 570/4500\n",
            "100/100 [==============================] - 0s 489us/step - loss: 0.6192 - acc: 0.6900 - val_loss: 0.6581 - val_acc: 0.6400\n",
            "Epoch 571/4500\n",
            "100/100 [==============================] - 0s 516us/step - loss: 0.6193 - acc: 0.6900 - val_loss: 0.6588 - val_acc: 0.6400\n",
            "Epoch 572/4500\n",
            "100/100 [==============================] - 0s 606us/step - loss: 0.6192 - acc: 0.6900 - val_loss: 0.6586 - val_acc: 0.6400\n",
            "Epoch 573/4500\n",
            "100/100 [==============================] - 0s 510us/step - loss: 0.6200 - acc: 0.6900 - val_loss: 0.6597 - val_acc: 0.6400\n",
            "Epoch 574/4500\n",
            "100/100 [==============================] - 0s 524us/step - loss: 0.6196 - acc: 0.6900 - val_loss: 0.6576 - val_acc: 0.6400\n",
            "Epoch 575/4500\n",
            "100/100 [==============================] - 0s 525us/step - loss: 0.6196 - acc: 0.6900 - val_loss: 0.6575 - val_acc: 0.6400\n",
            "Epoch 576/4500\n",
            "100/100 [==============================] - 0s 545us/step - loss: 0.6194 - acc: 0.6900 - val_loss: 0.6585 - val_acc: 0.6400\n",
            "Epoch 577/4500\n",
            "100/100 [==============================] - 0s 495us/step - loss: 0.6197 - acc: 0.6900 - val_loss: 0.6570 - val_acc: 0.6400\n",
            "Epoch 578/4500\n",
            "100/100 [==============================] - 0s 499us/step - loss: 0.6212 - acc: 0.6900 - val_loss: 0.6594 - val_acc: 0.6400\n",
            "Epoch 579/4500\n",
            "100/100 [==============================] - 0s 549us/step - loss: 0.6187 - acc: 0.6900 - val_loss: 0.6584 - val_acc: 0.6400\n",
            "Epoch 580/4500\n",
            "100/100 [==============================] - 0s 576us/step - loss: 0.6202 - acc: 0.6900 - val_loss: 0.6569 - val_acc: 0.6400\n",
            "Epoch 581/4500\n",
            "100/100 [==============================] - 0s 530us/step - loss: 0.6192 - acc: 0.6900 - val_loss: 0.6569 - val_acc: 0.6400\n",
            "Epoch 582/4500\n",
            "100/100 [==============================] - 0s 552us/step - loss: 0.6189 - acc: 0.6900 - val_loss: 0.6582 - val_acc: 0.6400\n",
            "Epoch 583/4500\n",
            "100/100 [==============================] - 0s 586us/step - loss: 0.6191 - acc: 0.6900 - val_loss: 0.6587 - val_acc: 0.6400\n",
            "Epoch 584/4500\n",
            "100/100 [==============================] - 0s 513us/step - loss: 0.6202 - acc: 0.6900 - val_loss: 0.6572 - val_acc: 0.6400\n",
            "Epoch 585/4500\n",
            "100/100 [==============================] - 0s 527us/step - loss: 0.6189 - acc: 0.6900 - val_loss: 0.6585 - val_acc: 0.6400\n",
            "Epoch 586/4500\n",
            "100/100 [==============================] - 0s 495us/step - loss: 0.6189 - acc: 0.6900 - val_loss: 0.6592 - val_acc: 0.6400\n",
            "Epoch 587/4500\n",
            "100/100 [==============================] - 0s 528us/step - loss: 0.6186 - acc: 0.6900 - val_loss: 0.6588 - val_acc: 0.6400\n",
            "Epoch 588/4500\n",
            "100/100 [==============================] - 0s 525us/step - loss: 0.6191 - acc: 0.6900 - val_loss: 0.6591 - val_acc: 0.6400\n",
            "Epoch 589/4500\n",
            "100/100 [==============================] - 0s 501us/step - loss: 0.6202 - acc: 0.6900 - val_loss: 0.6598 - val_acc: 0.6400\n",
            "Epoch 590/4500\n",
            "100/100 [==============================] - 0s 493us/step - loss: 0.6186 - acc: 0.6900 - val_loss: 0.6591 - val_acc: 0.6400\n",
            "Epoch 591/4500\n",
            "100/100 [==============================] - 0s 493us/step - loss: 0.6195 - acc: 0.6900 - val_loss: 0.6572 - val_acc: 0.6400\n",
            "Epoch 592/4500\n",
            "100/100 [==============================] - 0s 488us/step - loss: 0.6189 - acc: 0.6900 - val_loss: 0.6571 - val_acc: 0.6400\n",
            "Epoch 593/4500\n",
            "100/100 [==============================] - 0s 526us/step - loss: 0.6195 - acc: 0.6900 - val_loss: 0.6585 - val_acc: 0.6400\n",
            "Epoch 594/4500\n",
            "100/100 [==============================] - 0s 529us/step - loss: 0.6189 - acc: 0.6900 - val_loss: 0.6578 - val_acc: 0.6400\n",
            "Epoch 595/4500\n",
            "100/100 [==============================] - 0s 514us/step - loss: 0.6192 - acc: 0.6900 - val_loss: 0.6573 - val_acc: 0.6400\n",
            "Epoch 596/4500\n",
            "100/100 [==============================] - 0s 559us/step - loss: 0.6195 - acc: 0.6900 - val_loss: 0.6587 - val_acc: 0.6400\n",
            "Epoch 597/4500\n",
            "100/100 [==============================] - 0s 496us/step - loss: 0.6187 - acc: 0.6900 - val_loss: 0.6585 - val_acc: 0.6400\n",
            "Epoch 598/4500\n",
            "100/100 [==============================] - 0s 511us/step - loss: 0.6186 - acc: 0.6900 - val_loss: 0.6582 - val_acc: 0.6400\n",
            "Epoch 599/4500\n",
            "100/100 [==============================] - 0s 512us/step - loss: 0.6190 - acc: 0.6900 - val_loss: 0.6577 - val_acc: 0.6400\n",
            "Epoch 600/4500\n",
            "100/100 [==============================] - 0s 594us/step - loss: 0.6193 - acc: 0.6900 - val_loss: 0.6589 - val_acc: 0.6400\n",
            "Epoch 601/4500\n",
            "100/100 [==============================] - 0s 503us/step - loss: 0.6196 - acc: 0.6900 - val_loss: 0.6578 - val_acc: 0.6400\n",
            "Epoch 602/4500\n",
            "100/100 [==============================] - 0s 551us/step - loss: 0.6193 - acc: 0.6900 - val_loss: 0.6576 - val_acc: 0.6400\n",
            "Epoch 603/4500\n",
            "100/100 [==============================] - 0s 538us/step - loss: 0.6194 - acc: 0.6900 - val_loss: 0.6575 - val_acc: 0.6400\n",
            "Epoch 604/4500\n",
            "100/100 [==============================] - 0s 518us/step - loss: 0.6191 - acc: 0.6900 - val_loss: 0.6589 - val_acc: 0.6400\n",
            "Epoch 605/4500\n",
            "100/100 [==============================] - 0s 492us/step - loss: 0.6190 - acc: 0.6900 - val_loss: 0.6585 - val_acc: 0.6400\n",
            "Epoch 606/4500\n",
            "100/100 [==============================] - 0s 498us/step - loss: 0.6193 - acc: 0.6900 - val_loss: 0.6580 - val_acc: 0.6400\n",
            "Epoch 607/4500\n",
            "100/100 [==============================] - 0s 501us/step - loss: 0.6204 - acc: 0.6900 - val_loss: 0.6597 - val_acc: 0.6400\n",
            "Epoch 608/4500\n",
            "100/100 [==============================] - 0s 578us/step - loss: 0.6196 - acc: 0.6900 - val_loss: 0.6582 - val_acc: 0.6400\n",
            "Epoch 609/4500\n",
            "100/100 [==============================] - 0s 594us/step - loss: 0.6186 - acc: 0.6900 - val_loss: 0.6583 - val_acc: 0.6400\n",
            "Epoch 610/4500\n",
            "100/100 [==============================] - 0s 505us/step - loss: 0.6196 - acc: 0.6900 - val_loss: 0.6574 - val_acc: 0.6400\n",
            "Epoch 611/4500\n",
            "100/100 [==============================] - 0s 497us/step - loss: 0.6201 - acc: 0.6900 - val_loss: 0.6588 - val_acc: 0.6400\n",
            "Epoch 612/4500\n",
            "100/100 [==============================] - 0s 498us/step - loss: 0.6192 - acc: 0.6900 - val_loss: 0.6578 - val_acc: 0.6400\n",
            "Epoch 613/4500\n",
            "100/100 [==============================] - 0s 508us/step - loss: 0.6189 - acc: 0.6900 - val_loss: 0.6576 - val_acc: 0.6400\n",
            "Epoch 614/4500\n",
            "100/100 [==============================] - 0s 508us/step - loss: 0.6191 - acc: 0.6900 - val_loss: 0.6587 - val_acc: 0.6400\n",
            "Epoch 615/4500\n",
            "100/100 [==============================] - 0s 514us/step - loss: 0.6192 - acc: 0.6900 - val_loss: 0.6584 - val_acc: 0.6400\n",
            "Epoch 616/4500\n",
            "100/100 [==============================] - 0s 505us/step - loss: 0.6195 - acc: 0.6900 - val_loss: 0.6573 - val_acc: 0.6400\n",
            "Epoch 617/4500\n",
            "100/100 [==============================] - 0s 494us/step - loss: 0.6196 - acc: 0.6900 - val_loss: 0.6591 - val_acc: 0.6400\n",
            "Epoch 618/4500\n",
            "100/100 [==============================] - 0s 517us/step - loss: 0.6198 - acc: 0.6900 - val_loss: 0.6600 - val_acc: 0.6400\n",
            "Epoch 619/4500\n",
            "100/100 [==============================] - 0s 527us/step - loss: 0.6187 - acc: 0.6900 - val_loss: 0.6583 - val_acc: 0.6400\n",
            "Epoch 620/4500\n",
            "100/100 [==============================] - 0s 608us/step - loss: 0.6196 - acc: 0.6900 - val_loss: 0.6583 - val_acc: 0.6400\n",
            "Epoch 621/4500\n",
            "100/100 [==============================] - 0s 590us/step - loss: 0.6188 - acc: 0.6900 - val_loss: 0.6581 - val_acc: 0.6400\n",
            "Epoch 622/4500\n",
            "100/100 [==============================] - 0s 537us/step - loss: 0.6190 - acc: 0.6900 - val_loss: 0.6572 - val_acc: 0.6400\n",
            "Epoch 623/4500\n",
            "100/100 [==============================] - 0s 528us/step - loss: 0.6189 - acc: 0.6900 - val_loss: 0.6576 - val_acc: 0.6400\n",
            "Epoch 624/4500\n",
            "100/100 [==============================] - 0s 515us/step - loss: 0.6191 - acc: 0.6900 - val_loss: 0.6578 - val_acc: 0.6400\n",
            "Epoch 625/4500\n",
            "100/100 [==============================] - 0s 513us/step - loss: 0.6189 - acc: 0.6900 - val_loss: 0.6581 - val_acc: 0.6400\n",
            "Epoch 626/4500\n",
            "100/100 [==============================] - 0s 504us/step - loss: 0.6196 - acc: 0.6900 - val_loss: 0.6585 - val_acc: 0.6400\n",
            "Epoch 627/4500\n",
            "100/100 [==============================] - 0s 529us/step - loss: 0.6187 - acc: 0.6900 - val_loss: 0.6583 - val_acc: 0.6400\n",
            "Epoch 628/4500\n",
            "100/100 [==============================] - 0s 585us/step - loss: 0.6190 - acc: 0.6900 - val_loss: 0.6584 - val_acc: 0.6400\n",
            "Epoch 629/4500\n",
            "100/100 [==============================] - 0s 501us/step - loss: 0.6187 - acc: 0.6900 - val_loss: 0.6581 - val_acc: 0.6400\n",
            "Epoch 630/4500\n",
            "100/100 [==============================] - 0s 609us/step - loss: 0.6189 - acc: 0.6900 - val_loss: 0.6575 - val_acc: 0.6400\n",
            "Epoch 631/4500\n",
            "100/100 [==============================] - 0s 569us/step - loss: 0.6187 - acc: 0.6900 - val_loss: 0.6578 - val_acc: 0.6400\n",
            "Epoch 632/4500\n",
            "100/100 [==============================] - 0s 517us/step - loss: 0.6191 - acc: 0.6900 - val_loss: 0.6582 - val_acc: 0.6400\n",
            "Epoch 633/4500\n",
            "100/100 [==============================] - 0s 498us/step - loss: 0.6191 - acc: 0.6900 - val_loss: 0.6578 - val_acc: 0.6400\n",
            "Epoch 634/4500\n",
            "100/100 [==============================] - 0s 521us/step - loss: 0.6187 - acc: 0.6900 - val_loss: 0.6582 - val_acc: 0.6400\n",
            "Epoch 635/4500\n",
            "100/100 [==============================] - 0s 517us/step - loss: 0.6206 - acc: 0.6900 - val_loss: 0.6573 - val_acc: 0.6400\n",
            "Epoch 636/4500\n",
            "100/100 [==============================] - 0s 509us/step - loss: 0.6197 - acc: 0.6900 - val_loss: 0.6594 - val_acc: 0.6400\n",
            "Epoch 637/4500\n",
            "100/100 [==============================] - 0s 502us/step - loss: 0.6188 - acc: 0.6900 - val_loss: 0.6594 - val_acc: 0.6400\n",
            "Epoch 638/4500\n",
            "100/100 [==============================] - 0s 498us/step - loss: 0.6199 - acc: 0.6900 - val_loss: 0.6580 - val_acc: 0.6400\n",
            "Epoch 639/4500\n",
            "100/100 [==============================] - 0s 529us/step - loss: 0.6198 - acc: 0.6900 - val_loss: 0.6595 - val_acc: 0.6400\n",
            "Epoch 640/4500\n",
            "100/100 [==============================] - 0s 589us/step - loss: 0.6188 - acc: 0.6900 - val_loss: 0.6591 - val_acc: 0.6400\n",
            "Epoch 641/4500\n",
            "100/100 [==============================] - 0s 546us/step - loss: 0.6187 - acc: 0.6900 - val_loss: 0.6577 - val_acc: 0.6400\n",
            "Epoch 642/4500\n",
            "100/100 [==============================] - 0s 533us/step - loss: 0.6192 - acc: 0.6900 - val_loss: 0.6568 - val_acc: 0.6400\n",
            "Epoch 643/4500\n",
            "100/100 [==============================] - 0s 499us/step - loss: 0.6187 - acc: 0.6900 - val_loss: 0.6575 - val_acc: 0.6400\n",
            "Epoch 644/4500\n",
            "100/100 [==============================] - 0s 526us/step - loss: 0.6190 - acc: 0.6900 - val_loss: 0.6573 - val_acc: 0.6400\n",
            "Epoch 645/4500\n",
            "100/100 [==============================] - 0s 519us/step - loss: 0.6189 - acc: 0.6900 - val_loss: 0.6581 - val_acc: 0.6400\n",
            "Epoch 646/4500\n",
            "100/100 [==============================] - 0s 555us/step - loss: 0.6188 - acc: 0.6900 - val_loss: 0.6582 - val_acc: 0.6400\n",
            "Epoch 647/4500\n",
            "100/100 [==============================] - 0s 560us/step - loss: 0.6189 - acc: 0.6900 - val_loss: 0.6585 - val_acc: 0.6400\n",
            "Epoch 648/4500\n",
            "100/100 [==============================] - 0s 597us/step - loss: 0.6189 - acc: 0.6900 - val_loss: 0.6590 - val_acc: 0.6400\n",
            "Epoch 649/4500\n",
            "100/100 [==============================] - 0s 518us/step - loss: 0.6193 - acc: 0.6900 - val_loss: 0.6596 - val_acc: 0.6400\n",
            "Epoch 650/4500\n",
            "100/100 [==============================] - 0s 534us/step - loss: 0.6188 - acc: 0.6900 - val_loss: 0.6593 - val_acc: 0.6400\n",
            "Epoch 651/4500\n",
            "100/100 [==============================] - 0s 522us/step - loss: 0.6187 - acc: 0.6900 - val_loss: 0.6586 - val_acc: 0.6400\n",
            "Epoch 652/4500\n",
            "100/100 [==============================] - 0s 530us/step - loss: 0.6188 - acc: 0.6900 - val_loss: 0.6583 - val_acc: 0.6400\n",
            "Epoch 653/4500\n",
            "100/100 [==============================] - 0s 504us/step - loss: 0.6186 - acc: 0.6900 - val_loss: 0.6574 - val_acc: 0.6400\n",
            "Epoch 654/4500\n",
            "100/100 [==============================] - 0s 518us/step - loss: 0.6196 - acc: 0.6900 - val_loss: 0.6565 - val_acc: 0.6400\n",
            "Epoch 655/4500\n",
            "100/100 [==============================] - 0s 522us/step - loss: 0.6191 - acc: 0.6900 - val_loss: 0.6572 - val_acc: 0.6400\n",
            "Epoch 656/4500\n",
            "100/100 [==============================] - 0s 564us/step - loss: 0.6190 - acc: 0.6900 - val_loss: 0.6584 - val_acc: 0.6400\n",
            "Epoch 657/4500\n",
            "100/100 [==============================] - 0s 515us/step - loss: 0.6190 - acc: 0.6900 - val_loss: 0.6576 - val_acc: 0.6400\n",
            "Epoch 658/4500\n",
            "100/100 [==============================] - 0s 518us/step - loss: 0.6185 - acc: 0.6900 - val_loss: 0.6581 - val_acc: 0.6400\n",
            "Epoch 659/4500\n",
            "100/100 [==============================] - 0s 703us/step - loss: 0.6187 - acc: 0.6900 - val_loss: 0.6579 - val_acc: 0.6400\n",
            "Epoch 660/4500\n",
            "100/100 [==============================] - 0s 701us/step - loss: 0.6187 - acc: 0.6900 - val_loss: 0.6579 - val_acc: 0.6400\n",
            "Epoch 661/4500\n",
            "100/100 [==============================] - 0s 616us/step - loss: 0.6191 - acc: 0.6900 - val_loss: 0.6577 - val_acc: 0.6400\n",
            "Epoch 662/4500\n",
            "100/100 [==============================] - 0s 596us/step - loss: 0.6191 - acc: 0.6900 - val_loss: 0.6586 - val_acc: 0.6400\n",
            "Epoch 663/4500\n",
            "100/100 [==============================] - 0s 565us/step - loss: 0.6190 - acc: 0.6900 - val_loss: 0.6589 - val_acc: 0.6400\n",
            "Epoch 664/4500\n",
            "100/100 [==============================] - 0s 540us/step - loss: 0.6189 - acc: 0.6900 - val_loss: 0.6592 - val_acc: 0.6400\n",
            "Epoch 665/4500\n",
            "100/100 [==============================] - 0s 517us/step - loss: 0.6191 - acc: 0.6900 - val_loss: 0.6590 - val_acc: 0.6400\n",
            "Epoch 666/4500\n",
            "100/100 [==============================] - 0s 586us/step - loss: 0.6185 - acc: 0.6900 - val_loss: 0.6584 - val_acc: 0.6400\n",
            "Epoch 667/4500\n",
            "100/100 [==============================] - 0s 608us/step - loss: 0.6188 - acc: 0.6900 - val_loss: 0.6575 - val_acc: 0.6400\n",
            "Epoch 668/4500\n",
            "100/100 [==============================] - 0s 581us/step - loss: 0.6193 - acc: 0.6900 - val_loss: 0.6570 - val_acc: 0.6400\n",
            "Epoch 669/4500\n",
            "100/100 [==============================] - 0s 550us/step - loss: 0.6188 - acc: 0.6900 - val_loss: 0.6571 - val_acc: 0.6400\n",
            "Epoch 670/4500\n",
            "100/100 [==============================] - 0s 550us/step - loss: 0.6186 - acc: 0.6900 - val_loss: 0.6573 - val_acc: 0.6400\n",
            "Epoch 671/4500\n",
            "100/100 [==============================] - 0s 518us/step - loss: 0.6191 - acc: 0.6900 - val_loss: 0.6589 - val_acc: 0.6400\n",
            "Epoch 672/4500\n",
            "100/100 [==============================] - 0s 524us/step - loss: 0.6194 - acc: 0.6900 - val_loss: 0.6587 - val_acc: 0.6400\n",
            "Epoch 673/4500\n",
            "100/100 [==============================] - 0s 526us/step - loss: 0.6192 - acc: 0.6900 - val_loss: 0.6579 - val_acc: 0.6400\n",
            "Epoch 674/4500\n",
            "100/100 [==============================] - 0s 548us/step - loss: 0.6187 - acc: 0.6900 - val_loss: 0.6584 - val_acc: 0.6400\n",
            "Epoch 675/4500\n",
            "100/100 [==============================] - 0s 573us/step - loss: 0.6190 - acc: 0.6900 - val_loss: 0.6589 - val_acc: 0.6400\n",
            "Epoch 676/4500\n",
            "100/100 [==============================] - 0s 664us/step - loss: 0.6229 - acc: 0.6900 - val_loss: 0.6564 - val_acc: 0.6400\n",
            "Epoch 677/4500\n",
            "100/100 [==============================] - 0s 659us/step - loss: 0.6189 - acc: 0.6900 - val_loss: 0.6574 - val_acc: 0.6400\n",
            "Epoch 678/4500\n",
            "100/100 [==============================] - 0s 512us/step - loss: 0.6198 - acc: 0.6900 - val_loss: 0.6594 - val_acc: 0.6400\n",
            "Epoch 679/4500\n",
            "100/100 [==============================] - 0s 503us/step - loss: 0.6192 - acc: 0.6900 - val_loss: 0.6591 - val_acc: 0.6400\n",
            "Epoch 680/4500\n",
            "100/100 [==============================] - 0s 514us/step - loss: 0.6186 - acc: 0.6900 - val_loss: 0.6584 - val_acc: 0.6400\n",
            "Epoch 681/4500\n",
            "100/100 [==============================] - 0s 517us/step - loss: 0.6188 - acc: 0.6900 - val_loss: 0.6578 - val_acc: 0.6400\n",
            "Epoch 682/4500\n",
            "100/100 [==============================] - 0s 500us/step - loss: 0.6192 - acc: 0.6900 - val_loss: 0.6574 - val_acc: 0.6400\n",
            "Epoch 683/4500\n",
            "100/100 [==============================] - 0s 501us/step - loss: 0.6189 - acc: 0.6900 - val_loss: 0.6577 - val_acc: 0.6400\n",
            "Epoch 684/4500\n",
            "100/100 [==============================] - 0s 547us/step - loss: 0.6191 - acc: 0.6900 - val_loss: 0.6580 - val_acc: 0.6400\n",
            "Epoch 685/4500\n",
            "100/100 [==============================] - 0s 558us/step - loss: 0.6191 - acc: 0.6900 - val_loss: 0.6584 - val_acc: 0.6400\n",
            "Epoch 686/4500\n",
            "100/100 [==============================] - 0s 530us/step - loss: 0.6188 - acc: 0.6900 - val_loss: 0.6574 - val_acc: 0.6400\n",
            "Epoch 687/4500\n",
            "100/100 [==============================] - 0s 530us/step - loss: 0.6187 - acc: 0.6900 - val_loss: 0.6576 - val_acc: 0.6400\n",
            "Epoch 688/4500\n",
            "100/100 [==============================] - 0s 589us/step - loss: 0.6188 - acc: 0.6900 - val_loss: 0.6582 - val_acc: 0.6400\n",
            "Epoch 689/4500\n",
            "100/100 [==============================] - 0s 590us/step - loss: 0.6188 - acc: 0.6900 - val_loss: 0.6582 - val_acc: 0.6400\n",
            "Epoch 690/4500\n",
            "100/100 [==============================] - 0s 555us/step - loss: 0.6191 - acc: 0.6900 - val_loss: 0.6589 - val_acc: 0.6400\n",
            "Epoch 691/4500\n",
            "100/100 [==============================] - 0s 521us/step - loss: 0.6187 - acc: 0.6900 - val_loss: 0.6577 - val_acc: 0.6400\n",
            "Epoch 692/4500\n",
            "100/100 [==============================] - 0s 505us/step - loss: 0.6188 - acc: 0.6900 - val_loss: 0.6581 - val_acc: 0.6400\n",
            "Epoch 693/4500\n",
            "100/100 [==============================] - 0s 519us/step - loss: 0.6188 - acc: 0.6900 - val_loss: 0.6581 - val_acc: 0.6400\n",
            "Epoch 694/4500\n",
            "100/100 [==============================] - 0s 525us/step - loss: 0.6187 - acc: 0.6900 - val_loss: 0.6575 - val_acc: 0.6400\n",
            "Epoch 695/4500\n",
            "100/100 [==============================] - 0s 622us/step - loss: 0.6194 - acc: 0.6900 - val_loss: 0.6586 - val_acc: 0.6400\n",
            "Epoch 696/4500\n",
            "100/100 [==============================] - 0s 564us/step - loss: 0.6186 - acc: 0.6900 - val_loss: 0.6577 - val_acc: 0.6400\n",
            "Epoch 697/4500\n",
            "100/100 [==============================] - 0s 513us/step - loss: 0.6187 - acc: 0.6900 - val_loss: 0.6575 - val_acc: 0.6400\n",
            "Epoch 698/4500\n",
            "100/100 [==============================] - 0s 511us/step - loss: 0.6190 - acc: 0.6900 - val_loss: 0.6584 - val_acc: 0.6400\n",
            "Epoch 699/4500\n",
            "100/100 [==============================] - 0s 504us/step - loss: 0.6190 - acc: 0.6900 - val_loss: 0.6579 - val_acc: 0.6400\n",
            "Epoch 700/4500\n",
            "100/100 [==============================] - 0s 494us/step - loss: 0.6185 - acc: 0.6900 - val_loss: 0.6576 - val_acc: 0.6400\n",
            "Epoch 701/4500\n",
            "100/100 [==============================] - 0s 489us/step - loss: 0.6195 - acc: 0.6900 - val_loss: 0.6569 - val_acc: 0.6400\n",
            "Epoch 702/4500\n",
            "100/100 [==============================] - 0s 517us/step - loss: 0.6192 - acc: 0.6900 - val_loss: 0.6581 - val_acc: 0.6400\n",
            "Epoch 703/4500\n",
            "100/100 [==============================] - 0s 553us/step - loss: 0.6185 - acc: 0.6900 - val_loss: 0.6583 - val_acc: 0.6400\n",
            "Epoch 704/4500\n",
            "100/100 [==============================] - 0s 521us/step - loss: 0.6186 - acc: 0.6900 - val_loss: 0.6583 - val_acc: 0.6400\n",
            "Epoch 705/4500\n",
            "100/100 [==============================] - 0s 523us/step - loss: 0.6188 - acc: 0.6900 - val_loss: 0.6578 - val_acc: 0.6400\n",
            "Epoch 706/4500\n",
            "100/100 [==============================] - 0s 516us/step - loss: 0.6188 - acc: 0.6900 - val_loss: 0.6580 - val_acc: 0.6400\n",
            "Epoch 707/4500\n",
            "100/100 [==============================] - 0s 493us/step - loss: 0.6198 - acc: 0.6900 - val_loss: 0.6594 - val_acc: 0.6400\n",
            "Epoch 708/4500\n",
            "100/100 [==============================] - 0s 518us/step - loss: 0.6195 - acc: 0.6900 - val_loss: 0.6598 - val_acc: 0.6400\n",
            "Epoch 709/4500\n",
            "100/100 [==============================] - 0s 515us/step - loss: 0.6196 - acc: 0.6900 - val_loss: 0.6572 - val_acc: 0.6400\n",
            "Epoch 710/4500\n",
            "100/100 [==============================] - 0s 558us/step - loss: 0.6188 - acc: 0.6900 - val_loss: 0.6579 - val_acc: 0.6400\n",
            "Epoch 711/4500\n",
            "100/100 [==============================] - 0s 623us/step - loss: 0.6189 - acc: 0.6900 - val_loss: 0.6581 - val_acc: 0.6400\n",
            "Epoch 712/4500\n",
            "100/100 [==============================] - 0s 608us/step - loss: 0.6184 - acc: 0.6900 - val_loss: 0.6581 - val_acc: 0.6400\n",
            "Epoch 713/4500\n",
            "100/100 [==============================] - 0s 588us/step - loss: 0.6186 - acc: 0.6900 - val_loss: 0.6573 - val_acc: 0.6400\n",
            "Epoch 714/4500\n",
            "100/100 [==============================] - 0s 556us/step - loss: 0.6186 - acc: 0.6900 - val_loss: 0.6572 - val_acc: 0.6400\n",
            "Epoch 715/4500\n",
            "100/100 [==============================] - 0s 529us/step - loss: 0.6184 - acc: 0.6900 - val_loss: 0.6575 - val_acc: 0.6400\n",
            "Epoch 716/4500\n",
            "100/100 [==============================] - 0s 532us/step - loss: 0.6185 - acc: 0.6900 - val_loss: 0.6582 - val_acc: 0.6400\n",
            "Epoch 717/4500\n",
            "100/100 [==============================] - 0s 538us/step - loss: 0.6190 - acc: 0.6900 - val_loss: 0.6588 - val_acc: 0.6400\n",
            "Epoch 718/4500\n",
            "100/100 [==============================] - 0s 650us/step - loss: 0.6191 - acc: 0.6900 - val_loss: 0.6576 - val_acc: 0.6400\n",
            "Epoch 719/4500\n",
            "100/100 [==============================] - 0s 568us/step - loss: 0.6196 - acc: 0.6900 - val_loss: 0.6588 - val_acc: 0.6400\n",
            "Epoch 720/4500\n",
            "100/100 [==============================] - 0s 568us/step - loss: 0.6185 - acc: 0.6900 - val_loss: 0.6582 - val_acc: 0.6400\n",
            "Epoch 721/4500\n",
            "100/100 [==============================] - 0s 586us/step - loss: 0.6193 - acc: 0.6900 - val_loss: 0.6569 - val_acc: 0.6400\n",
            "Epoch 722/4500\n",
            "100/100 [==============================] - 0s 559us/step - loss: 0.6187 - acc: 0.6900 - val_loss: 0.6572 - val_acc: 0.6400\n",
            "Epoch 723/4500\n",
            "100/100 [==============================] - 0s 524us/step - loss: 0.6190 - acc: 0.6900 - val_loss: 0.6577 - val_acc: 0.6400\n",
            "Epoch 724/4500\n",
            "100/100 [==============================] - 0s 553us/step - loss: 0.6190 - acc: 0.6900 - val_loss: 0.6574 - val_acc: 0.6400\n",
            "Epoch 725/4500\n",
            "100/100 [==============================] - 0s 591us/step - loss: 0.6186 - acc: 0.6900 - val_loss: 0.6582 - val_acc: 0.6400\n",
            "Epoch 726/4500\n",
            "100/100 [==============================] - 0s 532us/step - loss: 0.6189 - acc: 0.6900 - val_loss: 0.6587 - val_acc: 0.6400\n",
            "Epoch 727/4500\n",
            "100/100 [==============================] - 0s 547us/step - loss: 0.6184 - acc: 0.6900 - val_loss: 0.6581 - val_acc: 0.6400\n",
            "Epoch 728/4500\n",
            "100/100 [==============================] - 0s 557us/step - loss: 0.6201 - acc: 0.6900 - val_loss: 0.6568 - val_acc: 0.6400\n",
            "Epoch 729/4500\n",
            "100/100 [==============================] - 0s 582us/step - loss: 0.6205 - acc: 0.6900 - val_loss: 0.6591 - val_acc: 0.6400\n",
            "Epoch 730/4500\n",
            "100/100 [==============================] - 0s 608us/step - loss: 0.6201 - acc: 0.6900 - val_loss: 0.6574 - val_acc: 0.6400\n",
            "Epoch 731/4500\n",
            "100/100 [==============================] - 0s 594us/step - loss: 0.6194 - acc: 0.6900 - val_loss: 0.6570 - val_acc: 0.6400\n",
            "Epoch 732/4500\n",
            "100/100 [==============================] - 0s 515us/step - loss: 0.6188 - acc: 0.6900 - val_loss: 0.6581 - val_acc: 0.6400\n",
            "Epoch 733/4500\n",
            "100/100 [==============================] - 0s 522us/step - loss: 0.6184 - acc: 0.6900 - val_loss: 0.6581 - val_acc: 0.6400\n",
            "Epoch 734/4500\n",
            "100/100 [==============================] - 0s 604us/step - loss: 0.6186 - acc: 0.6900 - val_loss: 0.6585 - val_acc: 0.6400\n",
            "Epoch 735/4500\n",
            "100/100 [==============================] - 0s 571us/step - loss: 0.6191 - acc: 0.6900 - val_loss: 0.6591 - val_acc: 0.6400\n",
            "Epoch 736/4500\n",
            "100/100 [==============================] - 0s 561us/step - loss: 0.6185 - acc: 0.6900 - val_loss: 0.6581 - val_acc: 0.6400\n",
            "Epoch 737/4500\n",
            "100/100 [==============================] - 0s 529us/step - loss: 0.6186 - acc: 0.6900 - val_loss: 0.6581 - val_acc: 0.6400\n",
            "Epoch 738/4500\n",
            "100/100 [==============================] - 0s 545us/step - loss: 0.6190 - acc: 0.6900 - val_loss: 0.6574 - val_acc: 0.6400\n",
            "Epoch 739/4500\n",
            "100/100 [==============================] - 0s 536us/step - loss: 0.6189 - acc: 0.6900 - val_loss: 0.6584 - val_acc: 0.6400\n",
            "Epoch 740/4500\n",
            "100/100 [==============================] - 0s 531us/step - loss: 0.6186 - acc: 0.6900 - val_loss: 0.6580 - val_acc: 0.6400\n",
            "Epoch 741/4500\n",
            "100/100 [==============================] - 0s 557us/step - loss: 0.6192 - acc: 0.6900 - val_loss: 0.6577 - val_acc: 0.6400\n",
            "Epoch 742/4500\n",
            "100/100 [==============================] - 0s 563us/step - loss: 0.6184 - acc: 0.6900 - val_loss: 0.6578 - val_acc: 0.6400\n",
            "Epoch 743/4500\n",
            "100/100 [==============================] - 0s 566us/step - loss: 0.6187 - acc: 0.6900 - val_loss: 0.6573 - val_acc: 0.6400\n",
            "Epoch 744/4500\n",
            "100/100 [==============================] - 0s 554us/step - loss: 0.6186 - acc: 0.6900 - val_loss: 0.6578 - val_acc: 0.6400\n",
            "Epoch 745/4500\n",
            "100/100 [==============================] - 0s 649us/step - loss: 0.6186 - acc: 0.6900 - val_loss: 0.6580 - val_acc: 0.6400\n",
            "Epoch 746/4500\n",
            "100/100 [==============================] - 0s 534us/step - loss: 0.6185 - acc: 0.6900 - val_loss: 0.6581 - val_acc: 0.6400\n",
            "Epoch 747/4500\n",
            "100/100 [==============================] - 0s 495us/step - loss: 0.6187 - acc: 0.6900 - val_loss: 0.6577 - val_acc: 0.6400\n",
            "Epoch 748/4500\n",
            "100/100 [==============================] - 0s 589us/step - loss: 0.6191 - acc: 0.6900 - val_loss: 0.6576 - val_acc: 0.6400\n",
            "Epoch 749/4500\n",
            "100/100 [==============================] - 0s 644us/step - loss: 0.6186 - acc: 0.6900 - val_loss: 0.6580 - val_acc: 0.6400\n",
            "Epoch 750/4500\n",
            "100/100 [==============================] - 0s 584us/step - loss: 0.6221 - acc: 0.6900 - val_loss: 0.6601 - val_acc: 0.6400\n",
            "Epoch 751/4500\n",
            "100/100 [==============================] - 0s 599us/step - loss: 0.6183 - acc: 0.6900 - val_loss: 0.6582 - val_acc: 0.6400\n",
            "Epoch 752/4500\n",
            "100/100 [==============================] - 0s 575us/step - loss: 0.6184 - acc: 0.6900 - val_loss: 0.6581 - val_acc: 0.6400\n",
            "Epoch 753/4500\n",
            "100/100 [==============================] - 0s 533us/step - loss: 0.6193 - acc: 0.6900 - val_loss: 0.6566 - val_acc: 0.6400\n",
            "Epoch 754/4500\n",
            "100/100 [==============================] - 0s 531us/step - loss: 0.6189 - acc: 0.6900 - val_loss: 0.6577 - val_acc: 0.6400\n",
            "Epoch 755/4500\n",
            "100/100 [==============================] - 0s 578us/step - loss: 0.6204 - acc: 0.6900 - val_loss: 0.6565 - val_acc: 0.6400\n",
            "Epoch 756/4500\n",
            "100/100 [==============================] - 0s 501us/step - loss: 0.6186 - acc: 0.6900 - val_loss: 0.6573 - val_acc: 0.6400\n",
            "Epoch 757/4500\n",
            "100/100 [==============================] - 0s 536us/step - loss: 0.6190 - acc: 0.6900 - val_loss: 0.6573 - val_acc: 0.6400\n",
            "Epoch 758/4500\n",
            "100/100 [==============================] - 0s 493us/step - loss: 0.6187 - acc: 0.6900 - val_loss: 0.6585 - val_acc: 0.6400\n",
            "Epoch 759/4500\n",
            "100/100 [==============================] - 0s 578us/step - loss: 0.6192 - acc: 0.6900 - val_loss: 0.6595 - val_acc: 0.6400\n",
            "Epoch 760/4500\n",
            "100/100 [==============================] - 0s 548us/step - loss: 0.6183 - acc: 0.6900 - val_loss: 0.6589 - val_acc: 0.6400\n",
            "Epoch 761/4500\n",
            "100/100 [==============================] - 0s 537us/step - loss: 0.6187 - acc: 0.6900 - val_loss: 0.6577 - val_acc: 0.6400\n",
            "Epoch 762/4500\n",
            "100/100 [==============================] - 0s 550us/step - loss: 0.6190 - acc: 0.6900 - val_loss: 0.6571 - val_acc: 0.6400\n",
            "Epoch 763/4500\n",
            "100/100 [==============================] - 0s 538us/step - loss: 0.6200 - acc: 0.6900 - val_loss: 0.6588 - val_acc: 0.6400\n",
            "Epoch 764/4500\n",
            "100/100 [==============================] - 0s 510us/step - loss: 0.6189 - acc: 0.6900 - val_loss: 0.6573 - val_acc: 0.6400\n",
            "Epoch 765/4500\n",
            "100/100 [==============================] - 0s 527us/step - loss: 0.6185 - acc: 0.6900 - val_loss: 0.6578 - val_acc: 0.6400\n",
            "Epoch 766/4500\n",
            "100/100 [==============================] - 0s 522us/step - loss: 0.6188 - acc: 0.6900 - val_loss: 0.6574 - val_acc: 0.6400\n",
            "Epoch 767/4500\n",
            "100/100 [==============================] - 0s 612us/step - loss: 0.6189 - acc: 0.6900 - val_loss: 0.6580 - val_acc: 0.6400\n",
            "Epoch 768/4500\n",
            "100/100 [==============================] - 0s 568us/step - loss: 0.6187 - acc: 0.6900 - val_loss: 0.6580 - val_acc: 0.6400\n",
            "Epoch 769/4500\n",
            "100/100 [==============================] - 0s 562us/step - loss: 0.6191 - acc: 0.6900 - val_loss: 0.6581 - val_acc: 0.6400\n",
            "Epoch 770/4500\n",
            "100/100 [==============================] - 0s 533us/step - loss: 0.6186 - acc: 0.6900 - val_loss: 0.6574 - val_acc: 0.6400\n",
            "Epoch 771/4500\n",
            "100/100 [==============================] - 0s 499us/step - loss: 0.6191 - acc: 0.6900 - val_loss: 0.6581 - val_acc: 0.6400\n",
            "Epoch 772/4500\n",
            "100/100 [==============================] - 0s 536us/step - loss: 0.6187 - acc: 0.6900 - val_loss: 0.6573 - val_acc: 0.6400\n",
            "Epoch 773/4500\n",
            "100/100 [==============================] - 0s 546us/step - loss: 0.6190 - acc: 0.6900 - val_loss: 0.6569 - val_acc: 0.6400\n",
            "Epoch 774/4500\n",
            "100/100 [==============================] - 0s 507us/step - loss: 0.6185 - acc: 0.6900 - val_loss: 0.6579 - val_acc: 0.6400\n",
            "Epoch 775/4500\n",
            "100/100 [==============================] - 0s 538us/step - loss: 0.6191 - acc: 0.6900 - val_loss: 0.6591 - val_acc: 0.6400\n",
            "Epoch 776/4500\n",
            "100/100 [==============================] - 0s 525us/step - loss: 0.6194 - acc: 0.6900 - val_loss: 0.6576 - val_acc: 0.6400\n",
            "Epoch 777/4500\n",
            "100/100 [==============================] - 0s 538us/step - loss: 0.6187 - acc: 0.6900 - val_loss: 0.6578 - val_acc: 0.6400\n",
            "Epoch 778/4500\n",
            "100/100 [==============================] - 0s 490us/step - loss: 0.6184 - acc: 0.6900 - val_loss: 0.6582 - val_acc: 0.6400\n",
            "Epoch 779/4500\n",
            "100/100 [==============================] - 0s 505us/step - loss: 0.6189 - acc: 0.6900 - val_loss: 0.6588 - val_acc: 0.6400\n",
            "Epoch 780/4500\n",
            "100/100 [==============================] - 0s 541us/step - loss: 0.6189 - acc: 0.6900 - val_loss: 0.6574 - val_acc: 0.6400\n",
            "Epoch 781/4500\n",
            "100/100 [==============================] - 0s 526us/step - loss: 0.6189 - acc: 0.6900 - val_loss: 0.6576 - val_acc: 0.6400\n",
            "Epoch 782/4500\n",
            "100/100 [==============================] - 0s 530us/step - loss: 0.6188 - acc: 0.6900 - val_loss: 0.6584 - val_acc: 0.6400\n",
            "Epoch 783/4500\n",
            "100/100 [==============================] - 0s 591us/step - loss: 0.6185 - acc: 0.6900 - val_loss: 0.6582 - val_acc: 0.6400\n",
            "Epoch 784/4500\n",
            "100/100 [==============================] - 0s 550us/step - loss: 0.6186 - acc: 0.6900 - val_loss: 0.6578 - val_acc: 0.6400\n",
            "Epoch 785/4500\n",
            "100/100 [==============================] - 0s 486us/step - loss: 0.6186 - acc: 0.6900 - val_loss: 0.6578 - val_acc: 0.6400\n",
            "Epoch 786/4500\n",
            "100/100 [==============================] - 0s 591us/step - loss: 0.6183 - acc: 0.6900 - val_loss: 0.6578 - val_acc: 0.6400\n",
            "Epoch 787/4500\n",
            "100/100 [==============================] - 0s 495us/step - loss: 0.6182 - acc: 0.6900 - val_loss: 0.6578 - val_acc: 0.6400\n",
            "Epoch 788/4500\n",
            "100/100 [==============================] - 0s 531us/step - loss: 0.6184 - acc: 0.6900 - val_loss: 0.6579 - val_acc: 0.6400\n",
            "Epoch 789/4500\n",
            "100/100 [==============================] - 0s 541us/step - loss: 0.6184 - acc: 0.6900 - val_loss: 0.6578 - val_acc: 0.6400\n",
            "Epoch 790/4500\n",
            "100/100 [==============================] - 0s 553us/step - loss: 0.6182 - acc: 0.6900 - val_loss: 0.6579 - val_acc: 0.6400\n",
            "Epoch 791/4500\n",
            "100/100 [==============================] - 0s 552us/step - loss: 0.6188 - acc: 0.6900 - val_loss: 0.6582 - val_acc: 0.6400\n",
            "Epoch 792/4500\n",
            "100/100 [==============================] - 0s 541us/step - loss: 0.6187 - acc: 0.6900 - val_loss: 0.6579 - val_acc: 0.6400\n",
            "Epoch 793/4500\n",
            "100/100 [==============================] - 0s 551us/step - loss: 0.6183 - acc: 0.6900 - val_loss: 0.6575 - val_acc: 0.6400\n",
            "Epoch 794/4500\n",
            "100/100 [==============================] - 0s 518us/step - loss: 0.6187 - acc: 0.6900 - val_loss: 0.6572 - val_acc: 0.6400\n",
            "Epoch 795/4500\n",
            "100/100 [==============================] - 0s 506us/step - loss: 0.6195 - acc: 0.6900 - val_loss: 0.6588 - val_acc: 0.6400\n",
            "Epoch 796/4500\n",
            "100/100 [==============================] - 0s 513us/step - loss: 0.6185 - acc: 0.6900 - val_loss: 0.6577 - val_acc: 0.6400\n",
            "Epoch 797/4500\n",
            "100/100 [==============================] - 0s 527us/step - loss: 0.6185 - acc: 0.6900 - val_loss: 0.6573 - val_acc: 0.6400\n",
            "Epoch 798/4500\n",
            "100/100 [==============================] - 0s 498us/step - loss: 0.6186 - acc: 0.6900 - val_loss: 0.6583 - val_acc: 0.6400\n",
            "Epoch 799/4500\n",
            "100/100 [==============================] - 0s 496us/step - loss: 0.6185 - acc: 0.6900 - val_loss: 0.6576 - val_acc: 0.6400\n",
            "Epoch 800/4500\n",
            "100/100 [==============================] - 0s 585us/step - loss: 0.6186 - acc: 0.6900 - val_loss: 0.6583 - val_acc: 0.6400\n",
            "Epoch 801/4500\n",
            "100/100 [==============================] - 0s 559us/step - loss: 0.6184 - acc: 0.6900 - val_loss: 0.6581 - val_acc: 0.6400\n",
            "Epoch 802/4500\n",
            "100/100 [==============================] - 0s 535us/step - loss: 0.6187 - acc: 0.6900 - val_loss: 0.6572 - val_acc: 0.6400\n",
            "Epoch 803/4500\n",
            "100/100 [==============================] - 0s 518us/step - loss: 0.6183 - acc: 0.6900 - val_loss: 0.6578 - val_acc: 0.6400\n",
            "Epoch 804/4500\n",
            "100/100 [==============================] - 0s 538us/step - loss: 0.6185 - acc: 0.6900 - val_loss: 0.6576 - val_acc: 0.6400\n",
            "Epoch 805/4500\n",
            "100/100 [==============================] - 0s 602us/step - loss: 0.6184 - acc: 0.6900 - val_loss: 0.6581 - val_acc: 0.6400\n",
            "Epoch 806/4500\n",
            "100/100 [==============================] - 0s 518us/step - loss: 0.6188 - acc: 0.6900 - val_loss: 0.6575 - val_acc: 0.6400\n",
            "Epoch 807/4500\n",
            "100/100 [==============================] - 0s 500us/step - loss: 0.6186 - acc: 0.6900 - val_loss: 0.6574 - val_acc: 0.6400\n",
            "Epoch 808/4500\n",
            "100/100 [==============================] - 0s 610us/step - loss: 0.6184 - acc: 0.6900 - val_loss: 0.6580 - val_acc: 0.6400\n",
            "Epoch 809/4500\n",
            "100/100 [==============================] - 0s 529us/step - loss: 0.6184 - acc: 0.6900 - val_loss: 0.6582 - val_acc: 0.6400\n",
            "Epoch 810/4500\n",
            "100/100 [==============================] - 0s 530us/step - loss: 0.6189 - acc: 0.6900 - val_loss: 0.6576 - val_acc: 0.6400\n",
            "Epoch 811/4500\n",
            "100/100 [==============================] - 0s 579us/step - loss: 0.6187 - acc: 0.6900 - val_loss: 0.6575 - val_acc: 0.6400\n",
            "Epoch 812/4500\n",
            "100/100 [==============================] - 0s 502us/step - loss: 0.6186 - acc: 0.6900 - val_loss: 0.6581 - val_acc: 0.6400\n",
            "Epoch 813/4500\n",
            "100/100 [==============================] - 0s 529us/step - loss: 0.6182 - acc: 0.6900 - val_loss: 0.6583 - val_acc: 0.6400\n",
            "Epoch 814/4500\n",
            "100/100 [==============================] - 0s 516us/step - loss: 0.6189 - acc: 0.6900 - val_loss: 0.6593 - val_acc: 0.6400\n",
            "Epoch 815/4500\n",
            "100/100 [==============================] - 0s 508us/step - loss: 0.6183 - acc: 0.6900 - val_loss: 0.6588 - val_acc: 0.6400\n",
            "Epoch 816/4500\n",
            "100/100 [==============================] - 0s 509us/step - loss: 0.6192 - acc: 0.6900 - val_loss: 0.6592 - val_acc: 0.6400\n",
            "Epoch 817/4500\n",
            "100/100 [==============================] - 0s 515us/step - loss: 0.6185 - acc: 0.6900 - val_loss: 0.6578 - val_acc: 0.6400\n",
            "Epoch 818/4500\n",
            "100/100 [==============================] - 0s 547us/step - loss: 0.6186 - acc: 0.6900 - val_loss: 0.6569 - val_acc: 0.6400\n",
            "Epoch 819/4500\n",
            "100/100 [==============================] - 0s 538us/step - loss: 0.6184 - acc: 0.6900 - val_loss: 0.6569 - val_acc: 0.6400\n",
            "Epoch 820/4500\n",
            "100/100 [==============================] - 0s 535us/step - loss: 0.6182 - acc: 0.6900 - val_loss: 0.6577 - val_acc: 0.6400\n",
            "Epoch 821/4500\n",
            "100/100 [==============================] - 0s 508us/step - loss: 0.6185 - acc: 0.6900 - val_loss: 0.6577 - val_acc: 0.6400\n",
            "Epoch 822/4500\n",
            "100/100 [==============================] - 0s 584us/step - loss: 0.6185 - acc: 0.6900 - val_loss: 0.6583 - val_acc: 0.6400\n",
            "Epoch 823/4500\n",
            "100/100 [==============================] - 0s 553us/step - loss: 0.6187 - acc: 0.6900 - val_loss: 0.6575 - val_acc: 0.6400\n",
            "Epoch 824/4500\n",
            "100/100 [==============================] - 0s 509us/step - loss: 0.6189 - acc: 0.6900 - val_loss: 0.6581 - val_acc: 0.6400\n",
            "Epoch 825/4500\n",
            "100/100 [==============================] - 0s 500us/step - loss: 0.6187 - acc: 0.6900 - val_loss: 0.6586 - val_acc: 0.6400\n",
            "Epoch 826/4500\n",
            "100/100 [==============================] - 0s 497us/step - loss: 0.6186 - acc: 0.6900 - val_loss: 0.6584 - val_acc: 0.6400\n",
            "Epoch 827/4500\n",
            "100/100 [==============================] - 0s 502us/step - loss: 0.6192 - acc: 0.6900 - val_loss: 0.6590 - val_acc: 0.6400\n",
            "Epoch 828/4500\n",
            "100/100 [==============================] - 0s 533us/step - loss: 0.6191 - acc: 0.6900 - val_loss: 0.6573 - val_acc: 0.6400\n",
            "Epoch 829/4500\n",
            "100/100 [==============================] - 0s 520us/step - loss: 0.6189 - acc: 0.6900 - val_loss: 0.6573 - val_acc: 0.6400\n",
            "Epoch 830/4500\n",
            "100/100 [==============================] - 0s 560us/step - loss: 0.6187 - acc: 0.6900 - val_loss: 0.6568 - val_acc: 0.6400\n",
            "Epoch 831/4500\n",
            "100/100 [==============================] - 0s 610us/step - loss: 0.6184 - acc: 0.6900 - val_loss: 0.6572 - val_acc: 0.6400\n",
            "Epoch 832/4500\n",
            "100/100 [==============================] - 0s 538us/step - loss: 0.6185 - acc: 0.6900 - val_loss: 0.6569 - val_acc: 0.6400\n",
            "Epoch 833/4500\n",
            "100/100 [==============================] - 0s 512us/step - loss: 0.6200 - acc: 0.6900 - val_loss: 0.6588 - val_acc: 0.6400\n",
            "Epoch 834/4500\n",
            "100/100 [==============================] - 0s 506us/step - loss: 0.6184 - acc: 0.6900 - val_loss: 0.6586 - val_acc: 0.6400\n",
            "Epoch 835/4500\n",
            "100/100 [==============================] - 0s 504us/step - loss: 0.6184 - acc: 0.6900 - val_loss: 0.6574 - val_acc: 0.6400\n",
            "Epoch 836/4500\n",
            "100/100 [==============================] - 0s 495us/step - loss: 0.6189 - acc: 0.6900 - val_loss: 0.6566 - val_acc: 0.6400\n",
            "Epoch 837/4500\n",
            "100/100 [==============================] - 0s 507us/step - loss: 0.6191 - acc: 0.6900 - val_loss: 0.6579 - val_acc: 0.6400\n",
            "Epoch 838/4500\n",
            "100/100 [==============================] - 0s 521us/step - loss: 0.6186 - acc: 0.6900 - val_loss: 0.6580 - val_acc: 0.6400\n",
            "Epoch 839/4500\n",
            "100/100 [==============================] - 0s 536us/step - loss: 0.6184 - acc: 0.6900 - val_loss: 0.6576 - val_acc: 0.6400\n",
            "Epoch 840/4500\n",
            "100/100 [==============================] - 0s 516us/step - loss: 0.6185 - acc: 0.6900 - val_loss: 0.6572 - val_acc: 0.6400\n",
            "Epoch 841/4500\n",
            "100/100 [==============================] - 0s 540us/step - loss: 0.6189 - acc: 0.6900 - val_loss: 0.6564 - val_acc: 0.6400\n",
            "Epoch 842/4500\n",
            "100/100 [==============================] - 0s 542us/step - loss: 0.6182 - acc: 0.6900 - val_loss: 0.6571 - val_acc: 0.6400\n",
            "Epoch 843/4500\n",
            "100/100 [==============================] - 0s 529us/step - loss: 0.6186 - acc: 0.6900 - val_loss: 0.6580 - val_acc: 0.6400\n",
            "Epoch 844/4500\n",
            "100/100 [==============================] - 0s 537us/step - loss: 0.6182 - acc: 0.6900 - val_loss: 0.6579 - val_acc: 0.6400\n",
            "Epoch 845/4500\n",
            "100/100 [==============================] - 0s 556us/step - loss: 0.6182 - acc: 0.6900 - val_loss: 0.6578 - val_acc: 0.6400\n",
            "Epoch 846/4500\n",
            "100/100 [==============================] - 0s 498us/step - loss: 0.6183 - acc: 0.6900 - val_loss: 0.6577 - val_acc: 0.6400\n",
            "Epoch 847/4500\n",
            "100/100 [==============================] - 0s 501us/step - loss: 0.6187 - acc: 0.6900 - val_loss: 0.6583 - val_acc: 0.6400\n",
            "Epoch 848/4500\n",
            "100/100 [==============================] - 0s 514us/step - loss: 0.6182 - acc: 0.6900 - val_loss: 0.6578 - val_acc: 0.6400\n",
            "Epoch 849/4500\n",
            "100/100 [==============================] - 0s 518us/step - loss: 0.6182 - acc: 0.6900 - val_loss: 0.6577 - val_acc: 0.6400\n",
            "Epoch 850/4500\n",
            "100/100 [==============================] - 0s 538us/step - loss: 0.6183 - acc: 0.6900 - val_loss: 0.6579 - val_acc: 0.6400\n",
            "Epoch 851/4500\n",
            "100/100 [==============================] - 0s 552us/step - loss: 0.6189 - acc: 0.6900 - val_loss: 0.6587 - val_acc: 0.6400\n",
            "Epoch 852/4500\n",
            "100/100 [==============================] - 0s 473us/step - loss: 0.6185 - acc: 0.6900 - val_loss: 0.6577 - val_acc: 0.6400\n",
            "Epoch 853/4500\n",
            "100/100 [==============================] - 0s 513us/step - loss: 0.6183 - acc: 0.6900 - val_loss: 0.6577 - val_acc: 0.6400\n",
            "Epoch 854/4500\n",
            "100/100 [==============================] - 0s 521us/step - loss: 0.6190 - acc: 0.6900 - val_loss: 0.6566 - val_acc: 0.6400\n",
            "Epoch 855/4500\n",
            "100/100 [==============================] - 0s 515us/step - loss: 0.6184 - acc: 0.6900 - val_loss: 0.6572 - val_acc: 0.6400\n",
            "Epoch 856/4500\n",
            "100/100 [==============================] - 0s 520us/step - loss: 0.6182 - acc: 0.6900 - val_loss: 0.6571 - val_acc: 0.6400\n",
            "Epoch 857/4500\n",
            "100/100 [==============================] - 0s 506us/step - loss: 0.6186 - acc: 0.6900 - val_loss: 0.6572 - val_acc: 0.6400\n",
            "Epoch 858/4500\n",
            "100/100 [==============================] - 0s 548us/step - loss: 0.6184 - acc: 0.6900 - val_loss: 0.6576 - val_acc: 0.6400\n",
            "Epoch 859/4500\n",
            "100/100 [==============================] - 0s 545us/step - loss: 0.6183 - acc: 0.6900 - val_loss: 0.6578 - val_acc: 0.6400\n",
            "Epoch 860/4500\n",
            "100/100 [==============================] - 0s 495us/step - loss: 0.6184 - acc: 0.6900 - val_loss: 0.6576 - val_acc: 0.6400\n",
            "Epoch 861/4500\n",
            "100/100 [==============================] - 0s 561us/step - loss: 0.6189 - acc: 0.6900 - val_loss: 0.6588 - val_acc: 0.6400\n",
            "Epoch 862/4500\n",
            "100/100 [==============================] - 0s 604us/step - loss: 0.6187 - acc: 0.6900 - val_loss: 0.6575 - val_acc: 0.6400\n",
            "Epoch 863/4500\n",
            "100/100 [==============================] - 0s 511us/step - loss: 0.6185 - acc: 0.6900 - val_loss: 0.6571 - val_acc: 0.6400\n",
            "Epoch 864/4500\n",
            "100/100 [==============================] - 0s 491us/step - loss: 0.6181 - acc: 0.6900 - val_loss: 0.6575 - val_acc: 0.6400\n",
            "Epoch 865/4500\n",
            "100/100 [==============================] - 0s 481us/step - loss: 0.6183 - acc: 0.6900 - val_loss: 0.6580 - val_acc: 0.6400\n",
            "Epoch 866/4500\n",
            "100/100 [==============================] - 0s 494us/step - loss: 0.6182 - acc: 0.6900 - val_loss: 0.6578 - val_acc: 0.6400\n",
            "Epoch 867/4500\n",
            "100/100 [==============================] - 0s 521us/step - loss: 0.6193 - acc: 0.6900 - val_loss: 0.6568 - val_acc: 0.6400\n",
            "Epoch 868/4500\n",
            "100/100 [==============================] - 0s 615us/step - loss: 0.6183 - acc: 0.6900 - val_loss: 0.6577 - val_acc: 0.6400\n",
            "Epoch 869/4500\n",
            "100/100 [==============================] - 0s 590us/step - loss: 0.6182 - acc: 0.6900 - val_loss: 0.6581 - val_acc: 0.6400\n",
            "Epoch 870/4500\n",
            "100/100 [==============================] - 0s 638us/step - loss: 0.6188 - acc: 0.6900 - val_loss: 0.6573 - val_acc: 0.6400\n",
            "Epoch 871/4500\n",
            "100/100 [==============================] - 0s 569us/step - loss: 0.6191 - acc: 0.6900 - val_loss: 0.6588 - val_acc: 0.6400\n",
            "Epoch 872/4500\n",
            "100/100 [==============================] - 0s 553us/step - loss: 0.6181 - acc: 0.6900 - val_loss: 0.6580 - val_acc: 0.6400\n",
            "Epoch 873/4500\n",
            "100/100 [==============================] - 0s 497us/step - loss: 0.6183 - acc: 0.6900 - val_loss: 0.6577 - val_acc: 0.6400\n",
            "Epoch 874/4500\n",
            "100/100 [==============================] - 0s 509us/step - loss: 0.6184 - acc: 0.6900 - val_loss: 0.6573 - val_acc: 0.6400\n",
            "Epoch 875/4500\n",
            "100/100 [==============================] - 0s 525us/step - loss: 0.6189 - acc: 0.6900 - val_loss: 0.6571 - val_acc: 0.6400\n",
            "Epoch 876/4500\n",
            "100/100 [==============================] - 0s 555us/step - loss: 0.6183 - acc: 0.6900 - val_loss: 0.6573 - val_acc: 0.6400\n",
            "Epoch 877/4500\n",
            "100/100 [==============================] - 0s 521us/step - loss: 0.6188 - acc: 0.6900 - val_loss: 0.6584 - val_acc: 0.6400\n",
            "Epoch 878/4500\n",
            "100/100 [==============================] - 0s 549us/step - loss: 0.6182 - acc: 0.6900 - val_loss: 0.6586 - val_acc: 0.6400\n",
            "Epoch 879/4500\n",
            "100/100 [==============================] - 0s 692us/step - loss: 0.6181 - acc: 0.6900 - val_loss: 0.6583 - val_acc: 0.6400\n",
            "Epoch 880/4500\n",
            "100/100 [==============================] - 0s 681us/step - loss: 0.6186 - acc: 0.6900 - val_loss: 0.6581 - val_acc: 0.6400\n",
            "Epoch 881/4500\n",
            "100/100 [==============================] - 0s 545us/step - loss: 0.6184 - acc: 0.6900 - val_loss: 0.6577 - val_acc: 0.6400\n",
            "Epoch 882/4500\n",
            "100/100 [==============================] - 0s 540us/step - loss: 0.6189 - acc: 0.6900 - val_loss: 0.6573 - val_acc: 0.6400\n",
            "Epoch 883/4500\n",
            "100/100 [==============================] - 0s 614us/step - loss: 0.6182 - acc: 0.6900 - val_loss: 0.6580 - val_acc: 0.6400\n",
            "Epoch 884/4500\n",
            "100/100 [==============================] - 0s 577us/step - loss: 0.6181 - acc: 0.6900 - val_loss: 0.6577 - val_acc: 0.6400\n",
            "Epoch 885/4500\n",
            "100/100 [==============================] - 0s 595us/step - loss: 0.6183 - acc: 0.6900 - val_loss: 0.6576 - val_acc: 0.6400\n",
            "Epoch 886/4500\n",
            "100/100 [==============================] - 0s 553us/step - loss: 0.6188 - acc: 0.6900 - val_loss: 0.6576 - val_acc: 0.6400\n",
            "Epoch 887/4500\n",
            "100/100 [==============================] - 0s 561us/step - loss: 0.6184 - acc: 0.6900 - val_loss: 0.6580 - val_acc: 0.6400\n",
            "Epoch 888/4500\n",
            "100/100 [==============================] - 0s 537us/step - loss: 0.6184 - acc: 0.6900 - val_loss: 0.6573 - val_acc: 0.6400\n",
            "Epoch 889/4500\n",
            "100/100 [==============================] - 0s 515us/step - loss: 0.6183 - acc: 0.6900 - val_loss: 0.6574 - val_acc: 0.6400\n",
            "Epoch 890/4500\n",
            "100/100 [==============================] - 0s 513us/step - loss: 0.6182 - acc: 0.6900 - val_loss: 0.6568 - val_acc: 0.6400\n",
            "Epoch 891/4500\n",
            "100/100 [==============================] - 0s 505us/step - loss: 0.6189 - acc: 0.6900 - val_loss: 0.6577 - val_acc: 0.6400\n",
            "Epoch 892/4500\n",
            "100/100 [==============================] - 0s 529us/step - loss: 0.6182 - acc: 0.6900 - val_loss: 0.6575 - val_acc: 0.6400\n",
            "Epoch 893/4500\n",
            "100/100 [==============================] - 0s 505us/step - loss: 0.6180 - acc: 0.6900 - val_loss: 0.6576 - val_acc: 0.6400\n",
            "Epoch 894/4500\n",
            "100/100 [==============================] - 0s 502us/step - loss: 0.6183 - acc: 0.6900 - val_loss: 0.6575 - val_acc: 0.6400\n",
            "Epoch 895/4500\n",
            "100/100 [==============================] - 0s 493us/step - loss: 0.6184 - acc: 0.6900 - val_loss: 0.6571 - val_acc: 0.6400\n",
            "Epoch 896/4500\n",
            "100/100 [==============================] - 0s 499us/step - loss: 0.6185 - acc: 0.6900 - val_loss: 0.6575 - val_acc: 0.6400\n",
            "Epoch 897/4500\n",
            "100/100 [==============================] - 0s 511us/step - loss: 0.6186 - acc: 0.6900 - val_loss: 0.6568 - val_acc: 0.6400\n",
            "Epoch 898/4500\n",
            "100/100 [==============================] - 0s 659us/step - loss: 0.6184 - acc: 0.6900 - val_loss: 0.6579 - val_acc: 0.6400\n",
            "Epoch 899/4500\n",
            "100/100 [==============================] - 0s 544us/step - loss: 0.6182 - acc: 0.6900 - val_loss: 0.6574 - val_acc: 0.6400\n",
            "Epoch 900/4500\n",
            "100/100 [==============================] - 0s 517us/step - loss: 0.6186 - acc: 0.6900 - val_loss: 0.6583 - val_acc: 0.6400\n",
            "Epoch 901/4500\n",
            "100/100 [==============================] - 0s 501us/step - loss: 0.6184 - acc: 0.6900 - val_loss: 0.6582 - val_acc: 0.6400\n",
            "Epoch 902/4500\n",
            "100/100 [==============================] - 0s 544us/step - loss: 0.6186 - acc: 0.6900 - val_loss: 0.6579 - val_acc: 0.6400\n",
            "Epoch 903/4500\n",
            "100/100 [==============================] - 0s 528us/step - loss: 0.6182 - acc: 0.6900 - val_loss: 0.6581 - val_acc: 0.6400\n",
            "Epoch 904/4500\n",
            "100/100 [==============================] - 0s 490us/step - loss: 0.6180 - acc: 0.6900 - val_loss: 0.6575 - val_acc: 0.6400\n",
            "Epoch 905/4500\n",
            "100/100 [==============================] - 0s 518us/step - loss: 0.6186 - acc: 0.6900 - val_loss: 0.6570 - val_acc: 0.6400\n",
            "Epoch 906/4500\n",
            "100/100 [==============================] - 0s 526us/step - loss: 0.6191 - acc: 0.6900 - val_loss: 0.6582 - val_acc: 0.6400\n",
            "Epoch 907/4500\n",
            "100/100 [==============================] - 0s 509us/step - loss: 0.6181 - acc: 0.6900 - val_loss: 0.6574 - val_acc: 0.6400\n",
            "Epoch 908/4500\n",
            "100/100 [==============================] - 0s 609us/step - loss: 0.6184 - acc: 0.6900 - val_loss: 0.6567 - val_acc: 0.6400\n",
            "Epoch 909/4500\n",
            "100/100 [==============================] - 0s 501us/step - loss: 0.6185 - acc: 0.6900 - val_loss: 0.6565 - val_acc: 0.6400\n",
            "Epoch 910/4500\n",
            "100/100 [==============================] - 0s 494us/step - loss: 0.6182 - acc: 0.6900 - val_loss: 0.6575 - val_acc: 0.6400\n",
            "Epoch 911/4500\n",
            "100/100 [==============================] - 0s 518us/step - loss: 0.6185 - acc: 0.6900 - val_loss: 0.6579 - val_acc: 0.6400\n",
            "Epoch 912/4500\n",
            "100/100 [==============================] - 0s 519us/step - loss: 0.6188 - acc: 0.6900 - val_loss: 0.6585 - val_acc: 0.6400\n",
            "Epoch 913/4500\n",
            "100/100 [==============================] - 0s 508us/step - loss: 0.6196 - acc: 0.6900 - val_loss: 0.6568 - val_acc: 0.6400\n",
            "Epoch 914/4500\n",
            "100/100 [==============================] - 0s 513us/step - loss: 0.6181 - acc: 0.6900 - val_loss: 0.6569 - val_acc: 0.6400\n",
            "Epoch 915/4500\n",
            "100/100 [==============================] - 0s 542us/step - loss: 0.6182 - acc: 0.6900 - val_loss: 0.6574 - val_acc: 0.6400\n",
            "Epoch 916/4500\n",
            "100/100 [==============================] - 0s 535us/step - loss: 0.6184 - acc: 0.6900 - val_loss: 0.6568 - val_acc: 0.6400\n",
            "Epoch 917/4500\n",
            "100/100 [==============================] - 0s 647us/step - loss: 0.6180 - acc: 0.6900 - val_loss: 0.6577 - val_acc: 0.6400\n",
            "Epoch 918/4500\n",
            "100/100 [==============================] - 0s 644us/step - loss: 0.6186 - acc: 0.6900 - val_loss: 0.6571 - val_acc: 0.6400\n",
            "Epoch 919/4500\n",
            "100/100 [==============================] - 0s 503us/step - loss: 0.6179 - acc: 0.6900 - val_loss: 0.6574 - val_acc: 0.6400\n",
            "Epoch 920/4500\n",
            "100/100 [==============================] - 0s 517us/step - loss: 0.6181 - acc: 0.6900 - val_loss: 0.6575 - val_acc: 0.6400\n",
            "Epoch 921/4500\n",
            "100/100 [==============================] - 0s 554us/step - loss: 0.6179 - acc: 0.6900 - val_loss: 0.6581 - val_acc: 0.6400\n",
            "Epoch 922/4500\n",
            "100/100 [==============================] - 0s 513us/step - loss: 0.6183 - acc: 0.6900 - val_loss: 0.6578 - val_acc: 0.6400\n",
            "Epoch 923/4500\n",
            "100/100 [==============================] - 0s 498us/step - loss: 0.6183 - acc: 0.6900 - val_loss: 0.6583 - val_acc: 0.6400\n",
            "Epoch 924/4500\n",
            "100/100 [==============================] - 0s 504us/step - loss: 0.6182 - acc: 0.6900 - val_loss: 0.6584 - val_acc: 0.6400\n",
            "Epoch 925/4500\n",
            "100/100 [==============================] - 0s 528us/step - loss: 0.6186 - acc: 0.6900 - val_loss: 0.6582 - val_acc: 0.6400\n",
            "Epoch 926/4500\n",
            "100/100 [==============================] - 0s 565us/step - loss: 0.6183 - acc: 0.6900 - val_loss: 0.6571 - val_acc: 0.6400\n",
            "Epoch 927/4500\n",
            "100/100 [==============================] - 0s 532us/step - loss: 0.6187 - acc: 0.6900 - val_loss: 0.6582 - val_acc: 0.6400\n",
            "Epoch 928/4500\n",
            "100/100 [==============================] - 0s 499us/step - loss: 0.6186 - acc: 0.6900 - val_loss: 0.6571 - val_acc: 0.6400\n",
            "Epoch 929/4500\n",
            "100/100 [==============================] - 0s 488us/step - loss: 0.6183 - acc: 0.6900 - val_loss: 0.6576 - val_acc: 0.6400\n",
            "Epoch 930/4500\n",
            "100/100 [==============================] - 0s 507us/step - loss: 0.6183 - acc: 0.6900 - val_loss: 0.6571 - val_acc: 0.6400\n",
            "Epoch 931/4500\n",
            "100/100 [==============================] - 0s 495us/step - loss: 0.6182 - acc: 0.6900 - val_loss: 0.6570 - val_acc: 0.6400\n",
            "Epoch 932/4500\n",
            "100/100 [==============================] - 0s 544us/step - loss: 0.6187 - acc: 0.6900 - val_loss: 0.6582 - val_acc: 0.6400\n",
            "Epoch 933/4500\n",
            "100/100 [==============================] - 0s 527us/step - loss: 0.6180 - acc: 0.6900 - val_loss: 0.6577 - val_acc: 0.6400\n",
            "Epoch 934/4500\n",
            "100/100 [==============================] - 0s 507us/step - loss: 0.6182 - acc: 0.6900 - val_loss: 0.6572 - val_acc: 0.6400\n",
            "Epoch 935/4500\n",
            "100/100 [==============================] - 0s 545us/step - loss: 0.6180 - acc: 0.6900 - val_loss: 0.6575 - val_acc: 0.6400\n",
            "Epoch 936/4500\n",
            "100/100 [==============================] - 0s 615us/step - loss: 0.6180 - acc: 0.6900 - val_loss: 0.6577 - val_acc: 0.6400\n",
            "Epoch 937/4500\n",
            "100/100 [==============================] - 0s 504us/step - loss: 0.6181 - acc: 0.6900 - val_loss: 0.6571 - val_acc: 0.6400\n",
            "Epoch 938/4500\n",
            "100/100 [==============================] - 0s 552us/step - loss: 0.6179 - acc: 0.6900 - val_loss: 0.6569 - val_acc: 0.6400\n",
            "Epoch 939/4500\n",
            "100/100 [==============================] - 0s 504us/step - loss: 0.6183 - acc: 0.6900 - val_loss: 0.6578 - val_acc: 0.6400\n",
            "Epoch 940/4500\n",
            "100/100 [==============================] - 0s 497us/step - loss: 0.6182 - acc: 0.6900 - val_loss: 0.6572 - val_acc: 0.6400\n",
            "Epoch 941/4500\n",
            "100/100 [==============================] - 0s 489us/step - loss: 0.6179 - acc: 0.6900 - val_loss: 0.6571 - val_acc: 0.6400\n",
            "Epoch 942/4500\n",
            "100/100 [==============================] - 0s 497us/step - loss: 0.6181 - acc: 0.6900 - val_loss: 0.6569 - val_acc: 0.6400\n",
            "Epoch 943/4500\n",
            "100/100 [==============================] - 0s 501us/step - loss: 0.6181 - acc: 0.6900 - val_loss: 0.6574 - val_acc: 0.6400\n",
            "Epoch 944/4500\n",
            "100/100 [==============================] - 0s 517us/step - loss: 0.6179 - acc: 0.6900 - val_loss: 0.6574 - val_acc: 0.6400\n",
            "Epoch 945/4500\n",
            "100/100 [==============================] - 0s 494us/step - loss: 0.6181 - acc: 0.6900 - val_loss: 0.6580 - val_acc: 0.6400\n",
            "Epoch 946/4500\n",
            "100/100 [==============================] - 0s 501us/step - loss: 0.6181 - acc: 0.6900 - val_loss: 0.6580 - val_acc: 0.6400\n",
            "Epoch 947/4500\n",
            "100/100 [==============================] - 0s 542us/step - loss: 0.6181 - acc: 0.6900 - val_loss: 0.6579 - val_acc: 0.6400\n",
            "Epoch 948/4500\n",
            "100/100 [==============================] - 0s 574us/step - loss: 0.6184 - acc: 0.6900 - val_loss: 0.6573 - val_acc: 0.6400\n",
            "Epoch 949/4500\n",
            "100/100 [==============================] - 0s 532us/step - loss: 0.6186 - acc: 0.6900 - val_loss: 0.6577 - val_acc: 0.6400\n",
            "Epoch 950/4500\n",
            "100/100 [==============================] - 0s 499us/step - loss: 0.6191 - acc: 0.6900 - val_loss: 0.6567 - val_acc: 0.6400\n",
            "Epoch 951/4500\n",
            "100/100 [==============================] - 0s 504us/step - loss: 0.6190 - acc: 0.6900 - val_loss: 0.6580 - val_acc: 0.6400\n",
            "Epoch 952/4500\n",
            "100/100 [==============================] - 0s 515us/step - loss: 0.6181 - acc: 0.6900 - val_loss: 0.6577 - val_acc: 0.6400\n",
            "Epoch 953/4500\n",
            "100/100 [==============================] - 0s 553us/step - loss: 0.6177 - acc: 0.6900 - val_loss: 0.6573 - val_acc: 0.6400\n",
            "Epoch 954/4500\n",
            "100/100 [==============================] - 0s 499us/step - loss: 0.6184 - acc: 0.6900 - val_loss: 0.6566 - val_acc: 0.6400\n",
            "Epoch 955/4500\n",
            "100/100 [==============================] - 0s 578us/step - loss: 0.6181 - acc: 0.6900 - val_loss: 0.6574 - val_acc: 0.6400\n",
            "Epoch 956/4500\n",
            "100/100 [==============================] - 0s 512us/step - loss: 0.6178 - acc: 0.6900 - val_loss: 0.6571 - val_acc: 0.6400\n",
            "Epoch 957/4500\n",
            "100/100 [==============================] - 0s 577us/step - loss: 0.6191 - acc: 0.6900 - val_loss: 0.6582 - val_acc: 0.6400\n",
            "Epoch 958/4500\n",
            "100/100 [==============================] - 0s 529us/step - loss: 0.6179 - acc: 0.6900 - val_loss: 0.6576 - val_acc: 0.6400\n",
            "Epoch 959/4500\n",
            "100/100 [==============================] - 0s 505us/step - loss: 0.6179 - acc: 0.6900 - val_loss: 0.6570 - val_acc: 0.6400\n",
            "Epoch 960/4500\n",
            "100/100 [==============================] - 0s 467us/step - loss: 0.6180 - acc: 0.6900 - val_loss: 0.6572 - val_acc: 0.6400\n",
            "Epoch 961/4500\n",
            "100/100 [==============================] - 0s 527us/step - loss: 0.6178 - acc: 0.6900 - val_loss: 0.6571 - val_acc: 0.6400\n",
            "Epoch 962/4500\n",
            "100/100 [==============================] - 0s 587us/step - loss: 0.6184 - acc: 0.6900 - val_loss: 0.6574 - val_acc: 0.6400\n",
            "Epoch 963/4500\n",
            "100/100 [==============================] - 0s 522us/step - loss: 0.6179 - acc: 0.6900 - val_loss: 0.6575 - val_acc: 0.6400\n",
            "Epoch 964/4500\n",
            "100/100 [==============================] - 0s 556us/step - loss: 0.6181 - acc: 0.6900 - val_loss: 0.6567 - val_acc: 0.6400\n",
            "Epoch 965/4500\n",
            "100/100 [==============================] - 0s 512us/step - loss: 0.6180 - acc: 0.6900 - val_loss: 0.6565 - val_acc: 0.6400\n",
            "Epoch 966/4500\n",
            "100/100 [==============================] - 0s 503us/step - loss: 0.6180 - acc: 0.6900 - val_loss: 0.6573 - val_acc: 0.6400\n",
            "Epoch 967/4500\n",
            "100/100 [==============================] - 0s 592us/step - loss: 0.6179 - acc: 0.6900 - val_loss: 0.6568 - val_acc: 0.6400\n",
            "Epoch 968/4500\n",
            "100/100 [==============================] - 0s 564us/step - loss: 0.6181 - acc: 0.6900 - val_loss: 0.6577 - val_acc: 0.6400\n",
            "Epoch 969/4500\n",
            "100/100 [==============================] - 0s 485us/step - loss: 0.6179 - acc: 0.6900 - val_loss: 0.6579 - val_acc: 0.6400\n",
            "Epoch 970/4500\n",
            "100/100 [==============================] - 0s 515us/step - loss: 0.6182 - acc: 0.6900 - val_loss: 0.6576 - val_acc: 0.6400\n",
            "Epoch 971/4500\n",
            "100/100 [==============================] - 0s 480us/step - loss: 0.6178 - acc: 0.6900 - val_loss: 0.6571 - val_acc: 0.6400\n",
            "Epoch 972/4500\n",
            "100/100 [==============================] - 0s 510us/step - loss: 0.6178 - acc: 0.6900 - val_loss: 0.6571 - val_acc: 0.6400\n",
            "Epoch 973/4500\n",
            "100/100 [==============================] - 0s 660us/step - loss: 0.6181 - acc: 0.6900 - val_loss: 0.6576 - val_acc: 0.6400\n",
            "Epoch 974/4500\n",
            "100/100 [==============================] - 0s 718us/step - loss: 0.6184 - acc: 0.6900 - val_loss: 0.6578 - val_acc: 0.6400\n",
            "Epoch 975/4500\n",
            "100/100 [==============================] - 0s 597us/step - loss: 0.6181 - acc: 0.6900 - val_loss: 0.6570 - val_acc: 0.6400\n",
            "Epoch 976/4500\n",
            "100/100 [==============================] - 0s 613us/step - loss: 0.6178 - acc: 0.6900 - val_loss: 0.6568 - val_acc: 0.6400\n",
            "Epoch 977/4500\n",
            "100/100 [==============================] - 0s 555us/step - loss: 0.6179 - acc: 0.6900 - val_loss: 0.6571 - val_acc: 0.6400\n",
            "Epoch 978/4500\n",
            "100/100 [==============================] - 0s 520us/step - loss: 0.6178 - acc: 0.6900 - val_loss: 0.6569 - val_acc: 0.6400\n",
            "Epoch 979/4500\n",
            "100/100 [==============================] - 0s 488us/step - loss: 0.6178 - acc: 0.6900 - val_loss: 0.6570 - val_acc: 0.6400\n",
            "Epoch 980/4500\n",
            "100/100 [==============================] - 0s 494us/step - loss: 0.6195 - acc: 0.6900 - val_loss: 0.6582 - val_acc: 0.6400\n",
            "Epoch 981/4500\n",
            "100/100 [==============================] - 0s 526us/step - loss: 0.6185 - acc: 0.6900 - val_loss: 0.6569 - val_acc: 0.6400\n",
            "Epoch 982/4500\n",
            "100/100 [==============================] - 0s 521us/step - loss: 0.6183 - acc: 0.6900 - val_loss: 0.6573 - val_acc: 0.6400\n",
            "Epoch 983/4500\n",
            "100/100 [==============================] - 0s 497us/step - loss: 0.6178 - acc: 0.6900 - val_loss: 0.6567 - val_acc: 0.6400\n",
            "Epoch 984/4500\n",
            "100/100 [==============================] - 0s 605us/step - loss: 0.6178 - acc: 0.6900 - val_loss: 0.6566 - val_acc: 0.6400\n",
            "Epoch 985/4500\n",
            "100/100 [==============================] - 0s 531us/step - loss: 0.6179 - acc: 0.6900 - val_loss: 0.6562 - val_acc: 0.6400\n",
            "Epoch 986/4500\n",
            "100/100 [==============================] - 0s 536us/step - loss: 0.6182 - acc: 0.6900 - val_loss: 0.6562 - val_acc: 0.6400\n",
            "Epoch 987/4500\n",
            "100/100 [==============================] - 0s 505us/step - loss: 0.6183 - acc: 0.6900 - val_loss: 0.6575 - val_acc: 0.6400\n",
            "Epoch 988/4500\n",
            "100/100 [==============================] - 0s 507us/step - loss: 0.6180 - acc: 0.6900 - val_loss: 0.6575 - val_acc: 0.6400\n",
            "Epoch 989/4500\n",
            "100/100 [==============================] - 0s 549us/step - loss: 0.6182 - acc: 0.6900 - val_loss: 0.6571 - val_acc: 0.6400\n",
            "Epoch 990/4500\n",
            "100/100 [==============================] - 0s 499us/step - loss: 0.6180 - acc: 0.6900 - val_loss: 0.6580 - val_acc: 0.6400\n",
            "Epoch 991/4500\n",
            "100/100 [==============================] - 0s 514us/step - loss: 0.6178 - acc: 0.6900 - val_loss: 0.6573 - val_acc: 0.6400\n",
            "Epoch 992/4500\n",
            "100/100 [==============================] - 0s 591us/step - loss: 0.6183 - acc: 0.6900 - val_loss: 0.6569 - val_acc: 0.6400\n",
            "Epoch 993/4500\n",
            "100/100 [==============================] - 0s 520us/step - loss: 0.6179 - acc: 0.6900 - val_loss: 0.6567 - val_acc: 0.6400\n",
            "Epoch 994/4500\n",
            "100/100 [==============================] - 0s 507us/step - loss: 0.6178 - acc: 0.6900 - val_loss: 0.6573 - val_acc: 0.6400\n",
            "Epoch 995/4500\n",
            "100/100 [==============================] - 0s 498us/step - loss: 0.6179 - acc: 0.6900 - val_loss: 0.6572 - val_acc: 0.6400\n",
            "Epoch 996/4500\n",
            "100/100 [==============================] - 0s 556us/step - loss: 0.6177 - acc: 0.6900 - val_loss: 0.6570 - val_acc: 0.6400\n",
            "Epoch 997/4500\n",
            "100/100 [==============================] - 0s 539us/step - loss: 0.6182 - acc: 0.6900 - val_loss: 0.6566 - val_acc: 0.6400\n",
            "Epoch 998/4500\n",
            "100/100 [==============================] - 0s 496us/step - loss: 0.6180 - acc: 0.6900 - val_loss: 0.6568 - val_acc: 0.6400\n",
            "Epoch 999/4500\n",
            "100/100 [==============================] - 0s 512us/step - loss: 0.6178 - acc: 0.6900 - val_loss: 0.6567 - val_acc: 0.6400\n",
            "Epoch 1000/4500\n",
            "100/100 [==============================] - 0s 500us/step - loss: 0.6179 - acc: 0.6900 - val_loss: 0.6577 - val_acc: 0.6400\n",
            "Epoch 1001/4500\n",
            "100/100 [==============================] - 0s 561us/step - loss: 0.6178 - acc: 0.6900 - val_loss: 0.6575 - val_acc: 0.6400\n",
            "Epoch 1002/4500\n",
            "100/100 [==============================] - 0s 490us/step - loss: 0.6178 - acc: 0.6900 - val_loss: 0.6578 - val_acc: 0.6400\n",
            "Epoch 1003/4500\n",
            "100/100 [==============================] - 0s 499us/step - loss: 0.6177 - acc: 0.6900 - val_loss: 0.6577 - val_acc: 0.6400\n",
            "Epoch 1004/4500\n",
            "100/100 [==============================] - 0s 492us/step - loss: 0.6188 - acc: 0.6900 - val_loss: 0.6564 - val_acc: 0.6400\n",
            "Epoch 1005/4500\n",
            "100/100 [==============================] - 0s 519us/step - loss: 0.6177 - acc: 0.6900 - val_loss: 0.6572 - val_acc: 0.6400\n",
            "Epoch 1006/4500\n",
            "100/100 [==============================] - 0s 600us/step - loss: 0.6183 - acc: 0.6900 - val_loss: 0.6580 - val_acc: 0.6400\n",
            "Epoch 1007/4500\n",
            "100/100 [==============================] - 0s 494us/step - loss: 0.6188 - acc: 0.6900 - val_loss: 0.6566 - val_acc: 0.6400\n",
            "Epoch 1008/4500\n",
            "100/100 [==============================] - 0s 506us/step - loss: 0.6178 - acc: 0.6900 - val_loss: 0.6570 - val_acc: 0.6400\n",
            "Epoch 1009/4500\n",
            "100/100 [==============================] - 0s 506us/step - loss: 0.6180 - acc: 0.6900 - val_loss: 0.6579 - val_acc: 0.6400\n",
            "Epoch 1010/4500\n",
            "100/100 [==============================] - 0s 535us/step - loss: 0.6176 - acc: 0.6900 - val_loss: 0.6572 - val_acc: 0.6400\n",
            "Epoch 1011/4500\n",
            "100/100 [==============================] - 0s 607us/step - loss: 0.6177 - acc: 0.6900 - val_loss: 0.6572 - val_acc: 0.6400\n",
            "Epoch 1012/4500\n",
            "100/100 [==============================] - 0s 554us/step - loss: 0.6177 - acc: 0.6900 - val_loss: 0.6568 - val_acc: 0.6400\n",
            "Epoch 1013/4500\n",
            "100/100 [==============================] - 0s 503us/step - loss: 0.6175 - acc: 0.6900 - val_loss: 0.6570 - val_acc: 0.6400\n",
            "Epoch 1014/4500\n",
            "100/100 [==============================] - 0s 533us/step - loss: 0.6178 - acc: 0.6900 - val_loss: 0.6567 - val_acc: 0.6400\n",
            "Epoch 1015/4500\n",
            "100/100 [==============================] - 0s 569us/step - loss: 0.6176 - acc: 0.6900 - val_loss: 0.6574 - val_acc: 0.6400\n",
            "Epoch 1016/4500\n",
            "100/100 [==============================] - 0s 562us/step - loss: 0.6176 - acc: 0.6900 - val_loss: 0.6573 - val_acc: 0.6400\n",
            "Epoch 1017/4500\n",
            "100/100 [==============================] - 0s 555us/step - loss: 0.6184 - acc: 0.6900 - val_loss: 0.6564 - val_acc: 0.6400\n",
            "Epoch 1018/4500\n",
            "100/100 [==============================] - 0s 508us/step - loss: 0.6179 - acc: 0.6900 - val_loss: 0.6577 - val_acc: 0.6400\n",
            "Epoch 1019/4500\n",
            "100/100 [==============================] - 0s 494us/step - loss: 0.6177 - acc: 0.6900 - val_loss: 0.6572 - val_acc: 0.6400\n",
            "Epoch 1020/4500\n",
            "100/100 [==============================] - 0s 511us/step - loss: 0.6177 - acc: 0.6900 - val_loss: 0.6570 - val_acc: 0.6400\n",
            "Epoch 1021/4500\n",
            "100/100 [==============================] - 0s 520us/step - loss: 0.6180 - acc: 0.6900 - val_loss: 0.6566 - val_acc: 0.6400\n",
            "Epoch 1022/4500\n",
            "100/100 [==============================] - 0s 496us/step - loss: 0.6177 - acc: 0.6900 - val_loss: 0.6569 - val_acc: 0.6400\n",
            "Epoch 1023/4500\n",
            "100/100 [==============================] - 0s 500us/step - loss: 0.6181 - acc: 0.6900 - val_loss: 0.6567 - val_acc: 0.6400\n",
            "Epoch 1024/4500\n",
            "100/100 [==============================] - 0s 523us/step - loss: 0.6182 - acc: 0.6900 - val_loss: 0.6574 - val_acc: 0.6400\n",
            "Epoch 1025/4500\n",
            "100/100 [==============================] - 0s 546us/step - loss: 0.6176 - acc: 0.6900 - val_loss: 0.6579 - val_acc: 0.6400\n",
            "Epoch 1026/4500\n",
            "100/100 [==============================] - 0s 554us/step - loss: 0.6178 - acc: 0.6900 - val_loss: 0.6573 - val_acc: 0.6400\n",
            "Epoch 1027/4500\n",
            "100/100 [==============================] - 0s 534us/step - loss: 0.6175 - acc: 0.6900 - val_loss: 0.6573 - val_acc: 0.6400\n",
            "Epoch 1028/4500\n",
            "100/100 [==============================] - 0s 512us/step - loss: 0.6186 - acc: 0.6900 - val_loss: 0.6564 - val_acc: 0.6400\n",
            "Epoch 1029/4500\n",
            "100/100 [==============================] - 0s 486us/step - loss: 0.6177 - acc: 0.6900 - val_loss: 0.6572 - val_acc: 0.6400\n",
            "Epoch 1030/4500\n",
            "100/100 [==============================] - 0s 657us/step - loss: 0.6177 - acc: 0.6900 - val_loss: 0.6571 - val_acc: 0.6400\n",
            "Epoch 1031/4500\n",
            "100/100 [==============================] - 0s 566us/step - loss: 0.6177 - acc: 0.6900 - val_loss: 0.6577 - val_acc: 0.6400\n",
            "Epoch 1032/4500\n",
            "100/100 [==============================] - 0s 555us/step - loss: 0.6180 - acc: 0.6900 - val_loss: 0.6570 - val_acc: 0.6400\n",
            "Epoch 1033/4500\n",
            "100/100 [==============================] - 0s 511us/step - loss: 0.6181 - acc: 0.6900 - val_loss: 0.6564 - val_acc: 0.6400\n",
            "Epoch 1034/4500\n",
            "100/100 [==============================] - 0s 507us/step - loss: 0.6175 - acc: 0.6900 - val_loss: 0.6571 - val_acc: 0.6400\n",
            "Epoch 1035/4500\n",
            "100/100 [==============================] - 0s 557us/step - loss: 0.6178 - acc: 0.6900 - val_loss: 0.6578 - val_acc: 0.6400\n",
            "Epoch 1036/4500\n",
            "100/100 [==============================] - 0s 654us/step - loss: 0.6179 - acc: 0.6900 - val_loss: 0.6573 - val_acc: 0.6400\n",
            "Epoch 1037/4500\n",
            "100/100 [==============================] - 0s 542us/step - loss: 0.6175 - acc: 0.6900 - val_loss: 0.6574 - val_acc: 0.6400\n",
            "Epoch 1038/4500\n",
            "100/100 [==============================] - 0s 510us/step - loss: 0.6175 - acc: 0.6900 - val_loss: 0.6575 - val_acc: 0.6400\n",
            "Epoch 1039/4500\n",
            "100/100 [==============================] - 0s 500us/step - loss: 0.6177 - acc: 0.6900 - val_loss: 0.6573 - val_acc: 0.6400\n",
            "Epoch 1040/4500\n",
            "100/100 [==============================] - 0s 551us/step - loss: 0.6175 - acc: 0.6900 - val_loss: 0.6572 - val_acc: 0.6400\n",
            "Epoch 1041/4500\n",
            "100/100 [==============================] - 0s 557us/step - loss: 0.6175 - acc: 0.6900 - val_loss: 0.6573 - val_acc: 0.6400\n",
            "Epoch 1042/4500\n",
            "100/100 [==============================] - 0s 496us/step - loss: 0.6180 - acc: 0.6900 - val_loss: 0.6569 - val_acc: 0.6400\n",
            "Epoch 1043/4500\n",
            "100/100 [==============================] - 0s 488us/step - loss: 0.6176 - acc: 0.6900 - val_loss: 0.6569 - val_acc: 0.6400\n",
            "Epoch 1044/4500\n",
            "100/100 [==============================] - 0s 532us/step - loss: 0.6178 - acc: 0.6900 - val_loss: 0.6565 - val_acc: 0.6400\n",
            "Epoch 1045/4500\n",
            "100/100 [==============================] - 0s 594us/step - loss: 0.6183 - acc: 0.6900 - val_loss: 0.6576 - val_acc: 0.6400\n",
            "Epoch 1046/4500\n",
            "100/100 [==============================] - 0s 569us/step - loss: 0.6177 - acc: 0.6900 - val_loss: 0.6568 - val_acc: 0.6400\n",
            "Epoch 1047/4500\n",
            "100/100 [==============================] - 0s 534us/step - loss: 0.6175 - acc: 0.6900 - val_loss: 0.6570 - val_acc: 0.6400\n",
            "Epoch 1048/4500\n",
            "100/100 [==============================] - 0s 797us/step - loss: 0.6189 - acc: 0.6900 - val_loss: 0.6558 - val_acc: 0.6400\n",
            "Epoch 1049/4500\n",
            "100/100 [==============================] - 0s 540us/step - loss: 0.6178 - acc: 0.6900 - val_loss: 0.6569 - val_acc: 0.6400\n",
            "Epoch 1050/4500\n",
            "100/100 [==============================] - 0s 569us/step - loss: 0.6181 - acc: 0.6900 - val_loss: 0.6575 - val_acc: 0.6400\n",
            "Epoch 1051/4500\n",
            "100/100 [==============================] - 0s 525us/step - loss: 0.6177 - acc: 0.6900 - val_loss: 0.6571 - val_acc: 0.6400\n",
            "Epoch 1052/4500\n",
            "100/100 [==============================] - 0s 529us/step - loss: 0.6181 - acc: 0.6900 - val_loss: 0.6564 - val_acc: 0.6400\n",
            "Epoch 1053/4500\n",
            "100/100 [==============================] - 0s 505us/step - loss: 0.6174 - acc: 0.6900 - val_loss: 0.6565 - val_acc: 0.6400\n",
            "Epoch 1054/4500\n",
            "100/100 [==============================] - 0s 589us/step - loss: 0.6174 - acc: 0.6900 - val_loss: 0.6569 - val_acc: 0.6400\n",
            "Epoch 1055/4500\n",
            "100/100 [==============================] - 0s 585us/step - loss: 0.6178 - acc: 0.6900 - val_loss: 0.6575 - val_acc: 0.6400\n",
            "Epoch 1056/4500\n",
            "100/100 [==============================] - 0s 499us/step - loss: 0.6174 - acc: 0.6900 - val_loss: 0.6572 - val_acc: 0.6400\n",
            "Epoch 1057/4500\n",
            "100/100 [==============================] - 0s 500us/step - loss: 0.6184 - acc: 0.6900 - val_loss: 0.6564 - val_acc: 0.6400\n",
            "Epoch 1058/4500\n",
            "100/100 [==============================] - 0s 509us/step - loss: 0.6184 - acc: 0.6900 - val_loss: 0.6576 - val_acc: 0.6400\n",
            "Epoch 1059/4500\n",
            "100/100 [==============================] - 0s 502us/step - loss: 0.6175 - acc: 0.6900 - val_loss: 0.6572 - val_acc: 0.6400\n",
            "Epoch 1060/4500\n",
            "100/100 [==============================] - 0s 493us/step - loss: 0.6179 - acc: 0.6900 - val_loss: 0.6563 - val_acc: 0.6400\n",
            "Epoch 1061/4500\n",
            "100/100 [==============================] - 0s 491us/step - loss: 0.6176 - acc: 0.6900 - val_loss: 0.6569 - val_acc: 0.6400\n",
            "Epoch 1062/4500\n",
            "100/100 [==============================] - 0s 515us/step - loss: 0.6175 - acc: 0.6900 - val_loss: 0.6566 - val_acc: 0.6400\n",
            "Epoch 1063/4500\n",
            "100/100 [==============================] - 0s 560us/step - loss: 0.6175 - acc: 0.6900 - val_loss: 0.6570 - val_acc: 0.6400\n",
            "Epoch 1064/4500\n",
            "100/100 [==============================] - 0s 640us/step - loss: 0.6181 - acc: 0.6900 - val_loss: 0.6576 - val_acc: 0.6400\n",
            "Epoch 1065/4500\n",
            "100/100 [==============================] - 0s 644us/step - loss: 0.6173 - acc: 0.6900 - val_loss: 0.6569 - val_acc: 0.6400\n",
            "Epoch 1066/4500\n",
            "100/100 [==============================] - 0s 709us/step - loss: 0.6175 - acc: 0.6900 - val_loss: 0.6570 - val_acc: 0.6400\n",
            "Epoch 1067/4500\n",
            "100/100 [==============================] - 0s 530us/step - loss: 0.6175 - acc: 0.6900 - val_loss: 0.6565 - val_acc: 0.6400\n",
            "Epoch 1068/4500\n",
            "100/100 [==============================] - 0s 536us/step - loss: 0.6178 - acc: 0.6900 - val_loss: 0.6560 - val_acc: 0.6400\n",
            "Epoch 1069/4500\n",
            "100/100 [==============================] - 0s 510us/step - loss: 0.6176 - acc: 0.6900 - val_loss: 0.6560 - val_acc: 0.6400\n",
            "Epoch 1070/4500\n",
            "100/100 [==============================] - 0s 542us/step - loss: 0.6174 - acc: 0.6900 - val_loss: 0.6563 - val_acc: 0.6400\n",
            "Epoch 1071/4500\n",
            "100/100 [==============================] - 0s 511us/step - loss: 0.6174 - acc: 0.6900 - val_loss: 0.6571 - val_acc: 0.6400\n",
            "Epoch 1072/4500\n",
            "100/100 [==============================] - 0s 512us/step - loss: 0.6176 - acc: 0.6900 - val_loss: 0.6569 - val_acc: 0.6400\n",
            "Epoch 1073/4500\n",
            "100/100 [==============================] - 0s 553us/step - loss: 0.6178 - acc: 0.6900 - val_loss: 0.6565 - val_acc: 0.6400\n",
            "Epoch 1074/4500\n",
            "100/100 [==============================] - 0s 527us/step - loss: 0.6178 - acc: 0.6900 - val_loss: 0.6570 - val_acc: 0.6400\n",
            "Epoch 1075/4500\n",
            "100/100 [==============================] - 0s 498us/step - loss: 0.6177 - acc: 0.6900 - val_loss: 0.6569 - val_acc: 0.6400\n",
            "Epoch 1076/4500\n",
            "100/100 [==============================] - 0s 505us/step - loss: 0.6174 - acc: 0.6900 - val_loss: 0.6568 - val_acc: 0.6400\n",
            "Epoch 1077/4500\n",
            "100/100 [==============================] - 0s 508us/step - loss: 0.6178 - acc: 0.6900 - val_loss: 0.6574 - val_acc: 0.6400\n",
            "Epoch 1078/4500\n",
            "100/100 [==============================] - 0s 499us/step - loss: 0.6177 - acc: 0.6900 - val_loss: 0.6568 - val_acc: 0.6400\n",
            "Epoch 1079/4500\n",
            "100/100 [==============================] - 0s 501us/step - loss: 0.6174 - acc: 0.6900 - val_loss: 0.6569 - val_acc: 0.6400\n",
            "Epoch 1080/4500\n",
            "100/100 [==============================] - 0s 506us/step - loss: 0.6174 - acc: 0.6900 - val_loss: 0.6567 - val_acc: 0.6400\n",
            "Epoch 1081/4500\n",
            "100/100 [==============================] - 0s 523us/step - loss: 0.6173 - acc: 0.6900 - val_loss: 0.6570 - val_acc: 0.6400\n",
            "Epoch 1082/4500\n",
            "100/100 [==============================] - 0s 536us/step - loss: 0.6177 - acc: 0.6900 - val_loss: 0.6577 - val_acc: 0.6400\n",
            "Epoch 1083/4500\n",
            "100/100 [==============================] - 0s 486us/step - loss: 0.6177 - acc: 0.6900 - val_loss: 0.6565 - val_acc: 0.6400\n",
            "Epoch 1084/4500\n",
            "100/100 [==============================] - 0s 514us/step - loss: 0.6181 - acc: 0.6900 - val_loss: 0.6559 - val_acc: 0.6400\n",
            "Epoch 1085/4500\n",
            "100/100 [==============================] - 0s 652us/step - loss: 0.6177 - acc: 0.6900 - val_loss: 0.6557 - val_acc: 0.6400\n",
            "Epoch 1086/4500\n",
            "100/100 [==============================] - 0s 520us/step - loss: 0.6171 - acc: 0.6900 - val_loss: 0.6566 - val_acc: 0.6400\n",
            "Epoch 1087/4500\n",
            "100/100 [==============================] - 0s 504us/step - loss: 0.6175 - acc: 0.6900 - val_loss: 0.6574 - val_acc: 0.6400\n",
            "Epoch 1088/4500\n",
            "100/100 [==============================] - 0s 527us/step - loss: 0.6173 - acc: 0.6900 - val_loss: 0.6572 - val_acc: 0.6400\n",
            "Epoch 1089/4500\n",
            "100/100 [==============================] - 0s 532us/step - loss: 0.6173 - acc: 0.6900 - val_loss: 0.6566 - val_acc: 0.6400\n",
            "Epoch 1090/4500\n",
            "100/100 [==============================] - 0s 499us/step - loss: 0.6179 - acc: 0.6900 - val_loss: 0.6576 - val_acc: 0.6400\n",
            "Epoch 1091/4500\n",
            "100/100 [==============================] - 0s 502us/step - loss: 0.6173 - acc: 0.6900 - val_loss: 0.6569 - val_acc: 0.6400\n",
            "Epoch 1092/4500\n",
            "100/100 [==============================] - 0s 532us/step - loss: 0.6177 - acc: 0.6900 - val_loss: 0.6573 - val_acc: 0.6400\n",
            "Epoch 1093/4500\n",
            "100/100 [==============================] - 0s 525us/step - loss: 0.6172 - acc: 0.6900 - val_loss: 0.6566 - val_acc: 0.6400\n",
            "Epoch 1094/4500\n",
            "100/100 [==============================] - 0s 538us/step - loss: 0.6174 - acc: 0.6900 - val_loss: 0.6561 - val_acc: 0.6400\n",
            "Epoch 1095/4500\n",
            "100/100 [==============================] - 0s 498us/step - loss: 0.6173 - acc: 0.6900 - val_loss: 0.6566 - val_acc: 0.6400\n",
            "Epoch 1096/4500\n",
            "100/100 [==============================] - 0s 511us/step - loss: 0.6174 - acc: 0.6900 - val_loss: 0.6570 - val_acc: 0.6400\n",
            "Epoch 1097/4500\n",
            "100/100 [==============================] - 0s 504us/step - loss: 0.6174 - acc: 0.6900 - val_loss: 0.6564 - val_acc: 0.6400\n",
            "Epoch 1098/4500\n",
            "100/100 [==============================] - 0s 491us/step - loss: 0.6173 - acc: 0.6900 - val_loss: 0.6568 - val_acc: 0.6400\n",
            "Epoch 1099/4500\n",
            "100/100 [==============================] - 0s 489us/step - loss: 0.6173 - acc: 0.6900 - val_loss: 0.6566 - val_acc: 0.6400\n",
            "Epoch 1100/4500\n",
            "100/100 [==============================] - 0s 505us/step - loss: 0.6179 - acc: 0.6900 - val_loss: 0.6559 - val_acc: 0.6400\n",
            "Epoch 1101/4500\n",
            "100/100 [==============================] - 0s 504us/step - loss: 0.6175 - acc: 0.6900 - val_loss: 0.6567 - val_acc: 0.6400\n",
            "Epoch 1102/4500\n",
            "100/100 [==============================] - 0s 535us/step - loss: 0.6173 - acc: 0.6900 - val_loss: 0.6566 - val_acc: 0.6400\n",
            "Epoch 1103/4500\n",
            "100/100 [==============================] - 0s 644us/step - loss: 0.6172 - acc: 0.6900 - val_loss: 0.6568 - val_acc: 0.6400\n",
            "Epoch 1104/4500\n",
            "100/100 [==============================] - 0s 659us/step - loss: 0.6171 - acc: 0.6900 - val_loss: 0.6568 - val_acc: 0.6400\n",
            "Epoch 1105/4500\n",
            "100/100 [==============================] - 0s 555us/step - loss: 0.6171 - acc: 0.6900 - val_loss: 0.6565 - val_acc: 0.6400\n",
            "Epoch 1106/4500\n",
            "100/100 [==============================] - 0s 526us/step - loss: 0.6181 - acc: 0.6900 - val_loss: 0.6557 - val_acc: 0.6400\n",
            "Epoch 1107/4500\n",
            "100/100 [==============================] - 0s 496us/step - loss: 0.6189 - acc: 0.6900 - val_loss: 0.6573 - val_acc: 0.6400\n",
            "Epoch 1108/4500\n",
            "100/100 [==============================] - 0s 501us/step - loss: 0.6171 - acc: 0.6900 - val_loss: 0.6569 - val_acc: 0.6400\n",
            "Epoch 1109/4500\n",
            "100/100 [==============================] - 0s 531us/step - loss: 0.6174 - acc: 0.6900 - val_loss: 0.6567 - val_acc: 0.6400\n",
            "Epoch 1110/4500\n",
            "100/100 [==============================] - 0s 527us/step - loss: 0.6172 - acc: 0.6900 - val_loss: 0.6561 - val_acc: 0.6400\n",
            "Epoch 1111/4500\n",
            "100/100 [==============================] - 0s 487us/step - loss: 0.6173 - acc: 0.6900 - val_loss: 0.6565 - val_acc: 0.6400\n",
            "Epoch 1112/4500\n",
            "100/100 [==============================] - 0s 521us/step - loss: 0.6174 - acc: 0.6900 - val_loss: 0.6567 - val_acc: 0.6400\n",
            "Epoch 1113/4500\n",
            "100/100 [==============================] - 0s 531us/step - loss: 0.6170 - acc: 0.6900 - val_loss: 0.6567 - val_acc: 0.6400\n",
            "Epoch 1114/4500\n",
            "100/100 [==============================] - 0s 481us/step - loss: 0.6172 - acc: 0.6900 - val_loss: 0.6562 - val_acc: 0.6400\n",
            "Epoch 1115/4500\n",
            "100/100 [==============================] - 0s 517us/step - loss: 0.6170 - acc: 0.6900 - val_loss: 0.6563 - val_acc: 0.6400\n",
            "Epoch 1116/4500\n",
            "100/100 [==============================] - 0s 497us/step - loss: 0.6173 - acc: 0.6900 - val_loss: 0.6561 - val_acc: 0.6400\n",
            "Epoch 1117/4500\n",
            "100/100 [==============================] - 0s 489us/step - loss: 0.6173 - acc: 0.6900 - val_loss: 0.6570 - val_acc: 0.6400\n",
            "Epoch 1118/4500\n",
            "100/100 [==============================] - 0s 490us/step - loss: 0.6170 - acc: 0.6900 - val_loss: 0.6566 - val_acc: 0.6400\n",
            "Epoch 1119/4500\n",
            "100/100 [==============================] - 0s 511us/step - loss: 0.6175 - acc: 0.6900 - val_loss: 0.6562 - val_acc: 0.6400\n",
            "Epoch 1120/4500\n",
            "100/100 [==============================] - 0s 517us/step - loss: 0.6172 - acc: 0.6900 - val_loss: 0.6561 - val_acc: 0.6400\n",
            "Epoch 1121/4500\n",
            "100/100 [==============================] - 0s 494us/step - loss: 0.6172 - acc: 0.6900 - val_loss: 0.6567 - val_acc: 0.6400\n",
            "Epoch 1122/4500\n",
            "100/100 [==============================] - 0s 613us/step - loss: 0.6174 - acc: 0.6900 - val_loss: 0.6561 - val_acc: 0.6400\n",
            "Epoch 1123/4500\n",
            "100/100 [==============================] - 0s 571us/step - loss: 0.6170 - acc: 0.6900 - val_loss: 0.6563 - val_acc: 0.6400\n",
            "Epoch 1124/4500\n",
            "100/100 [==============================] - 0s 522us/step - loss: 0.6172 - acc: 0.6900 - val_loss: 0.6564 - val_acc: 0.6400\n",
            "Epoch 1125/4500\n",
            "100/100 [==============================] - 0s 608us/step - loss: 0.6176 - acc: 0.6900 - val_loss: 0.6569 - val_acc: 0.6400\n",
            "Epoch 1126/4500\n",
            "100/100 [==============================] - 0s 525us/step - loss: 0.6176 - acc: 0.6900 - val_loss: 0.6560 - val_acc: 0.6400\n",
            "Epoch 1127/4500\n",
            "100/100 [==============================] - 0s 525us/step - loss: 0.6170 - acc: 0.6900 - val_loss: 0.6565 - val_acc: 0.6400\n",
            "Epoch 1128/4500\n",
            "100/100 [==============================] - 0s 545us/step - loss: 0.6176 - acc: 0.6900 - val_loss: 0.6559 - val_acc: 0.6400\n",
            "Epoch 1129/4500\n",
            "100/100 [==============================] - 0s 533us/step - loss: 0.6177 - acc: 0.6900 - val_loss: 0.6572 - val_acc: 0.6400\n",
            "Epoch 1130/4500\n",
            "100/100 [==============================] - 0s 501us/step - loss: 0.6174 - acc: 0.6900 - val_loss: 0.6574 - val_acc: 0.6400\n",
            "Epoch 1131/4500\n",
            "100/100 [==============================] - 0s 490us/step - loss: 0.6181 - acc: 0.6900 - val_loss: 0.6558 - val_acc: 0.6400\n",
            "Epoch 1132/4500\n",
            "100/100 [==============================] - 0s 541us/step - loss: 0.6177 - acc: 0.6900 - val_loss: 0.6569 - val_acc: 0.6400\n",
            "Epoch 1133/4500\n",
            "100/100 [==============================] - 0s 562us/step - loss: 0.6170 - acc: 0.6900 - val_loss: 0.6568 - val_acc: 0.6400\n",
            "Epoch 1134/4500\n",
            "100/100 [==============================] - 0s 494us/step - loss: 0.6170 - acc: 0.6900 - val_loss: 0.6567 - val_acc: 0.6400\n",
            "Epoch 1135/4500\n",
            "100/100 [==============================] - 0s 522us/step - loss: 0.6169 - acc: 0.6900 - val_loss: 0.6563 - val_acc: 0.6400\n",
            "Epoch 1136/4500\n",
            "100/100 [==============================] - 0s 515us/step - loss: 0.6169 - acc: 0.6900 - val_loss: 0.6562 - val_acc: 0.6400\n",
            "Epoch 1137/4500\n",
            "100/100 [==============================] - 0s 501us/step - loss: 0.6170 - acc: 0.6900 - val_loss: 0.6560 - val_acc: 0.6400\n",
            "Epoch 1138/4500\n",
            "100/100 [==============================] - 0s 494us/step - loss: 0.6171 - acc: 0.6900 - val_loss: 0.6561 - val_acc: 0.6400\n",
            "Epoch 1139/4500\n",
            "100/100 [==============================] - 0s 499us/step - loss: 0.6172 - acc: 0.6900 - val_loss: 0.6568 - val_acc: 0.6400\n",
            "Epoch 1140/4500\n",
            "100/100 [==============================] - 0s 520us/step - loss: 0.6173 - acc: 0.6900 - val_loss: 0.6560 - val_acc: 0.6400\n",
            "Epoch 1141/4500\n",
            "100/100 [==============================] - 0s 586us/step - loss: 0.6173 - acc: 0.6900 - val_loss: 0.6556 - val_acc: 0.6400\n",
            "Epoch 1142/4500\n",
            "100/100 [==============================] - 0s 665us/step - loss: 0.6174 - acc: 0.6900 - val_loss: 0.6558 - val_acc: 0.6400\n",
            "Epoch 1143/4500\n",
            "100/100 [==============================] - 0s 511us/step - loss: 0.6173 - acc: 0.6900 - val_loss: 0.6568 - val_acc: 0.6400\n",
            "Epoch 1144/4500\n",
            "100/100 [==============================] - 0s 494us/step - loss: 0.6170 - acc: 0.6900 - val_loss: 0.6568 - val_acc: 0.6400\n",
            "Epoch 1145/4500\n",
            "100/100 [==============================] - 0s 499us/step - loss: 0.6173 - acc: 0.6900 - val_loss: 0.6571 - val_acc: 0.6400\n",
            "Epoch 1146/4500\n",
            "100/100 [==============================] - 0s 497us/step - loss: 0.6176 - acc: 0.6900 - val_loss: 0.6558 - val_acc: 0.6400\n",
            "Epoch 1147/4500\n",
            "100/100 [==============================] - 0s 484us/step - loss: 0.6170 - acc: 0.6900 - val_loss: 0.6564 - val_acc: 0.6400\n",
            "Epoch 1148/4500\n",
            "100/100 [==============================] - 0s 516us/step - loss: 0.6171 - acc: 0.6900 - val_loss: 0.6561 - val_acc: 0.6400\n",
            "Epoch 1149/4500\n",
            "100/100 [==============================] - 0s 518us/step - loss: 0.6170 - acc: 0.6900 - val_loss: 0.6564 - val_acc: 0.6400\n",
            "Epoch 1150/4500\n",
            "100/100 [==============================] - 0s 545us/step - loss: 0.6173 - acc: 0.6900 - val_loss: 0.6561 - val_acc: 0.6400\n",
            "Epoch 1151/4500\n",
            "100/100 [==============================] - 0s 552us/step - loss: 0.6172 - acc: 0.6900 - val_loss: 0.6567 - val_acc: 0.6400\n",
            "Epoch 1152/4500\n",
            "100/100 [==============================] - 0s 564us/step - loss: 0.6174 - acc: 0.6900 - val_loss: 0.6558 - val_acc: 0.6400\n",
            "Epoch 1153/4500\n",
            "100/100 [==============================] - 0s 520us/step - loss: 0.6173 - acc: 0.6900 - val_loss: 0.6566 - val_acc: 0.6400\n",
            "Epoch 1154/4500\n",
            "100/100 [==============================] - 0s 505us/step - loss: 0.6176 - acc: 0.6900 - val_loss: 0.6569 - val_acc: 0.6400\n",
            "Epoch 1155/4500\n",
            "100/100 [==============================] - 0s 504us/step - loss: 0.6173 - acc: 0.6900 - val_loss: 0.6558 - val_acc: 0.6400\n",
            "Epoch 1156/4500\n",
            "100/100 [==============================] - 0s 554us/step - loss: 0.6171 - acc: 0.6900 - val_loss: 0.6564 - val_acc: 0.6400\n",
            "Epoch 1157/4500\n",
            "100/100 [==============================] - 0s 542us/step - loss: 0.6170 - acc: 0.6900 - val_loss: 0.6560 - val_acc: 0.6400\n",
            "Epoch 1158/4500\n",
            "100/100 [==============================] - 0s 505us/step - loss: 0.6173 - acc: 0.6900 - val_loss: 0.6566 - val_acc: 0.6400\n",
            "Epoch 1159/4500\n",
            "100/100 [==============================] - 0s 560us/step - loss: 0.6169 - acc: 0.6900 - val_loss: 0.6560 - val_acc: 0.6400\n",
            "Epoch 1160/4500\n",
            "100/100 [==============================] - 0s 514us/step - loss: 0.6170 - acc: 0.6900 - val_loss: 0.6558 - val_acc: 0.6400\n",
            "Epoch 1161/4500\n",
            "100/100 [==============================] - 0s 624us/step - loss: 0.6168 - acc: 0.6900 - val_loss: 0.6558 - val_acc: 0.6400\n",
            "Epoch 1162/4500\n",
            "100/100 [==============================] - 0s 532us/step - loss: 0.6171 - acc: 0.6900 - val_loss: 0.6555 - val_acc: 0.6400\n",
            "Epoch 1163/4500\n",
            "100/100 [==============================] - 0s 491us/step - loss: 0.6175 - acc: 0.6900 - val_loss: 0.6567 - val_acc: 0.6400\n",
            "Epoch 1164/4500\n",
            "100/100 [==============================] - 0s 526us/step - loss: 0.6176 - acc: 0.6900 - val_loss: 0.6556 - val_acc: 0.6400\n",
            "Epoch 1165/4500\n",
            "100/100 [==============================] - 0s 525us/step - loss: 0.6169 - acc: 0.6900 - val_loss: 0.6560 - val_acc: 0.6400\n",
            "Epoch 1166/4500\n",
            "100/100 [==============================] - 0s 555us/step - loss: 0.6168 - acc: 0.6900 - val_loss: 0.6561 - val_acc: 0.6400\n",
            "Epoch 1167/4500\n",
            "100/100 [==============================] - 0s 499us/step - loss: 0.6168 - acc: 0.6900 - val_loss: 0.6560 - val_acc: 0.6400\n",
            "Epoch 1168/4500\n",
            "100/100 [==============================] - 0s 485us/step - loss: 0.6173 - acc: 0.6900 - val_loss: 0.6564 - val_acc: 0.6400\n",
            "Epoch 1169/4500\n",
            "100/100 [==============================] - 0s 523us/step - loss: 0.6167 - acc: 0.6900 - val_loss: 0.6563 - val_acc: 0.6400\n",
            "Epoch 1170/4500\n",
            "100/100 [==============================] - 0s 497us/step - loss: 0.6169 - acc: 0.6900 - val_loss: 0.6560 - val_acc: 0.6400\n",
            "Epoch 1171/4500\n",
            "100/100 [==============================] - 0s 495us/step - loss: 0.6167 - acc: 0.6900 - val_loss: 0.6561 - val_acc: 0.6400\n",
            "Epoch 1172/4500\n",
            "100/100 [==============================] - 0s 605us/step - loss: 0.6174 - acc: 0.6900 - val_loss: 0.6569 - val_acc: 0.6400\n",
            "Epoch 1173/4500\n",
            "100/100 [==============================] - 0s 511us/step - loss: 0.6169 - acc: 0.6900 - val_loss: 0.6569 - val_acc: 0.6400\n",
            "Epoch 1174/4500\n",
            "100/100 [==============================] - 0s 525us/step - loss: 0.6173 - acc: 0.6900 - val_loss: 0.6558 - val_acc: 0.6400\n",
            "Epoch 1175/4500\n",
            "100/100 [==============================] - 0s 495us/step - loss: 0.6168 - acc: 0.6900 - val_loss: 0.6563 - val_acc: 0.6400\n",
            "Epoch 1176/4500\n",
            "100/100 [==============================] - 0s 502us/step - loss: 0.6167 - acc: 0.6900 - val_loss: 0.6562 - val_acc: 0.6400\n",
            "Epoch 1177/4500\n",
            "100/100 [==============================] - 0s 500us/step - loss: 0.6173 - acc: 0.6900 - val_loss: 0.6570 - val_acc: 0.6400\n",
            "Epoch 1178/4500\n",
            "100/100 [==============================] - 0s 545us/step - loss: 0.6165 - acc: 0.6900 - val_loss: 0.6562 - val_acc: 0.6400\n",
            "Epoch 1179/4500\n",
            "100/100 [==============================] - 0s 512us/step - loss: 0.6168 - acc: 0.6900 - val_loss: 0.6558 - val_acc: 0.6400\n",
            "Epoch 1180/4500\n",
            "100/100 [==============================] - 0s 590us/step - loss: 0.6168 - acc: 0.6900 - val_loss: 0.6560 - val_acc: 0.6400\n",
            "Epoch 1181/4500\n",
            "100/100 [==============================] - 0s 545us/step - loss: 0.6168 - acc: 0.6900 - val_loss: 0.6556 - val_acc: 0.6400\n",
            "Epoch 1182/4500\n",
            "100/100 [==============================] - 0s 547us/step - loss: 0.6181 - acc: 0.6900 - val_loss: 0.6568 - val_acc: 0.6400\n",
            "Epoch 1183/4500\n",
            "100/100 [==============================] - 0s 530us/step - loss: 0.6170 - acc: 0.6900 - val_loss: 0.6555 - val_acc: 0.6400\n",
            "Epoch 1184/4500\n",
            "100/100 [==============================] - 0s 523us/step - loss: 0.6168 - acc: 0.6900 - val_loss: 0.6552 - val_acc: 0.6400\n",
            "Epoch 1185/4500\n",
            "100/100 [==============================] - 0s 503us/step - loss: 0.6166 - acc: 0.6900 - val_loss: 0.6557 - val_acc: 0.6400\n",
            "Epoch 1186/4500\n",
            "100/100 [==============================] - 0s 492us/step - loss: 0.6166 - acc: 0.6900 - val_loss: 0.6560 - val_acc: 0.6400\n",
            "Epoch 1187/4500\n",
            "100/100 [==============================] - 0s 498us/step - loss: 0.6170 - acc: 0.6900 - val_loss: 0.6554 - val_acc: 0.6400\n",
            "Epoch 1188/4500\n",
            "100/100 [==============================] - 0s 505us/step - loss: 0.6173 - acc: 0.6900 - val_loss: 0.6550 - val_acc: 0.6400\n",
            "Epoch 1189/4500\n",
            "100/100 [==============================] - 0s 511us/step - loss: 0.6167 - acc: 0.6900 - val_loss: 0.6559 - val_acc: 0.6400\n",
            "Epoch 1190/4500\n",
            "100/100 [==============================] - 0s 522us/step - loss: 0.6165 - acc: 0.6900 - val_loss: 0.6562 - val_acc: 0.6400\n",
            "Epoch 1191/4500\n",
            "100/100 [==============================] - 0s 541us/step - loss: 0.6165 - acc: 0.6900 - val_loss: 0.6562 - val_acc: 0.6400\n",
            "Epoch 1192/4500\n",
            "100/100 [==============================] - 0s 653us/step - loss: 0.6164 - acc: 0.6900 - val_loss: 0.6561 - val_acc: 0.6400\n",
            "Epoch 1193/4500\n",
            "100/100 [==============================] - 0s 560us/step - loss: 0.6167 - acc: 0.6900 - val_loss: 0.6563 - val_acc: 0.6400\n",
            "Epoch 1194/4500\n",
            "100/100 [==============================] - 0s 528us/step - loss: 0.6169 - acc: 0.6900 - val_loss: 0.6556 - val_acc: 0.6400\n",
            "Epoch 1195/4500\n",
            "100/100 [==============================] - 0s 523us/step - loss: 0.6166 - acc: 0.6900 - val_loss: 0.6556 - val_acc: 0.6400\n",
            "Epoch 1196/4500\n",
            "100/100 [==============================] - 0s 516us/step - loss: 0.6165 - acc: 0.6900 - val_loss: 0.6561 - val_acc: 0.6400\n",
            "Epoch 1197/4500\n",
            "100/100 [==============================] - 0s 519us/step - loss: 0.6164 - acc: 0.6900 - val_loss: 0.6561 - val_acc: 0.6400\n",
            "Epoch 1198/4500\n",
            "100/100 [==============================] - 0s 515us/step - loss: 0.6168 - acc: 0.6900 - val_loss: 0.6566 - val_acc: 0.6400\n",
            "Epoch 1199/4500\n",
            "100/100 [==============================] - 0s 596us/step - loss: 0.6166 - acc: 0.6900 - val_loss: 0.6562 - val_acc: 0.6400\n",
            "Epoch 1200/4500\n",
            "100/100 [==============================] - 0s 567us/step - loss: 0.6170 - acc: 0.6900 - val_loss: 0.6557 - val_acc: 0.6400\n",
            "Epoch 1201/4500\n",
            "100/100 [==============================] - 0s 591us/step - loss: 0.6166 - acc: 0.6900 - val_loss: 0.6562 - val_acc: 0.6400\n",
            "Epoch 1202/4500\n",
            "100/100 [==============================] - 0s 511us/step - loss: 0.6165 - acc: 0.6900 - val_loss: 0.6562 - val_acc: 0.6400\n",
            "Epoch 1203/4500\n",
            "100/100 [==============================] - 0s 505us/step - loss: 0.6171 - acc: 0.6900 - val_loss: 0.6568 - val_acc: 0.6400\n",
            "Epoch 1204/4500\n",
            "100/100 [==============================] - 0s 514us/step - loss: 0.6176 - acc: 0.6900 - val_loss: 0.6551 - val_acc: 0.6400\n",
            "Epoch 1205/4500\n",
            "100/100 [==============================] - 0s 529us/step - loss: 0.6172 - acc: 0.6900 - val_loss: 0.6548 - val_acc: 0.6400\n",
            "Epoch 1206/4500\n",
            "100/100 [==============================] - 0s 536us/step - loss: 0.6164 - acc: 0.6900 - val_loss: 0.6552 - val_acc: 0.6400\n",
            "Epoch 1207/4500\n",
            "100/100 [==============================] - 0s 612us/step - loss: 0.6165 - acc: 0.6900 - val_loss: 0.6557 - val_acc: 0.6400\n",
            "Epoch 1208/4500\n",
            "100/100 [==============================] - 0s 623us/step - loss: 0.6165 - acc: 0.6900 - val_loss: 0.6557 - val_acc: 0.6400\n",
            "Epoch 1209/4500\n",
            "100/100 [==============================] - 0s 534us/step - loss: 0.6166 - acc: 0.6900 - val_loss: 0.6559 - val_acc: 0.6400\n",
            "Epoch 1210/4500\n",
            "100/100 [==============================] - 0s 528us/step - loss: 0.6166 - acc: 0.6900 - val_loss: 0.6556 - val_acc: 0.6400\n",
            "Epoch 1211/4500\n",
            "100/100 [==============================] - 0s 517us/step - loss: 0.6164 - acc: 0.6900 - val_loss: 0.6562 - val_acc: 0.6400\n",
            "Epoch 1212/4500\n",
            "100/100 [==============================] - 0s 489us/step - loss: 0.6165 - acc: 0.6900 - val_loss: 0.6561 - val_acc: 0.6400\n",
            "Epoch 1213/4500\n",
            "100/100 [==============================] - 0s 575us/step - loss: 0.6164 - acc: 0.6900 - val_loss: 0.6559 - val_acc: 0.6400\n",
            "Epoch 1214/4500\n",
            "100/100 [==============================] - 0s 620us/step - loss: 0.6165 - acc: 0.6900 - val_loss: 0.6563 - val_acc: 0.6400\n",
            "Epoch 1215/4500\n",
            "100/100 [==============================] - 0s 526us/step - loss: 0.6163 - acc: 0.6900 - val_loss: 0.6562 - val_acc: 0.6400\n",
            "Epoch 1216/4500\n",
            "100/100 [==============================] - 0s 515us/step - loss: 0.6165 - acc: 0.6900 - val_loss: 0.6562 - val_acc: 0.6400\n",
            "Epoch 1217/4500\n",
            "100/100 [==============================] - 0s 630us/step - loss: 0.6164 - acc: 0.6900 - val_loss: 0.6559 - val_acc: 0.6400\n",
            "Epoch 1218/4500\n",
            "100/100 [==============================] - 0s 522us/step - loss: 0.6171 - acc: 0.6900 - val_loss: 0.6550 - val_acc: 0.6400\n",
            "Epoch 1219/4500\n",
            "100/100 [==============================] - 0s 609us/step - loss: 0.6171 - acc: 0.6900 - val_loss: 0.6561 - val_acc: 0.6400\n",
            "Epoch 1220/4500\n",
            "100/100 [==============================] - 0s 619us/step - loss: 0.6164 - acc: 0.6900 - val_loss: 0.6561 - val_acc: 0.6400\n",
            "Epoch 1221/4500\n",
            "100/100 [==============================] - 0s 587us/step - loss: 0.6169 - acc: 0.6900 - val_loss: 0.6551 - val_acc: 0.6400\n",
            "Epoch 1222/4500\n",
            "100/100 [==============================] - 0s 559us/step - loss: 0.6168 - acc: 0.6900 - val_loss: 0.6558 - val_acc: 0.6400\n",
            "Epoch 1223/4500\n",
            "100/100 [==============================] - 0s 578us/step - loss: 0.6165 - acc: 0.6900 - val_loss: 0.6554 - val_acc: 0.6400\n",
            "Epoch 1224/4500\n",
            "100/100 [==============================] - 0s 633us/step - loss: 0.6166 - acc: 0.6900 - val_loss: 0.6550 - val_acc: 0.6400\n",
            "Epoch 1225/4500\n",
            "100/100 [==============================] - 0s 506us/step - loss: 0.6162 - acc: 0.6900 - val_loss: 0.6553 - val_acc: 0.6400\n",
            "Epoch 1226/4500\n",
            "100/100 [==============================] - 0s 516us/step - loss: 0.6162 - acc: 0.6900 - val_loss: 0.6556 - val_acc: 0.6400\n",
            "Epoch 1227/4500\n",
            "100/100 [==============================] - 0s 516us/step - loss: 0.6163 - acc: 0.6900 - val_loss: 0.6553 - val_acc: 0.6400\n",
            "Epoch 1228/4500\n",
            "100/100 [==============================] - 0s 552us/step - loss: 0.6164 - acc: 0.6900 - val_loss: 0.6553 - val_acc: 0.6400\n",
            "Epoch 1229/4500\n",
            "100/100 [==============================] - 0s 613us/step - loss: 0.6164 - acc: 0.6900 - val_loss: 0.6552 - val_acc: 0.6400\n",
            "Epoch 1230/4500\n",
            "100/100 [==============================] - 0s 536us/step - loss: 0.6162 - acc: 0.6900 - val_loss: 0.6555 - val_acc: 0.6400\n",
            "Epoch 1231/4500\n",
            "100/100 [==============================] - 0s 609us/step - loss: 0.6163 - acc: 0.6900 - val_loss: 0.6555 - val_acc: 0.6400\n",
            "Epoch 1232/4500\n",
            "100/100 [==============================] - 0s 623us/step - loss: 0.6167 - acc: 0.6900 - val_loss: 0.6560 - val_acc: 0.6400\n",
            "Epoch 1233/4500\n",
            "100/100 [==============================] - 0s 537us/step - loss: 0.6165 - acc: 0.6900 - val_loss: 0.6563 - val_acc: 0.6400\n",
            "Epoch 1234/4500\n",
            "100/100 [==============================] - 0s 531us/step - loss: 0.6162 - acc: 0.6900 - val_loss: 0.6562 - val_acc: 0.6400\n",
            "Epoch 1235/4500\n",
            "100/100 [==============================] - 0s 609us/step - loss: 0.6161 - acc: 0.6900 - val_loss: 0.6558 - val_acc: 0.6400\n",
            "Epoch 1236/4500\n",
            "100/100 [==============================] - 0s 544us/step - loss: 0.6166 - acc: 0.6900 - val_loss: 0.6550 - val_acc: 0.6400\n",
            "Epoch 1237/4500\n",
            "100/100 [==============================] - 0s 592us/step - loss: 0.6162 - acc: 0.6900 - val_loss: 0.6554 - val_acc: 0.6400\n",
            "Epoch 1238/4500\n",
            "100/100 [==============================] - 0s 585us/step - loss: 0.6165 - acc: 0.6900 - val_loss: 0.6551 - val_acc: 0.6400\n",
            "Epoch 1239/4500\n",
            "100/100 [==============================] - 0s 538us/step - loss: 0.6164 - acc: 0.6900 - val_loss: 0.6554 - val_acc: 0.6400\n",
            "Epoch 1240/4500\n",
            "100/100 [==============================] - 0s 546us/step - loss: 0.6164 - acc: 0.6900 - val_loss: 0.6560 - val_acc: 0.6400\n",
            "Epoch 1241/4500\n",
            "100/100 [==============================] - 0s 520us/step - loss: 0.6163 - acc: 0.6900 - val_loss: 0.6559 - val_acc: 0.6400\n",
            "Epoch 1242/4500\n",
            "100/100 [==============================] - 0s 534us/step - loss: 0.6162 - acc: 0.6900 - val_loss: 0.6560 - val_acc: 0.6400\n",
            "Epoch 1243/4500\n",
            "100/100 [==============================] - 0s 540us/step - loss: 0.6166 - acc: 0.6900 - val_loss: 0.6550 - val_acc: 0.6400\n",
            "Epoch 1244/4500\n",
            "100/100 [==============================] - 0s 536us/step - loss: 0.6161 - acc: 0.6900 - val_loss: 0.6554 - val_acc: 0.6400\n",
            "Epoch 1245/4500\n",
            "100/100 [==============================] - 0s 549us/step - loss: 0.6160 - acc: 0.6900 - val_loss: 0.6556 - val_acc: 0.6400\n",
            "Epoch 1246/4500\n",
            "100/100 [==============================] - 0s 554us/step - loss: 0.6161 - acc: 0.6900 - val_loss: 0.6554 - val_acc: 0.6400\n",
            "Epoch 1247/4500\n",
            "100/100 [==============================] - 0s 658us/step - loss: 0.6161 - acc: 0.6900 - val_loss: 0.6553 - val_acc: 0.6400\n",
            "Epoch 1248/4500\n",
            "100/100 [==============================] - 0s 535us/step - loss: 0.6161 - acc: 0.6900 - val_loss: 0.6554 - val_acc: 0.6400\n",
            "Epoch 1249/4500\n",
            "100/100 [==============================] - 0s 533us/step - loss: 0.6161 - acc: 0.6900 - val_loss: 0.6553 - val_acc: 0.6400\n",
            "Epoch 1250/4500\n",
            "100/100 [==============================] - 0s 524us/step - loss: 0.6164 - acc: 0.6900 - val_loss: 0.6548 - val_acc: 0.6400\n",
            "Epoch 1251/4500\n",
            "100/100 [==============================] - 0s 556us/step - loss: 0.6160 - acc: 0.6900 - val_loss: 0.6551 - val_acc: 0.6400\n",
            "Epoch 1252/4500\n",
            "100/100 [==============================] - 0s 546us/step - loss: 0.6161 - acc: 0.6900 - val_loss: 0.6554 - val_acc: 0.6400\n",
            "Epoch 1253/4500\n",
            "100/100 [==============================] - 0s 588us/step - loss: 0.6166 - acc: 0.6900 - val_loss: 0.6561 - val_acc: 0.6400\n",
            "Epoch 1254/4500\n",
            "100/100 [==============================] - 0s 576us/step - loss: 0.6162 - acc: 0.6900 - val_loss: 0.6556 - val_acc: 0.6400\n",
            "Epoch 1255/4500\n",
            "100/100 [==============================] - 0s 518us/step - loss: 0.6163 - acc: 0.6900 - val_loss: 0.6559 - val_acc: 0.6400\n",
            "Epoch 1256/4500\n",
            "100/100 [==============================] - 0s 565us/step - loss: 0.6162 - acc: 0.6900 - val_loss: 0.6554 - val_acc: 0.6400\n",
            "Epoch 1257/4500\n",
            "100/100 [==============================] - 0s 590us/step - loss: 0.6160 - acc: 0.6900 - val_loss: 0.6555 - val_acc: 0.6400\n",
            "Epoch 1258/4500\n",
            "100/100 [==============================] - 0s 641us/step - loss: 0.6165 - acc: 0.6900 - val_loss: 0.6546 - val_acc: 0.6400\n",
            "Epoch 1259/4500\n",
            "100/100 [==============================] - 0s 649us/step - loss: 0.6165 - acc: 0.6900 - val_loss: 0.6554 - val_acc: 0.6400\n",
            "Epoch 1260/4500\n",
            "100/100 [==============================] - 0s 541us/step - loss: 0.6160 - acc: 0.6900 - val_loss: 0.6553 - val_acc: 0.6400\n",
            "Epoch 1261/4500\n",
            "100/100 [==============================] - 0s 542us/step - loss: 0.6165 - acc: 0.6900 - val_loss: 0.6547 - val_acc: 0.6400\n",
            "Epoch 1262/4500\n",
            "100/100 [==============================] - 0s 521us/step - loss: 0.6160 - acc: 0.6900 - val_loss: 0.6548 - val_acc: 0.6400\n",
            "Epoch 1263/4500\n",
            "100/100 [==============================] - 0s 549us/step - loss: 0.6159 - acc: 0.6900 - val_loss: 0.6549 - val_acc: 0.6400\n",
            "Epoch 1264/4500\n",
            "100/100 [==============================] - 0s 597us/step - loss: 0.6160 - acc: 0.6900 - val_loss: 0.6548 - val_acc: 0.6400\n",
            "Epoch 1265/4500\n",
            "100/100 [==============================] - 0s 513us/step - loss: 0.6161 - acc: 0.6900 - val_loss: 0.6551 - val_acc: 0.6400\n",
            "Epoch 1266/4500\n",
            "100/100 [==============================] - 0s 556us/step - loss: 0.6168 - acc: 0.6900 - val_loss: 0.6561 - val_acc: 0.6400\n",
            "Epoch 1267/4500\n",
            "100/100 [==============================] - 0s 568us/step - loss: 0.6159 - acc: 0.6900 - val_loss: 0.6556 - val_acc: 0.6400\n",
            "Epoch 1268/4500\n",
            "100/100 [==============================] - 0s 581us/step - loss: 0.6161 - acc: 0.6900 - val_loss: 0.6556 - val_acc: 0.6400\n",
            "Epoch 1269/4500\n",
            "100/100 [==============================] - 0s 542us/step - loss: 0.6167 - acc: 0.6900 - val_loss: 0.6560 - val_acc: 0.6400\n",
            "Epoch 1270/4500\n",
            "100/100 [==============================] - 0s 599us/step - loss: 0.6158 - acc: 0.6900 - val_loss: 0.6556 - val_acc: 0.6400\n",
            "Epoch 1271/4500\n",
            "100/100 [==============================] - 0s 521us/step - loss: 0.6161 - acc: 0.6900 - val_loss: 0.6548 - val_acc: 0.6400\n",
            "Epoch 1272/4500\n",
            "100/100 [==============================] - 0s 530us/step - loss: 0.6160 - acc: 0.6900 - val_loss: 0.6552 - val_acc: 0.6400\n",
            "Epoch 1273/4500\n",
            "100/100 [==============================] - 0s 553us/step - loss: 0.6157 - acc: 0.6900 - val_loss: 0.6549 - val_acc: 0.6400\n",
            "Epoch 1274/4500\n",
            "100/100 [==============================] - 0s 568us/step - loss: 0.6161 - acc: 0.6900 - val_loss: 0.6544 - val_acc: 0.6400\n",
            "Epoch 1275/4500\n",
            "100/100 [==============================] - 0s 533us/step - loss: 0.6158 - acc: 0.6900 - val_loss: 0.6547 - val_acc: 0.6400\n",
            "Epoch 1276/4500\n",
            "100/100 [==============================] - 0s 545us/step - loss: 0.6159 - acc: 0.6900 - val_loss: 0.6548 - val_acc: 0.6400\n",
            "Epoch 1277/4500\n",
            "100/100 [==============================] - 0s 535us/step - loss: 0.6158 - acc: 0.6900 - val_loss: 0.6548 - val_acc: 0.6400\n",
            "Epoch 1278/4500\n",
            "100/100 [==============================] - 0s 568us/step - loss: 0.6160 - acc: 0.6900 - val_loss: 0.6554 - val_acc: 0.6400\n",
            "Epoch 1279/4500\n",
            "100/100 [==============================] - 0s 535us/step - loss: 0.6160 - acc: 0.6900 - val_loss: 0.6548 - val_acc: 0.6400\n",
            "Epoch 1280/4500\n",
            "100/100 [==============================] - 0s 549us/step - loss: 0.6157 - acc: 0.6900 - val_loss: 0.6547 - val_acc: 0.6400\n",
            "Epoch 1281/4500\n",
            "100/100 [==============================] - 0s 518us/step - loss: 0.6159 - acc: 0.6900 - val_loss: 0.6544 - val_acc: 0.6400\n",
            "Epoch 1282/4500\n",
            "100/100 [==============================] - 0s 530us/step - loss: 0.6159 - acc: 0.6900 - val_loss: 0.6550 - val_acc: 0.6400\n",
            "Epoch 1283/4500\n",
            "100/100 [==============================] - 0s 592us/step - loss: 0.6160 - acc: 0.6900 - val_loss: 0.6555 - val_acc: 0.6400\n",
            "Epoch 1284/4500\n",
            "100/100 [==============================] - 0s 662us/step - loss: 0.6157 - acc: 0.6900 - val_loss: 0.6552 - val_acc: 0.6400\n",
            "Epoch 1285/4500\n",
            "100/100 [==============================] - 0s 651us/step - loss: 0.6158 - acc: 0.6900 - val_loss: 0.6548 - val_acc: 0.6400\n",
            "Epoch 1286/4500\n",
            "100/100 [==============================] - 0s 557us/step - loss: 0.6157 - acc: 0.6900 - val_loss: 0.6546 - val_acc: 0.6400\n",
            "Epoch 1287/4500\n",
            "100/100 [==============================] - 0s 542us/step - loss: 0.6156 - acc: 0.6900 - val_loss: 0.6547 - val_acc: 0.6400\n",
            "Epoch 1288/4500\n",
            "100/100 [==============================] - 0s 621us/step - loss: 0.6158 - acc: 0.6900 - val_loss: 0.6546 - val_acc: 0.6400\n",
            "Epoch 1289/4500\n",
            "100/100 [==============================] - 0s 505us/step - loss: 0.6157 - acc: 0.6900 - val_loss: 0.6551 - val_acc: 0.6400\n",
            "Epoch 1290/4500\n",
            "100/100 [==============================] - 0s 551us/step - loss: 0.6165 - acc: 0.6900 - val_loss: 0.6561 - val_acc: 0.6400\n",
            "Epoch 1291/4500\n",
            "100/100 [==============================] - 0s 550us/step - loss: 0.6163 - acc: 0.6900 - val_loss: 0.6546 - val_acc: 0.6400\n",
            "Epoch 1292/4500\n",
            "100/100 [==============================] - 0s 600us/step - loss: 0.6157 - acc: 0.6900 - val_loss: 0.6544 - val_acc: 0.6400\n",
            "Epoch 1293/4500\n",
            "100/100 [==============================] - 0s 565us/step - loss: 0.6156 - acc: 0.6900 - val_loss: 0.6548 - val_acc: 0.6400\n",
            "Epoch 1294/4500\n",
            "100/100 [==============================] - 0s 513us/step - loss: 0.6160 - acc: 0.6900 - val_loss: 0.6549 - val_acc: 0.6400\n",
            "Epoch 1295/4500\n",
            "100/100 [==============================] - 0s 509us/step - loss: 0.6156 - acc: 0.6900 - val_loss: 0.6545 - val_acc: 0.6400\n",
            "Epoch 1296/4500\n",
            "100/100 [==============================] - 0s 526us/step - loss: 0.6155 - acc: 0.6900 - val_loss: 0.6546 - val_acc: 0.6400\n",
            "Epoch 1297/4500\n",
            "100/100 [==============================] - 0s 496us/step - loss: 0.6158 - acc: 0.6900 - val_loss: 0.6543 - val_acc: 0.6400\n",
            "Epoch 1298/4500\n",
            "100/100 [==============================] - 0s 564us/step - loss: 0.6155 - acc: 0.6900 - val_loss: 0.6544 - val_acc: 0.6400\n",
            "Epoch 1299/4500\n",
            "100/100 [==============================] - 0s 567us/step - loss: 0.6153 - acc: 0.6900 - val_loss: 0.6546 - val_acc: 0.6400\n",
            "Epoch 1300/4500\n",
            "100/100 [==============================] - 0s 597us/step - loss: 0.6154 - acc: 0.6900 - val_loss: 0.6548 - val_acc: 0.6400\n",
            "Epoch 1301/4500\n",
            "100/100 [==============================] - 0s 526us/step - loss: 0.6154 - acc: 0.6900 - val_loss: 0.6546 - val_acc: 0.6400\n",
            "Epoch 1302/4500\n",
            "100/100 [==============================] - 0s 534us/step - loss: 0.6155 - acc: 0.6900 - val_loss: 0.6549 - val_acc: 0.6400\n",
            "Epoch 1303/4500\n",
            "100/100 [==============================] - 0s 545us/step - loss: 0.6161 - acc: 0.6900 - val_loss: 0.6544 - val_acc: 0.6400\n",
            "Epoch 1304/4500\n",
            "100/100 [==============================] - 0s 557us/step - loss: 0.6155 - acc: 0.6900 - val_loss: 0.6549 - val_acc: 0.6400\n",
            "Epoch 1305/4500\n",
            "100/100 [==============================] - 0s 517us/step - loss: 0.6154 - acc: 0.6900 - val_loss: 0.6551 - val_acc: 0.6400\n",
            "Epoch 1306/4500\n",
            "100/100 [==============================] - 0s 597us/step - loss: 0.6153 - acc: 0.6900 - val_loss: 0.6549 - val_acc: 0.6400\n",
            "Epoch 1307/4500\n",
            "100/100 [==============================] - 0s 549us/step - loss: 0.6154 - acc: 0.6900 - val_loss: 0.6546 - val_acc: 0.6400\n",
            "Epoch 1308/4500\n",
            "100/100 [==============================] - 0s 570us/step - loss: 0.6153 - acc: 0.6900 - val_loss: 0.6547 - val_acc: 0.6400\n",
            "Epoch 1309/4500\n",
            "100/100 [==============================] - 0s 559us/step - loss: 0.6153 - acc: 0.6900 - val_loss: 0.6547 - val_acc: 0.6400\n",
            "Epoch 1310/4500\n",
            "100/100 [==============================] - 0s 504us/step - loss: 0.6153 - acc: 0.6900 - val_loss: 0.6548 - val_acc: 0.6400\n",
            "Epoch 1311/4500\n",
            "100/100 [==============================] - 0s 531us/step - loss: 0.6156 - acc: 0.6900 - val_loss: 0.6549 - val_acc: 0.6400\n",
            "Epoch 1312/4500\n",
            "100/100 [==============================] - 0s 574us/step - loss: 0.6153 - acc: 0.6900 - val_loss: 0.6550 - val_acc: 0.6400\n",
            "Epoch 1313/4500\n",
            "100/100 [==============================] - 0s 565us/step - loss: 0.6152 - acc: 0.6900 - val_loss: 0.6550 - val_acc: 0.6400\n",
            "Epoch 1314/4500\n",
            "100/100 [==============================] - 0s 580us/step - loss: 0.6157 - acc: 0.6900 - val_loss: 0.6546 - val_acc: 0.6400\n",
            "Epoch 1315/4500\n",
            "100/100 [==============================] - 0s 496us/step - loss: 0.6153 - acc: 0.6900 - val_loss: 0.6547 - val_acc: 0.6400\n",
            "Epoch 1316/4500\n",
            "100/100 [==============================] - 0s 545us/step - loss: 0.6153 - acc: 0.6900 - val_loss: 0.6544 - val_acc: 0.6400\n",
            "Epoch 1317/4500\n",
            "100/100 [==============================] - 0s 521us/step - loss: 0.6152 - acc: 0.6900 - val_loss: 0.6545 - val_acc: 0.6400\n",
            "Epoch 1318/4500\n",
            "100/100 [==============================] - 0s 557us/step - loss: 0.6151 - acc: 0.6900 - val_loss: 0.6546 - val_acc: 0.6400\n",
            "Epoch 1319/4500\n",
            "100/100 [==============================] - 0s 552us/step - loss: 0.6153 - acc: 0.6900 - val_loss: 0.6546 - val_acc: 0.6400\n",
            "Epoch 1320/4500\n",
            "100/100 [==============================] - 0s 526us/step - loss: 0.6152 - acc: 0.6900 - val_loss: 0.6546 - val_acc: 0.6400\n",
            "Epoch 1321/4500\n",
            "100/100 [==============================] - 0s 524us/step - loss: 0.6156 - acc: 0.6900 - val_loss: 0.6549 - val_acc: 0.6400\n",
            "Epoch 1322/4500\n",
            "100/100 [==============================] - 0s 588us/step - loss: 0.6153 - acc: 0.6900 - val_loss: 0.6546 - val_acc: 0.6400\n",
            "Epoch 1323/4500\n",
            "100/100 [==============================] - 0s 633us/step - loss: 0.6154 - acc: 0.6900 - val_loss: 0.6543 - val_acc: 0.6400\n",
            "Epoch 1324/4500\n",
            "100/100 [==============================] - 0s 551us/step - loss: 0.6156 - acc: 0.6900 - val_loss: 0.6544 - val_acc: 0.6400\n",
            "Epoch 1325/4500\n",
            "100/100 [==============================] - 0s 553us/step - loss: 0.6153 - acc: 0.6900 - val_loss: 0.6541 - val_acc: 0.6400\n",
            "Epoch 1326/4500\n",
            "100/100 [==============================] - 0s 530us/step - loss: 0.6153 - acc: 0.6900 - val_loss: 0.6544 - val_acc: 0.6400\n",
            "Epoch 1327/4500\n",
            "100/100 [==============================] - 0s 527us/step - loss: 0.6152 - acc: 0.6900 - val_loss: 0.6546 - val_acc: 0.6400\n",
            "Epoch 1328/4500\n",
            "100/100 [==============================] - 0s 569us/step - loss: 0.6151 - acc: 0.6900 - val_loss: 0.6541 - val_acc: 0.6400\n",
            "Epoch 1329/4500\n",
            "100/100 [==============================] - 0s 541us/step - loss: 0.6154 - acc: 0.6900 - val_loss: 0.6536 - val_acc: 0.6400\n",
            "Epoch 1330/4500\n",
            "100/100 [==============================] - 0s 527us/step - loss: 0.6150 - acc: 0.6900 - val_loss: 0.6539 - val_acc: 0.6400\n",
            "Epoch 1331/4500\n",
            "100/100 [==============================] - 0s 517us/step - loss: 0.6152 - acc: 0.6900 - val_loss: 0.6537 - val_acc: 0.6400\n",
            "Epoch 1332/4500\n",
            "100/100 [==============================] - 0s 523us/step - loss: 0.6151 - acc: 0.6900 - val_loss: 0.6542 - val_acc: 0.6400\n",
            "Epoch 1333/4500\n",
            "100/100 [==============================] - 0s 518us/step - loss: 0.6152 - acc: 0.6900 - val_loss: 0.6543 - val_acc: 0.6400\n",
            "Epoch 1334/4500\n",
            "100/100 [==============================] - 0s 518us/step - loss: 0.6150 - acc: 0.6900 - val_loss: 0.6543 - val_acc: 0.6400\n",
            "Epoch 1335/4500\n",
            "100/100 [==============================] - 0s 530us/step - loss: 0.6151 - acc: 0.6900 - val_loss: 0.6541 - val_acc: 0.6400\n",
            "Epoch 1336/4500\n",
            "100/100 [==============================] - 0s 510us/step - loss: 0.6151 - acc: 0.6900 - val_loss: 0.6543 - val_acc: 0.6400\n",
            "Epoch 1337/4500\n",
            "100/100 [==============================] - 0s 583us/step - loss: 0.6151 - acc: 0.6900 - val_loss: 0.6543 - val_acc: 0.6400\n",
            "Epoch 1338/4500\n",
            "100/100 [==============================] - 0s 500us/step - loss: 0.6150 - acc: 0.6900 - val_loss: 0.6540 - val_acc: 0.6400\n",
            "Epoch 1339/4500\n",
            "100/100 [==============================] - 0s 510us/step - loss: 0.6152 - acc: 0.6900 - val_loss: 0.6546 - val_acc: 0.6400\n",
            "Epoch 1340/4500\n",
            "100/100 [==============================] - 0s 495us/step - loss: 0.6149 - acc: 0.6900 - val_loss: 0.6543 - val_acc: 0.6400\n",
            "Epoch 1341/4500\n",
            "100/100 [==============================] - 0s 512us/step - loss: 0.6155 - acc: 0.6900 - val_loss: 0.6545 - val_acc: 0.6400\n",
            "Epoch 1342/4500\n",
            "100/100 [==============================] - 0s 534us/step - loss: 0.6162 - acc: 0.6900 - val_loss: 0.6532 - val_acc: 0.6400\n",
            "Epoch 1343/4500\n",
            "100/100 [==============================] - 0s 536us/step - loss: 0.6151 - acc: 0.6900 - val_loss: 0.6532 - val_acc: 0.6400\n",
            "Epoch 1344/4500\n",
            "100/100 [==============================] - 0s 530us/step - loss: 0.6150 - acc: 0.6900 - val_loss: 0.6539 - val_acc: 0.6400\n",
            "Epoch 1345/4500\n",
            "100/100 [==============================] - 0s 516us/step - loss: 0.6148 - acc: 0.6900 - val_loss: 0.6541 - val_acc: 0.6400\n",
            "Epoch 1346/4500\n",
            "100/100 [==============================] - 0s 529us/step - loss: 0.6149 - acc: 0.6900 - val_loss: 0.6542 - val_acc: 0.6400\n",
            "Epoch 1347/4500\n",
            "100/100 [==============================] - 0s 525us/step - loss: 0.6149 - acc: 0.6900 - val_loss: 0.6539 - val_acc: 0.6400\n",
            "Epoch 1348/4500\n",
            "100/100 [==============================] - 0s 511us/step - loss: 0.6148 - acc: 0.6900 - val_loss: 0.6540 - val_acc: 0.6400\n",
            "Epoch 1349/4500\n",
            "100/100 [==============================] - 0s 502us/step - loss: 0.6151 - acc: 0.6900 - val_loss: 0.6544 - val_acc: 0.6400\n",
            "Epoch 1350/4500\n",
            "100/100 [==============================] - 0s 515us/step - loss: 0.6150 - acc: 0.6900 - val_loss: 0.6546 - val_acc: 0.6400\n",
            "Epoch 1351/4500\n",
            "100/100 [==============================] - 0s 563us/step - loss: 0.6147 - acc: 0.6900 - val_loss: 0.6541 - val_acc: 0.6400\n",
            "Epoch 1352/4500\n",
            "100/100 [==============================] - 0s 537us/step - loss: 0.6148 - acc: 0.6900 - val_loss: 0.6540 - val_acc: 0.6400\n",
            "Epoch 1353/4500\n",
            "100/100 [==============================] - 0s 525us/step - loss: 0.6149 - acc: 0.6900 - val_loss: 0.6539 - val_acc: 0.6400\n",
            "Epoch 1354/4500\n",
            "100/100 [==============================] - 0s 534us/step - loss: 0.6149 - acc: 0.6900 - val_loss: 0.6534 - val_acc: 0.6400\n",
            "Epoch 1355/4500\n",
            "100/100 [==============================] - 0s 492us/step - loss: 0.6151 - acc: 0.6900 - val_loss: 0.6539 - val_acc: 0.6400\n",
            "Epoch 1356/4500\n",
            "100/100 [==============================] - 0s 513us/step - loss: 0.6148 - acc: 0.6900 - val_loss: 0.6538 - val_acc: 0.6400\n",
            "Epoch 1357/4500\n",
            "100/100 [==============================] - 0s 517us/step - loss: 0.6147 - acc: 0.6900 - val_loss: 0.6537 - val_acc: 0.6400\n",
            "Epoch 1358/4500\n",
            "100/100 [==============================] - 0s 515us/step - loss: 0.6146 - acc: 0.6900 - val_loss: 0.6534 - val_acc: 0.6400\n",
            "Epoch 1359/4500\n",
            "100/100 [==============================] - 0s 501us/step - loss: 0.6148 - acc: 0.6900 - val_loss: 0.6533 - val_acc: 0.6400\n",
            "Epoch 1360/4500\n",
            "100/100 [==============================] - 0s 506us/step - loss: 0.6151 - acc: 0.6900 - val_loss: 0.6542 - val_acc: 0.6400\n",
            "Epoch 1361/4500\n",
            "100/100 [==============================] - 0s 524us/step - loss: 0.6146 - acc: 0.6900 - val_loss: 0.6541 - val_acc: 0.6400\n",
            "Epoch 1362/4500\n",
            "100/100 [==============================] - 0s 675us/step - loss: 0.6151 - acc: 0.6900 - val_loss: 0.6537 - val_acc: 0.6400\n",
            "Epoch 1363/4500\n",
            "100/100 [==============================] - 0s 567us/step - loss: 0.6146 - acc: 0.6900 - val_loss: 0.6534 - val_acc: 0.6400\n",
            "Epoch 1364/4500\n",
            "100/100 [==============================] - 0s 545us/step - loss: 0.6146 - acc: 0.6900 - val_loss: 0.6537 - val_acc: 0.6400\n",
            "Epoch 1365/4500\n",
            "100/100 [==============================] - 0s 502us/step - loss: 0.6150 - acc: 0.6900 - val_loss: 0.6534 - val_acc: 0.6400\n",
            "Epoch 1366/4500\n",
            "100/100 [==============================] - 0s 490us/step - loss: 0.6147 - acc: 0.6900 - val_loss: 0.6539 - val_acc: 0.6400\n",
            "Epoch 1367/4500\n",
            "100/100 [==============================] - 0s 506us/step - loss: 0.6147 - acc: 0.6900 - val_loss: 0.6541 - val_acc: 0.6400\n",
            "Epoch 1368/4500\n",
            "100/100 [==============================] - 0s 511us/step - loss: 0.6147 - acc: 0.6900 - val_loss: 0.6536 - val_acc: 0.6400\n",
            "Epoch 1369/4500\n",
            "100/100 [==============================] - 0s 513us/step - loss: 0.6151 - acc: 0.6900 - val_loss: 0.6530 - val_acc: 0.6400\n",
            "Epoch 1370/4500\n",
            "100/100 [==============================] - 0s 546us/step - loss: 0.6145 - acc: 0.6900 - val_loss: 0.6535 - val_acc: 0.6400\n",
            "Epoch 1371/4500\n",
            "100/100 [==============================] - 0s 537us/step - loss: 0.6144 - acc: 0.6900 - val_loss: 0.6535 - val_acc: 0.6400\n",
            "Epoch 1372/4500\n",
            "100/100 [==============================] - 0s 535us/step - loss: 0.6145 - acc: 0.6900 - val_loss: 0.6535 - val_acc: 0.6400\n",
            "Epoch 1373/4500\n",
            "100/100 [==============================] - 0s 543us/step - loss: 0.6145 - acc: 0.6900 - val_loss: 0.6537 - val_acc: 0.6400\n",
            "Epoch 1374/4500\n",
            "100/100 [==============================] - 0s 508us/step - loss: 0.6148 - acc: 0.6900 - val_loss: 0.6529 - val_acc: 0.6400\n",
            "Epoch 1375/4500\n",
            "100/100 [==============================] - 0s 511us/step - loss: 0.6145 - acc: 0.6900 - val_loss: 0.6535 - val_acc: 0.6400\n",
            "Epoch 1376/4500\n",
            "100/100 [==============================] - 0s 525us/step - loss: 0.6144 - acc: 0.6900 - val_loss: 0.6535 - val_acc: 0.6400\n",
            "Epoch 1377/4500\n",
            "100/100 [==============================] - 0s 530us/step - loss: 0.6145 - acc: 0.6900 - val_loss: 0.6532 - val_acc: 0.6400\n",
            "Epoch 1378/4500\n",
            "100/100 [==============================] - 0s 519us/step - loss: 0.6142 - acc: 0.6900 - val_loss: 0.6534 - val_acc: 0.6400\n",
            "Epoch 1379/4500\n",
            "100/100 [==============================] - 0s 510us/step - loss: 0.6144 - acc: 0.6900 - val_loss: 0.6537 - val_acc: 0.6400\n",
            "Epoch 1380/4500\n",
            "100/100 [==============================] - 0s 539us/step - loss: 0.6146 - acc: 0.6900 - val_loss: 0.6530 - val_acc: 0.6400\n",
            "Epoch 1381/4500\n",
            "100/100 [==============================] - 0s 652us/step - loss: 0.6146 - acc: 0.6900 - val_loss: 0.6535 - val_acc: 0.6400\n",
            "Epoch 1382/4500\n",
            "100/100 [==============================] - 0s 501us/step - loss: 0.6142 - acc: 0.6900 - val_loss: 0.6534 - val_acc: 0.6400\n",
            "Epoch 1383/4500\n",
            "100/100 [==============================] - 0s 516us/step - loss: 0.6142 - acc: 0.6900 - val_loss: 0.6533 - val_acc: 0.6400\n",
            "Epoch 1384/4500\n",
            "100/100 [==============================] - 0s 500us/step - loss: 0.6144 - acc: 0.6900 - val_loss: 0.6539 - val_acc: 0.6400\n",
            "Epoch 1385/4500\n",
            "100/100 [==============================] - 0s 509us/step - loss: 0.6142 - acc: 0.6900 - val_loss: 0.6537 - val_acc: 0.6400\n",
            "Epoch 1386/4500\n",
            "100/100 [==============================] - 0s 501us/step - loss: 0.6146 - acc: 0.6900 - val_loss: 0.6538 - val_acc: 0.6400\n",
            "Epoch 1387/4500\n",
            "100/100 [==============================] - 0s 528us/step - loss: 0.6150 - acc: 0.6900 - val_loss: 0.6529 - val_acc: 0.6400\n",
            "Epoch 1388/4500\n",
            "100/100 [==============================] - 0s 592us/step - loss: 0.6141 - acc: 0.6900 - val_loss: 0.6529 - val_acc: 0.6400\n",
            "Epoch 1389/4500\n",
            "100/100 [==============================] - 0s 580us/step - loss: 0.6143 - acc: 0.6900 - val_loss: 0.6535 - val_acc: 0.6400\n",
            "Epoch 1390/4500\n",
            "100/100 [==============================] - 0s 557us/step - loss: 0.6140 - acc: 0.6900 - val_loss: 0.6534 - val_acc: 0.6400\n",
            "Epoch 1391/4500\n",
            "100/100 [==============================] - 0s 597us/step - loss: 0.6140 - acc: 0.6900 - val_loss: 0.6532 - val_acc: 0.6400\n",
            "Epoch 1392/4500\n",
            "100/100 [==============================] - 0s 535us/step - loss: 0.6143 - acc: 0.6900 - val_loss: 0.6529 - val_acc: 0.6400\n",
            "Epoch 1393/4500\n",
            "100/100 [==============================] - 0s 566us/step - loss: 0.6141 - acc: 0.6900 - val_loss: 0.6527 - val_acc: 0.6400\n",
            "Epoch 1394/4500\n",
            "100/100 [==============================] - 0s 523us/step - loss: 0.6140 - acc: 0.6900 - val_loss: 0.6531 - val_acc: 0.6400\n",
            "Epoch 1395/4500\n",
            "100/100 [==============================] - 0s 512us/step - loss: 0.6144 - acc: 0.6900 - val_loss: 0.6537 - val_acc: 0.6400\n",
            "Epoch 1396/4500\n",
            "100/100 [==============================] - 0s 496us/step - loss: 0.6142 - acc: 0.6900 - val_loss: 0.6529 - val_acc: 0.6400\n",
            "Epoch 1397/4500\n",
            "100/100 [==============================] - 0s 502us/step - loss: 0.6141 - acc: 0.6900 - val_loss: 0.6532 - val_acc: 0.6400\n",
            "Epoch 1398/4500\n",
            "100/100 [==============================] - 0s 497us/step - loss: 0.6139 - acc: 0.6900 - val_loss: 0.6531 - val_acc: 0.6400\n",
            "Epoch 1399/4500\n",
            "100/100 [==============================] - 0s 505us/step - loss: 0.6140 - acc: 0.6900 - val_loss: 0.6532 - val_acc: 0.6400\n",
            "Epoch 1400/4500\n",
            "100/100 [==============================] - 0s 632us/step - loss: 0.6140 - acc: 0.6900 - val_loss: 0.6529 - val_acc: 0.6400\n",
            "Epoch 1401/4500\n",
            "100/100 [==============================] - 0s 557us/step - loss: 0.6139 - acc: 0.6900 - val_loss: 0.6529 - val_acc: 0.6400\n",
            "Epoch 1402/4500\n",
            "100/100 [==============================] - 0s 533us/step - loss: 0.6139 - acc: 0.6900 - val_loss: 0.6529 - val_acc: 0.6400\n",
            "Epoch 1403/4500\n",
            "100/100 [==============================] - 0s 548us/step - loss: 0.6138 - acc: 0.6900 - val_loss: 0.6532 - val_acc: 0.6400\n",
            "Epoch 1404/4500\n",
            "100/100 [==============================] - 0s 511us/step - loss: 0.6138 - acc: 0.6900 - val_loss: 0.6528 - val_acc: 0.6400\n",
            "Epoch 1405/4500\n",
            "100/100 [==============================] - 0s 483us/step - loss: 0.6139 - acc: 0.6900 - val_loss: 0.6526 - val_acc: 0.6400\n",
            "Epoch 1406/4500\n",
            "100/100 [==============================] - 0s 512us/step - loss: 0.6141 - acc: 0.6900 - val_loss: 0.6529 - val_acc: 0.6400\n",
            "Epoch 1407/4500\n",
            "100/100 [==============================] - 0s 484us/step - loss: 0.6137 - acc: 0.6900 - val_loss: 0.6526 - val_acc: 0.6400\n",
            "Epoch 1408/4500\n",
            "100/100 [==============================] - 0s 529us/step - loss: 0.6138 - acc: 0.6900 - val_loss: 0.6526 - val_acc: 0.6400\n",
            "Epoch 1409/4500\n",
            "100/100 [==============================] - 0s 511us/step - loss: 0.6139 - acc: 0.6900 - val_loss: 0.6523 - val_acc: 0.6400\n",
            "Epoch 1410/4500\n",
            "100/100 [==============================] - 0s 582us/step - loss: 0.6135 - acc: 0.6900 - val_loss: 0.6525 - val_acc: 0.6400\n",
            "Epoch 1411/4500\n",
            "100/100 [==============================] - 0s 527us/step - loss: 0.6137 - acc: 0.6900 - val_loss: 0.6530 - val_acc: 0.6400\n",
            "Epoch 1412/4500\n",
            "100/100 [==============================] - 0s 495us/step - loss: 0.6136 - acc: 0.6900 - val_loss: 0.6529 - val_acc: 0.6400\n",
            "Epoch 1413/4500\n",
            "100/100 [==============================] - 0s 503us/step - loss: 0.6138 - acc: 0.6900 - val_loss: 0.6527 - val_acc: 0.6400\n",
            "Epoch 1414/4500\n",
            "100/100 [==============================] - 0s 490us/step - loss: 0.6136 - acc: 0.6900 - val_loss: 0.6530 - val_acc: 0.6400\n",
            "Epoch 1415/4500\n",
            "100/100 [==============================] - 0s 494us/step - loss: 0.6140 - acc: 0.6900 - val_loss: 0.6526 - val_acc: 0.6400\n",
            "Epoch 1416/4500\n",
            "100/100 [==============================] - 0s 491us/step - loss: 0.6140 - acc: 0.6900 - val_loss: 0.6533 - val_acc: 0.6400\n",
            "Epoch 1417/4500\n",
            "100/100 [==============================] - 0s 501us/step - loss: 0.6138 - acc: 0.6900 - val_loss: 0.6533 - val_acc: 0.6400\n",
            "Epoch 1418/4500\n",
            "100/100 [==============================] - 0s 593us/step - loss: 0.6134 - acc: 0.6900 - val_loss: 0.6529 - val_acc: 0.6400\n",
            "Epoch 1419/4500\n",
            "100/100 [==============================] - 0s 612us/step - loss: 0.6134 - acc: 0.6900 - val_loss: 0.6525 - val_acc: 0.6400\n",
            "Epoch 1420/4500\n",
            "100/100 [==============================] - 0s 538us/step - loss: 0.6138 - acc: 0.6900 - val_loss: 0.6530 - val_acc: 0.6400\n",
            "Epoch 1421/4500\n",
            "100/100 [==============================] - 0s 488us/step - loss: 0.6134 - acc: 0.6900 - val_loss: 0.6524 - val_acc: 0.6400\n",
            "Epoch 1422/4500\n",
            "100/100 [==============================] - 0s 520us/step - loss: 0.6146 - acc: 0.6900 - val_loss: 0.6514 - val_acc: 0.6400\n",
            "Epoch 1423/4500\n",
            "100/100 [==============================] - 0s 530us/step - loss: 0.6135 - acc: 0.6900 - val_loss: 0.6518 - val_acc: 0.6400\n",
            "Epoch 1424/4500\n",
            "100/100 [==============================] - 0s 514us/step - loss: 0.6136 - acc: 0.6900 - val_loss: 0.6524 - val_acc: 0.6400\n",
            "Epoch 1425/4500\n",
            "100/100 [==============================] - 0s 506us/step - loss: 0.6133 - acc: 0.6900 - val_loss: 0.6522 - val_acc: 0.6400\n",
            "Epoch 1426/4500\n",
            "100/100 [==============================] - 0s 526us/step - loss: 0.6133 - acc: 0.6900 - val_loss: 0.6525 - val_acc: 0.6400\n",
            "Epoch 1427/4500\n",
            "100/100 [==============================] - 0s 552us/step - loss: 0.6135 - acc: 0.6900 - val_loss: 0.6525 - val_acc: 0.6400\n",
            "Epoch 1428/4500\n",
            "100/100 [==============================] - 0s 668us/step - loss: 0.6134 - acc: 0.6900 - val_loss: 0.6522 - val_acc: 0.6400\n",
            "Epoch 1429/4500\n",
            "100/100 [==============================] - 0s 566us/step - loss: 0.6133 - acc: 0.6900 - val_loss: 0.6524 - val_acc: 0.6400\n",
            "Epoch 1430/4500\n",
            "100/100 [==============================] - 0s 555us/step - loss: 0.6132 - acc: 0.6900 - val_loss: 0.6524 - val_acc: 0.6400\n",
            "Epoch 1431/4500\n",
            "100/100 [==============================] - 0s 609us/step - loss: 0.6131 - acc: 0.6900 - val_loss: 0.6521 - val_acc: 0.6400\n",
            "Epoch 1432/4500\n",
            "100/100 [==============================] - 0s 607us/step - loss: 0.6134 - acc: 0.6900 - val_loss: 0.6525 - val_acc: 0.6400\n",
            "Epoch 1433/4500\n",
            "100/100 [==============================] - 0s 524us/step - loss: 0.6135 - acc: 0.6900 - val_loss: 0.6519 - val_acc: 0.6400\n",
            "Epoch 1434/4500\n",
            "100/100 [==============================] - 0s 514us/step - loss: 0.6132 - acc: 0.6900 - val_loss: 0.6520 - val_acc: 0.6400\n",
            "Epoch 1435/4500\n",
            "100/100 [==============================] - 0s 499us/step - loss: 0.6132 - acc: 0.6900 - val_loss: 0.6520 - val_acc: 0.6400\n",
            "Epoch 1436/4500\n",
            "100/100 [==============================] - 0s 509us/step - loss: 0.6135 - acc: 0.6900 - val_loss: 0.6516 - val_acc: 0.6400\n",
            "Epoch 1437/4500\n",
            "100/100 [==============================] - 0s 586us/step - loss: 0.6130 - acc: 0.6900 - val_loss: 0.6517 - val_acc: 0.6400\n",
            "Epoch 1438/4500\n",
            "100/100 [==============================] - 0s 543us/step - loss: 0.6131 - acc: 0.6900 - val_loss: 0.6520 - val_acc: 0.6400\n",
            "Epoch 1439/4500\n",
            "100/100 [==============================] - 0s 561us/step - loss: 0.6144 - acc: 0.6900 - val_loss: 0.6513 - val_acc: 0.6400\n",
            "Epoch 1440/4500\n",
            "100/100 [==============================] - 0s 513us/step - loss: 0.6128 - acc: 0.6900 - val_loss: 0.6518 - val_acc: 0.6400\n",
            "Epoch 1441/4500\n",
            "100/100 [==============================] - 0s 509us/step - loss: 0.6132 - acc: 0.6900 - val_loss: 0.6525 - val_acc: 0.6400\n",
            "Epoch 1442/4500\n",
            "100/100 [==============================] - 0s 525us/step - loss: 0.6129 - acc: 0.6900 - val_loss: 0.6523 - val_acc: 0.6400\n",
            "Epoch 1443/4500\n",
            "100/100 [==============================] - 0s 490us/step - loss: 0.6128 - acc: 0.6900 - val_loss: 0.6521 - val_acc: 0.6400\n",
            "Epoch 1444/4500\n",
            "100/100 [==============================] - 0s 494us/step - loss: 0.6135 - acc: 0.6900 - val_loss: 0.6515 - val_acc: 0.6400\n",
            "Epoch 1445/4500\n",
            "100/100 [==============================] - 0s 570us/step - loss: 0.6129 - acc: 0.6900 - val_loss: 0.6514 - val_acc: 0.6400\n",
            "Epoch 1446/4500\n",
            "100/100 [==============================] - 0s 537us/step - loss: 0.6131 - acc: 0.6900 - val_loss: 0.6521 - val_acc: 0.6400\n",
            "Epoch 1447/4500\n",
            "100/100 [==============================] - 0s 504us/step - loss: 0.6127 - acc: 0.6900 - val_loss: 0.6523 - val_acc: 0.6400\n",
            "Epoch 1448/4500\n",
            "100/100 [==============================] - 0s 526us/step - loss: 0.6128 - acc: 0.6900 - val_loss: 0.6524 - val_acc: 0.6400\n",
            "Epoch 1449/4500\n",
            "100/100 [==============================] - 0s 524us/step - loss: 0.6127 - acc: 0.6900 - val_loss: 0.6521 - val_acc: 0.6400\n",
            "Epoch 1450/4500\n",
            "100/100 [==============================] - 0s 516us/step - loss: 0.6130 - acc: 0.6900 - val_loss: 0.6524 - val_acc: 0.6400\n",
            "Epoch 1451/4500\n",
            "100/100 [==============================] - 0s 499us/step - loss: 0.6128 - acc: 0.6900 - val_loss: 0.6518 - val_acc: 0.6400\n",
            "Epoch 1452/4500\n",
            "100/100 [==============================] - 0s 523us/step - loss: 0.6128 - acc: 0.6900 - val_loss: 0.6521 - val_acc: 0.6400\n",
            "Epoch 1453/4500\n",
            "100/100 [==============================] - 0s 596us/step - loss: 0.6129 - acc: 0.6900 - val_loss: 0.6513 - val_acc: 0.6400\n",
            "Epoch 1454/4500\n",
            "100/100 [==============================] - 0s 567us/step - loss: 0.6127 - acc: 0.6900 - val_loss: 0.6511 - val_acc: 0.6400\n",
            "Epoch 1455/4500\n",
            "100/100 [==============================] - 0s 518us/step - loss: 0.6126 - acc: 0.6900 - val_loss: 0.6512 - val_acc: 0.6400\n",
            "Epoch 1456/4500\n",
            "100/100 [==============================] - 0s 543us/step - loss: 0.6126 - acc: 0.6900 - val_loss: 0.6512 - val_acc: 0.6400\n",
            "Epoch 1457/4500\n",
            "100/100 [==============================] - 0s 511us/step - loss: 0.6126 - acc: 0.6900 - val_loss: 0.6516 - val_acc: 0.6400\n",
            "Epoch 1458/4500\n",
            "100/100 [==============================] - 0s 517us/step - loss: 0.6128 - acc: 0.6900 - val_loss: 0.6513 - val_acc: 0.6400\n",
            "Epoch 1459/4500\n",
            "100/100 [==============================] - 0s 535us/step - loss: 0.6127 - acc: 0.6900 - val_loss: 0.6519 - val_acc: 0.6400\n",
            "Epoch 1460/4500\n",
            "100/100 [==============================] - 0s 528us/step - loss: 0.6127 - acc: 0.6900 - val_loss: 0.6513 - val_acc: 0.6400\n",
            "Epoch 1461/4500\n",
            "100/100 [==============================] - 0s 511us/step - loss: 0.6130 - acc: 0.6900 - val_loss: 0.6507 - val_acc: 0.6400\n",
            "Epoch 1462/4500\n",
            "100/100 [==============================] - 0s 517us/step - loss: 0.6126 - acc: 0.6900 - val_loss: 0.6515 - val_acc: 0.6400\n",
            "Epoch 1463/4500\n",
            "100/100 [==============================] - 0s 493us/step - loss: 0.6124 - acc: 0.6900 - val_loss: 0.6512 - val_acc: 0.6400\n",
            "Epoch 1464/4500\n",
            "100/100 [==============================] - 0s 510us/step - loss: 0.6130 - acc: 0.6900 - val_loss: 0.6520 - val_acc: 0.6400\n",
            "Epoch 1465/4500\n",
            "100/100 [==============================] - 0s 543us/step - loss: 0.6125 - acc: 0.6900 - val_loss: 0.6514 - val_acc: 0.6400\n",
            "Epoch 1466/4500\n",
            "100/100 [==============================] - 0s 560us/step - loss: 0.6124 - acc: 0.6900 - val_loss: 0.6512 - val_acc: 0.6400\n",
            "Epoch 1467/4500\n",
            "100/100 [==============================] - 0s 519us/step - loss: 0.6123 - acc: 0.6900 - val_loss: 0.6509 - val_acc: 0.6400\n",
            "Epoch 1468/4500\n",
            "100/100 [==============================] - 0s 558us/step - loss: 0.6128 - acc: 0.6900 - val_loss: 0.6517 - val_acc: 0.6400\n",
            "Epoch 1469/4500\n",
            "100/100 [==============================] - 0s 523us/step - loss: 0.6132 - acc: 0.6900 - val_loss: 0.6507 - val_acc: 0.6400\n",
            "Epoch 1470/4500\n",
            "100/100 [==============================] - 0s 557us/step - loss: 0.6122 - acc: 0.6900 - val_loss: 0.6508 - val_acc: 0.6400\n",
            "Epoch 1471/4500\n",
            "100/100 [==============================] - 0s 535us/step - loss: 0.6121 - acc: 0.6900 - val_loss: 0.6511 - val_acc: 0.6400\n",
            "Epoch 1472/4500\n",
            "100/100 [==============================] - 0s 619us/step - loss: 0.6121 - acc: 0.6900 - val_loss: 0.6508 - val_acc: 0.6400\n",
            "Epoch 1473/4500\n",
            "100/100 [==============================] - 0s 542us/step - loss: 0.6122 - acc: 0.6900 - val_loss: 0.6510 - val_acc: 0.6400\n",
            "Epoch 1474/4500\n",
            "100/100 [==============================] - 0s 519us/step - loss: 0.6121 - acc: 0.6900 - val_loss: 0.6512 - val_acc: 0.6400\n",
            "Epoch 1475/4500\n",
            "100/100 [==============================] - 0s 598us/step - loss: 0.6119 - acc: 0.6900 - val_loss: 0.6510 - val_acc: 0.6400\n",
            "Epoch 1476/4500\n",
            "100/100 [==============================] - 0s 516us/step - loss: 0.6121 - acc: 0.6900 - val_loss: 0.6510 - val_acc: 0.6400\n",
            "Epoch 1477/4500\n",
            "100/100 [==============================] - 0s 514us/step - loss: 0.6120 - acc: 0.6900 - val_loss: 0.6511 - val_acc: 0.6400\n",
            "Epoch 1478/4500\n",
            "100/100 [==============================] - 0s 541us/step - loss: 0.6121 - acc: 0.6900 - val_loss: 0.6514 - val_acc: 0.6400\n",
            "Epoch 1479/4500\n",
            "100/100 [==============================] - 0s 578us/step - loss: 0.6118 - acc: 0.6900 - val_loss: 0.6510 - val_acc: 0.6400\n",
            "Epoch 1480/4500\n",
            "100/100 [==============================] - 0s 533us/step - loss: 0.6120 - acc: 0.6900 - val_loss: 0.6505 - val_acc: 0.6400\n",
            "Epoch 1481/4500\n",
            "100/100 [==============================] - 0s 552us/step - loss: 0.6120 - acc: 0.6900 - val_loss: 0.6509 - val_acc: 0.6400\n",
            "Epoch 1482/4500\n",
            "100/100 [==============================] - 0s 535us/step - loss: 0.6119 - acc: 0.6900 - val_loss: 0.6510 - val_acc: 0.6400\n",
            "Epoch 1483/4500\n",
            "100/100 [==============================] - 0s 530us/step - loss: 0.6119 - acc: 0.6900 - val_loss: 0.6504 - val_acc: 0.6400\n",
            "Epoch 1484/4500\n",
            "100/100 [==============================] - 0s 504us/step - loss: 0.6119 - acc: 0.6900 - val_loss: 0.6509 - val_acc: 0.6400\n",
            "Epoch 1485/4500\n",
            "100/100 [==============================] - 0s 528us/step - loss: 0.6118 - acc: 0.6900 - val_loss: 0.6503 - val_acc: 0.6400\n",
            "Epoch 1486/4500\n",
            "100/100 [==============================] - 0s 503us/step - loss: 0.6121 - acc: 0.6900 - val_loss: 0.6510 - val_acc: 0.6400\n",
            "Epoch 1487/4500\n",
            "100/100 [==============================] - 0s 541us/step - loss: 0.6120 - acc: 0.6900 - val_loss: 0.6502 - val_acc: 0.6400\n",
            "Epoch 1488/4500\n",
            "100/100 [==============================] - 0s 502us/step - loss: 0.6116 - acc: 0.6900 - val_loss: 0.6501 - val_acc: 0.6400\n",
            "Epoch 1489/4500\n",
            "100/100 [==============================] - 0s 494us/step - loss: 0.6115 - acc: 0.6900 - val_loss: 0.6504 - val_acc: 0.6400\n",
            "Epoch 1490/4500\n",
            "100/100 [==============================] - 0s 511us/step - loss: 0.6115 - acc: 0.6900 - val_loss: 0.6502 - val_acc: 0.6400\n",
            "Epoch 1491/4500\n",
            "100/100 [==============================] - 0s 513us/step - loss: 0.6114 - acc: 0.6900 - val_loss: 0.6502 - val_acc: 0.6400\n",
            "Epoch 1492/4500\n",
            "100/100 [==============================] - 0s 530us/step - loss: 0.6117 - acc: 0.6900 - val_loss: 0.6502 - val_acc: 0.6400\n",
            "Epoch 1493/4500\n",
            "100/100 [==============================] - 0s 562us/step - loss: 0.6114 - acc: 0.6900 - val_loss: 0.6505 - val_acc: 0.6400\n",
            "Epoch 1494/4500\n",
            "100/100 [==============================] - 0s 581us/step - loss: 0.6115 - acc: 0.6900 - val_loss: 0.6501 - val_acc: 0.6400\n",
            "Epoch 1495/4500\n",
            "100/100 [==============================] - 0s 602us/step - loss: 0.6114 - acc: 0.6900 - val_loss: 0.6500 - val_acc: 0.6400\n",
            "Epoch 1496/4500\n",
            "100/100 [==============================] - 0s 548us/step - loss: 0.6114 - acc: 0.6900 - val_loss: 0.6502 - val_acc: 0.6400\n",
            "Epoch 1497/4500\n",
            "100/100 [==============================] - 0s 505us/step - loss: 0.6123 - acc: 0.6900 - val_loss: 0.6509 - val_acc: 0.6400\n",
            "Epoch 1498/4500\n",
            "100/100 [==============================] - 0s 610us/step - loss: 0.6114 - acc: 0.6900 - val_loss: 0.6502 - val_acc: 0.6400\n",
            "Epoch 1499/4500\n",
            "100/100 [==============================] - 0s 495us/step - loss: 0.6112 - acc: 0.6900 - val_loss: 0.6501 - val_acc: 0.6400\n",
            "Epoch 1500/4500\n",
            "100/100 [==============================] - 0s 532us/step - loss: 0.6114 - acc: 0.6900 - val_loss: 0.6496 - val_acc: 0.6400\n",
            "Epoch 1501/4500\n",
            "100/100 [==============================] - 0s 567us/step - loss: 0.6113 - acc: 0.6900 - val_loss: 0.6494 - val_acc: 0.6400\n",
            "Epoch 1502/4500\n",
            "100/100 [==============================] - 0s 567us/step - loss: 0.6116 - acc: 0.6900 - val_loss: 0.6501 - val_acc: 0.6400\n",
            "Epoch 1503/4500\n",
            "100/100 [==============================] - 0s 514us/step - loss: 0.6110 - acc: 0.6900 - val_loss: 0.6500 - val_acc: 0.6400\n",
            "Epoch 1504/4500\n",
            "100/100 [==============================] - 0s 498us/step - loss: 0.6111 - acc: 0.6900 - val_loss: 0.6501 - val_acc: 0.6400\n",
            "Epoch 1505/4500\n",
            "100/100 [==============================] - 0s 511us/step - loss: 0.6110 - acc: 0.6900 - val_loss: 0.6498 - val_acc: 0.6400\n",
            "Epoch 1506/4500\n",
            "100/100 [==============================] - 0s 482us/step - loss: 0.6110 - acc: 0.6900 - val_loss: 0.6500 - val_acc: 0.6400\n",
            "Epoch 1507/4500\n",
            "100/100 [==============================] - 0s 596us/step - loss: 0.6111 - acc: 0.6900 - val_loss: 0.6494 - val_acc: 0.6400\n",
            "Epoch 1508/4500\n",
            "100/100 [==============================] - 0s 505us/step - loss: 0.6110 - acc: 0.6900 - val_loss: 0.6497 - val_acc: 0.6400\n",
            "Epoch 1509/4500\n",
            "100/100 [==============================] - 0s 482us/step - loss: 0.6109 - acc: 0.6900 - val_loss: 0.6497 - val_acc: 0.6400\n",
            "Epoch 1510/4500\n",
            "100/100 [==============================] - 0s 563us/step - loss: 0.6108 - acc: 0.6900 - val_loss: 0.6498 - val_acc: 0.6400\n",
            "Epoch 1511/4500\n",
            "100/100 [==============================] - 0s 513us/step - loss: 0.6107 - acc: 0.6900 - val_loss: 0.6498 - val_acc: 0.6400\n",
            "Epoch 1512/4500\n",
            "100/100 [==============================] - 0s 528us/step - loss: 0.6108 - acc: 0.6900 - val_loss: 0.6497 - val_acc: 0.6400\n",
            "Epoch 1513/4500\n",
            "100/100 [==============================] - 0s 525us/step - loss: 0.6107 - acc: 0.6900 - val_loss: 0.6494 - val_acc: 0.6400\n",
            "Epoch 1514/4500\n",
            "100/100 [==============================] - 0s 490us/step - loss: 0.6107 - acc: 0.6900 - val_loss: 0.6493 - val_acc: 0.6400\n",
            "Epoch 1515/4500\n",
            "100/100 [==============================] - 0s 505us/step - loss: 0.6108 - acc: 0.6900 - val_loss: 0.6496 - val_acc: 0.6400\n",
            "Epoch 1516/4500\n",
            "100/100 [==============================] - 0s 511us/step - loss: 0.6106 - acc: 0.6900 - val_loss: 0.6493 - val_acc: 0.6400\n",
            "Epoch 1517/4500\n",
            "100/100 [==============================] - 0s 559us/step - loss: 0.6106 - acc: 0.6900 - val_loss: 0.6490 - val_acc: 0.6400\n",
            "Epoch 1518/4500\n",
            "100/100 [==============================] - 0s 603us/step - loss: 0.6104 - acc: 0.6900 - val_loss: 0.6492 - val_acc: 0.6400\n",
            "Epoch 1519/4500\n",
            "100/100 [==============================] - 0s 523us/step - loss: 0.6106 - acc: 0.6900 - val_loss: 0.6491 - val_acc: 0.6400\n",
            "Epoch 1520/4500\n",
            "100/100 [==============================] - 0s 502us/step - loss: 0.6106 - acc: 0.6900 - val_loss: 0.6488 - val_acc: 0.6400\n",
            "Epoch 1521/4500\n",
            "100/100 [==============================] - 0s 553us/step - loss: 0.6103 - acc: 0.6900 - val_loss: 0.6491 - val_acc: 0.6400\n",
            "Epoch 1522/4500\n",
            "100/100 [==============================] - 0s 597us/step - loss: 0.6104 - acc: 0.6900 - val_loss: 0.6495 - val_acc: 0.6400\n",
            "Epoch 1523/4500\n",
            "100/100 [==============================] - 0s 545us/step - loss: 0.6104 - acc: 0.6900 - val_loss: 0.6491 - val_acc: 0.6400\n",
            "Epoch 1524/4500\n",
            "100/100 [==============================] - 0s 501us/step - loss: 0.6102 - acc: 0.6900 - val_loss: 0.6491 - val_acc: 0.6400\n",
            "Epoch 1525/4500\n",
            "100/100 [==============================] - 0s 525us/step - loss: 0.6105 - acc: 0.6900 - val_loss: 0.6494 - val_acc: 0.6400\n",
            "Epoch 1526/4500\n",
            "100/100 [==============================] - 0s 560us/step - loss: 0.6103 - acc: 0.6900 - val_loss: 0.6491 - val_acc: 0.6400\n",
            "Epoch 1527/4500\n",
            "100/100 [==============================] - 0s 590us/step - loss: 0.6105 - acc: 0.6900 - val_loss: 0.6493 - val_acc: 0.6400\n",
            "Epoch 1528/4500\n",
            "100/100 [==============================] - 0s 508us/step - loss: 0.6102 - acc: 0.6900 - val_loss: 0.6486 - val_acc: 0.6400\n",
            "Epoch 1529/4500\n",
            "100/100 [==============================] - 0s 491us/step - loss: 0.6101 - acc: 0.6900 - val_loss: 0.6487 - val_acc: 0.6400\n",
            "Epoch 1530/4500\n",
            "100/100 [==============================] - 0s 512us/step - loss: 0.6100 - acc: 0.6900 - val_loss: 0.6486 - val_acc: 0.6400\n",
            "Epoch 1531/4500\n",
            "100/100 [==============================] - 0s 581us/step - loss: 0.6099 - acc: 0.6900 - val_loss: 0.6486 - val_acc: 0.6400\n",
            "Epoch 1532/4500\n",
            "100/100 [==============================] - 0s 555us/step - loss: 0.6100 - acc: 0.6900 - val_loss: 0.6484 - val_acc: 0.6400\n",
            "Epoch 1533/4500\n",
            "100/100 [==============================] - 0s 560us/step - loss: 0.6100 - acc: 0.6900 - val_loss: 0.6481 - val_acc: 0.6400\n",
            "Epoch 1534/4500\n",
            "100/100 [==============================] - 0s 516us/step - loss: 0.6100 - acc: 0.6900 - val_loss: 0.6487 - val_acc: 0.6400\n",
            "Epoch 1535/4500\n",
            "100/100 [==============================] - 0s 567us/step - loss: 0.6101 - acc: 0.6900 - val_loss: 0.6481 - val_acc: 0.6400\n",
            "Epoch 1536/4500\n",
            "100/100 [==============================] - 0s 586us/step - loss: 0.6099 - acc: 0.6900 - val_loss: 0.6485 - val_acc: 0.6400\n",
            "Epoch 1537/4500\n",
            "100/100 [==============================] - 0s 547us/step - loss: 0.6101 - acc: 0.6900 - val_loss: 0.6481 - val_acc: 0.6400\n",
            "Epoch 1538/4500\n",
            "100/100 [==============================] - 0s 507us/step - loss: 0.6096 - acc: 0.6900 - val_loss: 0.6483 - val_acc: 0.6400\n",
            "Epoch 1539/4500\n",
            "100/100 [==============================] - 0s 501us/step - loss: 0.6097 - acc: 0.6900 - val_loss: 0.6486 - val_acc: 0.6400\n",
            "Epoch 1540/4500\n",
            "100/100 [==============================] - 0s 532us/step - loss: 0.6098 - acc: 0.6900 - val_loss: 0.6488 - val_acc: 0.6400\n",
            "Epoch 1541/4500\n",
            "100/100 [==============================] - 0s 544us/step - loss: 0.6103 - acc: 0.6900 - val_loss: 0.6492 - val_acc: 0.6400\n",
            "Epoch 1542/4500\n",
            "100/100 [==============================] - 0s 493us/step - loss: 0.6094 - acc: 0.6900 - val_loss: 0.6487 - val_acc: 0.6400\n",
            "Epoch 1543/4500\n",
            "100/100 [==============================] - 0s 502us/step - loss: 0.6096 - acc: 0.6900 - val_loss: 0.6481 - val_acc: 0.6400\n",
            "Epoch 1544/4500\n",
            "100/100 [==============================] - 0s 524us/step - loss: 0.6095 - acc: 0.6900 - val_loss: 0.6476 - val_acc: 0.6400\n",
            "Epoch 1545/4500\n",
            "100/100 [==============================] - 0s 539us/step - loss: 0.6095 - acc: 0.6900 - val_loss: 0.6479 - val_acc: 0.6400\n",
            "Epoch 1546/4500\n",
            "100/100 [==============================] - 0s 523us/step - loss: 0.6092 - acc: 0.6900 - val_loss: 0.6478 - val_acc: 0.6400\n",
            "Epoch 1547/4500\n",
            "100/100 [==============================] - 0s 522us/step - loss: 0.6092 - acc: 0.6900 - val_loss: 0.6476 - val_acc: 0.6400\n",
            "Epoch 1548/4500\n",
            "100/100 [==============================] - 0s 513us/step - loss: 0.6096 - acc: 0.6900 - val_loss: 0.6481 - val_acc: 0.6400\n",
            "Epoch 1549/4500\n",
            "100/100 [==============================] - 0s 537us/step - loss: 0.6094 - acc: 0.6900 - val_loss: 0.6475 - val_acc: 0.6400\n",
            "Epoch 1550/4500\n",
            "100/100 [==============================] - 0s 575us/step - loss: 0.6093 - acc: 0.6900 - val_loss: 0.6473 - val_acc: 0.6400\n",
            "Epoch 1551/4500\n",
            "100/100 [==============================] - 0s 532us/step - loss: 0.6092 - acc: 0.6900 - val_loss: 0.6472 - val_acc: 0.6400\n",
            "Epoch 1552/4500\n",
            "100/100 [==============================] - 0s 508us/step - loss: 0.6098 - acc: 0.6900 - val_loss: 0.6481 - val_acc: 0.6400\n",
            "Epoch 1553/4500\n",
            "100/100 [==============================] - 0s 502us/step - loss: 0.6094 - acc: 0.6900 - val_loss: 0.6473 - val_acc: 0.6400\n",
            "Epoch 1554/4500\n",
            "100/100 [==============================] - 0s 528us/step - loss: 0.6091 - acc: 0.6900 - val_loss: 0.6476 - val_acc: 0.6400\n",
            "Epoch 1555/4500\n",
            "100/100 [==============================] - 0s 525us/step - loss: 0.6089 - acc: 0.6900 - val_loss: 0.6476 - val_acc: 0.6400\n",
            "Epoch 1556/4500\n",
            "100/100 [==============================] - 0s 531us/step - loss: 0.6089 - acc: 0.6900 - val_loss: 0.6474 - val_acc: 0.6400\n",
            "Epoch 1557/4500\n",
            "100/100 [==============================] - 0s 548us/step - loss: 0.6088 - acc: 0.6900 - val_loss: 0.6473 - val_acc: 0.6400\n",
            "Epoch 1558/4500\n",
            "100/100 [==============================] - 0s 520us/step - loss: 0.6088 - acc: 0.6900 - val_loss: 0.6471 - val_acc: 0.6400\n",
            "Epoch 1559/4500\n",
            "100/100 [==============================] - 0s 486us/step - loss: 0.6090 - acc: 0.6900 - val_loss: 0.6474 - val_acc: 0.6400\n",
            "Epoch 1560/4500\n",
            "100/100 [==============================] - 0s 488us/step - loss: 0.6086 - acc: 0.6900 - val_loss: 0.6474 - val_acc: 0.6400\n",
            "Epoch 1561/4500\n",
            "100/100 [==============================] - 0s 511us/step - loss: 0.6087 - acc: 0.6900 - val_loss: 0.6475 - val_acc: 0.6400\n",
            "Epoch 1562/4500\n",
            "100/100 [==============================] - 0s 537us/step - loss: 0.6088 - acc: 0.6900 - val_loss: 0.6468 - val_acc: 0.6400\n",
            "Epoch 1563/4500\n",
            "100/100 [==============================] - 0s 552us/step - loss: 0.6087 - acc: 0.6900 - val_loss: 0.6469 - val_acc: 0.6400\n",
            "Epoch 1564/4500\n",
            "100/100 [==============================] - 0s 534us/step - loss: 0.6090 - acc: 0.6900 - val_loss: 0.6463 - val_acc: 0.6400\n",
            "Epoch 1565/4500\n",
            "100/100 [==============================] - 0s 547us/step - loss: 0.6084 - acc: 0.6900 - val_loss: 0.6467 - val_acc: 0.6400\n",
            "Epoch 1566/4500\n",
            "100/100 [==============================] - 0s 517us/step - loss: 0.6084 - acc: 0.6900 - val_loss: 0.6470 - val_acc: 0.6400\n",
            "Epoch 1567/4500\n",
            "100/100 [==============================] - 0s 501us/step - loss: 0.6084 - acc: 0.6900 - val_loss: 0.6472 - val_acc: 0.6400\n",
            "Epoch 1568/4500\n",
            "100/100 [==============================] - 0s 500us/step - loss: 0.6082 - acc: 0.6900 - val_loss: 0.6471 - val_acc: 0.6400\n",
            "Epoch 1569/4500\n",
            "100/100 [==============================] - 0s 583us/step - loss: 0.6088 - acc: 0.6900 - val_loss: 0.6462 - val_acc: 0.6400\n",
            "Epoch 1570/4500\n",
            "100/100 [==============================] - 0s 528us/step - loss: 0.6081 - acc: 0.6900 - val_loss: 0.6462 - val_acc: 0.6400\n",
            "Epoch 1571/4500\n",
            "100/100 [==============================] - 0s 523us/step - loss: 0.6080 - acc: 0.6900 - val_loss: 0.6465 - val_acc: 0.6400\n",
            "Epoch 1572/4500\n",
            "100/100 [==============================] - 0s 529us/step - loss: 0.6080 - acc: 0.6900 - val_loss: 0.6467 - val_acc: 0.6400\n",
            "Epoch 1573/4500\n",
            "100/100 [==============================] - 0s 516us/step - loss: 0.6081 - acc: 0.6900 - val_loss: 0.6462 - val_acc: 0.6400\n",
            "Epoch 1574/4500\n",
            "100/100 [==============================] - 0s 520us/step - loss: 0.6079 - acc: 0.6900 - val_loss: 0.6463 - val_acc: 0.6400\n",
            "Epoch 1575/4500\n",
            "100/100 [==============================] - 0s 504us/step - loss: 0.6078 - acc: 0.6900 - val_loss: 0.6464 - val_acc: 0.6400\n",
            "Epoch 1576/4500\n",
            "100/100 [==============================] - 0s 533us/step - loss: 0.6085 - acc: 0.6900 - val_loss: 0.6457 - val_acc: 0.6400\n",
            "Epoch 1577/4500\n",
            "100/100 [==============================] - 0s 563us/step - loss: 0.6078 - acc: 0.6900 - val_loss: 0.6461 - val_acc: 0.6400\n",
            "Epoch 1578/4500\n",
            "100/100 [==============================] - 0s 520us/step - loss: 0.6084 - acc: 0.6900 - val_loss: 0.6467 - val_acc: 0.6400\n",
            "Epoch 1579/4500\n",
            "100/100 [==============================] - 0s 549us/step - loss: 0.6077 - acc: 0.6900 - val_loss: 0.6466 - val_acc: 0.6400\n",
            "Epoch 1580/4500\n",
            "100/100 [==============================] - 0s 512us/step - loss: 0.6077 - acc: 0.6900 - val_loss: 0.6459 - val_acc: 0.6400\n",
            "Epoch 1581/4500\n",
            "100/100 [==============================] - 0s 522us/step - loss: 0.6077 - acc: 0.6900 - val_loss: 0.6455 - val_acc: 0.6400\n",
            "Epoch 1582/4500\n",
            "100/100 [==============================] - 0s 521us/step - loss: 0.6077 - acc: 0.6900 - val_loss: 0.6452 - val_acc: 0.6400\n",
            "Epoch 1583/4500\n",
            "100/100 [==============================] - 0s 621us/step - loss: 0.6078 - acc: 0.6900 - val_loss: 0.6460 - val_acc: 0.6400\n",
            "Epoch 1584/4500\n",
            "100/100 [==============================] - 0s 630us/step - loss: 0.6075 - acc: 0.6900 - val_loss: 0.6455 - val_acc: 0.6400\n",
            "Epoch 1585/4500\n",
            "100/100 [==============================] - 0s 575us/step - loss: 0.6075 - acc: 0.6900 - val_loss: 0.6459 - val_acc: 0.6400\n",
            "Epoch 1586/4500\n",
            "100/100 [==============================] - 0s 510us/step - loss: 0.6074 - acc: 0.6900 - val_loss: 0.6453 - val_acc: 0.6400\n",
            "Epoch 1587/4500\n",
            "100/100 [==============================] - 0s 578us/step - loss: 0.6071 - acc: 0.6900 - val_loss: 0.6454 - val_acc: 0.6400\n",
            "Epoch 1588/4500\n",
            "100/100 [==============================] - 0s 505us/step - loss: 0.6070 - acc: 0.6900 - val_loss: 0.6454 - val_acc: 0.6400\n",
            "Epoch 1589/4500\n",
            "100/100 [==============================] - 0s 478us/step - loss: 0.6071 - acc: 0.6900 - val_loss: 0.6453 - val_acc: 0.6400\n",
            "Epoch 1590/4500\n",
            "100/100 [==============================] - 0s 489us/step - loss: 0.6073 - acc: 0.6900 - val_loss: 0.6449 - val_acc: 0.6400\n",
            "Epoch 1591/4500\n",
            "100/100 [==============================] - 0s 520us/step - loss: 0.6068 - acc: 0.6900 - val_loss: 0.6451 - val_acc: 0.6400\n",
            "Epoch 1592/4500\n",
            "100/100 [==============================] - 0s 518us/step - loss: 0.6069 - acc: 0.6900 - val_loss: 0.6450 - val_acc: 0.6400\n",
            "Epoch 1593/4500\n",
            "100/100 [==============================] - 0s 524us/step - loss: 0.6068 - acc: 0.6900 - val_loss: 0.6453 - val_acc: 0.6400\n",
            "Epoch 1594/4500\n",
            "100/100 [==============================] - 0s 507us/step - loss: 0.6066 - acc: 0.6900 - val_loss: 0.6453 - val_acc: 0.6400\n",
            "Epoch 1595/4500\n",
            "100/100 [==============================] - 0s 549us/step - loss: 0.6068 - acc: 0.6900 - val_loss: 0.6447 - val_acc: 0.6400\n",
            "Epoch 1596/4500\n",
            "100/100 [==============================] - 0s 542us/step - loss: 0.6066 - acc: 0.6900 - val_loss: 0.6447 - val_acc: 0.6400\n",
            "Epoch 1597/4500\n",
            "100/100 [==============================] - 0s 543us/step - loss: 0.6066 - acc: 0.6900 - val_loss: 0.6447 - val_acc: 0.6400\n",
            "Epoch 1598/4500\n",
            "100/100 [==============================] - 0s 512us/step - loss: 0.6065 - acc: 0.6900 - val_loss: 0.6445 - val_acc: 0.6400\n",
            "Epoch 1599/4500\n",
            "100/100 [==============================] - 0s 504us/step - loss: 0.6067 - acc: 0.6900 - val_loss: 0.6451 - val_acc: 0.6400\n",
            "Epoch 1600/4500\n",
            "100/100 [==============================] - 0s 496us/step - loss: 0.6064 - acc: 0.6900 - val_loss: 0.6446 - val_acc: 0.6400\n",
            "Epoch 1601/4500\n",
            "100/100 [==============================] - 0s 534us/step - loss: 0.6063 - acc: 0.6900 - val_loss: 0.6448 - val_acc: 0.6400\n",
            "Epoch 1602/4500\n",
            "100/100 [==============================] - 0s 536us/step - loss: 0.6060 - acc: 0.6900 - val_loss: 0.6446 - val_acc: 0.6400\n",
            "Epoch 1603/4500\n",
            "100/100 [==============================] - 0s 501us/step - loss: 0.6060 - acc: 0.6900 - val_loss: 0.6444 - val_acc: 0.6400\n",
            "Epoch 1604/4500\n",
            "100/100 [==============================] - 0s 526us/step - loss: 0.6059 - acc: 0.6900 - val_loss: 0.6443 - val_acc: 0.6400\n",
            "Epoch 1605/4500\n",
            "100/100 [==============================] - 0s 568us/step - loss: 0.6060 - acc: 0.6900 - val_loss: 0.6442 - val_acc: 0.6400\n",
            "Epoch 1606/4500\n",
            "100/100 [==============================] - 0s 518us/step - loss: 0.6064 - acc: 0.6900 - val_loss: 0.6445 - val_acc: 0.6400\n",
            "Epoch 1607/4500\n",
            "100/100 [==============================] - 0s 591us/step - loss: 0.6058 - acc: 0.6900 - val_loss: 0.6443 - val_acc: 0.6400\n",
            "Epoch 1608/4500\n",
            "100/100 [==============================] - 0s 539us/step - loss: 0.6056 - acc: 0.6900 - val_loss: 0.6440 - val_acc: 0.6400\n",
            "Epoch 1609/4500\n",
            "100/100 [==============================] - 0s 530us/step - loss: 0.6058 - acc: 0.6900 - val_loss: 0.6442 - val_acc: 0.6400\n",
            "Epoch 1610/4500\n",
            "100/100 [==============================] - 0s 507us/step - loss: 0.6056 - acc: 0.6900 - val_loss: 0.6440 - val_acc: 0.6400\n",
            "Epoch 1611/4500\n",
            "100/100 [==============================] - 0s 647us/step - loss: 0.6059 - acc: 0.6900 - val_loss: 0.6433 - val_acc: 0.6400\n",
            "Epoch 1612/4500\n",
            "100/100 [==============================] - 0s 652us/step - loss: 0.6060 - acc: 0.6900 - val_loss: 0.6438 - val_acc: 0.6400\n",
            "Epoch 1613/4500\n",
            "100/100 [==============================] - 0s 585us/step - loss: 0.6053 - acc: 0.6900 - val_loss: 0.6436 - val_acc: 0.6400\n",
            "Epoch 1614/4500\n",
            "100/100 [==============================] - 0s 536us/step - loss: 0.6053 - acc: 0.6900 - val_loss: 0.6437 - val_acc: 0.6400\n",
            "Epoch 1615/4500\n",
            "100/100 [==============================] - 0s 505us/step - loss: 0.6056 - acc: 0.6900 - val_loss: 0.6431 - val_acc: 0.6400\n",
            "Epoch 1616/4500\n",
            "100/100 [==============================] - 0s 497us/step - loss: 0.6055 - acc: 0.6900 - val_loss: 0.6430 - val_acc: 0.6400\n",
            "Epoch 1617/4500\n",
            "100/100 [==============================] - 0s 518us/step - loss: 0.6051 - acc: 0.6900 - val_loss: 0.6428 - val_acc: 0.6400\n",
            "Epoch 1618/4500\n",
            "100/100 [==============================] - 0s 501us/step - loss: 0.6053 - acc: 0.6900 - val_loss: 0.6432 - val_acc: 0.6400\n",
            "Epoch 1619/4500\n",
            "100/100 [==============================] - 0s 519us/step - loss: 0.6048 - acc: 0.6900 - val_loss: 0.6431 - val_acc: 0.6400\n",
            "Epoch 1620/4500\n",
            "100/100 [==============================] - 0s 516us/step - loss: 0.6048 - acc: 0.6900 - val_loss: 0.6427 - val_acc: 0.6400\n",
            "Epoch 1621/4500\n",
            "100/100 [==============================] - 0s 528us/step - loss: 0.6050 - acc: 0.6900 - val_loss: 0.6432 - val_acc: 0.6400\n",
            "Epoch 1622/4500\n",
            "100/100 [==============================] - 0s 503us/step - loss: 0.6047 - acc: 0.6900 - val_loss: 0.6432 - val_acc: 0.6400\n",
            "Epoch 1623/4500\n",
            "100/100 [==============================] - 0s 552us/step - loss: 0.6046 - acc: 0.6900 - val_loss: 0.6426 - val_acc: 0.6400\n",
            "Epoch 1624/4500\n",
            "100/100 [==============================] - 0s 556us/step - loss: 0.6044 - acc: 0.6900 - val_loss: 0.6426 - val_acc: 0.6400\n",
            "Epoch 1625/4500\n",
            "100/100 [==============================] - 0s 611us/step - loss: 0.6044 - acc: 0.6900 - val_loss: 0.6424 - val_acc: 0.6400\n",
            "Epoch 1626/4500\n",
            "100/100 [==============================] - 0s 517us/step - loss: 0.6044 - acc: 0.6900 - val_loss: 0.6425 - val_acc: 0.6400\n",
            "Epoch 1627/4500\n",
            "100/100 [==============================] - 0s 533us/step - loss: 0.6042 - acc: 0.6900 - val_loss: 0.6420 - val_acc: 0.6400\n",
            "Epoch 1628/4500\n",
            "100/100 [==============================] - 0s 535us/step - loss: 0.6041 - acc: 0.6900 - val_loss: 0.6420 - val_acc: 0.6400\n",
            "Epoch 1629/4500\n",
            "100/100 [==============================] - 0s 508us/step - loss: 0.6041 - acc: 0.6900 - val_loss: 0.6421 - val_acc: 0.6400\n",
            "Epoch 1630/4500\n",
            "100/100 [==============================] - 0s 571us/step - loss: 0.6040 - acc: 0.6900 - val_loss: 0.6416 - val_acc: 0.6400\n",
            "Epoch 1631/4500\n",
            "100/100 [==============================] - 0s 528us/step - loss: 0.6039 - acc: 0.6900 - val_loss: 0.6416 - val_acc: 0.6400\n",
            "Epoch 1632/4500\n",
            "100/100 [==============================] - 0s 488us/step - loss: 0.6037 - acc: 0.6900 - val_loss: 0.6415 - val_acc: 0.6400\n",
            "Epoch 1633/4500\n",
            "100/100 [==============================] - 0s 495us/step - loss: 0.6036 - acc: 0.6900 - val_loss: 0.6417 - val_acc: 0.6400\n",
            "Epoch 1634/4500\n",
            "100/100 [==============================] - 0s 534us/step - loss: 0.6037 - acc: 0.6900 - val_loss: 0.6419 - val_acc: 0.6400\n",
            "Epoch 1635/4500\n",
            "100/100 [==============================] - 0s 487us/step - loss: 0.6035 - acc: 0.6900 - val_loss: 0.6414 - val_acc: 0.6400\n",
            "Epoch 1636/4500\n",
            "100/100 [==============================] - 0s 521us/step - loss: 0.6035 - acc: 0.6900 - val_loss: 0.6411 - val_acc: 0.6400\n",
            "Epoch 1637/4500\n",
            "100/100 [==============================] - 0s 528us/step - loss: 0.6032 - acc: 0.6900 - val_loss: 0.6413 - val_acc: 0.6400\n",
            "Epoch 1638/4500\n",
            "100/100 [==============================] - 0s 527us/step - loss: 0.6032 - acc: 0.6900 - val_loss: 0.6413 - val_acc: 0.6400\n",
            "Epoch 1639/4500\n",
            "100/100 [==============================] - 0s 552us/step - loss: 0.6031 - acc: 0.6900 - val_loss: 0.6412 - val_acc: 0.6400\n",
            "Epoch 1640/4500\n",
            "100/100 [==============================] - 0s 531us/step - loss: 0.6030 - acc: 0.6900 - val_loss: 0.6411 - val_acc: 0.6400\n",
            "Epoch 1641/4500\n",
            "100/100 [==============================] - 0s 517us/step - loss: 0.6030 - acc: 0.6900 - val_loss: 0.6410 - val_acc: 0.6400\n",
            "Epoch 1642/4500\n",
            "100/100 [==============================] - 0s 517us/step - loss: 0.6028 - acc: 0.6900 - val_loss: 0.6409 - val_acc: 0.6400\n",
            "Epoch 1643/4500\n",
            "100/100 [==============================] - 0s 563us/step - loss: 0.6029 - acc: 0.6900 - val_loss: 0.6404 - val_acc: 0.6400\n",
            "Epoch 1644/4500\n",
            "100/100 [==============================] - 0s 609us/step - loss: 0.6027 - acc: 0.6900 - val_loss: 0.6401 - val_acc: 0.6400\n",
            "Epoch 1645/4500\n",
            "100/100 [==============================] - 0s 529us/step - loss: 0.6026 - acc: 0.6900 - val_loss: 0.6400 - val_acc: 0.6400\n",
            "Epoch 1646/4500\n",
            "100/100 [==============================] - 0s 505us/step - loss: 0.6025 - acc: 0.6900 - val_loss: 0.6404 - val_acc: 0.6400\n",
            "Epoch 1647/4500\n",
            "100/100 [==============================] - 0s 528us/step - loss: 0.6027 - acc: 0.6900 - val_loss: 0.6407 - val_acc: 0.6400\n",
            "Epoch 1648/4500\n",
            "100/100 [==============================] - 0s 534us/step - loss: 0.6022 - acc: 0.6900 - val_loss: 0.6404 - val_acc: 0.6400\n",
            "Epoch 1649/4500\n",
            "100/100 [==============================] - 0s 506us/step - loss: 0.6022 - acc: 0.6900 - val_loss: 0.6403 - val_acc: 0.6400\n",
            "Epoch 1650/4500\n",
            "100/100 [==============================] - 0s 636us/step - loss: 0.6022 - acc: 0.6900 - val_loss: 0.6398 - val_acc: 0.6400\n",
            "Epoch 1651/4500\n",
            "100/100 [==============================] - 0s 552us/step - loss: 0.6019 - acc: 0.6900 - val_loss: 0.6397 - val_acc: 0.6400\n",
            "Epoch 1652/4500\n",
            "100/100 [==============================] - 0s 515us/step - loss: 0.6024 - acc: 0.6900 - val_loss: 0.6399 - val_acc: 0.6400\n",
            "Epoch 1653/4500\n",
            "100/100 [==============================] - 0s 532us/step - loss: 0.6018 - acc: 0.6900 - val_loss: 0.6393 - val_acc: 0.6400\n",
            "Epoch 1654/4500\n",
            "100/100 [==============================] - 0s 628us/step - loss: 0.6017 - acc: 0.6900 - val_loss: 0.6395 - val_acc: 0.6400\n",
            "Epoch 1655/4500\n",
            "100/100 [==============================] - 0s 522us/step - loss: 0.6017 - acc: 0.6900 - val_loss: 0.6396 - val_acc: 0.6400\n",
            "Epoch 1656/4500\n",
            "100/100 [==============================] - 0s 488us/step - loss: 0.6017 - acc: 0.6900 - val_loss: 0.6392 - val_acc: 0.6400\n",
            "Epoch 1657/4500\n",
            "100/100 [==============================] - 0s 509us/step - loss: 0.6014 - acc: 0.6900 - val_loss: 0.6393 - val_acc: 0.6400\n",
            "Epoch 1658/4500\n",
            "100/100 [==============================] - 0s 488us/step - loss: 0.6015 - acc: 0.6900 - val_loss: 0.6393 - val_acc: 0.6400\n",
            "Epoch 1659/4500\n",
            "100/100 [==============================] - 0s 528us/step - loss: 0.6018 - acc: 0.6900 - val_loss: 0.6383 - val_acc: 0.6400\n",
            "Epoch 1660/4500\n",
            "100/100 [==============================] - 0s 478us/step - loss: 0.6012 - acc: 0.6900 - val_loss: 0.6387 - val_acc: 0.6400\n",
            "Epoch 1661/4500\n",
            "100/100 [==============================] - 0s 547us/step - loss: 0.6013 - acc: 0.6900 - val_loss: 0.6381 - val_acc: 0.6400\n",
            "Epoch 1662/4500\n",
            "100/100 [==============================] - 0s 619us/step - loss: 0.6010 - acc: 0.6900 - val_loss: 0.6382 - val_acc: 0.6400\n",
            "Epoch 1663/4500\n",
            "100/100 [==============================] - 0s 536us/step - loss: 0.6010 - acc: 0.6900 - val_loss: 0.6387 - val_acc: 0.6400\n",
            "Epoch 1664/4500\n",
            "100/100 [==============================] - 0s 500us/step - loss: 0.6007 - acc: 0.6900 - val_loss: 0.6381 - val_acc: 0.6400\n",
            "Epoch 1665/4500\n",
            "100/100 [==============================] - 0s 493us/step - loss: 0.6006 - acc: 0.6900 - val_loss: 0.6377 - val_acc: 0.6400\n",
            "Epoch 1666/4500\n",
            "100/100 [==============================] - 0s 540us/step - loss: 0.6003 - acc: 0.6900 - val_loss: 0.6378 - val_acc: 0.6400\n",
            "Epoch 1667/4500\n",
            "100/100 [==============================] - 0s 517us/step - loss: 0.6003 - acc: 0.6900 - val_loss: 0.6376 - val_acc: 0.6400\n",
            "Epoch 1668/4500\n",
            "100/100 [==============================] - 0s 511us/step - loss: 0.6002 - acc: 0.6900 - val_loss: 0.6375 - val_acc: 0.6400\n",
            "Epoch 1669/4500\n",
            "100/100 [==============================] - 0s 527us/step - loss: 0.6001 - acc: 0.6900 - val_loss: 0.6379 - val_acc: 0.6400\n",
            "Epoch 1670/4500\n",
            "100/100 [==============================] - 0s 500us/step - loss: 0.6000 - acc: 0.6900 - val_loss: 0.6377 - val_acc: 0.6400\n",
            "Epoch 1671/4500\n",
            "100/100 [==============================] - 0s 527us/step - loss: 0.5998 - acc: 0.6900 - val_loss: 0.6374 - val_acc: 0.6400\n",
            "Epoch 1672/4500\n",
            "100/100 [==============================] - 0s 511us/step - loss: 0.5998 - acc: 0.6900 - val_loss: 0.6370 - val_acc: 0.6400\n",
            "Epoch 1673/4500\n",
            "100/100 [==============================] - 0s 591us/step - loss: 0.5995 - acc: 0.6900 - val_loss: 0.6370 - val_acc: 0.6400\n",
            "Epoch 1674/4500\n",
            "100/100 [==============================] - 0s 488us/step - loss: 0.5996 - acc: 0.6900 - val_loss: 0.6368 - val_acc: 0.6400\n",
            "Epoch 1675/4500\n",
            "100/100 [==============================] - 0s 504us/step - loss: 0.5996 - acc: 0.6900 - val_loss: 0.6372 - val_acc: 0.6400\n",
            "Epoch 1676/4500\n",
            "100/100 [==============================] - 0s 534us/step - loss: 0.5992 - acc: 0.6900 - val_loss: 0.6371 - val_acc: 0.6400\n",
            "Epoch 1677/4500\n",
            "100/100 [==============================] - 0s 493us/step - loss: 0.5993 - acc: 0.6900 - val_loss: 0.6372 - val_acc: 0.6400\n",
            "Epoch 1678/4500\n",
            "100/100 [==============================] - 0s 485us/step - loss: 0.5989 - acc: 0.6900 - val_loss: 0.6363 - val_acc: 0.6400\n",
            "Epoch 1679/4500\n",
            "100/100 [==============================] - 0s 489us/step - loss: 0.5990 - acc: 0.6900 - val_loss: 0.6358 - val_acc: 0.6400\n",
            "Epoch 1680/4500\n",
            "100/100 [==============================] - 0s 499us/step - loss: 0.5988 - acc: 0.6900 - val_loss: 0.6354 - val_acc: 0.6400\n",
            "Epoch 1681/4500\n",
            "100/100 [==============================] - 0s 521us/step - loss: 0.5983 - acc: 0.6900 - val_loss: 0.6355 - val_acc: 0.6400\n",
            "Epoch 1682/4500\n",
            "100/100 [==============================] - 0s 618us/step - loss: 0.5988 - acc: 0.6900 - val_loss: 0.6352 - val_acc: 0.6400\n",
            "Epoch 1683/4500\n",
            "100/100 [==============================] - 0s 517us/step - loss: 0.5981 - acc: 0.6900 - val_loss: 0.6355 - val_acc: 0.6400\n",
            "Epoch 1684/4500\n",
            "100/100 [==============================] - 0s 508us/step - loss: 0.5981 - acc: 0.6900 - val_loss: 0.6354 - val_acc: 0.6400\n",
            "Epoch 1685/4500\n",
            "100/100 [==============================] - 0s 626us/step - loss: 0.5984 - acc: 0.6900 - val_loss: 0.6358 - val_acc: 0.6400\n",
            "Epoch 1686/4500\n",
            "100/100 [==============================] - 0s 569us/step - loss: 0.5979 - acc: 0.6900 - val_loss: 0.6355 - val_acc: 0.6400\n",
            "Epoch 1687/4500\n",
            "100/100 [==============================] - 0s 511us/step - loss: 0.5979 - acc: 0.6900 - val_loss: 0.6355 - val_acc: 0.6400\n",
            "Epoch 1688/4500\n",
            "100/100 [==============================] - 0s 543us/step - loss: 0.5974 - acc: 0.6900 - val_loss: 0.6349 - val_acc: 0.6400\n",
            "Epoch 1689/4500\n",
            "100/100 [==============================] - 0s 502us/step - loss: 0.5972 - acc: 0.6900 - val_loss: 0.6346 - val_acc: 0.6400\n",
            "Epoch 1690/4500\n",
            "100/100 [==============================] - 0s 502us/step - loss: 0.5972 - acc: 0.6900 - val_loss: 0.6345 - val_acc: 0.6400\n",
            "Epoch 1691/4500\n",
            "100/100 [==============================] - 0s 511us/step - loss: 0.5972 - acc: 0.6900 - val_loss: 0.6344 - val_acc: 0.6400\n",
            "Epoch 1692/4500\n",
            "100/100 [==============================] - 0s 494us/step - loss: 0.5970 - acc: 0.6900 - val_loss: 0.6344 - val_acc: 0.6400\n",
            "Epoch 1693/4500\n",
            "100/100 [==============================] - 0s 634us/step - loss: 0.5967 - acc: 0.6900 - val_loss: 0.6337 - val_acc: 0.6400\n",
            "Epoch 1694/4500\n",
            "100/100 [==============================] - 0s 509us/step - loss: 0.5967 - acc: 0.6900 - val_loss: 0.6340 - val_acc: 0.6400\n",
            "Epoch 1695/4500\n",
            "100/100 [==============================] - 0s 507us/step - loss: 0.5965 - acc: 0.6900 - val_loss: 0.6333 - val_acc: 0.6400\n",
            "Epoch 1696/4500\n",
            "100/100 [==============================] - 0s 491us/step - loss: 0.5962 - acc: 0.6900 - val_loss: 0.6330 - val_acc: 0.6400\n",
            "Epoch 1697/4500\n",
            "100/100 [==============================] - 0s 486us/step - loss: 0.5965 - acc: 0.6900 - val_loss: 0.6331 - val_acc: 0.6400\n",
            "Epoch 1698/4500\n",
            "100/100 [==============================] - 0s 492us/step - loss: 0.5959 - acc: 0.6900 - val_loss: 0.6327 - val_acc: 0.6400\n",
            "Epoch 1699/4500\n",
            "100/100 [==============================] - 0s 521us/step - loss: 0.5958 - acc: 0.6900 - val_loss: 0.6326 - val_acc: 0.6400\n",
            "Epoch 1700/4500\n",
            "100/100 [==============================] - 0s 488us/step - loss: 0.5958 - acc: 0.6900 - val_loss: 0.6330 - val_acc: 0.6400\n",
            "Epoch 1701/4500\n",
            "100/100 [==============================] - 0s 613us/step - loss: 0.5955 - acc: 0.6900 - val_loss: 0.6326 - val_acc: 0.6400\n",
            "Epoch 1702/4500\n",
            "100/100 [==============================] - 0s 606us/step - loss: 0.5954 - acc: 0.6900 - val_loss: 0.6321 - val_acc: 0.6400\n",
            "Epoch 1703/4500\n",
            "100/100 [==============================] - 0s 582us/step - loss: 0.5952 - acc: 0.6900 - val_loss: 0.6319 - val_acc: 0.6400\n",
            "Epoch 1704/4500\n",
            "100/100 [==============================] - 0s 511us/step - loss: 0.5951 - acc: 0.6900 - val_loss: 0.6323 - val_acc: 0.6400\n",
            "Epoch 1705/4500\n",
            "100/100 [==============================] - 0s 512us/step - loss: 0.5950 - acc: 0.6900 - val_loss: 0.6318 - val_acc: 0.6400\n",
            "Epoch 1706/4500\n",
            "100/100 [==============================] - 0s 513us/step - loss: 0.5948 - acc: 0.6900 - val_loss: 0.6314 - val_acc: 0.6400\n",
            "Epoch 1707/4500\n",
            "100/100 [==============================] - 0s 490us/step - loss: 0.5949 - acc: 0.6900 - val_loss: 0.6317 - val_acc: 0.6400\n",
            "Epoch 1708/4500\n",
            "100/100 [==============================] - 0s 492us/step - loss: 0.5943 - acc: 0.6900 - val_loss: 0.6313 - val_acc: 0.6400\n",
            "Epoch 1709/4500\n",
            "100/100 [==============================] - 0s 508us/step - loss: 0.5946 - acc: 0.6900 - val_loss: 0.6309 - val_acc: 0.6400\n",
            "Epoch 1710/4500\n",
            "100/100 [==============================] - 0s 525us/step - loss: 0.5940 - acc: 0.6900 - val_loss: 0.6310 - val_acc: 0.6400\n",
            "Epoch 1711/4500\n",
            "100/100 [==============================] - 0s 485us/step - loss: 0.5945 - acc: 0.6900 - val_loss: 0.6302 - val_acc: 0.6400\n",
            "Epoch 1712/4500\n",
            "100/100 [==============================] - 0s 495us/step - loss: 0.5939 - acc: 0.6900 - val_loss: 0.6309 - val_acc: 0.6400\n",
            "Epoch 1713/4500\n",
            "100/100 [==============================] - 0s 549us/step - loss: 0.5935 - acc: 0.6900 - val_loss: 0.6307 - val_acc: 0.6400\n",
            "Epoch 1714/4500\n",
            "100/100 [==============================] - 0s 485us/step - loss: 0.5934 - acc: 0.6900 - val_loss: 0.6300 - val_acc: 0.6400\n",
            "Epoch 1715/4500\n",
            "100/100 [==============================] - 0s 499us/step - loss: 0.5933 - acc: 0.6900 - val_loss: 0.6299 - val_acc: 0.6400\n",
            "Epoch 1716/4500\n",
            "100/100 [==============================] - 0s 529us/step - loss: 0.5931 - acc: 0.6900 - val_loss: 0.6301 - val_acc: 0.6400\n",
            "Epoch 1717/4500\n",
            "100/100 [==============================] - 0s 533us/step - loss: 0.5929 - acc: 0.6900 - val_loss: 0.6296 - val_acc: 0.6400\n",
            "Epoch 1718/4500\n",
            "100/100 [==============================] - 0s 510us/step - loss: 0.5927 - acc: 0.6900 - val_loss: 0.6294 - val_acc: 0.6400\n",
            "Epoch 1719/4500\n",
            "100/100 [==============================] - 0s 533us/step - loss: 0.5927 - acc: 0.6900 - val_loss: 0.6287 - val_acc: 0.6400\n",
            "Epoch 1720/4500\n",
            "100/100 [==============================] - 0s 595us/step - loss: 0.5929 - acc: 0.6900 - val_loss: 0.6285 - val_acc: 0.6400\n",
            "Epoch 1721/4500\n",
            "100/100 [==============================] - 0s 518us/step - loss: 0.5920 - acc: 0.6900 - val_loss: 0.6287 - val_acc: 0.6400\n",
            "Epoch 1722/4500\n",
            "100/100 [==============================] - 0s 534us/step - loss: 0.5919 - acc: 0.6900 - val_loss: 0.6287 - val_acc: 0.6400\n",
            "Epoch 1723/4500\n",
            "100/100 [==============================] - 0s 510us/step - loss: 0.5918 - acc: 0.6900 - val_loss: 0.6288 - val_acc: 0.6400\n",
            "Epoch 1724/4500\n",
            "100/100 [==============================] - 0s 523us/step - loss: 0.5917 - acc: 0.6900 - val_loss: 0.6284 - val_acc: 0.6400\n",
            "Epoch 1725/4500\n",
            "100/100 [==============================] - 0s 536us/step - loss: 0.5913 - acc: 0.6900 - val_loss: 0.6283 - val_acc: 0.6400\n",
            "Epoch 1726/4500\n",
            "100/100 [==============================] - 0s 533us/step - loss: 0.5911 - acc: 0.6900 - val_loss: 0.6277 - val_acc: 0.6400\n",
            "Epoch 1727/4500\n",
            "100/100 [==============================] - 0s 535us/step - loss: 0.5908 - acc: 0.6900 - val_loss: 0.6276 - val_acc: 0.6400\n",
            "Epoch 1728/4500\n",
            "100/100 [==============================] - 0s 531us/step - loss: 0.5907 - acc: 0.6900 - val_loss: 0.6274 - val_acc: 0.6400\n",
            "Epoch 1729/4500\n",
            "100/100 [==============================] - 0s 518us/step - loss: 0.5904 - acc: 0.6900 - val_loss: 0.6271 - val_acc: 0.6400\n",
            "Epoch 1730/4500\n",
            "100/100 [==============================] - 0s 506us/step - loss: 0.5903 - acc: 0.6900 - val_loss: 0.6267 - val_acc: 0.6400\n",
            "Epoch 1731/4500\n",
            "100/100 [==============================] - 0s 507us/step - loss: 0.5901 - acc: 0.6900 - val_loss: 0.6264 - val_acc: 0.6400\n",
            "Epoch 1732/4500\n",
            "100/100 [==============================] - 0s 507us/step - loss: 0.5904 - acc: 0.6900 - val_loss: 0.6268 - val_acc: 0.6400\n",
            "Epoch 1733/4500\n",
            "100/100 [==============================] - 0s 621us/step - loss: 0.5904 - acc: 0.6900 - val_loss: 0.6255 - val_acc: 0.6400\n",
            "Epoch 1734/4500\n",
            "100/100 [==============================] - 0s 536us/step - loss: 0.5899 - acc: 0.6900 - val_loss: 0.6258 - val_acc: 0.6400\n",
            "Epoch 1735/4500\n",
            "100/100 [==============================] - 0s 481us/step - loss: 0.5894 - acc: 0.6900 - val_loss: 0.6255 - val_acc: 0.6400\n",
            "Epoch 1736/4500\n",
            "100/100 [==============================] - 0s 493us/step - loss: 0.5903 - acc: 0.6900 - val_loss: 0.6263 - val_acc: 0.6400\n",
            "Epoch 1737/4500\n",
            "100/100 [==============================] - 0s 489us/step - loss: 0.5891 - acc: 0.6900 - val_loss: 0.6251 - val_acc: 0.6400\n",
            "Epoch 1738/4500\n",
            "100/100 [==============================] - 0s 507us/step - loss: 0.5889 - acc: 0.6900 - val_loss: 0.6243 - val_acc: 0.6400\n",
            "Epoch 1739/4500\n",
            "100/100 [==============================] - 0s 660us/step - loss: 0.5884 - acc: 0.6900 - val_loss: 0.6245 - val_acc: 0.6400\n",
            "Epoch 1740/4500\n",
            "100/100 [==============================] - 0s 556us/step - loss: 0.5887 - acc: 0.6900 - val_loss: 0.6249 - val_acc: 0.6400\n",
            "Epoch 1741/4500\n",
            "100/100 [==============================] - 0s 584us/step - loss: 0.5881 - acc: 0.6900 - val_loss: 0.6243 - val_acc: 0.6400\n",
            "Epoch 1742/4500\n",
            "100/100 [==============================] - 0s 606us/step - loss: 0.5879 - acc: 0.6900 - val_loss: 0.6239 - val_acc: 0.6400\n",
            "Epoch 1743/4500\n",
            "100/100 [==============================] - 0s 511us/step - loss: 0.5877 - acc: 0.6900 - val_loss: 0.6236 - val_acc: 0.6400\n",
            "Epoch 1744/4500\n",
            "100/100 [==============================] - 0s 521us/step - loss: 0.5875 - acc: 0.6900 - val_loss: 0.6230 - val_acc: 0.6400\n",
            "Epoch 1745/4500\n",
            "100/100 [==============================] - 0s 555us/step - loss: 0.5871 - acc: 0.6900 - val_loss: 0.6231 - val_acc: 0.6400\n",
            "Epoch 1746/4500\n",
            "100/100 [==============================] - 0s 548us/step - loss: 0.5871 - acc: 0.6900 - val_loss: 0.6233 - val_acc: 0.6400\n",
            "Epoch 1747/4500\n",
            "100/100 [==============================] - 0s 496us/step - loss: 0.5867 - acc: 0.6900 - val_loss: 0.6227 - val_acc: 0.6400\n",
            "Epoch 1748/4500\n",
            "100/100 [==============================] - 0s 494us/step - loss: 0.5865 - acc: 0.6900 - val_loss: 0.6223 - val_acc: 0.6400\n",
            "Epoch 1749/4500\n",
            "100/100 [==============================] - 0s 513us/step - loss: 0.5865 - acc: 0.6900 - val_loss: 0.6214 - val_acc: 0.6400\n",
            "Epoch 1750/4500\n",
            "100/100 [==============================] - 0s 494us/step - loss: 0.5859 - acc: 0.6900 - val_loss: 0.6215 - val_acc: 0.6400\n",
            "Epoch 1751/4500\n",
            "100/100 [==============================] - 0s 529us/step - loss: 0.5856 - acc: 0.6900 - val_loss: 0.6215 - val_acc: 0.6400\n",
            "Epoch 1752/4500\n",
            "100/100 [==============================] - 0s 507us/step - loss: 0.5852 - acc: 0.6900 - val_loss: 0.6211 - val_acc: 0.6400\n",
            "Epoch 1753/4500\n",
            "100/100 [==============================] - 0s 494us/step - loss: 0.5853 - acc: 0.6900 - val_loss: 0.6210 - val_acc: 0.6400\n",
            "Epoch 1754/4500\n",
            "100/100 [==============================] - 0s 497us/step - loss: 0.5852 - acc: 0.6900 - val_loss: 0.6209 - val_acc: 0.6400\n",
            "Epoch 1755/4500\n",
            "100/100 [==============================] - 0s 625us/step - loss: 0.5848 - acc: 0.6900 - val_loss: 0.6204 - val_acc: 0.6400\n",
            "Epoch 1756/4500\n",
            "100/100 [==============================] - 0s 540us/step - loss: 0.5844 - acc: 0.6900 - val_loss: 0.6205 - val_acc: 0.6400\n",
            "Epoch 1757/4500\n",
            "100/100 [==============================] - 0s 520us/step - loss: 0.5842 - acc: 0.6900 - val_loss: 0.6203 - val_acc: 0.6400\n",
            "Epoch 1758/4500\n",
            "100/100 [==============================] - 0s 610us/step - loss: 0.5837 - acc: 0.6900 - val_loss: 0.6197 - val_acc: 0.6400\n",
            "Epoch 1759/4500\n",
            "100/100 [==============================] - 0s 538us/step - loss: 0.5837 - acc: 0.6900 - val_loss: 0.6190 - val_acc: 0.6400\n",
            "Epoch 1760/4500\n",
            "100/100 [==============================] - 0s 500us/step - loss: 0.5832 - acc: 0.6900 - val_loss: 0.6187 - val_acc: 0.6400\n",
            "Epoch 1761/4500\n",
            "100/100 [==============================] - 0s 522us/step - loss: 0.5833 - acc: 0.6900 - val_loss: 0.6190 - val_acc: 0.6400\n",
            "Epoch 1762/4500\n",
            "100/100 [==============================] - 0s 540us/step - loss: 0.5829 - acc: 0.6900 - val_loss: 0.6183 - val_acc: 0.6400\n",
            "Epoch 1763/4500\n",
            "100/100 [==============================] - 0s 507us/step - loss: 0.5833 - acc: 0.6900 - val_loss: 0.6175 - val_acc: 0.6400\n",
            "Epoch 1764/4500\n",
            "100/100 [==============================] - 0s 507us/step - loss: 0.5822 - acc: 0.6900 - val_loss: 0.6175 - val_acc: 0.6400\n",
            "Epoch 1765/4500\n",
            "100/100 [==============================] - 0s 531us/step - loss: 0.5818 - acc: 0.6900 - val_loss: 0.6173 - val_acc: 0.6400\n",
            "Epoch 1766/4500\n",
            "100/100 [==============================] - 0s 530us/step - loss: 0.5818 - acc: 0.6900 - val_loss: 0.6173 - val_acc: 0.6400\n",
            "Epoch 1767/4500\n",
            "100/100 [==============================] - 0s 507us/step - loss: 0.5815 - acc: 0.6900 - val_loss: 0.6166 - val_acc: 0.6400\n",
            "Epoch 1768/4500\n",
            "100/100 [==============================] - 0s 527us/step - loss: 0.5811 - acc: 0.6900 - val_loss: 0.6162 - val_acc: 0.6400\n",
            "Epoch 1769/4500\n",
            "100/100 [==============================] - 0s 523us/step - loss: 0.5807 - acc: 0.6900 - val_loss: 0.6158 - val_acc: 0.6400\n",
            "Epoch 1770/4500\n",
            "100/100 [==============================] - 0s 553us/step - loss: 0.5804 - acc: 0.6900 - val_loss: 0.6156 - val_acc: 0.6400\n",
            "Epoch 1771/4500\n",
            "100/100 [==============================] - 0s 547us/step - loss: 0.5801 - acc: 0.6900 - val_loss: 0.6153 - val_acc: 0.6400\n",
            "Epoch 1772/4500\n",
            "100/100 [==============================] - 0s 531us/step - loss: 0.5798 - acc: 0.6900 - val_loss: 0.6149 - val_acc: 0.6400\n",
            "Epoch 1773/4500\n",
            "100/100 [==============================] - 0s 536us/step - loss: 0.5795 - acc: 0.6900 - val_loss: 0.6150 - val_acc: 0.6400\n",
            "Epoch 1774/4500\n",
            "100/100 [==============================] - 0s 504us/step - loss: 0.5795 - acc: 0.6900 - val_loss: 0.6144 - val_acc: 0.6400\n",
            "Epoch 1775/4500\n",
            "100/100 [==============================] - 0s 491us/step - loss: 0.5792 - acc: 0.6900 - val_loss: 0.6139 - val_acc: 0.6400\n",
            "Epoch 1776/4500\n",
            "100/100 [==============================] - 0s 518us/step - loss: 0.5787 - acc: 0.6900 - val_loss: 0.6139 - val_acc: 0.6400\n",
            "Epoch 1777/4500\n",
            "100/100 [==============================] - 0s 592us/step - loss: 0.5786 - acc: 0.6900 - val_loss: 0.6133 - val_acc: 0.6400\n",
            "Epoch 1778/4500\n",
            "100/100 [==============================] - 0s 529us/step - loss: 0.5785 - acc: 0.6900 - val_loss: 0.6127 - val_acc: 0.6400\n",
            "Epoch 1779/4500\n",
            "100/100 [==============================] - 0s 502us/step - loss: 0.5777 - acc: 0.6900 - val_loss: 0.6124 - val_acc: 0.6400\n",
            "Epoch 1780/4500\n",
            "100/100 [==============================] - 0s 495us/step - loss: 0.5773 - acc: 0.6900 - val_loss: 0.6127 - val_acc: 0.6400\n",
            "Epoch 1781/4500\n",
            "100/100 [==============================] - 0s 623us/step - loss: 0.5770 - acc: 0.6900 - val_loss: 0.6122 - val_acc: 0.6400\n",
            "Epoch 1782/4500\n",
            "100/100 [==============================] - 0s 540us/step - loss: 0.5766 - acc: 0.6900 - val_loss: 0.6118 - val_acc: 0.6400\n",
            "Epoch 1783/4500\n",
            "100/100 [==============================] - 0s 502us/step - loss: 0.5768 - acc: 0.6900 - val_loss: 0.6117 - val_acc: 0.6400\n",
            "Epoch 1784/4500\n",
            "100/100 [==============================] - 0s 497us/step - loss: 0.5760 - acc: 0.6900 - val_loss: 0.6112 - val_acc: 0.6400\n",
            "Epoch 1785/4500\n",
            "100/100 [==============================] - 0s 501us/step - loss: 0.5757 - acc: 0.6900 - val_loss: 0.6109 - val_acc: 0.6400\n",
            "Epoch 1786/4500\n",
            "100/100 [==============================] - 0s 502us/step - loss: 0.5758 - acc: 0.6900 - val_loss: 0.6099 - val_acc: 0.6400\n",
            "Epoch 1787/4500\n",
            "100/100 [==============================] - 0s 569us/step - loss: 0.5752 - acc: 0.6900 - val_loss: 0.6094 - val_acc: 0.6400\n",
            "Epoch 1788/4500\n",
            "100/100 [==============================] - 0s 530us/step - loss: 0.5747 - acc: 0.6900 - val_loss: 0.6097 - val_acc: 0.6400\n",
            "Epoch 1789/4500\n",
            "100/100 [==============================] - 0s 500us/step - loss: 0.5744 - acc: 0.6900 - val_loss: 0.6094 - val_acc: 0.6400\n",
            "Epoch 1790/4500\n",
            "100/100 [==============================] - 0s 539us/step - loss: 0.5743 - acc: 0.6900 - val_loss: 0.6094 - val_acc: 0.6400\n",
            "Epoch 1791/4500\n",
            "100/100 [==============================] - 0s 540us/step - loss: 0.5736 - acc: 0.6900 - val_loss: 0.6085 - val_acc: 0.6400\n",
            "Epoch 1792/4500\n",
            "100/100 [==============================] - 0s 513us/step - loss: 0.5734 - acc: 0.6900 - val_loss: 0.6082 - val_acc: 0.6400\n",
            "Epoch 1793/4500\n",
            "100/100 [==============================] - 0s 527us/step - loss: 0.5733 - acc: 0.6900 - val_loss: 0.6079 - val_acc: 0.6400\n",
            "Epoch 1794/4500\n",
            "100/100 [==============================] - 0s 506us/step - loss: 0.5729 - acc: 0.6900 - val_loss: 0.6077 - val_acc: 0.6400\n",
            "Epoch 1795/4500\n",
            "100/100 [==============================] - 0s 511us/step - loss: 0.5723 - acc: 0.6900 - val_loss: 0.6065 - val_acc: 0.6400\n",
            "Epoch 1796/4500\n",
            "100/100 [==============================] - 0s 614us/step - loss: 0.5718 - acc: 0.6900 - val_loss: 0.6057 - val_acc: 0.6400\n",
            "Epoch 1797/4500\n",
            "100/100 [==============================] - 0s 560us/step - loss: 0.5715 - acc: 0.6900 - val_loss: 0.6055 - val_acc: 0.6400\n",
            "Epoch 1798/4500\n",
            "100/100 [==============================] - 0s 507us/step - loss: 0.5718 - acc: 0.6900 - val_loss: 0.6060 - val_acc: 0.6400\n",
            "Epoch 1799/4500\n",
            "100/100 [==============================] - 0s 499us/step - loss: 0.5712 - acc: 0.6900 - val_loss: 0.6055 - val_acc: 0.6400\n",
            "Epoch 1800/4500\n",
            "100/100 [==============================] - 0s 535us/step - loss: 0.5705 - acc: 0.6900 - val_loss: 0.6042 - val_acc: 0.6400\n",
            "Epoch 1801/4500\n",
            "100/100 [==============================] - 0s 552us/step - loss: 0.5701 - acc: 0.6900 - val_loss: 0.6037 - val_acc: 0.6400\n",
            "Epoch 1802/4500\n",
            "100/100 [==============================] - 0s 517us/step - loss: 0.5699 - acc: 0.6900 - val_loss: 0.6031 - val_acc: 0.6400\n",
            "Epoch 1803/4500\n",
            "100/100 [==============================] - 0s 506us/step - loss: 0.5692 - acc: 0.6900 - val_loss: 0.6030 - val_acc: 0.6400\n",
            "Epoch 1804/4500\n",
            "100/100 [==============================] - 0s 511us/step - loss: 0.5691 - acc: 0.6900 - val_loss: 0.6035 - val_acc: 0.6400\n",
            "Epoch 1805/4500\n",
            "100/100 [==============================] - 0s 517us/step - loss: 0.5686 - acc: 0.6900 - val_loss: 0.6033 - val_acc: 0.6400\n",
            "Epoch 1806/4500\n",
            "100/100 [==============================] - 0s 532us/step - loss: 0.5682 - acc: 0.6900 - val_loss: 0.6024 - val_acc: 0.6400\n",
            "Epoch 1807/4500\n",
            "100/100 [==============================] - 0s 517us/step - loss: 0.5677 - acc: 0.6900 - val_loss: 0.6019 - val_acc: 0.6400\n",
            "Epoch 1808/4500\n",
            "100/100 [==============================] - 0s 613us/step - loss: 0.5671 - acc: 0.6900 - val_loss: 0.6015 - val_acc: 0.6400\n",
            "Epoch 1809/4500\n",
            "100/100 [==============================] - 0s 502us/step - loss: 0.5669 - acc: 0.6900 - val_loss: 0.6011 - val_acc: 0.6400\n",
            "Epoch 1810/4500\n",
            "100/100 [==============================] - 0s 491us/step - loss: 0.5664 - acc: 0.6900 - val_loss: 0.6004 - val_acc: 0.6400\n",
            "Epoch 1811/4500\n",
            "100/100 [==============================] - 0s 526us/step - loss: 0.5659 - acc: 0.6900 - val_loss: 0.5998 - val_acc: 0.6400\n",
            "Epoch 1812/4500\n",
            "100/100 [==============================] - 0s 538us/step - loss: 0.5657 - acc: 0.6900 - val_loss: 0.5996 - val_acc: 0.6400\n",
            "Epoch 1813/4500\n",
            "100/100 [==============================] - 0s 495us/step - loss: 0.5653 - acc: 0.6900 - val_loss: 0.5989 - val_acc: 0.6400\n",
            "Epoch 1814/4500\n",
            "100/100 [==============================] - 0s 488us/step - loss: 0.5649 - acc: 0.6900 - val_loss: 0.5987 - val_acc: 0.6400\n",
            "Epoch 1815/4500\n",
            "100/100 [==============================] - 0s 569us/step - loss: 0.5644 - acc: 0.6900 - val_loss: 0.5983 - val_acc: 0.6400\n",
            "Epoch 1816/4500\n",
            "100/100 [==============================] - 0s 498us/step - loss: 0.5639 - acc: 0.6900 - val_loss: 0.5975 - val_acc: 0.6400\n",
            "Epoch 1817/4500\n",
            "100/100 [==============================] - 0s 482us/step - loss: 0.5639 - acc: 0.6900 - val_loss: 0.5963 - val_acc: 0.6400\n",
            "Epoch 1818/4500\n",
            "100/100 [==============================] - 0s 509us/step - loss: 0.5633 - acc: 0.6900 - val_loss: 0.5958 - val_acc: 0.6400\n",
            "Epoch 1819/4500\n",
            "100/100 [==============================] - 0s 544us/step - loss: 0.5628 - acc: 0.6900 - val_loss: 0.5964 - val_acc: 0.6400\n",
            "Epoch 1820/4500\n",
            "100/100 [==============================] - 0s 585us/step - loss: 0.5624 - acc: 0.6900 - val_loss: 0.5964 - val_acc: 0.6400\n",
            "Epoch 1821/4500\n",
            "100/100 [==============================] - 0s 536us/step - loss: 0.5619 - acc: 0.6900 - val_loss: 0.5955 - val_acc: 0.6400\n",
            "Epoch 1822/4500\n",
            "100/100 [==============================] - 0s 512us/step - loss: 0.5619 - acc: 0.6900 - val_loss: 0.5941 - val_acc: 0.6400\n",
            "Epoch 1823/4500\n",
            "100/100 [==============================] - 0s 507us/step - loss: 0.5610 - acc: 0.6900 - val_loss: 0.5946 - val_acc: 0.6400\n",
            "Epoch 1824/4500\n",
            "100/100 [==============================] - 0s 503us/step - loss: 0.5608 - acc: 0.6900 - val_loss: 0.5937 - val_acc: 0.6400\n",
            "Epoch 1825/4500\n",
            "100/100 [==============================] - 0s 493us/step - loss: 0.5601 - acc: 0.6900 - val_loss: 0.5941 - val_acc: 0.6400\n",
            "Epoch 1826/4500\n",
            "100/100 [==============================] - 0s 497us/step - loss: 0.5596 - acc: 0.6900 - val_loss: 0.5930 - val_acc: 0.6400\n",
            "Epoch 1827/4500\n",
            "100/100 [==============================] - 0s 540us/step - loss: 0.5588 - acc: 0.6900 - val_loss: 0.5927 - val_acc: 0.6400\n",
            "Epoch 1828/4500\n",
            "100/100 [==============================] - 0s 516us/step - loss: 0.5584 - acc: 0.6900 - val_loss: 0.5919 - val_acc: 0.6400\n",
            "Epoch 1829/4500\n",
            "100/100 [==============================] - 0s 506us/step - loss: 0.5581 - acc: 0.6900 - val_loss: 0.5911 - val_acc: 0.6400\n",
            "Epoch 1830/4500\n",
            "100/100 [==============================] - 0s 508us/step - loss: 0.5575 - acc: 0.6900 - val_loss: 0.5904 - val_acc: 0.6400\n",
            "Epoch 1831/4500\n",
            "100/100 [==============================] - 0s 517us/step - loss: 0.5573 - acc: 0.6900 - val_loss: 0.5899 - val_acc: 0.6400\n",
            "Epoch 1832/4500\n",
            "100/100 [==============================] - 0s 507us/step - loss: 0.5565 - acc: 0.6900 - val_loss: 0.5898 - val_acc: 0.6400\n",
            "Epoch 1833/4500\n",
            "100/100 [==============================] - 0s 537us/step - loss: 0.5559 - acc: 0.6900 - val_loss: 0.5897 - val_acc: 0.6400\n",
            "Epoch 1834/4500\n",
            "100/100 [==============================] - 0s 597us/step - loss: 0.5565 - acc: 0.6900 - val_loss: 0.5903 - val_acc: 0.6400\n",
            "Epoch 1835/4500\n",
            "100/100 [==============================] - 0s 517us/step - loss: 0.5567 - acc: 0.6900 - val_loss: 0.5881 - val_acc: 0.6400\n",
            "Epoch 1836/4500\n",
            "100/100 [==============================] - 0s 532us/step - loss: 0.5548 - acc: 0.6900 - val_loss: 0.5884 - val_acc: 0.6400\n",
            "Epoch 1837/4500\n",
            "100/100 [==============================] - 0s 512us/step - loss: 0.5541 - acc: 0.6900 - val_loss: 0.5876 - val_acc: 0.6400\n",
            "Epoch 1838/4500\n",
            "100/100 [==============================] - 0s 518us/step - loss: 0.5539 - acc: 0.6900 - val_loss: 0.5880 - val_acc: 0.6400\n",
            "Epoch 1839/4500\n",
            "100/100 [==============================] - 0s 494us/step - loss: 0.5535 - acc: 0.6900 - val_loss: 0.5870 - val_acc: 0.6400\n",
            "Epoch 1840/4500\n",
            "100/100 [==============================] - 0s 525us/step - loss: 0.5534 - acc: 0.6900 - val_loss: 0.5854 - val_acc: 0.6400\n",
            "Epoch 1841/4500\n",
            "100/100 [==============================] - 0s 512us/step - loss: 0.5529 - acc: 0.6900 - val_loss: 0.5845 - val_acc: 0.6400\n",
            "Epoch 1842/4500\n",
            "100/100 [==============================] - 0s 495us/step - loss: 0.5525 - acc: 0.6900 - val_loss: 0.5857 - val_acc: 0.6400\n",
            "Epoch 1843/4500\n",
            "100/100 [==============================] - 0s 515us/step - loss: 0.5519 - acc: 0.6900 - val_loss: 0.5848 - val_acc: 0.6400\n",
            "Epoch 1844/4500\n",
            "100/100 [==============================] - 0s 529us/step - loss: 0.5511 - acc: 0.6900 - val_loss: 0.5850 - val_acc: 0.6400\n",
            "Epoch 1845/4500\n",
            "100/100 [==============================] - 0s 489us/step - loss: 0.5503 - acc: 0.6900 - val_loss: 0.5841 - val_acc: 0.6400\n",
            "Epoch 1846/4500\n",
            "100/100 [==============================] - 0s 516us/step - loss: 0.5503 - acc: 0.6900 - val_loss: 0.5823 - val_acc: 0.6400\n",
            "Epoch 1847/4500\n",
            "100/100 [==============================] - 0s 515us/step - loss: 0.5492 - acc: 0.6900 - val_loss: 0.5819 - val_acc: 0.6400\n",
            "Epoch 1848/4500\n",
            "100/100 [==============================] - 0s 518us/step - loss: 0.5488 - acc: 0.6900 - val_loss: 0.5817 - val_acc: 0.6400\n",
            "Epoch 1849/4500\n",
            "100/100 [==============================] - 0s 518us/step - loss: 0.5481 - acc: 0.6900 - val_loss: 0.5811 - val_acc: 0.6400\n",
            "Epoch 1850/4500\n",
            "100/100 [==============================] - 0s 542us/step - loss: 0.5479 - acc: 0.6900 - val_loss: 0.5804 - val_acc: 0.6400\n",
            "Epoch 1851/4500\n",
            "100/100 [==============================] - 0s 576us/step - loss: 0.5472 - acc: 0.6900 - val_loss: 0.5805 - val_acc: 0.6400\n",
            "Epoch 1852/4500\n",
            "100/100 [==============================] - 0s 521us/step - loss: 0.5469 - acc: 0.6900 - val_loss: 0.5803 - val_acc: 0.6400\n",
            "Epoch 1853/4500\n",
            "100/100 [==============================] - 0s 650us/step - loss: 0.5467 - acc: 0.6900 - val_loss: 0.5798 - val_acc: 0.6400\n",
            "Epoch 1854/4500\n",
            "100/100 [==============================] - 0s 484us/step - loss: 0.5457 - acc: 0.6900 - val_loss: 0.5786 - val_acc: 0.6400\n",
            "Epoch 1855/4500\n",
            "100/100 [==============================] - 0s 510us/step - loss: 0.5451 - acc: 0.6900 - val_loss: 0.5774 - val_acc: 0.6500\n",
            "Epoch 1856/4500\n",
            "100/100 [==============================] - 0s 498us/step - loss: 0.5446 - acc: 0.6900 - val_loss: 0.5770 - val_acc: 0.6500\n",
            "Epoch 1857/4500\n",
            "100/100 [==============================] - 0s 523us/step - loss: 0.5455 - acc: 0.6900 - val_loss: 0.5777 - val_acc: 0.6500\n",
            "Epoch 1858/4500\n",
            "100/100 [==============================] - 0s 501us/step - loss: 0.5436 - acc: 0.6900 - val_loss: 0.5761 - val_acc: 0.6500\n",
            "Epoch 1859/4500\n",
            "100/100 [==============================] - 0s 514us/step - loss: 0.5434 - acc: 0.6900 - val_loss: 0.5753 - val_acc: 0.6500\n",
            "Epoch 1860/4500\n",
            "100/100 [==============================] - 0s 588us/step - loss: 0.5430 - acc: 0.7200 - val_loss: 0.5737 - val_acc: 0.6500\n",
            "Epoch 1861/4500\n",
            "100/100 [==============================] - 0s 527us/step - loss: 0.5429 - acc: 0.7000 - val_loss: 0.5752 - val_acc: 0.6500\n",
            "Epoch 1862/4500\n",
            "100/100 [==============================] - 0s 528us/step - loss: 0.5414 - acc: 0.7100 - val_loss: 0.5734 - val_acc: 0.6500\n",
            "Epoch 1863/4500\n",
            "100/100 [==============================] - 0s 521us/step - loss: 0.5410 - acc: 0.7100 - val_loss: 0.5733 - val_acc: 0.6500\n",
            "Epoch 1864/4500\n",
            "100/100 [==============================] - 0s 503us/step - loss: 0.5401 - acc: 0.7100 - val_loss: 0.5723 - val_acc: 0.6500\n",
            "Epoch 1865/4500\n",
            "100/100 [==============================] - 0s 506us/step - loss: 0.5416 - acc: 0.7300 - val_loss: 0.5705 - val_acc: 0.6600\n",
            "Epoch 1866/4500\n",
            "100/100 [==============================] - 0s 511us/step - loss: 0.5396 - acc: 0.7200 - val_loss: 0.5722 - val_acc: 0.6500\n",
            "Epoch 1867/4500\n",
            "100/100 [==============================] - 0s 522us/step - loss: 0.5383 - acc: 0.7100 - val_loss: 0.5715 - val_acc: 0.6500\n",
            "Epoch 1868/4500\n",
            "100/100 [==============================] - 0s 527us/step - loss: 0.5379 - acc: 0.7100 - val_loss: 0.5700 - val_acc: 0.6600\n",
            "Epoch 1869/4500\n",
            "100/100 [==============================] - 0s 496us/step - loss: 0.5381 - acc: 0.7200 - val_loss: 0.5702 - val_acc: 0.6500\n",
            "Epoch 1870/4500\n",
            "100/100 [==============================] - 0s 546us/step - loss: 0.5369 - acc: 0.7200 - val_loss: 0.5692 - val_acc: 0.6600\n",
            "Epoch 1871/4500\n",
            "100/100 [==============================] - 0s 587us/step - loss: 0.5371 - acc: 0.7300 - val_loss: 0.5670 - val_acc: 0.7000\n",
            "Epoch 1872/4500\n",
            "100/100 [==============================] - 0s 549us/step - loss: 0.5365 - acc: 0.7300 - val_loss: 0.5662 - val_acc: 0.7000\n",
            "Epoch 1873/4500\n",
            "100/100 [==============================] - 0s 490us/step - loss: 0.5350 - acc: 0.7300 - val_loss: 0.5672 - val_acc: 0.6800\n",
            "Epoch 1874/4500\n",
            "100/100 [==============================] - 0s 501us/step - loss: 0.5353 - acc: 0.7300 - val_loss: 0.5654 - val_acc: 0.7000\n",
            "Epoch 1875/4500\n",
            "100/100 [==============================] - 0s 481us/step - loss: 0.5338 - acc: 0.7300 - val_loss: 0.5660 - val_acc: 0.6900\n",
            "Epoch 1876/4500\n",
            "100/100 [==============================] - 0s 513us/step - loss: 0.5335 - acc: 0.7300 - val_loss: 0.5659 - val_acc: 0.6800\n",
            "Epoch 1877/4500\n",
            "100/100 [==============================] - 0s 504us/step - loss: 0.5329 - acc: 0.7300 - val_loss: 0.5643 - val_acc: 0.6900\n",
            "Epoch 1878/4500\n",
            "100/100 [==============================] - 0s 512us/step - loss: 0.5323 - acc: 0.7300 - val_loss: 0.5639 - val_acc: 0.6900\n",
            "Epoch 1879/4500\n",
            "100/100 [==============================] - 0s 495us/step - loss: 0.5319 - acc: 0.7300 - val_loss: 0.5637 - val_acc: 0.6900\n",
            "Epoch 1880/4500\n",
            "100/100 [==============================] - 0s 530us/step - loss: 0.5310 - acc: 0.7400 - val_loss: 0.5614 - val_acc: 0.7200\n",
            "Epoch 1881/4500\n",
            "100/100 [==============================] - 0s 493us/step - loss: 0.5317 - acc: 0.7400 - val_loss: 0.5608 - val_acc: 0.7200\n",
            "Epoch 1882/4500\n",
            "100/100 [==============================] - 0s 493us/step - loss: 0.5302 - acc: 0.7400 - val_loss: 0.5610 - val_acc: 0.7200\n",
            "Epoch 1883/4500\n",
            "100/100 [==============================] - 0s 534us/step - loss: 0.5305 - acc: 0.7400 - val_loss: 0.5615 - val_acc: 0.7200\n",
            "Epoch 1884/4500\n",
            "100/100 [==============================] - 0s 494us/step - loss: 0.5291 - acc: 0.7400 - val_loss: 0.5581 - val_acc: 0.7200\n",
            "Epoch 1885/4500\n",
            "100/100 [==============================] - 0s 519us/step - loss: 0.5277 - acc: 0.7400 - val_loss: 0.5583 - val_acc: 0.7200\n",
            "Epoch 1886/4500\n",
            "100/100 [==============================] - 0s 496us/step - loss: 0.5275 - acc: 0.7400 - val_loss: 0.5574 - val_acc: 0.7200\n",
            "Epoch 1887/4500\n",
            "100/100 [==============================] - 0s 505us/step - loss: 0.5267 - acc: 0.7400 - val_loss: 0.5580 - val_acc: 0.7200\n",
            "Epoch 1888/4500\n",
            "100/100 [==============================] - 0s 494us/step - loss: 0.5258 - acc: 0.7400 - val_loss: 0.5571 - val_acc: 0.7200\n",
            "Epoch 1889/4500\n",
            "100/100 [==============================] - 0s 491us/step - loss: 0.5256 - acc: 0.7200 - val_loss: 0.5551 - val_acc: 0.7200\n",
            "Epoch 1890/4500\n",
            "100/100 [==============================] - 0s 519us/step - loss: 0.5251 - acc: 0.7300 - val_loss: 0.5554 - val_acc: 0.7100\n",
            "Epoch 1891/4500\n",
            "100/100 [==============================] - 0s 585us/step - loss: 0.5242 - acc: 0.7300 - val_loss: 0.5547 - val_acc: 0.7100\n",
            "Epoch 1892/4500\n",
            "100/100 [==============================] - 0s 529us/step - loss: 0.5234 - acc: 0.7300 - val_loss: 0.5534 - val_acc: 0.7200\n",
            "Epoch 1893/4500\n",
            "100/100 [==============================] - 0s 542us/step - loss: 0.5250 - acc: 0.7300 - val_loss: 0.5520 - val_acc: 0.7300\n",
            "Epoch 1894/4500\n",
            "100/100 [==============================] - 0s 483us/step - loss: 0.5222 - acc: 0.7300 - val_loss: 0.5533 - val_acc: 0.7200\n",
            "Epoch 1895/4500\n",
            "100/100 [==============================] - 0s 515us/step - loss: 0.5224 - acc: 0.7200 - val_loss: 0.5531 - val_acc: 0.7100\n",
            "Epoch 1896/4500\n",
            "100/100 [==============================] - 0s 497us/step - loss: 0.5209 - acc: 0.7300 - val_loss: 0.5519 - val_acc: 0.7100\n",
            "Epoch 1897/4500\n",
            "100/100 [==============================] - 0s 552us/step - loss: 0.5211 - acc: 0.7300 - val_loss: 0.5496 - val_acc: 0.7300\n",
            "Epoch 1898/4500\n",
            "100/100 [==============================] - 0s 502us/step - loss: 0.5199 - acc: 0.7300 - val_loss: 0.5499 - val_acc: 0.7300\n",
            "Epoch 1899/4500\n",
            "100/100 [==============================] - 0s 513us/step - loss: 0.5190 - acc: 0.7300 - val_loss: 0.5491 - val_acc: 0.7300\n",
            "Epoch 1900/4500\n",
            "100/100 [==============================] - 0s 556us/step - loss: 0.5186 - acc: 0.7300 - val_loss: 0.5473 - val_acc: 0.7300\n",
            "Epoch 1901/4500\n",
            "100/100 [==============================] - 0s 514us/step - loss: 0.5178 - acc: 0.7300 - val_loss: 0.5467 - val_acc: 0.7300\n",
            "Epoch 1902/4500\n",
            "100/100 [==============================] - 0s 492us/step - loss: 0.5169 - acc: 0.7300 - val_loss: 0.5458 - val_acc: 0.7400\n",
            "Epoch 1903/4500\n",
            "100/100 [==============================] - 0s 551us/step - loss: 0.5160 - acc: 0.7300 - val_loss: 0.5462 - val_acc: 0.7300\n",
            "Epoch 1904/4500\n",
            "100/100 [==============================] - 0s 497us/step - loss: 0.5153 - acc: 0.7300 - val_loss: 0.5458 - val_acc: 0.7300\n",
            "Epoch 1905/4500\n",
            "100/100 [==============================] - 0s 511us/step - loss: 0.5150 - acc: 0.7300 - val_loss: 0.5446 - val_acc: 0.7400\n",
            "Epoch 1906/4500\n",
            "100/100 [==============================] - 0s 516us/step - loss: 0.5145 - acc: 0.7300 - val_loss: 0.5441 - val_acc: 0.7400\n",
            "Epoch 1907/4500\n",
            "100/100 [==============================] - 0s 495us/step - loss: 0.5138 - acc: 0.7300 - val_loss: 0.5431 - val_acc: 0.7400\n",
            "Epoch 1908/4500\n",
            "100/100 [==============================] - 0s 493us/step - loss: 0.5130 - acc: 0.7500 - val_loss: 0.5421 - val_acc: 0.7400\n",
            "Epoch 1909/4500\n",
            "100/100 [==============================] - 0s 504us/step - loss: 0.5136 - acc: 0.7300 - val_loss: 0.5419 - val_acc: 0.7400\n",
            "Epoch 1910/4500\n",
            "100/100 [==============================] - 0s 515us/step - loss: 0.5135 - acc: 0.7700 - val_loss: 0.5404 - val_acc: 0.7400\n",
            "Epoch 1911/4500\n",
            "100/100 [==============================] - 0s 739us/step - loss: 0.5115 - acc: 0.7500 - val_loss: 0.5413 - val_acc: 0.7400\n",
            "Epoch 1912/4500\n",
            "100/100 [==============================] - 0s 504us/step - loss: 0.5138 - acc: 0.7300 - val_loss: 0.5421 - val_acc: 0.7300\n",
            "Epoch 1913/4500\n",
            "100/100 [==============================] - 0s 493us/step - loss: 0.5102 - acc: 0.7500 - val_loss: 0.5376 - val_acc: 0.7600\n",
            "Epoch 1914/4500\n",
            "100/100 [==============================] - 0s 499us/step - loss: 0.5103 - acc: 0.7700 - val_loss: 0.5378 - val_acc: 0.7400\n",
            "Epoch 1915/4500\n",
            "100/100 [==============================] - 0s 506us/step - loss: 0.5094 - acc: 0.7600 - val_loss: 0.5374 - val_acc: 0.7400\n",
            "Epoch 1916/4500\n",
            "100/100 [==============================] - 0s 531us/step - loss: 0.5082 - acc: 0.7700 - val_loss: 0.5360 - val_acc: 0.7600\n",
            "Epoch 1917/4500\n",
            "100/100 [==============================] - 0s 566us/step - loss: 0.5072 - acc: 0.7700 - val_loss: 0.5349 - val_acc: 0.7600\n",
            "Epoch 1918/4500\n",
            "100/100 [==============================] - 0s 521us/step - loss: 0.5063 - acc: 0.7900 - val_loss: 0.5345 - val_acc: 0.7600\n",
            "Epoch 1919/4500\n",
            "100/100 [==============================] - 0s 547us/step - loss: 0.5063 - acc: 0.7800 - val_loss: 0.5344 - val_acc: 0.7600\n",
            "Epoch 1920/4500\n",
            "100/100 [==============================] - 0s 665us/step - loss: 0.5060 - acc: 0.7600 - val_loss: 0.5345 - val_acc: 0.7500\n",
            "Epoch 1921/4500\n",
            "100/100 [==============================] - 0s 551us/step - loss: 0.5046 - acc: 0.8000 - val_loss: 0.5317 - val_acc: 0.7600\n",
            "Epoch 1922/4500\n",
            "100/100 [==============================] - 0s 524us/step - loss: 0.5044 - acc: 0.8000 - val_loss: 0.5310 - val_acc: 0.7600\n",
            "Epoch 1923/4500\n",
            "100/100 [==============================] - 0s 512us/step - loss: 0.5030 - acc: 0.7900 - val_loss: 0.5315 - val_acc: 0.7600\n",
            "Epoch 1924/4500\n",
            "100/100 [==============================] - 0s 495us/step - loss: 0.5026 - acc: 0.7800 - val_loss: 0.5304 - val_acc: 0.7600\n",
            "Epoch 1925/4500\n",
            "100/100 [==============================] - 0s 500us/step - loss: 0.5024 - acc: 0.8000 - val_loss: 0.5295 - val_acc: 0.7600\n",
            "Epoch 1926/4500\n",
            "100/100 [==============================] - 0s 525us/step - loss: 0.5011 - acc: 0.7900 - val_loss: 0.5302 - val_acc: 0.7600\n",
            "Epoch 1927/4500\n",
            "100/100 [==============================] - 0s 531us/step - loss: 0.5004 - acc: 0.8000 - val_loss: 0.5284 - val_acc: 0.7600\n",
            "Epoch 1928/4500\n",
            "100/100 [==============================] - 0s 525us/step - loss: 0.5006 - acc: 0.7800 - val_loss: 0.5290 - val_acc: 0.7600\n",
            "Epoch 1929/4500\n",
            "100/100 [==============================] - 0s 598us/step - loss: 0.4986 - acc: 0.8000 - val_loss: 0.5262 - val_acc: 0.7500\n",
            "Epoch 1930/4500\n",
            "100/100 [==============================] - 0s 585us/step - loss: 0.4985 - acc: 0.8000 - val_loss: 0.5260 - val_acc: 0.7500\n",
            "Epoch 1931/4500\n",
            "100/100 [==============================] - 0s 503us/step - loss: 0.4981 - acc: 0.7900 - val_loss: 0.5239 - val_acc: 0.7500\n",
            "Epoch 1932/4500\n",
            "100/100 [==============================] - 0s 514us/step - loss: 0.4986 - acc: 0.7900 - val_loss: 0.5263 - val_acc: 0.7600\n",
            "Epoch 1933/4500\n",
            "100/100 [==============================] - 0s 601us/step - loss: 0.4965 - acc: 0.8000 - val_loss: 0.5237 - val_acc: 0.7500\n",
            "Epoch 1934/4500\n",
            "100/100 [==============================] - 0s 502us/step - loss: 0.4982 - acc: 0.7900 - val_loss: 0.5213 - val_acc: 0.7400\n",
            "Epoch 1935/4500\n",
            "100/100 [==============================] - 0s 488us/step - loss: 0.4963 - acc: 0.7900 - val_loss: 0.5245 - val_acc: 0.7600\n",
            "Epoch 1936/4500\n",
            "100/100 [==============================] - 0s 507us/step - loss: 0.4944 - acc: 0.8000 - val_loss: 0.5223 - val_acc: 0.7500\n",
            "Epoch 1937/4500\n",
            "100/100 [==============================] - 0s 533us/step - loss: 0.4959 - acc: 0.7900 - val_loss: 0.5196 - val_acc: 0.7400\n",
            "Epoch 1938/4500\n",
            "100/100 [==============================] - 0s 492us/step - loss: 0.4935 - acc: 0.8000 - val_loss: 0.5229 - val_acc: 0.7600\n",
            "Epoch 1939/4500\n",
            "100/100 [==============================] - 0s 519us/step - loss: 0.4933 - acc: 0.8000 - val_loss: 0.5200 - val_acc: 0.7500\n",
            "Epoch 1940/4500\n",
            "100/100 [==============================] - 0s 510us/step - loss: 0.4920 - acc: 0.7900 - val_loss: 0.5190 - val_acc: 0.7500\n",
            "Epoch 1941/4500\n",
            "100/100 [==============================] - 0s 502us/step - loss: 0.4922 - acc: 0.7900 - val_loss: 0.5176 - val_acc: 0.7500\n",
            "Epoch 1942/4500\n",
            "100/100 [==============================] - 0s 515us/step - loss: 0.4900 - acc: 0.7900 - val_loss: 0.5181 - val_acc: 0.7500\n",
            "Epoch 1943/4500\n",
            "100/100 [==============================] - 0s 516us/step - loss: 0.4897 - acc: 0.8000 - val_loss: 0.5196 - val_acc: 0.7600\n",
            "Epoch 1944/4500\n",
            "100/100 [==============================] - 0s 495us/step - loss: 0.4902 - acc: 0.7900 - val_loss: 0.5161 - val_acc: 0.7500\n",
            "Epoch 1945/4500\n",
            "100/100 [==============================] - 0s 488us/step - loss: 0.4897 - acc: 0.8000 - val_loss: 0.5155 - val_acc: 0.7500\n",
            "Epoch 1946/4500\n",
            "100/100 [==============================] - 0s 512us/step - loss: 0.4880 - acc: 0.7900 - val_loss: 0.5135 - val_acc: 0.7500\n",
            "Epoch 1947/4500\n",
            "100/100 [==============================] - 0s 529us/step - loss: 0.4871 - acc: 0.7900 - val_loss: 0.5144 - val_acc: 0.7500\n",
            "Epoch 1948/4500\n",
            "100/100 [==============================] - 0s 543us/step - loss: 0.4882 - acc: 0.8000 - val_loss: 0.5149 - val_acc: 0.7500\n",
            "Epoch 1949/4500\n",
            "100/100 [==============================] - 0s 563us/step - loss: 0.4873 - acc: 0.7800 - val_loss: 0.5106 - val_acc: 0.7500\n",
            "Epoch 1950/4500\n",
            "100/100 [==============================] - 0s 540us/step - loss: 0.4850 - acc: 0.7900 - val_loss: 0.5105 - val_acc: 0.7500\n",
            "Epoch 1951/4500\n",
            "100/100 [==============================] - 0s 499us/step - loss: 0.4860 - acc: 0.7900 - val_loss: 0.5134 - val_acc: 0.7500\n",
            "Epoch 1952/4500\n",
            "100/100 [==============================] - 0s 499us/step - loss: 0.4840 - acc: 0.8000 - val_loss: 0.5100 - val_acc: 0.7500\n",
            "Epoch 1953/4500\n",
            "100/100 [==============================] - 0s 508us/step - loss: 0.4840 - acc: 0.7900 - val_loss: 0.5090 - val_acc: 0.7500\n",
            "Epoch 1954/4500\n",
            "100/100 [==============================] - 0s 499us/step - loss: 0.4829 - acc: 0.7900 - val_loss: 0.5079 - val_acc: 0.7500\n",
            "Epoch 1955/4500\n",
            "100/100 [==============================] - 0s 490us/step - loss: 0.4818 - acc: 0.7800 - val_loss: 0.5081 - val_acc: 0.7500\n",
            "Epoch 1956/4500\n",
            "100/100 [==============================] - 0s 519us/step - loss: 0.4809 - acc: 0.7900 - val_loss: 0.5085 - val_acc: 0.7400\n",
            "Epoch 1957/4500\n",
            "100/100 [==============================] - 0s 514us/step - loss: 0.4807 - acc: 0.7900 - val_loss: 0.5092 - val_acc: 0.7500\n",
            "Epoch 1958/4500\n",
            "100/100 [==============================] - 0s 507us/step - loss: 0.4804 - acc: 0.7900 - val_loss: 0.5068 - val_acc: 0.7500\n",
            "Epoch 1959/4500\n",
            "100/100 [==============================] - 0s 536us/step - loss: 0.4793 - acc: 0.7900 - val_loss: 0.5062 - val_acc: 0.7500\n",
            "Epoch 1960/4500\n",
            "100/100 [==============================] - 0s 542us/step - loss: 0.4783 - acc: 0.7900 - val_loss: 0.5030 - val_acc: 0.7600\n",
            "Epoch 1961/4500\n",
            "100/100 [==============================] - 0s 514us/step - loss: 0.4797 - acc: 0.7900 - val_loss: 0.5048 - val_acc: 0.7500\n",
            "Epoch 1962/4500\n",
            "100/100 [==============================] - 0s 541us/step - loss: 0.4761 - acc: 0.7900 - val_loss: 0.5027 - val_acc: 0.7600\n",
            "Epoch 1963/4500\n",
            "100/100 [==============================] - 0s 530us/step - loss: 0.4765 - acc: 0.7800 - val_loss: 0.5015 - val_acc: 0.7700\n",
            "Epoch 1964/4500\n",
            "100/100 [==============================] - 0s 654us/step - loss: 0.4757 - acc: 0.7800 - val_loss: 0.5004 - val_acc: 0.7700\n",
            "Epoch 1965/4500\n",
            "100/100 [==============================] - 0s 525us/step - loss: 0.4805 - acc: 0.7900 - val_loss: 0.5052 - val_acc: 0.7400\n",
            "Epoch 1966/4500\n",
            "100/100 [==============================] - 0s 521us/step - loss: 0.4745 - acc: 0.7900 - val_loss: 0.4995 - val_acc: 0.7700\n",
            "Epoch 1967/4500\n",
            "100/100 [==============================] - 0s 607us/step - loss: 0.4742 - acc: 0.7900 - val_loss: 0.4977 - val_acc: 0.7800\n",
            "Epoch 1968/4500\n",
            "100/100 [==============================] - 0s 577us/step - loss: 0.4744 - acc: 0.7800 - val_loss: 0.5010 - val_acc: 0.7600\n",
            "Epoch 1969/4500\n",
            "100/100 [==============================] - 0s 627us/step - loss: 0.4744 - acc: 0.7800 - val_loss: 0.4972 - val_acc: 0.7700\n",
            "Epoch 1970/4500\n",
            "100/100 [==============================] - 0s 496us/step - loss: 0.4727 - acc: 0.7900 - val_loss: 0.4979 - val_acc: 0.7700\n",
            "Epoch 1971/4500\n",
            "100/100 [==============================] - 0s 511us/step - loss: 0.4710 - acc: 0.7900 - val_loss: 0.4973 - val_acc: 0.7700\n",
            "Epoch 1972/4500\n",
            "100/100 [==============================] - 0s 518us/step - loss: 0.4706 - acc: 0.7900 - val_loss: 0.4960 - val_acc: 0.7700\n",
            "Epoch 1973/4500\n",
            "100/100 [==============================] - 0s 500us/step - loss: 0.4713 - acc: 0.7900 - val_loss: 0.4939 - val_acc: 0.7900\n",
            "Epoch 1974/4500\n",
            "100/100 [==============================] - 0s 507us/step - loss: 0.4685 - acc: 0.7900 - val_loss: 0.4958 - val_acc: 0.7700\n",
            "Epoch 1975/4500\n",
            "100/100 [==============================] - 0s 515us/step - loss: 0.4676 - acc: 0.7800 - val_loss: 0.4941 - val_acc: 0.7900\n",
            "Epoch 1976/4500\n",
            "100/100 [==============================] - 0s 516us/step - loss: 0.4678 - acc: 0.7800 - val_loss: 0.4933 - val_acc: 0.7900\n",
            "Epoch 1977/4500\n",
            "100/100 [==============================] - 0s 528us/step - loss: 0.4663 - acc: 0.7800 - val_loss: 0.4927 - val_acc: 0.7900\n",
            "Epoch 1978/4500\n",
            "100/100 [==============================] - 0s 509us/step - loss: 0.4656 - acc: 0.7900 - val_loss: 0.4923 - val_acc: 0.7900\n",
            "Epoch 1979/4500\n",
            "100/100 [==============================] - 0s 511us/step - loss: 0.4652 - acc: 0.7800 - val_loss: 0.4900 - val_acc: 0.7900\n",
            "Epoch 1980/4500\n",
            "100/100 [==============================] - 0s 490us/step - loss: 0.4643 - acc: 0.7900 - val_loss: 0.4890 - val_acc: 0.8000\n",
            "Epoch 1981/4500\n",
            "100/100 [==============================] - 0s 506us/step - loss: 0.4638 - acc: 0.7900 - val_loss: 0.4897 - val_acc: 0.7900\n",
            "Epoch 1982/4500\n",
            "100/100 [==============================] - 0s 496us/step - loss: 0.4629 - acc: 0.7900 - val_loss: 0.4886 - val_acc: 0.7900\n",
            "Epoch 1983/4500\n",
            "100/100 [==============================] - 0s 519us/step - loss: 0.4621 - acc: 0.7900 - val_loss: 0.4884 - val_acc: 0.7900\n",
            "Epoch 1984/4500\n",
            "100/100 [==============================] - 0s 542us/step - loss: 0.4627 - acc: 0.7900 - val_loss: 0.4865 - val_acc: 0.8000\n",
            "Epoch 1985/4500\n",
            "100/100 [==============================] - 0s 490us/step - loss: 0.4626 - acc: 0.7900 - val_loss: 0.4875 - val_acc: 0.7900\n",
            "Epoch 1986/4500\n",
            "100/100 [==============================] - 0s 711us/step - loss: 0.4627 - acc: 0.7800 - val_loss: 0.4886 - val_acc: 0.7900\n",
            "Epoch 1987/4500\n",
            "100/100 [==============================] - 0s 666us/step - loss: 0.4648 - acc: 0.7900 - val_loss: 0.4900 - val_acc: 0.7900\n",
            "Epoch 1988/4500\n",
            "100/100 [==============================] - 0s 548us/step - loss: 0.4621 - acc: 0.7900 - val_loss: 0.4836 - val_acc: 0.8000\n",
            "Epoch 1989/4500\n",
            "100/100 [==============================] - 0s 550us/step - loss: 0.4581 - acc: 0.7900 - val_loss: 0.4843 - val_acc: 0.8000\n",
            "Epoch 1990/4500\n",
            "100/100 [==============================] - 0s 510us/step - loss: 0.4579 - acc: 0.7800 - val_loss: 0.4838 - val_acc: 0.8000\n",
            "Epoch 1991/4500\n",
            "100/100 [==============================] - 0s 504us/step - loss: 0.4579 - acc: 0.7900 - val_loss: 0.4824 - val_acc: 0.8000\n",
            "Epoch 1992/4500\n",
            "100/100 [==============================] - 0s 524us/step - loss: 0.4594 - acc: 0.7800 - val_loss: 0.4851 - val_acc: 0.7900\n",
            "Epoch 1993/4500\n",
            "100/100 [==============================] - 0s 529us/step - loss: 0.4551 - acc: 0.7800 - val_loss: 0.4810 - val_acc: 0.8000\n",
            "Epoch 1994/4500\n",
            "100/100 [==============================] - 0s 504us/step - loss: 0.4556 - acc: 0.7900 - val_loss: 0.4800 - val_acc: 0.8000\n",
            "Epoch 1995/4500\n",
            "100/100 [==============================] - 0s 561us/step - loss: 0.4556 - acc: 0.7800 - val_loss: 0.4813 - val_acc: 0.8000\n",
            "Epoch 1996/4500\n",
            "100/100 [==============================] - 0s 572us/step - loss: 0.4539 - acc: 0.7800 - val_loss: 0.4798 - val_acc: 0.8000\n",
            "Epoch 1997/4500\n",
            "100/100 [==============================] - 0s 494us/step - loss: 0.4537 - acc: 0.7900 - val_loss: 0.4776 - val_acc: 0.8000\n",
            "Epoch 1998/4500\n",
            "100/100 [==============================] - 0s 547us/step - loss: 0.4539 - acc: 0.7900 - val_loss: 0.4771 - val_acc: 0.8000\n",
            "Epoch 1999/4500\n",
            "100/100 [==============================] - 0s 520us/step - loss: 0.4528 - acc: 0.7900 - val_loss: 0.4793 - val_acc: 0.8000\n",
            "Epoch 2000/4500\n",
            "100/100 [==============================] - 0s 523us/step - loss: 0.4501 - acc: 0.7900 - val_loss: 0.4767 - val_acc: 0.8000\n",
            "Epoch 2001/4500\n",
            "100/100 [==============================] - 0s 504us/step - loss: 0.4505 - acc: 0.7900 - val_loss: 0.4757 - val_acc: 0.8000\n",
            "Epoch 2002/4500\n",
            "100/100 [==============================] - 0s 519us/step - loss: 0.4502 - acc: 0.7900 - val_loss: 0.4765 - val_acc: 0.8000\n",
            "Epoch 2003/4500\n",
            "100/100 [==============================] - 0s 516us/step - loss: 0.4483 - acc: 0.7900 - val_loss: 0.4759 - val_acc: 0.8000\n",
            "Epoch 2004/4500\n",
            "100/100 [==============================] - 0s 495us/step - loss: 0.4471 - acc: 0.7900 - val_loss: 0.4738 - val_acc: 0.8000\n",
            "Epoch 2005/4500\n",
            "100/100 [==============================] - 0s 596us/step - loss: 0.4468 - acc: 0.7900 - val_loss: 0.4731 - val_acc: 0.8000\n",
            "Epoch 2006/4500\n",
            "100/100 [==============================] - 0s 517us/step - loss: 0.4459 - acc: 0.7900 - val_loss: 0.4737 - val_acc: 0.8000\n",
            "Epoch 2007/4500\n",
            "100/100 [==============================] - 0s 557us/step - loss: 0.4469 - acc: 0.7900 - val_loss: 0.4739 - val_acc: 0.8000\n",
            "Epoch 2008/4500\n",
            "100/100 [==============================] - 0s 624us/step - loss: 0.4447 - acc: 0.7800 - val_loss: 0.4711 - val_acc: 0.8000\n",
            "Epoch 2009/4500\n",
            "100/100 [==============================] - 0s 599us/step - loss: 0.4446 - acc: 0.7800 - val_loss: 0.4693 - val_acc: 0.7900\n",
            "Epoch 2010/4500\n",
            "100/100 [==============================] - 0s 504us/step - loss: 0.4445 - acc: 0.7900 - val_loss: 0.4698 - val_acc: 0.8000\n",
            "Epoch 2011/4500\n",
            "100/100 [==============================] - 0s 503us/step - loss: 0.4426 - acc: 0.7900 - val_loss: 0.4704 - val_acc: 0.8000\n",
            "Epoch 2012/4500\n",
            "100/100 [==============================] - 0s 489us/step - loss: 0.4463 - acc: 0.7900 - val_loss: 0.4678 - val_acc: 0.7900\n",
            "Epoch 2013/4500\n",
            "100/100 [==============================] - 0s 510us/step - loss: 0.4419 - acc: 0.7900 - val_loss: 0.4688 - val_acc: 0.8000\n",
            "Epoch 2014/4500\n",
            "100/100 [==============================] - 0s 497us/step - loss: 0.4409 - acc: 0.7900 - val_loss: 0.4691 - val_acc: 0.8000\n",
            "Epoch 2015/4500\n",
            "100/100 [==============================] - 0s 555us/step - loss: 0.4418 - acc: 0.7900 - val_loss: 0.4698 - val_acc: 0.8000\n",
            "Epoch 2016/4500\n",
            "100/100 [==============================] - 0s 529us/step - loss: 0.4412 - acc: 0.7900 - val_loss: 0.4664 - val_acc: 0.8000\n",
            "Epoch 2017/4500\n",
            "100/100 [==============================] - 0s 528us/step - loss: 0.4410 - acc: 0.7900 - val_loss: 0.4661 - val_acc: 0.8000\n",
            "Epoch 2018/4500\n",
            "100/100 [==============================] - 0s 598us/step - loss: 0.4392 - acc: 0.8000 - val_loss: 0.4678 - val_acc: 0.8000\n",
            "Epoch 2019/4500\n",
            "100/100 [==============================] - 0s 518us/step - loss: 0.4365 - acc: 0.7900 - val_loss: 0.4648 - val_acc: 0.8000\n",
            "Epoch 2020/4500\n",
            "100/100 [==============================] - 0s 511us/step - loss: 0.4380 - acc: 0.7900 - val_loss: 0.4629 - val_acc: 0.7900\n",
            "Epoch 2021/4500\n",
            "100/100 [==============================] - 0s 515us/step - loss: 0.4385 - acc: 0.7800 - val_loss: 0.4631 - val_acc: 0.8000\n",
            "Epoch 2022/4500\n",
            "100/100 [==============================] - 0s 524us/step - loss: 0.4348 - acc: 0.7900 - val_loss: 0.4629 - val_acc: 0.8000\n",
            "Epoch 2023/4500\n",
            "100/100 [==============================] - 0s 539us/step - loss: 0.4386 - acc: 0.8000 - val_loss: 0.4655 - val_acc: 0.8000\n",
            "Epoch 2024/4500\n",
            "100/100 [==============================] - 0s 577us/step - loss: 0.4335 - acc: 0.7900 - val_loss: 0.4619 - val_acc: 0.8000\n",
            "Epoch 2025/4500\n",
            "100/100 [==============================] - 0s 511us/step - loss: 0.4328 - acc: 0.7900 - val_loss: 0.4601 - val_acc: 0.7900\n",
            "Epoch 2026/4500\n",
            "100/100 [==============================] - 0s 496us/step - loss: 0.4328 - acc: 0.7900 - val_loss: 0.4600 - val_acc: 0.8000\n",
            "Epoch 2027/4500\n",
            "100/100 [==============================] - 0s 569us/step - loss: 0.4315 - acc: 0.7900 - val_loss: 0.4592 - val_acc: 0.8000\n",
            "Epoch 2028/4500\n",
            "100/100 [==============================] - 0s 507us/step - loss: 0.4314 - acc: 0.7900 - val_loss: 0.4584 - val_acc: 0.7900\n",
            "Epoch 2029/4500\n",
            "100/100 [==============================] - 0s 479us/step - loss: 0.4308 - acc: 0.7900 - val_loss: 0.4603 - val_acc: 0.8000\n",
            "Epoch 2030/4500\n",
            "100/100 [==============================] - 0s 507us/step - loss: 0.4333 - acc: 0.7900 - val_loss: 0.4574 - val_acc: 0.8000\n",
            "Epoch 2031/4500\n",
            "100/100 [==============================] - 0s 485us/step - loss: 0.4285 - acc: 0.7900 - val_loss: 0.4602 - val_acc: 0.8000\n",
            "Epoch 2032/4500\n",
            "100/100 [==============================] - 0s 525us/step - loss: 0.4280 - acc: 0.8000 - val_loss: 0.4584 - val_acc: 0.8000\n",
            "Epoch 2033/4500\n",
            "100/100 [==============================] - 0s 495us/step - loss: 0.4312 - acc: 0.7900 - val_loss: 0.4553 - val_acc: 0.7800\n",
            "Epoch 2034/4500\n",
            "100/100 [==============================] - 0s 502us/step - loss: 0.4280 - acc: 0.7900 - val_loss: 0.4556 - val_acc: 0.8000\n",
            "Epoch 2035/4500\n",
            "100/100 [==============================] - 0s 486us/step - loss: 0.4257 - acc: 0.7900 - val_loss: 0.4573 - val_acc: 0.8000\n",
            "Epoch 2036/4500\n",
            "100/100 [==============================] - 0s 508us/step - loss: 0.4266 - acc: 0.8000 - val_loss: 0.4580 - val_acc: 0.8000\n",
            "Epoch 2037/4500\n",
            "100/100 [==============================] - 0s 512us/step - loss: 0.4246 - acc: 0.7900 - val_loss: 0.4541 - val_acc: 0.8000\n",
            "Epoch 2038/4500\n",
            "100/100 [==============================] - 0s 500us/step - loss: 0.4237 - acc: 0.7900 - val_loss: 0.4530 - val_acc: 0.8000\n",
            "Epoch 2039/4500\n",
            "100/100 [==============================] - 0s 521us/step - loss: 0.4271 - acc: 0.7800 - val_loss: 0.4519 - val_acc: 0.7900\n",
            "Epoch 2040/4500\n",
            "100/100 [==============================] - 0s 514us/step - loss: 0.4310 - acc: 0.7800 - val_loss: 0.4579 - val_acc: 0.8000\n",
            "Epoch 2041/4500\n",
            "100/100 [==============================] - 0s 498us/step - loss: 0.4231 - acc: 0.7900 - val_loss: 0.4541 - val_acc: 0.8000\n",
            "Epoch 2042/4500\n",
            "100/100 [==============================] - 0s 501us/step - loss: 0.4251 - acc: 0.7800 - val_loss: 0.4507 - val_acc: 0.7800\n",
            "Epoch 2043/4500\n",
            "100/100 [==============================] - 0s 608us/step - loss: 0.4203 - acc: 0.7800 - val_loss: 0.4517 - val_acc: 0.8000\n",
            "Epoch 2044/4500\n",
            "100/100 [==============================] - 0s 509us/step - loss: 0.4270 - acc: 0.7900 - val_loss: 0.4551 - val_acc: 0.8000\n",
            "Epoch 2045/4500\n",
            "100/100 [==============================] - 0s 517us/step - loss: 0.4187 - acc: 0.7900 - val_loss: 0.4496 - val_acc: 0.8000\n",
            "Epoch 2046/4500\n",
            "100/100 [==============================] - 0s 494us/step - loss: 0.4205 - acc: 0.7800 - val_loss: 0.4490 - val_acc: 0.7900\n",
            "Epoch 2047/4500\n",
            "100/100 [==============================] - 0s 558us/step - loss: 0.4200 - acc: 0.7900 - val_loss: 0.4507 - val_acc: 0.8000\n",
            "Epoch 2048/4500\n",
            "100/100 [==============================] - 0s 612us/step - loss: 0.4172 - acc: 0.7900 - val_loss: 0.4497 - val_acc: 0.8000\n",
            "Epoch 2049/4500\n",
            "100/100 [==============================] - 0s 508us/step - loss: 0.4180 - acc: 0.7800 - val_loss: 0.4478 - val_acc: 0.8000\n",
            "Epoch 2050/4500\n",
            "100/100 [==============================] - 0s 497us/step - loss: 0.4155 - acc: 0.7900 - val_loss: 0.4475 - val_acc: 0.8000\n",
            "Epoch 2051/4500\n",
            "100/100 [==============================] - 0s 523us/step - loss: 0.4162 - acc: 0.7900 - val_loss: 0.4490 - val_acc: 0.8000\n",
            "Epoch 2052/4500\n",
            "100/100 [==============================] - 0s 505us/step - loss: 0.4151 - acc: 0.7800 - val_loss: 0.4467 - val_acc: 0.8000\n",
            "Epoch 2053/4500\n",
            "100/100 [==============================] - 0s 487us/step - loss: 0.4144 - acc: 0.7900 - val_loss: 0.4463 - val_acc: 0.8000\n",
            "Epoch 2054/4500\n",
            "100/100 [==============================] - 0s 496us/step - loss: 0.4136 - acc: 0.7900 - val_loss: 0.4455 - val_acc: 0.8000\n",
            "Epoch 2055/4500\n",
            "100/100 [==============================] - 0s 503us/step - loss: 0.4139 - acc: 0.7800 - val_loss: 0.4473 - val_acc: 0.8000\n",
            "Epoch 2056/4500\n",
            "100/100 [==============================] - 0s 489us/step - loss: 0.4124 - acc: 0.7900 - val_loss: 0.4464 - val_acc: 0.8000\n",
            "Epoch 2057/4500\n",
            "100/100 [==============================] - 0s 618us/step - loss: 0.4113 - acc: 0.8000 - val_loss: 0.4436 - val_acc: 0.7900\n",
            "Epoch 2058/4500\n",
            "100/100 [==============================] - 0s 542us/step - loss: 0.4118 - acc: 0.8100 - val_loss: 0.4440 - val_acc: 0.8100\n",
            "Epoch 2059/4500\n",
            "100/100 [==============================] - 0s 573us/step - loss: 0.4128 - acc: 0.7900 - val_loss: 0.4447 - val_acc: 0.8000\n",
            "Epoch 2060/4500\n",
            "100/100 [==============================] - 0s 594us/step - loss: 0.4108 - acc: 0.7900 - val_loss: 0.4449 - val_acc: 0.8000\n",
            "Epoch 2061/4500\n",
            "100/100 [==============================] - 0s 514us/step - loss: 0.4133 - acc: 0.8000 - val_loss: 0.4424 - val_acc: 0.8000\n",
            "Epoch 2062/4500\n",
            "100/100 [==============================] - 0s 622us/step - loss: 0.4090 - acc: 0.8000 - val_loss: 0.4430 - val_acc: 0.8100\n",
            "Epoch 2063/4500\n",
            "100/100 [==============================] - 0s 488us/step - loss: 0.4061 - acc: 0.8000 - val_loss: 0.4441 - val_acc: 0.8000\n",
            "Epoch 2064/4500\n",
            "100/100 [==============================] - 0s 491us/step - loss: 0.4062 - acc: 0.7900 - val_loss: 0.4424 - val_acc: 0.8100\n",
            "Epoch 2065/4500\n",
            "100/100 [==============================] - 0s 494us/step - loss: 0.4068 - acc: 0.8000 - val_loss: 0.4417 - val_acc: 0.8100\n",
            "Epoch 2066/4500\n",
            "100/100 [==============================] - 0s 488us/step - loss: 0.4054 - acc: 0.8000 - val_loss: 0.4415 - val_acc: 0.8100\n",
            "Epoch 2067/4500\n",
            "100/100 [==============================] - 0s 551us/step - loss: 0.4074 - acc: 0.7900 - val_loss: 0.4417 - val_acc: 0.8100\n",
            "Epoch 2068/4500\n",
            "100/100 [==============================] - 0s 568us/step - loss: 0.4075 - acc: 0.8100 - val_loss: 0.4394 - val_acc: 0.7800\n",
            "Epoch 2069/4500\n",
            "100/100 [==============================] - 0s 547us/step - loss: 0.4028 - acc: 0.8200 - val_loss: 0.4396 - val_acc: 0.8100\n",
            "Epoch 2070/4500\n",
            "100/100 [==============================] - 0s 527us/step - loss: 0.4053 - acc: 0.8000 - val_loss: 0.4419 - val_acc: 0.8100\n",
            "Epoch 2071/4500\n",
            "100/100 [==============================] - 0s 515us/step - loss: 0.4044 - acc: 0.8100 - val_loss: 0.4390 - val_acc: 0.8100\n",
            "Epoch 2072/4500\n",
            "100/100 [==============================] - 0s 544us/step - loss: 0.4016 - acc: 0.8000 - val_loss: 0.4407 - val_acc: 0.8100\n",
            "Epoch 2073/4500\n",
            "100/100 [==============================] - 0s 491us/step - loss: 0.4026 - acc: 0.8000 - val_loss: 0.4402 - val_acc: 0.8100\n",
            "Epoch 2074/4500\n",
            "100/100 [==============================] - 0s 498us/step - loss: 0.4020 - acc: 0.8200 - val_loss: 0.4380 - val_acc: 0.8000\n",
            "Epoch 2075/4500\n",
            "100/100 [==============================] - 0s 515us/step - loss: 0.4003 - acc: 0.8100 - val_loss: 0.4390 - val_acc: 0.8100\n",
            "Epoch 2076/4500\n",
            "100/100 [==============================] - 0s 491us/step - loss: 0.3991 - acc: 0.8000 - val_loss: 0.4385 - val_acc: 0.8100\n",
            "Epoch 2077/4500\n",
            "100/100 [==============================] - 0s 630us/step - loss: 0.3985 - acc: 0.8000 - val_loss: 0.4378 - val_acc: 0.8100\n",
            "Epoch 2078/4500\n",
            "100/100 [==============================] - 0s 600us/step - loss: 0.4016 - acc: 0.8200 - val_loss: 0.4362 - val_acc: 0.7700\n",
            "Epoch 2079/4500\n",
            "100/100 [==============================] - 0s 538us/step - loss: 0.3988 - acc: 0.8200 - val_loss: 0.4378 - val_acc: 0.8000\n",
            "Epoch 2080/4500\n",
            "100/100 [==============================] - 0s 559us/step - loss: 0.3963 - acc: 0.8200 - val_loss: 0.4367 - val_acc: 0.8000\n",
            "Epoch 2081/4500\n",
            "100/100 [==============================] - 0s 534us/step - loss: 0.3952 - acc: 0.8200 - val_loss: 0.4370 - val_acc: 0.8000\n",
            "Epoch 2082/4500\n",
            "100/100 [==============================] - 0s 516us/step - loss: 0.3993 - acc: 0.8200 - val_loss: 0.4352 - val_acc: 0.7900\n",
            "Epoch 2083/4500\n",
            "100/100 [==============================] - 0s 489us/step - loss: 0.3943 - acc: 0.8200 - val_loss: 0.4365 - val_acc: 0.8000\n",
            "Epoch 2084/4500\n",
            "100/100 [==============================] - 0s 480us/step - loss: 0.3944 - acc: 0.8200 - val_loss: 0.4360 - val_acc: 0.8000\n",
            "Epoch 2085/4500\n",
            "100/100 [==============================] - 0s 491us/step - loss: 0.3929 - acc: 0.8200 - val_loss: 0.4364 - val_acc: 0.8000\n",
            "Epoch 2086/4500\n",
            "100/100 [==============================] - 0s 501us/step - loss: 0.3963 - acc: 0.8400 - val_loss: 0.4343 - val_acc: 0.7900\n",
            "Epoch 2087/4500\n",
            "100/100 [==============================] - 0s 538us/step - loss: 0.3931 - acc: 0.8200 - val_loss: 0.4363 - val_acc: 0.8000\n",
            "Epoch 2088/4500\n",
            "100/100 [==============================] - 0s 518us/step - loss: 0.3945 - acc: 0.8100 - val_loss: 0.4369 - val_acc: 0.8000\n",
            "Epoch 2089/4500\n",
            "100/100 [==============================] - 0s 603us/step - loss: 0.3924 - acc: 0.8200 - val_loss: 0.4335 - val_acc: 0.7900\n",
            "Epoch 2090/4500\n",
            "100/100 [==============================] - 0s 482us/step - loss: 0.3920 - acc: 0.8500 - val_loss: 0.4330 - val_acc: 0.7800\n",
            "Epoch 2091/4500\n",
            "100/100 [==============================] - 0s 490us/step - loss: 0.3909 - acc: 0.8500 - val_loss: 0.4330 - val_acc: 0.7900\n",
            "Epoch 2092/4500\n",
            "100/100 [==============================] - 0s 489us/step - loss: 0.3895 - acc: 0.8300 - val_loss: 0.4341 - val_acc: 0.7900\n",
            "Epoch 2093/4500\n",
            "100/100 [==============================] - 0s 491us/step - loss: 0.3901 - acc: 0.8500 - val_loss: 0.4330 - val_acc: 0.7900\n",
            "Epoch 2094/4500\n",
            "100/100 [==============================] - 0s 518us/step - loss: 0.3891 - acc: 0.8300 - val_loss: 0.4348 - val_acc: 0.7900\n",
            "Epoch 2095/4500\n",
            "100/100 [==============================] - 0s 543us/step - loss: 0.3883 - acc: 0.8300 - val_loss: 0.4341 - val_acc: 0.7900\n",
            "Epoch 2096/4500\n",
            "100/100 [==============================] - 0s 496us/step - loss: 0.3906 - acc: 0.8500 - val_loss: 0.4320 - val_acc: 0.7900\n",
            "Epoch 2097/4500\n",
            "100/100 [==============================] - 0s 557us/step - loss: 0.3877 - acc: 0.8500 - val_loss: 0.4323 - val_acc: 0.7900\n",
            "Epoch 2098/4500\n",
            "100/100 [==============================] - 0s 560us/step - loss: 0.3867 - acc: 0.8400 - val_loss: 0.4326 - val_acc: 0.7900\n",
            "Epoch 2099/4500\n",
            "100/100 [==============================] - 0s 528us/step - loss: 0.3860 - acc: 0.8500 - val_loss: 0.4316 - val_acc: 0.7900\n",
            "Epoch 2100/4500\n",
            "100/100 [==============================] - 0s 673us/step - loss: 0.3855 - acc: 0.8500 - val_loss: 0.4312 - val_acc: 0.7900\n",
            "Epoch 2101/4500\n",
            "100/100 [==============================] - 0s 507us/step - loss: 0.3864 - acc: 0.8500 - val_loss: 0.4317 - val_acc: 0.7900\n",
            "Epoch 2102/4500\n",
            "100/100 [==============================] - 0s 521us/step - loss: 0.3868 - acc: 0.8500 - val_loss: 0.4306 - val_acc: 0.7900\n",
            "Epoch 2103/4500\n",
            "100/100 [==============================] - 0s 557us/step - loss: 0.3835 - acc: 0.8500 - val_loss: 0.4316 - val_acc: 0.7900\n",
            "Epoch 2104/4500\n",
            "100/100 [==============================] - 0s 531us/step - loss: 0.3848 - acc: 0.8500 - val_loss: 0.4314 - val_acc: 0.7900\n",
            "Epoch 2105/4500\n",
            "100/100 [==============================] - 0s 512us/step - loss: 0.3828 - acc: 0.8500 - val_loss: 0.4311 - val_acc: 0.7900\n",
            "Epoch 2106/4500\n",
            "100/100 [==============================] - 0s 525us/step - loss: 0.3843 - acc: 0.8500 - val_loss: 0.4304 - val_acc: 0.8000\n",
            "Epoch 2107/4500\n",
            "100/100 [==============================] - 0s 514us/step - loss: 0.3829 - acc: 0.8500 - val_loss: 0.4315 - val_acc: 0.7900\n",
            "Epoch 2108/4500\n",
            "100/100 [==============================] - 0s 500us/step - loss: 0.3820 - acc: 0.8500 - val_loss: 0.4302 - val_acc: 0.7900\n",
            "Epoch 2109/4500\n",
            "100/100 [==============================] - 0s 493us/step - loss: 0.3823 - acc: 0.8500 - val_loss: 0.4296 - val_acc: 0.7900\n",
            "Epoch 2110/4500\n",
            "100/100 [==============================] - 0s 503us/step - loss: 0.3830 - acc: 0.8500 - val_loss: 0.4297 - val_acc: 0.7900\n",
            "Epoch 2111/4500\n",
            "100/100 [==============================] - 0s 529us/step - loss: 0.3803 - acc: 0.8500 - val_loss: 0.4316 - val_acc: 0.7900\n",
            "Epoch 2112/4500\n",
            "100/100 [==============================] - 0s 538us/step - loss: 0.3802 - acc: 0.8500 - val_loss: 0.4296 - val_acc: 0.7900\n",
            "Epoch 2113/4500\n",
            "100/100 [==============================] - 0s 521us/step - loss: 0.3800 - acc: 0.8500 - val_loss: 0.4301 - val_acc: 0.7900\n",
            "Epoch 2114/4500\n",
            "100/100 [==============================] - 0s 563us/step - loss: 0.3799 - acc: 0.8500 - val_loss: 0.4293 - val_acc: 0.7900\n",
            "Epoch 2115/4500\n",
            "100/100 [==============================] - 0s 518us/step - loss: 0.3804 - acc: 0.8500 - val_loss: 0.4288 - val_acc: 0.7900\n",
            "Epoch 2116/4500\n",
            "100/100 [==============================] - 0s 529us/step - loss: 0.3771 - acc: 0.8500 - val_loss: 0.4302 - val_acc: 0.8000\n",
            "Epoch 2117/4500\n",
            "100/100 [==============================] - 0s 532us/step - loss: 0.3770 - acc: 0.8500 - val_loss: 0.4305 - val_acc: 0.8000\n",
            "Epoch 2118/4500\n",
            "100/100 [==============================] - 0s 491us/step - loss: 0.3772 - acc: 0.8500 - val_loss: 0.4299 - val_acc: 0.7900\n",
            "Epoch 2119/4500\n",
            "100/100 [==============================] - 0s 629us/step - loss: 0.3778 - acc: 0.8500 - val_loss: 0.4298 - val_acc: 0.7900\n",
            "Epoch 2120/4500\n",
            "100/100 [==============================] - 0s 531us/step - loss: 0.3753 - acc: 0.8500 - val_loss: 0.4285 - val_acc: 0.7900\n",
            "Epoch 2121/4500\n",
            "100/100 [==============================] - 0s 518us/step - loss: 0.3767 - acc: 0.8400 - val_loss: 0.4282 - val_acc: 0.7800\n",
            "Epoch 2122/4500\n",
            "100/100 [==============================] - 0s 521us/step - loss: 0.3753 - acc: 0.8500 - val_loss: 0.4285 - val_acc: 0.7900\n",
            "Epoch 2123/4500\n",
            "100/100 [==============================] - 0s 504us/step - loss: 0.3745 - acc: 0.8500 - val_loss: 0.4285 - val_acc: 0.7900\n",
            "Epoch 2124/4500\n",
            "100/100 [==============================] - 0s 511us/step - loss: 0.3745 - acc: 0.8500 - val_loss: 0.4285 - val_acc: 0.7900\n",
            "Epoch 2125/4500\n",
            "100/100 [==============================] - 0s 515us/step - loss: 0.3750 - acc: 0.8500 - val_loss: 0.4288 - val_acc: 0.7900\n",
            "Epoch 2126/4500\n",
            "100/100 [==============================] - 0s 549us/step - loss: 0.3752 - acc: 0.8400 - val_loss: 0.4287 - val_acc: 0.7900\n",
            "Epoch 2127/4500\n",
            "100/100 [==============================] - 0s 534us/step - loss: 0.3754 - acc: 0.8400 - val_loss: 0.4279 - val_acc: 0.7800\n",
            "Epoch 2128/4500\n",
            "100/100 [==============================] - 0s 550us/step - loss: 0.3749 - acc: 0.8500 - val_loss: 0.4290 - val_acc: 0.7900\n",
            "Epoch 2129/4500\n",
            "100/100 [==============================] - 0s 525us/step - loss: 0.3738 - acc: 0.8500 - val_loss: 0.4279 - val_acc: 0.7800\n",
            "Epoch 2130/4500\n",
            "100/100 [==============================] - 0s 501us/step - loss: 0.3737 - acc: 0.8500 - val_loss: 0.4281 - val_acc: 0.7900\n",
            "Epoch 2131/4500\n",
            "100/100 [==============================] - 0s 494us/step - loss: 0.3736 - acc: 0.8500 - val_loss: 0.4271 - val_acc: 0.7900\n",
            "Epoch 2132/4500\n",
            "100/100 [==============================] - 0s 507us/step - loss: 0.3731 - acc: 0.8400 - val_loss: 0.4276 - val_acc: 0.7800\n",
            "Epoch 2133/4500\n",
            "100/100 [==============================] - 0s 551us/step - loss: 0.3720 - acc: 0.8500 - val_loss: 0.4284 - val_acc: 0.7900\n",
            "Epoch 2134/4500\n",
            "100/100 [==============================] - 0s 519us/step - loss: 0.3805 - acc: 0.8400 - val_loss: 0.4267 - val_acc: 0.7800\n",
            "Epoch 2135/4500\n",
            "100/100 [==============================] - 0s 514us/step - loss: 0.3687 - acc: 0.8400 - val_loss: 0.4291 - val_acc: 0.7900\n",
            "Epoch 2136/4500\n",
            "100/100 [==============================] - 0s 535us/step - loss: 0.3716 - acc: 0.8600 - val_loss: 0.4302 - val_acc: 0.7900\n",
            "Epoch 2137/4500\n",
            "100/100 [==============================] - 0s 486us/step - loss: 0.3709 - acc: 0.8600 - val_loss: 0.4279 - val_acc: 0.7900\n",
            "Epoch 2138/4500\n",
            "100/100 [==============================] - 0s 576us/step - loss: 0.3711 - acc: 0.8400 - val_loss: 0.4262 - val_acc: 0.7900\n",
            "Epoch 2139/4500\n",
            "100/100 [==============================] - 0s 526us/step - loss: 0.3692 - acc: 0.8400 - val_loss: 0.4267 - val_acc: 0.7800\n",
            "Epoch 2140/4500\n",
            "100/100 [==============================] - 0s 626us/step - loss: 0.3698 - acc: 0.8400 - val_loss: 0.4269 - val_acc: 0.7800\n",
            "Epoch 2141/4500\n",
            "100/100 [==============================] - 0s 614us/step - loss: 0.3694 - acc: 0.8400 - val_loss: 0.4278 - val_acc: 0.7800\n",
            "Epoch 2142/4500\n",
            "100/100 [==============================] - 0s 498us/step - loss: 0.3725 - acc: 0.8500 - val_loss: 0.4278 - val_acc: 0.7800\n",
            "Epoch 2143/4500\n",
            "100/100 [==============================] - 0s 481us/step - loss: 0.3720 - acc: 0.8400 - val_loss: 0.4262 - val_acc: 0.7900\n",
            "Epoch 2144/4500\n",
            "100/100 [==============================] - 0s 487us/step - loss: 0.3730 - acc: 0.8500 - val_loss: 0.4295 - val_acc: 0.7900\n",
            "Epoch 2145/4500\n",
            "100/100 [==============================] - 0s 523us/step - loss: 0.3686 - acc: 0.8500 - val_loss: 0.4272 - val_acc: 0.7800\n",
            "Epoch 2146/4500\n",
            "100/100 [==============================] - 0s 534us/step - loss: 0.3675 - acc: 0.8400 - val_loss: 0.4260 - val_acc: 0.7800\n",
            "Epoch 2147/4500\n",
            "100/100 [==============================] - 0s 490us/step - loss: 0.3682 - acc: 0.8400 - val_loss: 0.4260 - val_acc: 0.7900\n",
            "Epoch 2148/4500\n",
            "100/100 [==============================] - 0s 492us/step - loss: 0.3672 - acc: 0.8400 - val_loss: 0.4265 - val_acc: 0.7900\n",
            "Epoch 2149/4500\n",
            "100/100 [==============================] - 0s 496us/step - loss: 0.3672 - acc: 0.8400 - val_loss: 0.4267 - val_acc: 0.7900\n",
            "Epoch 2150/4500\n",
            "100/100 [==============================] - 0s 508us/step - loss: 0.3661 - acc: 0.8400 - val_loss: 0.4268 - val_acc: 0.7900\n",
            "Epoch 2151/4500\n",
            "100/100 [==============================] - 0s 506us/step - loss: 0.3713 - acc: 0.8400 - val_loss: 0.4277 - val_acc: 0.7900\n",
            "Epoch 2152/4500\n",
            "100/100 [==============================] - 0s 533us/step - loss: 0.3670 - acc: 0.8400 - val_loss: 0.4257 - val_acc: 0.7900\n",
            "Epoch 2153/4500\n",
            "100/100 [==============================] - 0s 502us/step - loss: 0.3655 - acc: 0.8500 - val_loss: 0.4257 - val_acc: 0.7900\n",
            "Epoch 2154/4500\n",
            "100/100 [==============================] - 0s 497us/step - loss: 0.3666 - acc: 0.8400 - val_loss: 0.4267 - val_acc: 0.7900\n",
            "Epoch 2155/4500\n",
            "100/100 [==============================] - 0s 476us/step - loss: 0.3657 - acc: 0.8400 - val_loss: 0.4262 - val_acc: 0.7900\n",
            "Epoch 2156/4500\n",
            "100/100 [==============================] - 0s 571us/step - loss: 0.3646 - acc: 0.8400 - val_loss: 0.4261 - val_acc: 0.7900\n",
            "Epoch 2157/4500\n",
            "100/100 [==============================] - 0s 580us/step - loss: 0.3676 - acc: 0.8400 - val_loss: 0.4271 - val_acc: 0.7800\n",
            "Epoch 2158/4500\n",
            "100/100 [==============================] - 0s 498us/step - loss: 0.3633 - acc: 0.8400 - val_loss: 0.4258 - val_acc: 0.7900\n",
            "Epoch 2159/4500\n",
            "100/100 [==============================] - 0s 529us/step - loss: 0.3662 - acc: 0.8500 - val_loss: 0.4258 - val_acc: 0.7900\n",
            "Epoch 2160/4500\n",
            "100/100 [==============================] - 0s 538us/step - loss: 0.3646 - acc: 0.8500 - val_loss: 0.4261 - val_acc: 0.7900\n",
            "Epoch 2161/4500\n",
            "100/100 [==============================] - 0s 504us/step - loss: 0.3642 - acc: 0.8400 - val_loss: 0.4260 - val_acc: 0.7900\n",
            "Epoch 2162/4500\n",
            "100/100 [==============================] - 0s 491us/step - loss: 0.3675 - acc: 0.8400 - val_loss: 0.4266 - val_acc: 0.7800\n",
            "Epoch 2163/4500\n",
            "100/100 [==============================] - 0s 514us/step - loss: 0.3653 - acc: 0.8400 - val_loss: 0.4254 - val_acc: 0.7900\n",
            "Epoch 2164/4500\n",
            "100/100 [==============================] - 0s 528us/step - loss: 0.3648 - acc: 0.8600 - val_loss: 0.4250 - val_acc: 0.7900\n",
            "Epoch 2165/4500\n",
            "100/100 [==============================] - 0s 503us/step - loss: 0.3633 - acc: 0.8500 - val_loss: 0.4263 - val_acc: 0.7900\n",
            "Epoch 2166/4500\n",
            "100/100 [==============================] - 0s 535us/step - loss: 0.3640 - acc: 0.8400 - val_loss: 0.4258 - val_acc: 0.7900\n",
            "Epoch 2167/4500\n",
            "100/100 [==============================] - 0s 490us/step - loss: 0.3633 - acc: 0.8400 - val_loss: 0.4265 - val_acc: 0.7900\n",
            "Epoch 2168/4500\n",
            "100/100 [==============================] - 0s 506us/step - loss: 0.3627 - acc: 0.8400 - val_loss: 0.4256 - val_acc: 0.7900\n",
            "Epoch 2169/4500\n",
            "100/100 [==============================] - 0s 642us/step - loss: 0.3641 - acc: 0.8500 - val_loss: 0.4248 - val_acc: 0.7900\n",
            "Epoch 2170/4500\n",
            "100/100 [==============================] - 0s 635us/step - loss: 0.3615 - acc: 0.8600 - val_loss: 0.4255 - val_acc: 0.7900\n",
            "Epoch 2171/4500\n",
            "100/100 [==============================] - 0s 601us/step - loss: 0.3639 - acc: 0.8500 - val_loss: 0.4282 - val_acc: 0.7800\n",
            "Epoch 2172/4500\n",
            "100/100 [==============================] - 0s 634us/step - loss: 0.3673 - acc: 0.8500 - val_loss: 0.4250 - val_acc: 0.7900\n",
            "Epoch 2173/4500\n",
            "100/100 [==============================] - 0s 509us/step - loss: 0.3612 - acc: 0.8500 - val_loss: 0.4253 - val_acc: 0.7900\n",
            "Epoch 2174/4500\n",
            "100/100 [==============================] - 0s 519us/step - loss: 0.3618 - acc: 0.8500 - val_loss: 0.4261 - val_acc: 0.7900\n",
            "Epoch 2175/4500\n",
            "100/100 [==============================] - 0s 729us/step - loss: 0.3649 - acc: 0.8400 - val_loss: 0.4247 - val_acc: 0.7900\n",
            "Epoch 2176/4500\n",
            "100/100 [==============================] - 0s 583us/step - loss: 0.3634 - acc: 0.8400 - val_loss: 0.4256 - val_acc: 0.7900\n",
            "Epoch 2177/4500\n",
            "100/100 [==============================] - 0s 510us/step - loss: 0.3598 - acc: 0.8600 - val_loss: 0.4247 - val_acc: 0.7800\n",
            "Epoch 2178/4500\n",
            "100/100 [==============================] - 0s 498us/step - loss: 0.3594 - acc: 0.8600 - val_loss: 0.4248 - val_acc: 0.8000\n",
            "Epoch 2179/4500\n",
            "100/100 [==============================] - 0s 489us/step - loss: 0.3592 - acc: 0.8600 - val_loss: 0.4250 - val_acc: 0.7900\n",
            "Epoch 2180/4500\n",
            "100/100 [==============================] - 0s 497us/step - loss: 0.3604 - acc: 0.8600 - val_loss: 0.4249 - val_acc: 0.8000\n",
            "Epoch 2181/4500\n",
            "100/100 [==============================] - 0s 515us/step - loss: 0.3605 - acc: 0.8600 - val_loss: 0.4255 - val_acc: 0.7900\n",
            "Epoch 2182/4500\n",
            "100/100 [==============================] - 0s 499us/step - loss: 0.3607 - acc: 0.8400 - val_loss: 0.4264 - val_acc: 0.7900\n",
            "Epoch 2183/4500\n",
            "100/100 [==============================] - 0s 496us/step - loss: 0.3638 - acc: 0.8500 - val_loss: 0.4245 - val_acc: 0.7800\n",
            "Epoch 2184/4500\n",
            "100/100 [==============================] - 0s 502us/step - loss: 0.3628 - acc: 0.8600 - val_loss: 0.4246 - val_acc: 0.7900\n",
            "Epoch 2185/4500\n",
            "100/100 [==============================] - 0s 570us/step - loss: 0.3638 - acc: 0.8400 - val_loss: 0.4247 - val_acc: 0.8000\n",
            "Epoch 2186/4500\n",
            "100/100 [==============================] - 0s 560us/step - loss: 0.3633 - acc: 0.8600 - val_loss: 0.4243 - val_acc: 0.7800\n",
            "Epoch 2187/4500\n",
            "100/100 [==============================] - 0s 512us/step - loss: 0.3620 - acc: 0.8400 - val_loss: 0.4291 - val_acc: 0.7800\n",
            "Epoch 2188/4500\n",
            "100/100 [==============================] - 0s 520us/step - loss: 0.3599 - acc: 0.8600 - val_loss: 0.4263 - val_acc: 0.7900\n",
            "Epoch 2189/4500\n",
            "100/100 [==============================] - 0s 505us/step - loss: 0.3582 - acc: 0.8600 - val_loss: 0.4246 - val_acc: 0.7800\n",
            "Epoch 2190/4500\n",
            "100/100 [==============================] - 0s 537us/step - loss: 0.3587 - acc: 0.8600 - val_loss: 0.4249 - val_acc: 0.8000\n",
            "Epoch 2191/4500\n",
            "100/100 [==============================] - 0s 646us/step - loss: 0.3587 - acc: 0.8500 - val_loss: 0.4277 - val_acc: 0.7800\n",
            "Epoch 2192/4500\n",
            "100/100 [==============================] - 0s 560us/step - loss: 0.3576 - acc: 0.8500 - val_loss: 0.4263 - val_acc: 0.7900\n",
            "Epoch 2193/4500\n",
            "100/100 [==============================] - 0s 526us/step - loss: 0.3586 - acc: 0.8600 - val_loss: 0.4244 - val_acc: 0.7800\n",
            "Epoch 2194/4500\n",
            "100/100 [==============================] - 0s 679us/step - loss: 0.3587 - acc: 0.8600 - val_loss: 0.4245 - val_acc: 0.8000\n",
            "Epoch 2195/4500\n",
            "100/100 [==============================] - 0s 505us/step - loss: 0.3650 - acc: 0.8500 - val_loss: 0.4273 - val_acc: 0.7800\n",
            "Epoch 2196/4500\n",
            "100/100 [==============================] - 0s 488us/step - loss: 0.3569 - acc: 0.8400 - val_loss: 0.4250 - val_acc: 0.7900\n",
            "Epoch 2197/4500\n",
            "100/100 [==============================] - 0s 497us/step - loss: 0.3611 - acc: 0.8600 - val_loss: 0.4238 - val_acc: 0.7800\n",
            "Epoch 2198/4500\n",
            "100/100 [==============================] - 0s 483us/step - loss: 0.3614 - acc: 0.8500 - val_loss: 0.4242 - val_acc: 0.7800\n",
            "Epoch 2199/4500\n",
            "100/100 [==============================] - 0s 514us/step - loss: 0.3604 - acc: 0.8600 - val_loss: 0.4246 - val_acc: 0.8000\n",
            "Epoch 2200/4500\n",
            "100/100 [==============================] - 0s 497us/step - loss: 0.3575 - acc: 0.8600 - val_loss: 0.4242 - val_acc: 0.8000\n",
            "Epoch 2201/4500\n",
            "100/100 [==============================] - 0s 513us/step - loss: 0.3569 - acc: 0.8600 - val_loss: 0.4236 - val_acc: 0.7900\n",
            "Epoch 2202/4500\n",
            "100/100 [==============================] - 0s 522us/step - loss: 0.3589 - acc: 0.8500 - val_loss: 0.4238 - val_acc: 0.7800\n",
            "Epoch 2203/4500\n",
            "100/100 [==============================] - 0s 514us/step - loss: 0.3579 - acc: 0.8400 - val_loss: 0.4276 - val_acc: 0.7800\n",
            "Epoch 2204/4500\n",
            "100/100 [==============================] - 0s 501us/step - loss: 0.3559 - acc: 0.8500 - val_loss: 0.4254 - val_acc: 0.8000\n",
            "Epoch 2205/4500\n",
            "100/100 [==============================] - 0s 519us/step - loss: 0.3549 - acc: 0.8600 - val_loss: 0.4252 - val_acc: 0.8000\n",
            "Epoch 2206/4500\n",
            "100/100 [==============================] - 0s 493us/step - loss: 0.3544 - acc: 0.8600 - val_loss: 0.4245 - val_acc: 0.8000\n",
            "Epoch 2207/4500\n",
            "100/100 [==============================] - 0s 532us/step - loss: 0.3550 - acc: 0.8600 - val_loss: 0.4250 - val_acc: 0.8000\n",
            "Epoch 2208/4500\n",
            "100/100 [==============================] - 0s 686us/step - loss: 0.3567 - acc: 0.8600 - val_loss: 0.4251 - val_acc: 0.8000\n",
            "Epoch 2209/4500\n",
            "100/100 [==============================] - 0s 586us/step - loss: 0.3568 - acc: 0.8600 - val_loss: 0.4239 - val_acc: 0.7800\n",
            "Epoch 2210/4500\n",
            "100/100 [==============================] - 0s 546us/step - loss: 0.3549 - acc: 0.8600 - val_loss: 0.4241 - val_acc: 0.7800\n",
            "Epoch 2211/4500\n",
            "100/100 [==============================] - 0s 525us/step - loss: 0.3547 - acc: 0.8600 - val_loss: 0.4256 - val_acc: 0.7900\n",
            "Epoch 2212/4500\n",
            "100/100 [==============================] - 0s 498us/step - loss: 0.3600 - acc: 0.8600 - val_loss: 0.4239 - val_acc: 0.7800\n",
            "Epoch 2213/4500\n",
            "100/100 [==============================] - 0s 606us/step - loss: 0.3577 - acc: 0.8600 - val_loss: 0.4259 - val_acc: 0.8000\n",
            "Epoch 2214/4500\n",
            "100/100 [==============================] - 0s 554us/step - loss: 0.3547 - acc: 0.8600 - val_loss: 0.4244 - val_acc: 0.8000\n",
            "Epoch 2215/4500\n",
            "100/100 [==============================] - 0s 497us/step - loss: 0.3538 - acc: 0.8600 - val_loss: 0.4246 - val_acc: 0.8000\n",
            "Epoch 2216/4500\n",
            "100/100 [==============================] - 0s 503us/step - loss: 0.3538 - acc: 0.8600 - val_loss: 0.4250 - val_acc: 0.8000\n",
            "Epoch 2217/4500\n",
            "100/100 [==============================] - 0s 547us/step - loss: 0.3561 - acc: 0.8600 - val_loss: 0.4239 - val_acc: 0.7900\n",
            "Epoch 2218/4500\n",
            "100/100 [==============================] - 0s 514us/step - loss: 0.3539 - acc: 0.8600 - val_loss: 0.4247 - val_acc: 0.8000\n",
            "Epoch 2219/4500\n",
            "100/100 [==============================] - 0s 505us/step - loss: 0.3592 - acc: 0.8500 - val_loss: 0.4282 - val_acc: 0.7800\n",
            "Epoch 2220/4500\n",
            "100/100 [==============================] - 0s 527us/step - loss: 0.3536 - acc: 0.8500 - val_loss: 0.4262 - val_acc: 0.7900\n",
            "Epoch 2221/4500\n",
            "100/100 [==============================] - 0s 514us/step - loss: 0.3525 - acc: 0.8600 - val_loss: 0.4243 - val_acc: 0.8000\n",
            "Epoch 2222/4500\n",
            "100/100 [==============================] - 0s 525us/step - loss: 0.3528 - acc: 0.8600 - val_loss: 0.4231 - val_acc: 0.7900\n",
            "Epoch 2223/4500\n",
            "100/100 [==============================] - 0s 551us/step - loss: 0.3529 - acc: 0.8500 - val_loss: 0.4235 - val_acc: 0.7900\n",
            "Epoch 2224/4500\n",
            "100/100 [==============================] - 0s 525us/step - loss: 0.3542 - acc: 0.8600 - val_loss: 0.4254 - val_acc: 0.8000\n",
            "Epoch 2225/4500\n",
            "100/100 [==============================] - 0s 501us/step - loss: 0.3546 - acc: 0.8600 - val_loss: 0.4279 - val_acc: 0.7800\n",
            "Epoch 2226/4500\n",
            "100/100 [==============================] - 0s 501us/step - loss: 0.3508 - acc: 0.8600 - val_loss: 0.4245 - val_acc: 0.7800\n",
            "Epoch 2227/4500\n",
            "100/100 [==============================] - 0s 513us/step - loss: 0.3525 - acc: 0.8600 - val_loss: 0.4234 - val_acc: 0.7900\n",
            "Epoch 2228/4500\n",
            "100/100 [==============================] - 0s 506us/step - loss: 0.3508 - acc: 0.8600 - val_loss: 0.4240 - val_acc: 0.7900\n",
            "Epoch 2229/4500\n",
            "100/100 [==============================] - 0s 499us/step - loss: 0.3514 - acc: 0.8600 - val_loss: 0.4253 - val_acc: 0.8000\n",
            "Epoch 2230/4500\n",
            "100/100 [==============================] - 0s 497us/step - loss: 0.3514 - acc: 0.8600 - val_loss: 0.4242 - val_acc: 0.7900\n",
            "Epoch 2231/4500\n",
            "100/100 [==============================] - 0s 497us/step - loss: 0.3492 - acc: 0.8600 - val_loss: 0.4246 - val_acc: 0.7900\n",
            "Epoch 2232/4500\n",
            "100/100 [==============================] - 0s 567us/step - loss: 0.3516 - acc: 0.8600 - val_loss: 0.4237 - val_acc: 0.7900\n",
            "Epoch 2233/4500\n",
            "100/100 [==============================] - 0s 535us/step - loss: 0.3494 - acc: 0.8600 - val_loss: 0.4246 - val_acc: 0.8000\n",
            "Epoch 2234/4500\n",
            "100/100 [==============================] - 0s 588us/step - loss: 0.3520 - acc: 0.8600 - val_loss: 0.4255 - val_acc: 0.7900\n",
            "Epoch 2235/4500\n",
            "100/100 [==============================] - 0s 495us/step - loss: 0.3504 - acc: 0.8600 - val_loss: 0.4209 - val_acc: 0.7900\n",
            "Epoch 2236/4500\n",
            "100/100 [==============================] - 0s 481us/step - loss: 0.3623 - acc: 0.8600 - val_loss: 0.4226 - val_acc: 0.7900\n",
            "Epoch 2237/4500\n",
            "100/100 [==============================] - 0s 511us/step - loss: 0.3502 - acc: 0.8600 - val_loss: 0.4232 - val_acc: 0.7900\n",
            "Epoch 2238/4500\n",
            "100/100 [==============================] - 0s 512us/step - loss: 0.3493 - acc: 0.8600 - val_loss: 0.4243 - val_acc: 0.8000\n",
            "Epoch 2239/4500\n",
            "100/100 [==============================] - 0s 487us/step - loss: 0.3524 - acc: 0.8600 - val_loss: 0.4236 - val_acc: 0.7900\n",
            "Epoch 2240/4500\n",
            "100/100 [==============================] - 0s 530us/step - loss: 0.3488 - acc: 0.8600 - val_loss: 0.4229 - val_acc: 0.7900\n",
            "Epoch 2241/4500\n",
            "100/100 [==============================] - 0s 510us/step - loss: 0.3541 - acc: 0.8600 - val_loss: 0.4225 - val_acc: 0.7900\n",
            "Epoch 2242/4500\n",
            "100/100 [==============================] - 0s 512us/step - loss: 0.3543 - acc: 0.8600 - val_loss: 0.4211 - val_acc: 0.7900\n",
            "Epoch 2243/4500\n",
            "100/100 [==============================] - 0s 497us/step - loss: 0.3525 - acc: 0.8600 - val_loss: 0.4234 - val_acc: 0.7800\n",
            "Epoch 2244/4500\n",
            "100/100 [==============================] - 0s 550us/step - loss: 0.3501 - acc: 0.8600 - val_loss: 0.4231 - val_acc: 0.7900\n",
            "Epoch 2245/4500\n",
            "100/100 [==============================] - 0s 579us/step - loss: 0.3505 - acc: 0.8600 - val_loss: 0.4227 - val_acc: 0.7900\n",
            "Epoch 2246/4500\n",
            "100/100 [==============================] - 0s 505us/step - loss: 0.3495 - acc: 0.8600 - val_loss: 0.4246 - val_acc: 0.8000\n",
            "Epoch 2247/4500\n",
            "100/100 [==============================] - 0s 495us/step - loss: 0.3495 - acc: 0.8600 - val_loss: 0.4243 - val_acc: 0.8000\n",
            "Epoch 2248/4500\n",
            "100/100 [==============================] - 0s 510us/step - loss: 0.3492 - acc: 0.8600 - val_loss: 0.4233 - val_acc: 0.7900\n",
            "Epoch 2249/4500\n",
            "100/100 [==============================] - 0s 504us/step - loss: 0.3478 - acc: 0.8600 - val_loss: 0.4237 - val_acc: 0.7900\n",
            "Epoch 2250/4500\n",
            "100/100 [==============================] - 0s 499us/step - loss: 0.3495 - acc: 0.8600 - val_loss: 0.4248 - val_acc: 0.8000\n",
            "Epoch 2251/4500\n",
            "100/100 [==============================] - 0s 600us/step - loss: 0.3495 - acc: 0.8600 - val_loss: 0.4230 - val_acc: 0.7900\n",
            "Epoch 2252/4500\n",
            "100/100 [==============================] - 0s 522us/step - loss: 0.3483 - acc: 0.8600 - val_loss: 0.4230 - val_acc: 0.7900\n",
            "Epoch 2253/4500\n",
            "100/100 [==============================] - 0s 501us/step - loss: 0.3495 - acc: 0.8500 - val_loss: 0.4225 - val_acc: 0.7900\n",
            "Epoch 2254/4500\n",
            "100/100 [==============================] - 0s 606us/step - loss: 0.3478 - acc: 0.8600 - val_loss: 0.4247 - val_acc: 0.8000\n",
            "Epoch 2255/4500\n",
            "100/100 [==============================] - 0s 544us/step - loss: 0.3471 - acc: 0.8600 - val_loss: 0.4247 - val_acc: 0.8000\n",
            "Epoch 2256/4500\n",
            "100/100 [==============================] - 0s 508us/step - loss: 0.3482 - acc: 0.8600 - val_loss: 0.4245 - val_acc: 0.8000\n",
            "Epoch 2257/4500\n",
            "100/100 [==============================] - 0s 492us/step - loss: 0.3468 - acc: 0.8600 - val_loss: 0.4239 - val_acc: 0.7900\n",
            "Epoch 2258/4500\n",
            "100/100 [==============================] - 0s 489us/step - loss: 0.3507 - acc: 0.8600 - val_loss: 0.4225 - val_acc: 0.7900\n",
            "Epoch 2259/4500\n",
            "100/100 [==============================] - 0s 483us/step - loss: 0.3476 - acc: 0.8600 - val_loss: 0.4258 - val_acc: 0.7900\n",
            "Epoch 2260/4500\n",
            "100/100 [==============================] - 0s 508us/step - loss: 0.3474 - acc: 0.8600 - val_loss: 0.4233 - val_acc: 0.7800\n",
            "Epoch 2261/4500\n",
            "100/100 [==============================] - 0s 551us/step - loss: 0.3517 - acc: 0.8600 - val_loss: 0.4241 - val_acc: 0.8000\n",
            "Epoch 2262/4500\n",
            "100/100 [==============================] - 0s 518us/step - loss: 0.3491 - acc: 0.8600 - val_loss: 0.4230 - val_acc: 0.7800\n",
            "Epoch 2263/4500\n",
            "100/100 [==============================] - 0s 491us/step - loss: 0.3483 - acc: 0.8600 - val_loss: 0.4227 - val_acc: 0.7900\n",
            "Epoch 2264/4500\n",
            "100/100 [==============================] - 0s 627us/step - loss: 0.3472 - acc: 0.8600 - val_loss: 0.4221 - val_acc: 0.7900\n",
            "Epoch 2265/4500\n",
            "100/100 [==============================] - 0s 516us/step - loss: 0.3474 - acc: 0.8600 - val_loss: 0.4234 - val_acc: 0.7900\n",
            "Epoch 2266/4500\n",
            "100/100 [==============================] - 0s 516us/step - loss: 0.3457 - acc: 0.8600 - val_loss: 0.4225 - val_acc: 0.7900\n",
            "Epoch 2267/4500\n",
            "100/100 [==============================] - 0s 502us/step - loss: 0.3514 - acc: 0.8500 - val_loss: 0.4217 - val_acc: 0.7900\n",
            "Epoch 2268/4500\n",
            "100/100 [==============================] - 0s 504us/step - loss: 0.3462 - acc: 0.8600 - val_loss: 0.4240 - val_acc: 0.8000\n",
            "Epoch 2269/4500\n",
            "100/100 [==============================] - 0s 489us/step - loss: 0.3456 - acc: 0.8600 - val_loss: 0.4244 - val_acc: 0.8000\n",
            "Epoch 2270/4500\n",
            "100/100 [==============================] - 0s 563us/step - loss: 0.3460 - acc: 0.8600 - val_loss: 0.4235 - val_acc: 0.7900\n",
            "Epoch 2271/4500\n",
            "100/100 [==============================] - 0s 527us/step - loss: 0.3464 - acc: 0.8600 - val_loss: 0.4230 - val_acc: 0.7900\n",
            "Epoch 2272/4500\n",
            "100/100 [==============================] - 0s 516us/step - loss: 0.3452 - acc: 0.8600 - val_loss: 0.4233 - val_acc: 0.7900\n",
            "Epoch 2273/4500\n",
            "100/100 [==============================] - 0s 489us/step - loss: 0.3485 - acc: 0.8600 - val_loss: 0.4233 - val_acc: 0.7900\n",
            "Epoch 2274/4500\n",
            "100/100 [==============================] - 0s 528us/step - loss: 0.3453 - acc: 0.8600 - val_loss: 0.4183 - val_acc: 0.7900\n",
            "Epoch 2275/4500\n",
            "100/100 [==============================] - 0s 513us/step - loss: 0.3491 - acc: 0.8600 - val_loss: 0.4213 - val_acc: 0.7800\n",
            "Epoch 2276/4500\n",
            "100/100 [==============================] - 0s 518us/step - loss: 0.3478 - acc: 0.8600 - val_loss: 0.4218 - val_acc: 0.7900\n",
            "Epoch 2277/4500\n",
            "100/100 [==============================] - 0s 496us/step - loss: 0.3442 - acc: 0.8600 - val_loss: 0.4235 - val_acc: 0.7900\n",
            "Epoch 2278/4500\n",
            "100/100 [==============================] - 0s 494us/step - loss: 0.3473 - acc: 0.8600 - val_loss: 0.4228 - val_acc: 0.7900\n",
            "Epoch 2279/4500\n",
            "100/100 [==============================] - 0s 494us/step - loss: 0.3482 - acc: 0.8600 - val_loss: 0.4262 - val_acc: 0.7900\n",
            "Epoch 2280/4500\n",
            "100/100 [==============================] - 0s 564us/step - loss: 0.3459 - acc: 0.8600 - val_loss: 0.4224 - val_acc: 0.7800\n",
            "Epoch 2281/4500\n",
            "100/100 [==============================] - 0s 502us/step - loss: 0.3450 - acc: 0.8600 - val_loss: 0.4221 - val_acc: 0.7800\n",
            "Epoch 2282/4500\n",
            "100/100 [==============================] - 0s 492us/step - loss: 0.3489 - acc: 0.8500 - val_loss: 0.4218 - val_acc: 0.7900\n",
            "Epoch 2283/4500\n",
            "100/100 [==============================] - 0s 502us/step - loss: 0.3447 - acc: 0.8600 - val_loss: 0.4234 - val_acc: 0.7800\n",
            "Epoch 2284/4500\n",
            "100/100 [==============================] - 0s 548us/step - loss: 0.3446 - acc: 0.8600 - val_loss: 0.4218 - val_acc: 0.7900\n",
            "Epoch 2285/4500\n",
            "100/100 [==============================] - 0s 514us/step - loss: 0.3430 - acc: 0.8600 - val_loss: 0.4221 - val_acc: 0.7800\n",
            "Epoch 2286/4500\n",
            "100/100 [==============================] - 0s 493us/step - loss: 0.3480 - acc: 0.8600 - val_loss: 0.4258 - val_acc: 0.7900\n",
            "Epoch 2287/4500\n",
            "100/100 [==============================] - 0s 539us/step - loss: 0.3438 - acc: 0.8600 - val_loss: 0.4218 - val_acc: 0.7900\n",
            "Epoch 2288/4500\n",
            "100/100 [==============================] - 0s 498us/step - loss: 0.3437 - acc: 0.8600 - val_loss: 0.4220 - val_acc: 0.7800\n",
            "Epoch 2289/4500\n",
            "100/100 [==============================] - 0s 497us/step - loss: 0.3450 - acc: 0.8500 - val_loss: 0.4209 - val_acc: 0.7900\n",
            "Epoch 2290/4500\n",
            "100/100 [==============================] - 0s 577us/step - loss: 0.3446 - acc: 0.8600 - val_loss: 0.4232 - val_acc: 0.7800\n",
            "Epoch 2291/4500\n",
            "100/100 [==============================] - 0s 519us/step - loss: 0.3445 - acc: 0.8600 - val_loss: 0.4230 - val_acc: 0.7800\n",
            "Epoch 2292/4500\n",
            "100/100 [==============================] - 0s 492us/step - loss: 0.3446 - acc: 0.8600 - val_loss: 0.4212 - val_acc: 0.7900\n",
            "Epoch 2293/4500\n",
            "100/100 [==============================] - 0s 504us/step - loss: 0.3438 - acc: 0.8600 - val_loss: 0.4217 - val_acc: 0.7900\n",
            "Epoch 2294/4500\n",
            "100/100 [==============================] - 0s 514us/step - loss: 0.3438 - acc: 0.8600 - val_loss: 0.4207 - val_acc: 0.7900\n",
            "Epoch 2295/4500\n",
            "100/100 [==============================] - 0s 502us/step - loss: 0.3480 - acc: 0.8600 - val_loss: 0.4221 - val_acc: 0.7900\n",
            "Epoch 2296/4500\n",
            "100/100 [==============================] - 0s 534us/step - loss: 0.3438 - acc: 0.8600 - val_loss: 0.4219 - val_acc: 0.7900\n",
            "Epoch 2297/4500\n",
            "100/100 [==============================] - 0s 508us/step - loss: 0.3439 - acc: 0.8600 - val_loss: 0.4230 - val_acc: 0.7900\n",
            "Epoch 2298/4500\n",
            "100/100 [==============================] - 0s 519us/step - loss: 0.3437 - acc: 0.8600 - val_loss: 0.4210 - val_acc: 0.7900\n",
            "Epoch 2299/4500\n",
            "100/100 [==============================] - 0s 496us/step - loss: 0.3449 - acc: 0.8600 - val_loss: 0.4214 - val_acc: 0.7900\n",
            "Epoch 2300/4500\n",
            "100/100 [==============================] - 0s 516us/step - loss: 0.3475 - acc: 0.8600 - val_loss: 0.4210 - val_acc: 0.7900\n",
            "Epoch 2301/4500\n",
            "100/100 [==============================] - 0s 505us/step - loss: 0.3437 - acc: 0.8600 - val_loss: 0.4244 - val_acc: 0.7900\n",
            "Epoch 2302/4500\n",
            "100/100 [==============================] - 0s 506us/step - loss: 0.3439 - acc: 0.8600 - val_loss: 0.4232 - val_acc: 0.7900\n",
            "Epoch 2303/4500\n",
            "100/100 [==============================] - 0s 538us/step - loss: 0.3413 - acc: 0.8600 - val_loss: 0.4211 - val_acc: 0.7800\n",
            "Epoch 2304/4500\n",
            "100/100 [==============================] - 0s 544us/step - loss: 0.3426 - acc: 0.8600 - val_loss: 0.4208 - val_acc: 0.7900\n",
            "Epoch 2305/4500\n",
            "100/100 [==============================] - 0s 503us/step - loss: 0.3431 - acc: 0.8600 - val_loss: 0.4210 - val_acc: 0.7900\n",
            "Epoch 2306/4500\n",
            "100/100 [==============================] - 0s 527us/step - loss: 0.3416 - acc: 0.8600 - val_loss: 0.4217 - val_acc: 0.7900\n",
            "Epoch 2307/4500\n",
            "100/100 [==============================] - 0s 496us/step - loss: 0.3411 - acc: 0.8600 - val_loss: 0.4210 - val_acc: 0.7900\n",
            "Epoch 2308/4500\n",
            "100/100 [==============================] - 0s 513us/step - loss: 0.3436 - acc: 0.8500 - val_loss: 0.4199 - val_acc: 0.7900\n",
            "Epoch 2309/4500\n",
            "100/100 [==============================] - 0s 642us/step - loss: 0.3437 - acc: 0.8500 - val_loss: 0.4202 - val_acc: 0.7900\n",
            "Epoch 2310/4500\n",
            "100/100 [==============================] - 0s 527us/step - loss: 0.3434 - acc: 0.8600 - val_loss: 0.4237 - val_acc: 0.7900\n",
            "Epoch 2311/4500\n",
            "100/100 [==============================] - 0s 567us/step - loss: 0.3441 - acc: 0.8600 - val_loss: 0.4218 - val_acc: 0.7800\n",
            "Epoch 2312/4500\n",
            "100/100 [==============================] - 0s 525us/step - loss: 0.3405 - acc: 0.8600 - val_loss: 0.4208 - val_acc: 0.7900\n",
            "Epoch 2313/4500\n",
            "100/100 [==============================] - 0s 567us/step - loss: 0.3425 - acc: 0.8600 - val_loss: 0.4209 - val_acc: 0.7900\n",
            "Epoch 2314/4500\n",
            "100/100 [==============================] - 0s 639us/step - loss: 0.3406 - acc: 0.8600 - val_loss: 0.4214 - val_acc: 0.7800\n",
            "Epoch 2315/4500\n",
            "100/100 [==============================] - 0s 512us/step - loss: 0.3431 - acc: 0.8500 - val_loss: 0.4197 - val_acc: 0.7900\n",
            "Epoch 2316/4500\n",
            "100/100 [==============================] - 0s 504us/step - loss: 0.3418 - acc: 0.8600 - val_loss: 0.4216 - val_acc: 0.7800\n",
            "Epoch 2317/4500\n",
            "100/100 [==============================] - 0s 514us/step - loss: 0.3412 - acc: 0.8600 - val_loss: 0.4220 - val_acc: 0.7800\n",
            "Epoch 2318/4500\n",
            "100/100 [==============================] - 0s 561us/step - loss: 0.3410 - acc: 0.8600 - val_loss: 0.4211 - val_acc: 0.7800\n",
            "Epoch 2319/4500\n",
            "100/100 [==============================] - 0s 532us/step - loss: 0.3400 - acc: 0.8600 - val_loss: 0.4201 - val_acc: 0.7900\n",
            "Epoch 2320/4500\n",
            "100/100 [==============================] - 0s 535us/step - loss: 0.3395 - acc: 0.8600 - val_loss: 0.4204 - val_acc: 0.7900\n",
            "Epoch 2321/4500\n",
            "100/100 [==============================] - 0s 557us/step - loss: 0.3414 - acc: 0.8600 - val_loss: 0.4197 - val_acc: 0.7900\n",
            "Epoch 2322/4500\n",
            "100/100 [==============================] - 0s 519us/step - loss: 0.3398 - acc: 0.8600 - val_loss: 0.4199 - val_acc: 0.7900\n",
            "Epoch 2323/4500\n",
            "100/100 [==============================] - 0s 532us/step - loss: 0.3391 - acc: 0.8600 - val_loss: 0.4203 - val_acc: 0.7800\n",
            "Epoch 2324/4500\n",
            "100/100 [==============================] - 0s 569us/step - loss: 0.3419 - acc: 0.8600 - val_loss: 0.4221 - val_acc: 0.7900\n",
            "Epoch 2325/4500\n",
            "100/100 [==============================] - 0s 481us/step - loss: 0.3439 - acc: 0.8600 - val_loss: 0.4199 - val_acc: 0.7900\n",
            "Epoch 2326/4500\n",
            "100/100 [==============================] - 0s 491us/step - loss: 0.3453 - acc: 0.8600 - val_loss: 0.4179 - val_acc: 0.7900\n",
            "Epoch 2327/4500\n",
            "100/100 [==============================] - 0s 502us/step - loss: 0.3427 - acc: 0.8600 - val_loss: 0.4212 - val_acc: 0.7800\n",
            "Epoch 2328/4500\n",
            "100/100 [==============================] - 0s 601us/step - loss: 0.3390 - acc: 0.8600 - val_loss: 0.4205 - val_acc: 0.7800\n",
            "Epoch 2329/4500\n",
            "100/100 [==============================] - 0s 531us/step - loss: 0.3399 - acc: 0.8600 - val_loss: 0.4190 - val_acc: 0.7900\n",
            "Epoch 2330/4500\n",
            "100/100 [==============================] - 0s 497us/step - loss: 0.3388 - acc: 0.8600 - val_loss: 0.4198 - val_acc: 0.7900\n",
            "Epoch 2331/4500\n",
            "100/100 [==============================] - 0s 490us/step - loss: 0.3400 - acc: 0.8600 - val_loss: 0.4190 - val_acc: 0.7900\n",
            "Epoch 2332/4500\n",
            "100/100 [==============================] - 0s 503us/step - loss: 0.3383 - acc: 0.8600 - val_loss: 0.4194 - val_acc: 0.7900\n",
            "Epoch 2333/4500\n",
            "100/100 [==============================] - 0s 536us/step - loss: 0.3419 - acc: 0.8600 - val_loss: 0.4226 - val_acc: 0.7900\n",
            "Epoch 2334/4500\n",
            "100/100 [==============================] - 0s 517us/step - loss: 0.3396 - acc: 0.8600 - val_loss: 0.4206 - val_acc: 0.7800\n",
            "Epoch 2335/4500\n",
            "100/100 [==============================] - 0s 499us/step - loss: 0.3409 - acc: 0.8600 - val_loss: 0.4201 - val_acc: 0.7800\n",
            "Epoch 2336/4500\n",
            "100/100 [==============================] - 0s 517us/step - loss: 0.3375 - acc: 0.8600 - val_loss: 0.4186 - val_acc: 0.7900\n",
            "Epoch 2337/4500\n",
            "100/100 [==============================] - 0s 493us/step - loss: 0.3470 - acc: 0.8500 - val_loss: 0.4175 - val_acc: 0.7900\n",
            "Epoch 2338/4500\n",
            "100/100 [==============================] - 0s 493us/step - loss: 0.3379 - acc: 0.8600 - val_loss: 0.4210 - val_acc: 0.7900\n",
            "Epoch 2339/4500\n",
            "100/100 [==============================] - 0s 505us/step - loss: 0.3388 - acc: 0.8600 - val_loss: 0.4205 - val_acc: 0.7800\n",
            "Epoch 2340/4500\n",
            "100/100 [==============================] - 0s 500us/step - loss: 0.3379 - acc: 0.8600 - val_loss: 0.4202 - val_acc: 0.7800\n",
            "Epoch 2341/4500\n",
            "100/100 [==============================] - 0s 505us/step - loss: 0.3387 - acc: 0.8600 - val_loss: 0.4188 - val_acc: 0.7900\n",
            "Epoch 2342/4500\n",
            "100/100 [==============================] - 0s 521us/step - loss: 0.3375 - acc: 0.8600 - val_loss: 0.4191 - val_acc: 0.7800\n",
            "Epoch 2343/4500\n",
            "100/100 [==============================] - 0s 522us/step - loss: 0.3382 - acc: 0.8600 - val_loss: 0.4198 - val_acc: 0.7800\n",
            "Epoch 2344/4500\n",
            "100/100 [==============================] - 0s 599us/step - loss: 0.3401 - acc: 0.8600 - val_loss: 0.4215 - val_acc: 0.7900\n",
            "Epoch 2345/4500\n",
            "100/100 [==============================] - 0s 546us/step - loss: 0.3382 - acc: 0.8600 - val_loss: 0.4171 - val_acc: 0.7800\n",
            "Epoch 2346/4500\n",
            "100/100 [==============================] - 0s 504us/step - loss: 0.3379 - acc: 0.8600 - val_loss: 0.4178 - val_acc: 0.7900\n",
            "Epoch 2347/4500\n",
            "100/100 [==============================] - 0s 594us/step - loss: 0.3383 - acc: 0.8600 - val_loss: 0.4200 - val_acc: 0.7800\n",
            "Epoch 2348/4500\n",
            "100/100 [==============================] - 0s 542us/step - loss: 0.3377 - acc: 0.8600 - val_loss: 0.4190 - val_acc: 0.7800\n",
            "Epoch 2349/4500\n",
            "100/100 [==============================] - 0s 549us/step - loss: 0.3363 - acc: 0.8600 - val_loss: 0.4193 - val_acc: 0.7800\n",
            "Epoch 2350/4500\n",
            "100/100 [==============================] - 0s 555us/step - loss: 0.3359 - acc: 0.8600 - val_loss: 0.4184 - val_acc: 0.7800\n",
            "Epoch 2351/4500\n",
            "100/100 [==============================] - 0s 491us/step - loss: 0.3405 - acc: 0.8500 - val_loss: 0.4169 - val_acc: 0.7900\n",
            "Epoch 2352/4500\n",
            "100/100 [==============================] - 0s 487us/step - loss: 0.3365 - acc: 0.8600 - val_loss: 0.4203 - val_acc: 0.7900\n",
            "Epoch 2353/4500\n",
            "100/100 [==============================] - 0s 569us/step - loss: 0.3380 - acc: 0.8600 - val_loss: 0.4209 - val_acc: 0.7900\n",
            "Epoch 2354/4500\n",
            "100/100 [==============================] - 0s 559us/step - loss: 0.3351 - acc: 0.8600 - val_loss: 0.4180 - val_acc: 0.7800\n",
            "Epoch 2355/4500\n",
            "100/100 [==============================] - 0s 525us/step - loss: 0.3358 - acc: 0.8600 - val_loss: 0.4174 - val_acc: 0.7800\n",
            "Epoch 2356/4500\n",
            "100/100 [==============================] - 0s 494us/step - loss: 0.3362 - acc: 0.8600 - val_loss: 0.4187 - val_acc: 0.7800\n",
            "Epoch 2357/4500\n",
            "100/100 [==============================] - 0s 509us/step - loss: 0.3364 - acc: 0.8600 - val_loss: 0.4174 - val_acc: 0.7800\n",
            "Epoch 2358/4500\n",
            "100/100 [==============================] - 0s 488us/step - loss: 0.3353 - acc: 0.8600 - val_loss: 0.4177 - val_acc: 0.7800\n",
            "Epoch 2359/4500\n",
            "100/100 [==============================] - 0s 517us/step - loss: 0.3361 - acc: 0.8600 - val_loss: 0.4171 - val_acc: 0.7800\n",
            "Epoch 2360/4500\n",
            "100/100 [==============================] - 0s 546us/step - loss: 0.3350 - acc: 0.8600 - val_loss: 0.4185 - val_acc: 0.7800\n",
            "Epoch 2361/4500\n",
            "100/100 [==============================] - 0s 498us/step - loss: 0.3357 - acc: 0.8600 - val_loss: 0.4194 - val_acc: 0.7800\n",
            "Epoch 2362/4500\n",
            "100/100 [==============================] - 0s 501us/step - loss: 0.3350 - acc: 0.8600 - val_loss: 0.4180 - val_acc: 0.7800\n",
            "Epoch 2363/4500\n",
            "100/100 [==============================] - 0s 542us/step - loss: 0.3357 - acc: 0.8600 - val_loss: 0.4168 - val_acc: 0.7800\n",
            "Epoch 2364/4500\n",
            "100/100 [==============================] - 0s 504us/step - loss: 0.3372 - acc: 0.8600 - val_loss: 0.4187 - val_acc: 0.7800\n",
            "Epoch 2365/4500\n",
            "100/100 [==============================] - 0s 495us/step - loss: 0.3334 - acc: 0.8600 - val_loss: 0.4141 - val_acc: 0.7900\n",
            "Epoch 2366/4500\n",
            "100/100 [==============================] - 0s 595us/step - loss: 0.3401 - acc: 0.8600 - val_loss: 0.4161 - val_acc: 0.7900\n",
            "Epoch 2367/4500\n",
            "100/100 [==============================] - 0s 554us/step - loss: 0.3425 - acc: 0.8600 - val_loss: 0.4163 - val_acc: 0.7800\n",
            "Epoch 2368/4500\n",
            "100/100 [==============================] - 0s 515us/step - loss: 0.3379 - acc: 0.8600 - val_loss: 0.4192 - val_acc: 0.7800\n",
            "Epoch 2369/4500\n",
            "100/100 [==============================] - 0s 501us/step - loss: 0.3356 - acc: 0.8600 - val_loss: 0.4178 - val_acc: 0.7800\n",
            "Epoch 2370/4500\n",
            "100/100 [==============================] - 0s 506us/step - loss: 0.3350 - acc: 0.8600 - val_loss: 0.4169 - val_acc: 0.7800\n",
            "Epoch 2371/4500\n",
            "100/100 [==============================] - 0s 486us/step - loss: 0.3352 - acc: 0.8600 - val_loss: 0.4172 - val_acc: 0.7800\n",
            "Epoch 2372/4500\n",
            "100/100 [==============================] - 0s 494us/step - loss: 0.3367 - acc: 0.8600 - val_loss: 0.4199 - val_acc: 0.7900\n",
            "Epoch 2373/4500\n",
            "100/100 [==============================] - 0s 537us/step - loss: 0.3340 - acc: 0.8600 - val_loss: 0.4168 - val_acc: 0.7800\n",
            "Epoch 2374/4500\n",
            "100/100 [==============================] - 0s 490us/step - loss: 0.3342 - acc: 0.8600 - val_loss: 0.4164 - val_acc: 0.7800\n",
            "Epoch 2375/4500\n",
            "100/100 [==============================] - 0s 531us/step - loss: 0.3349 - acc: 0.8600 - val_loss: 0.4160 - val_acc: 0.7800\n",
            "Epoch 2376/4500\n",
            "100/100 [==============================] - 0s 500us/step - loss: 0.3338 - acc: 0.8600 - val_loss: 0.4166 - val_acc: 0.7800\n",
            "Epoch 2377/4500\n",
            "100/100 [==============================] - 0s 501us/step - loss: 0.3346 - acc: 0.8600 - val_loss: 0.4180 - val_acc: 0.7800\n",
            "Epoch 2378/4500\n",
            "100/100 [==============================] - 0s 485us/step - loss: 0.3370 - acc: 0.8500 - val_loss: 0.4152 - val_acc: 0.7700\n",
            "Epoch 2379/4500\n",
            "100/100 [==============================] - 0s 502us/step - loss: 0.3337 - acc: 0.8600 - val_loss: 0.4169 - val_acc: 0.7800\n",
            "Epoch 2380/4500\n",
            "100/100 [==============================] - 0s 542us/step - loss: 0.3339 - acc: 0.8600 - val_loss: 0.4168 - val_acc: 0.7800\n",
            "Epoch 2381/4500\n",
            "100/100 [==============================] - 0s 593us/step - loss: 0.3334 - acc: 0.8600 - val_loss: 0.4157 - val_acc: 0.7800\n",
            "Epoch 2382/4500\n",
            "100/100 [==============================] - 0s 548us/step - loss: 0.3327 - acc: 0.8600 - val_loss: 0.4155 - val_acc: 0.7800\n",
            "Epoch 2383/4500\n",
            "100/100 [==============================] - 0s 532us/step - loss: 0.3367 - acc: 0.8500 - val_loss: 0.4146 - val_acc: 0.7800\n",
            "Epoch 2384/4500\n",
            "100/100 [==============================] - 0s 545us/step - loss: 0.3327 - acc: 0.8600 - val_loss: 0.4166 - val_acc: 0.7800\n",
            "Epoch 2385/4500\n",
            "100/100 [==============================] - 0s 602us/step - loss: 0.3332 - acc: 0.8600 - val_loss: 0.4179 - val_acc: 0.7800\n",
            "Epoch 2386/4500\n",
            "100/100 [==============================] - 0s 524us/step - loss: 0.3322 - acc: 0.8600 - val_loss: 0.4164 - val_acc: 0.7800\n",
            "Epoch 2387/4500\n",
            "100/100 [==============================] - 0s 488us/step - loss: 0.3343 - acc: 0.8600 - val_loss: 0.4167 - val_acc: 0.7800\n",
            "Epoch 2388/4500\n",
            "100/100 [==============================] - 0s 525us/step - loss: 0.3313 - acc: 0.8600 - val_loss: 0.4149 - val_acc: 0.7800\n",
            "Epoch 2389/4500\n",
            "100/100 [==============================] - 0s 504us/step - loss: 0.3344 - acc: 0.8600 - val_loss: 0.4143 - val_acc: 0.7800\n",
            "Epoch 2390/4500\n",
            "100/100 [==============================] - 0s 535us/step - loss: 0.3321 - acc: 0.8600 - val_loss: 0.4155 - val_acc: 0.7800\n",
            "Epoch 2391/4500\n",
            "100/100 [==============================] - 0s 513us/step - loss: 0.3336 - acc: 0.8600 - val_loss: 0.4128 - val_acc: 0.7800\n",
            "Epoch 2392/4500\n",
            "100/100 [==============================] - 0s 531us/step - loss: 0.3326 - acc: 0.8600 - val_loss: 0.4145 - val_acc: 0.7800\n",
            "Epoch 2393/4500\n",
            "100/100 [==============================] - 0s 532us/step - loss: 0.3371 - acc: 0.8600 - val_loss: 0.4169 - val_acc: 0.7800\n",
            "Epoch 2394/4500\n",
            "100/100 [==============================] - 0s 502us/step - loss: 0.3312 - acc: 0.8600 - val_loss: 0.4139 - val_acc: 0.7800\n",
            "Epoch 2395/4500\n",
            "100/100 [==============================] - 0s 506us/step - loss: 0.3308 - acc: 0.8600 - val_loss: 0.4144 - val_acc: 0.7800\n",
            "Epoch 2396/4500\n",
            "100/100 [==============================] - 0s 493us/step - loss: 0.3316 - acc: 0.8600 - val_loss: 0.4139 - val_acc: 0.7800\n",
            "Epoch 2397/4500\n",
            "100/100 [==============================] - 0s 501us/step - loss: 0.3320 - acc: 0.8600 - val_loss: 0.4148 - val_acc: 0.7800\n",
            "Epoch 2398/4500\n",
            "100/100 [==============================] - 0s 500us/step - loss: 0.3310 - acc: 0.8600 - val_loss: 0.4145 - val_acc: 0.7800\n",
            "Epoch 2399/4500\n",
            "100/100 [==============================] - 0s 517us/step - loss: 0.3306 - acc: 0.8600 - val_loss: 0.4140 - val_acc: 0.7800\n",
            "Epoch 2400/4500\n",
            "100/100 [==============================] - 0s 492us/step - loss: 0.3316 - acc: 0.8600 - val_loss: 0.4136 - val_acc: 0.7800\n",
            "Epoch 2401/4500\n",
            "100/100 [==============================] - 0s 561us/step - loss: 0.3302 - acc: 0.8600 - val_loss: 0.4140 - val_acc: 0.7800\n",
            "Epoch 2402/4500\n",
            "100/100 [==============================] - 0s 548us/step - loss: 0.3316 - acc: 0.8600 - val_loss: 0.4149 - val_acc: 0.7800\n",
            "Epoch 2403/4500\n",
            "100/100 [==============================] - 0s 580us/step - loss: 0.3309 - acc: 0.8600 - val_loss: 0.4142 - val_acc: 0.7800\n",
            "Epoch 2404/4500\n",
            "100/100 [==============================] - 0s 562us/step - loss: 0.3311 - acc: 0.8600 - val_loss: 0.4135 - val_acc: 0.7800\n",
            "Epoch 2405/4500\n",
            "100/100 [==============================] - 0s 525us/step - loss: 0.3298 - acc: 0.8600 - val_loss: 0.4135 - val_acc: 0.7800\n",
            "Epoch 2406/4500\n",
            "100/100 [==============================] - 0s 507us/step - loss: 0.3311 - acc: 0.8600 - val_loss: 0.4146 - val_acc: 0.7800\n",
            "Epoch 2407/4500\n",
            "100/100 [==============================] - 0s 510us/step - loss: 0.3332 - acc: 0.8600 - val_loss: 0.4139 - val_acc: 0.7800\n",
            "Epoch 2408/4500\n",
            "100/100 [==============================] - 0s 494us/step - loss: 0.3306 - acc: 0.8600 - val_loss: 0.4137 - val_acc: 0.7800\n",
            "Epoch 2409/4500\n",
            "100/100 [==============================] - 0s 558us/step - loss: 0.3302 - acc: 0.8600 - val_loss: 0.4124 - val_acc: 0.7800\n",
            "Epoch 2410/4500\n",
            "100/100 [==============================] - 0s 488us/step - loss: 0.3298 - acc: 0.8600 - val_loss: 0.4136 - val_acc: 0.7800\n",
            "Epoch 2411/4500\n",
            "100/100 [==============================] - 0s 492us/step - loss: 0.3300 - acc: 0.8600 - val_loss: 0.4143 - val_acc: 0.7800\n",
            "Epoch 2412/4500\n",
            "100/100 [==============================] - 0s 520us/step - loss: 0.3288 - acc: 0.8600 - val_loss: 0.4127 - val_acc: 0.7800\n",
            "Epoch 2413/4500\n",
            "100/100 [==============================] - 0s 551us/step - loss: 0.3293 - acc: 0.8600 - val_loss: 0.4121 - val_acc: 0.7800\n",
            "Epoch 2414/4500\n",
            "100/100 [==============================] - 0s 493us/step - loss: 0.3304 - acc: 0.8600 - val_loss: 0.4105 - val_acc: 0.7800\n",
            "Epoch 2415/4500\n",
            "100/100 [==============================] - 0s 559us/step - loss: 0.3287 - acc: 0.8600 - val_loss: 0.4124 - val_acc: 0.7800\n",
            "Epoch 2416/4500\n",
            "100/100 [==============================] - 0s 540us/step - loss: 0.3300 - acc: 0.8600 - val_loss: 0.4133 - val_acc: 0.7800\n",
            "Epoch 2417/4500\n",
            "100/100 [==============================] - 0s 501us/step - loss: 0.3298 - acc: 0.8600 - val_loss: 0.4113 - val_acc: 0.7800\n",
            "Epoch 2418/4500\n",
            "100/100 [==============================] - 0s 498us/step - loss: 0.3280 - acc: 0.8600 - val_loss: 0.4119 - val_acc: 0.7800\n",
            "Epoch 2419/4500\n",
            "100/100 [==============================] - 0s 508us/step - loss: 0.3288 - acc: 0.8600 - val_loss: 0.4140 - val_acc: 0.7800\n",
            "Epoch 2420/4500\n",
            "100/100 [==============================] - 0s 488us/step - loss: 0.3315 - acc: 0.8600 - val_loss: 0.4113 - val_acc: 0.7800\n",
            "Epoch 2421/4500\n",
            "100/100 [==============================] - 0s 510us/step - loss: 0.3306 - acc: 0.8600 - val_loss: 0.4116 - val_acc: 0.7800\n",
            "Epoch 2422/4500\n",
            "100/100 [==============================] - 0s 516us/step - loss: 0.3280 - acc: 0.8600 - val_loss: 0.4136 - val_acc: 0.7800\n",
            "Epoch 2423/4500\n",
            "100/100 [==============================] - 0s 581us/step - loss: 0.3293 - acc: 0.8600 - val_loss: 0.4138 - val_acc: 0.7800\n",
            "Epoch 2424/4500\n",
            "100/100 [==============================] - 0s 609us/step - loss: 0.3283 - acc: 0.8600 - val_loss: 0.4109 - val_acc: 0.7800\n",
            "Epoch 2425/4500\n",
            "100/100 [==============================] - 0s 492us/step - loss: 0.3278 - acc: 0.8600 - val_loss: 0.4108 - val_acc: 0.7800\n",
            "Epoch 2426/4500\n",
            "100/100 [==============================] - 0s 553us/step - loss: 0.3271 - acc: 0.8600 - val_loss: 0.4112 - val_acc: 0.7800\n",
            "Epoch 2427/4500\n",
            "100/100 [==============================] - 0s 517us/step - loss: 0.3270 - acc: 0.8600 - val_loss: 0.4113 - val_acc: 0.7800\n",
            "Epoch 2428/4500\n",
            "100/100 [==============================] - 0s 520us/step - loss: 0.3265 - acc: 0.8600 - val_loss: 0.4111 - val_acc: 0.7800\n",
            "Epoch 2429/4500\n",
            "100/100 [==============================] - 0s 543us/step - loss: 0.3273 - acc: 0.8600 - val_loss: 0.4138 - val_acc: 0.7800\n",
            "Epoch 2430/4500\n",
            "100/100 [==============================] - 0s 510us/step - loss: 0.3269 - acc: 0.8600 - val_loss: 0.4119 - val_acc: 0.7800\n",
            "Epoch 2431/4500\n",
            "100/100 [==============================] - 0s 511us/step - loss: 0.3276 - acc: 0.8600 - val_loss: 0.4107 - val_acc: 0.7800\n",
            "Epoch 2432/4500\n",
            "100/100 [==============================] - 0s 518us/step - loss: 0.3259 - acc: 0.8600 - val_loss: 0.4107 - val_acc: 0.7800\n",
            "Epoch 2433/4500\n",
            "100/100 [==============================] - 0s 579us/step - loss: 0.3274 - acc: 0.8600 - val_loss: 0.4107 - val_acc: 0.7800\n",
            "Epoch 2434/4500\n",
            "100/100 [==============================] - 0s 534us/step - loss: 0.3267 - acc: 0.8600 - val_loss: 0.4094 - val_acc: 0.7800\n",
            "Epoch 2435/4500\n",
            "100/100 [==============================] - 0s 485us/step - loss: 0.3262 - acc: 0.8600 - val_loss: 0.4093 - val_acc: 0.7800\n",
            "Epoch 2436/4500\n",
            "100/100 [==============================] - 0s 500us/step - loss: 0.3260 - acc: 0.8600 - val_loss: 0.4102 - val_acc: 0.7800\n",
            "Epoch 2437/4500\n",
            "100/100 [==============================] - 0s 499us/step - loss: 0.3267 - acc: 0.8600 - val_loss: 0.4089 - val_acc: 0.7800\n",
            "Epoch 2438/4500\n",
            "100/100 [==============================] - 0s 484us/step - loss: 0.3258 - acc: 0.8600 - val_loss: 0.4102 - val_acc: 0.7800\n",
            "Epoch 2439/4500\n",
            "100/100 [==============================] - 0s 513us/step - loss: 0.3258 - acc: 0.8600 - val_loss: 0.4082 - val_acc: 0.7800\n",
            "Epoch 2440/4500\n",
            "100/100 [==============================] - 0s 501us/step - loss: 0.3252 - acc: 0.8600 - val_loss: 0.4094 - val_acc: 0.7800\n",
            "Epoch 2441/4500\n",
            "100/100 [==============================] - 0s 526us/step - loss: 0.3250 - acc: 0.8600 - val_loss: 0.4093 - val_acc: 0.7800\n",
            "Epoch 2442/4500\n",
            "100/100 [==============================] - 0s 494us/step - loss: 0.3248 - acc: 0.8600 - val_loss: 0.4104 - val_acc: 0.7800\n",
            "Epoch 2443/4500\n",
            "100/100 [==============================] - 0s 613us/step - loss: 0.3279 - acc: 0.8600 - val_loss: 0.4079 - val_acc: 0.7800\n",
            "Epoch 2444/4500\n",
            "100/100 [==============================] - 0s 531us/step - loss: 0.3237 - acc: 0.8600 - val_loss: 0.4089 - val_acc: 0.7800\n",
            "Epoch 2445/4500\n",
            "100/100 [==============================] - 0s 507us/step - loss: 0.3258 - acc: 0.8600 - val_loss: 0.4103 - val_acc: 0.7800\n",
            "Epoch 2446/4500\n",
            "100/100 [==============================] - 0s 503us/step - loss: 0.3243 - acc: 0.8600 - val_loss: 0.4068 - val_acc: 0.7800\n",
            "Epoch 2447/4500\n",
            "100/100 [==============================] - 0s 491us/step - loss: 0.3267 - acc: 0.8600 - val_loss: 0.4074 - val_acc: 0.7800\n",
            "Epoch 2448/4500\n",
            "100/100 [==============================] - 0s 494us/step - loss: 0.3244 - acc: 0.8600 - val_loss: 0.4083 - val_acc: 0.7800\n",
            "Epoch 2449/4500\n",
            "100/100 [==============================] - 0s 524us/step - loss: 0.3244 - acc: 0.8600 - val_loss: 0.4088 - val_acc: 0.7800\n",
            "Epoch 2450/4500\n",
            "100/100 [==============================] - 0s 526us/step - loss: 0.3247 - acc: 0.8600 - val_loss: 0.4101 - val_acc: 0.7800\n",
            "Epoch 2451/4500\n",
            "100/100 [==============================] - 0s 542us/step - loss: 0.3241 - acc: 0.8600 - val_loss: 0.4087 - val_acc: 0.7800\n",
            "Epoch 2452/4500\n",
            "100/100 [==============================] - 0s 511us/step - loss: 0.3240 - acc: 0.8600 - val_loss: 0.4080 - val_acc: 0.7800\n",
            "Epoch 2453/4500\n",
            "100/100 [==============================] - 0s 517us/step - loss: 0.3252 - acc: 0.8600 - val_loss: 0.4089 - val_acc: 0.7800\n",
            "Epoch 2454/4500\n",
            "100/100 [==============================] - 0s 513us/step - loss: 0.3247 - acc: 0.8600 - val_loss: 0.4054 - val_acc: 0.7800\n",
            "Epoch 2455/4500\n",
            "100/100 [==============================] - 0s 501us/step - loss: 0.3254 - acc: 0.8600 - val_loss: 0.4081 - val_acc: 0.7800\n",
            "Epoch 2456/4500\n",
            "100/100 [==============================] - 0s 498us/step - loss: 0.3286 - acc: 0.8600 - val_loss: 0.4099 - val_acc: 0.7800\n",
            "Epoch 2457/4500\n",
            "100/100 [==============================] - 0s 490us/step - loss: 0.3271 - acc: 0.8600 - val_loss: 0.4053 - val_acc: 0.7800\n",
            "Epoch 2458/4500\n",
            "100/100 [==============================] - 0s 520us/step - loss: 0.3255 - acc: 0.8400 - val_loss: 0.4061 - val_acc: 0.7800\n",
            "Epoch 2459/4500\n",
            "100/100 [==============================] - 0s 485us/step - loss: 0.3218 - acc: 0.8600 - val_loss: 0.4097 - val_acc: 0.7800\n",
            "Epoch 2460/4500\n",
            "100/100 [==============================] - 0s 545us/step - loss: 0.3221 - acc: 0.8600 - val_loss: 0.4103 - val_acc: 0.7900\n",
            "Epoch 2461/4500\n",
            "100/100 [==============================] - 0s 498us/step - loss: 0.3249 - acc: 0.8600 - val_loss: 0.4064 - val_acc: 0.7800\n",
            "Epoch 2462/4500\n",
            "100/100 [==============================] - 0s 606us/step - loss: 0.3217 - acc: 0.8600 - val_loss: 0.4067 - val_acc: 0.7800\n",
            "Epoch 2463/4500\n",
            "100/100 [==============================] - 0s 586us/step - loss: 0.3227 - acc: 0.8600 - val_loss: 0.4085 - val_acc: 0.7800\n",
            "Epoch 2464/4500\n",
            "100/100 [==============================] - 0s 500us/step - loss: 0.3209 - acc: 0.8600 - val_loss: 0.4065 - val_acc: 0.7800\n",
            "Epoch 2465/4500\n",
            "100/100 [==============================] - 0s 536us/step - loss: 0.3227 - acc: 0.8600 - val_loss: 0.4069 - val_acc: 0.7800\n",
            "Epoch 2466/4500\n",
            "100/100 [==============================] - 0s 492us/step - loss: 0.3209 - acc: 0.8600 - val_loss: 0.4050 - val_acc: 0.7800\n",
            "Epoch 2467/4500\n",
            "100/100 [==============================] - 0s 514us/step - loss: 0.3207 - acc: 0.8600 - val_loss: 0.4054 - val_acc: 0.7800\n",
            "Epoch 2468/4500\n",
            "100/100 [==============================] - 0s 527us/step - loss: 0.3217 - acc: 0.8600 - val_loss: 0.4067 - val_acc: 0.7800\n",
            "Epoch 2469/4500\n",
            "100/100 [==============================] - 0s 503us/step - loss: 0.3214 - acc: 0.8600 - val_loss: 0.4074 - val_acc: 0.7800\n",
            "Epoch 2470/4500\n",
            "100/100 [==============================] - 0s 483us/step - loss: 0.3223 - acc: 0.8600 - val_loss: 0.4048 - val_acc: 0.7800\n",
            "Epoch 2471/4500\n",
            "100/100 [==============================] - 0s 496us/step - loss: 0.3243 - acc: 0.8600 - val_loss: 0.4065 - val_acc: 0.7800\n",
            "Epoch 2472/4500\n",
            "100/100 [==============================] - 0s 506us/step - loss: 0.3218 - acc: 0.8600 - val_loss: 0.4070 - val_acc: 0.7800\n",
            "Epoch 2473/4500\n",
            "100/100 [==============================] - 0s 521us/step - loss: 0.3196 - acc: 0.8600 - val_loss: 0.4050 - val_acc: 0.7800\n",
            "Epoch 2474/4500\n",
            "100/100 [==============================] - 0s 513us/step - loss: 0.3212 - acc: 0.8600 - val_loss: 0.4058 - val_acc: 0.7800\n",
            "Epoch 2475/4500\n",
            "100/100 [==============================] - 0s 502us/step - loss: 0.3223 - acc: 0.8600 - val_loss: 0.4043 - val_acc: 0.7800\n",
            "Epoch 2476/4500\n",
            "100/100 [==============================] - 0s 493us/step - loss: 0.3202 - acc: 0.8600 - val_loss: 0.4054 - val_acc: 0.7800\n",
            "Epoch 2477/4500\n",
            "100/100 [==============================] - 0s 501us/step - loss: 0.3199 - acc: 0.8600 - val_loss: 0.4061 - val_acc: 0.7800\n",
            "Epoch 2478/4500\n",
            "100/100 [==============================] - 0s 498us/step - loss: 0.3210 - acc: 0.8600 - val_loss: 0.4068 - val_acc: 0.7800\n",
            "Epoch 2479/4500\n",
            "100/100 [==============================] - 0s 519us/step - loss: 0.3200 - acc: 0.8600 - val_loss: 0.4051 - val_acc: 0.7800\n",
            "Epoch 2480/4500\n",
            "100/100 [==============================] - 0s 570us/step - loss: 0.3196 - acc: 0.8600 - val_loss: 0.4064 - val_acc: 0.7800\n",
            "Epoch 2481/4500\n",
            "100/100 [==============================] - 0s 595us/step - loss: 0.3191 - acc: 0.8600 - val_loss: 0.4054 - val_acc: 0.7800\n",
            "Epoch 2482/4500\n",
            "100/100 [==============================] - 0s 557us/step - loss: 0.3193 - acc: 0.8600 - val_loss: 0.4049 - val_acc: 0.7800\n",
            "Epoch 2483/4500\n",
            "100/100 [==============================] - 0s 625us/step - loss: 0.3193 - acc: 0.8600 - val_loss: 0.4052 - val_acc: 0.7800\n",
            "Epoch 2484/4500\n",
            "100/100 [==============================] - 0s 520us/step - loss: 0.3183 - acc: 0.8600 - val_loss: 0.4062 - val_acc: 0.7800\n",
            "Epoch 2485/4500\n",
            "100/100 [==============================] - 0s 500us/step - loss: 0.3212 - acc: 0.8600 - val_loss: 0.4037 - val_acc: 0.7800\n",
            "Epoch 2486/4500\n",
            "100/100 [==============================] - 0s 515us/step - loss: 0.3211 - acc: 0.8600 - val_loss: 0.4078 - val_acc: 0.7800\n",
            "Epoch 2487/4500\n",
            "100/100 [==============================] - 0s 511us/step - loss: 0.3202 - acc: 0.8600 - val_loss: 0.4038 - val_acc: 0.7800\n",
            "Epoch 2488/4500\n",
            "100/100 [==============================] - 0s 482us/step - loss: 0.3190 - acc: 0.8600 - val_loss: 0.4058 - val_acc: 0.7800\n",
            "Epoch 2489/4500\n",
            "100/100 [==============================] - 0s 492us/step - loss: 0.3177 - acc: 0.8600 - val_loss: 0.4043 - val_acc: 0.7800\n",
            "Epoch 2490/4500\n",
            "100/100 [==============================] - 0s 525us/step - loss: 0.3174 - acc: 0.8600 - val_loss: 0.4050 - val_acc: 0.7800\n",
            "Epoch 2491/4500\n",
            "100/100 [==============================] - 0s 504us/step - loss: 0.3186 - acc: 0.8600 - val_loss: 0.4041 - val_acc: 0.7800\n",
            "Epoch 2492/4500\n",
            "100/100 [==============================] - 0s 546us/step - loss: 0.3185 - acc: 0.8600 - val_loss: 0.4052 - val_acc: 0.7800\n",
            "Epoch 2493/4500\n",
            "100/100 [==============================] - 0s 544us/step - loss: 0.3167 - acc: 0.8600 - val_loss: 0.4053 - val_acc: 0.7800\n",
            "Epoch 2494/4500\n",
            "100/100 [==============================] - 0s 493us/step - loss: 0.3187 - acc: 0.8600 - val_loss: 0.4038 - val_acc: 0.7800\n",
            "Epoch 2495/4500\n",
            "100/100 [==============================] - 0s 481us/step - loss: 0.3178 - acc: 0.8600 - val_loss: 0.4035 - val_acc: 0.7800\n",
            "Epoch 2496/4500\n",
            "100/100 [==============================] - 0s 490us/step - loss: 0.3169 - acc: 0.8600 - val_loss: 0.4051 - val_acc: 0.7800\n",
            "Epoch 2497/4500\n",
            "100/100 [==============================] - 0s 491us/step - loss: 0.3162 - acc: 0.8600 - val_loss: 0.4051 - val_acc: 0.7800\n",
            "Epoch 2498/4500\n",
            "100/100 [==============================] - 0s 508us/step - loss: 0.3185 - acc: 0.8600 - val_loss: 0.4051 - val_acc: 0.7800\n",
            "Epoch 2499/4500\n",
            "100/100 [==============================] - 0s 550us/step - loss: 0.3163 - acc: 0.8600 - val_loss: 0.4043 - val_acc: 0.7800\n",
            "Epoch 2500/4500\n",
            "100/100 [==============================] - 0s 511us/step - loss: 0.3181 - acc: 0.8600 - val_loss: 0.4023 - val_acc: 0.7800\n",
            "Epoch 2501/4500\n",
            "100/100 [==============================] - 0s 595us/step - loss: 0.3158 - acc: 0.8600 - val_loss: 0.4042 - val_acc: 0.7800\n",
            "Epoch 2502/4500\n",
            "100/100 [==============================] - 0s 491us/step - loss: 0.3173 - acc: 0.8600 - val_loss: 0.4032 - val_acc: 0.7800\n",
            "Epoch 2503/4500\n",
            "100/100 [==============================] - 0s 567us/step - loss: 0.3154 - acc: 0.8600 - val_loss: 0.4032 - val_acc: 0.7800\n",
            "Epoch 2504/4500\n",
            "100/100 [==============================] - 0s 504us/step - loss: 0.3150 - acc: 0.8600 - val_loss: 0.4049 - val_acc: 0.7800\n",
            "Epoch 2505/4500\n",
            "100/100 [==============================] - 0s 493us/step - loss: 0.3244 - acc: 0.8600 - val_loss: 0.4078 - val_acc: 0.7900\n",
            "Epoch 2506/4500\n",
            "100/100 [==============================] - 0s 519us/step - loss: 0.3186 - acc: 0.8600 - val_loss: 0.4023 - val_acc: 0.7800\n",
            "Epoch 2507/4500\n",
            "100/100 [==============================] - 0s 529us/step - loss: 0.3160 - acc: 0.8600 - val_loss: 0.4021 - val_acc: 0.7800\n",
            "Epoch 2508/4500\n",
            "100/100 [==============================] - 0s 502us/step - loss: 0.3158 - acc: 0.8600 - val_loss: 0.4032 - val_acc: 0.7800\n",
            "Epoch 2509/4500\n",
            "100/100 [==============================] - 0s 499us/step - loss: 0.3163 - acc: 0.8600 - val_loss: 0.4023 - val_acc: 0.7800\n",
            "Epoch 2510/4500\n",
            "100/100 [==============================] - 0s 512us/step - loss: 0.3142 - acc: 0.8600 - val_loss: 0.4038 - val_acc: 0.7800\n",
            "Epoch 2511/4500\n",
            "100/100 [==============================] - 0s 510us/step - loss: 0.3188 - acc: 0.8600 - val_loss: 0.4071 - val_acc: 0.7900\n",
            "Epoch 2512/4500\n",
            "100/100 [==============================] - 0s 603us/step - loss: 0.3158 - acc: 0.8600 - val_loss: 0.4020 - val_acc: 0.7800\n",
            "Epoch 2513/4500\n",
            "100/100 [==============================] - 0s 494us/step - loss: 0.3160 - acc: 0.8600 - val_loss: 0.4026 - val_acc: 0.7800\n",
            "Epoch 2514/4500\n",
            "100/100 [==============================] - 0s 543us/step - loss: 0.3141 - acc: 0.8600 - val_loss: 0.4024 - val_acc: 0.7800\n",
            "Epoch 2515/4500\n",
            "100/100 [==============================] - 0s 501us/step - loss: 0.3144 - acc: 0.8600 - val_loss: 0.4027 - val_acc: 0.7800\n",
            "Epoch 2516/4500\n",
            "100/100 [==============================] - 0s 486us/step - loss: 0.3144 - acc: 0.8600 - val_loss: 0.4035 - val_acc: 0.7800\n",
            "Epoch 2517/4500\n",
            "100/100 [==============================] - 0s 475us/step - loss: 0.3169 - acc: 0.8600 - val_loss: 0.4035 - val_acc: 0.7800\n",
            "Epoch 2518/4500\n",
            "100/100 [==============================] - 0s 499us/step - loss: 0.3134 - acc: 0.8600 - val_loss: 0.4034 - val_acc: 0.7800\n",
            "Epoch 2519/4500\n",
            "100/100 [==============================] - 0s 513us/step - loss: 0.3151 - acc: 0.8600 - val_loss: 0.4014 - val_acc: 0.7800\n",
            "Epoch 2520/4500\n",
            "100/100 [==============================] - 0s 622us/step - loss: 0.3134 - acc: 0.8600 - val_loss: 0.4026 - val_acc: 0.7800\n",
            "Epoch 2521/4500\n",
            "100/100 [==============================] - 0s 533us/step - loss: 0.3135 - acc: 0.8600 - val_loss: 0.4022 - val_acc: 0.7800\n",
            "Epoch 2522/4500\n",
            "100/100 [==============================] - 0s 561us/step - loss: 0.3130 - acc: 0.8600 - val_loss: 0.4035 - val_acc: 0.7800\n",
            "Epoch 2523/4500\n",
            "100/100 [==============================] - 0s 632us/step - loss: 0.3132 - acc: 0.8600 - val_loss: 0.4038 - val_acc: 0.7800\n",
            "Epoch 2524/4500\n",
            "100/100 [==============================] - 0s 558us/step - loss: 0.3143 - acc: 0.8600 - val_loss: 0.4016 - val_acc: 0.7800\n",
            "Epoch 2525/4500\n",
            "100/100 [==============================] - 0s 526us/step - loss: 0.3130 - acc: 0.8600 - val_loss: 0.4020 - val_acc: 0.7800\n",
            "Epoch 2526/4500\n",
            "100/100 [==============================] - 0s 520us/step - loss: 0.3127 - acc: 0.8600 - val_loss: 0.4021 - val_acc: 0.7800\n",
            "Epoch 2527/4500\n",
            "100/100 [==============================] - 0s 589us/step - loss: 0.3124 - acc: 0.8600 - val_loss: 0.4027 - val_acc: 0.7800\n",
            "Epoch 2528/4500\n",
            "100/100 [==============================] - 0s 529us/step - loss: 0.3131 - acc: 0.8600 - val_loss: 0.4010 - val_acc: 0.7800\n",
            "Epoch 2529/4500\n",
            "100/100 [==============================] - 0s 537us/step - loss: 0.3118 - acc: 0.8600 - val_loss: 0.4026 - val_acc: 0.7800\n",
            "Epoch 2530/4500\n",
            "100/100 [==============================] - 0s 499us/step - loss: 0.3121 - acc: 0.8600 - val_loss: 0.4031 - val_acc: 0.7800\n",
            "Epoch 2531/4500\n",
            "100/100 [==============================] - 0s 511us/step - loss: 0.3120 - acc: 0.8600 - val_loss: 0.4014 - val_acc: 0.7800\n",
            "Epoch 2532/4500\n",
            "100/100 [==============================] - 0s 600us/step - loss: 0.3135 - acc: 0.8600 - val_loss: 0.4021 - val_acc: 0.7800\n",
            "Epoch 2533/4500\n",
            "100/100 [==============================] - 0s 513us/step - loss: 0.3142 - acc: 0.8600 - val_loss: 0.4002 - val_acc: 0.7800\n",
            "Epoch 2534/4500\n",
            "100/100 [==============================] - 0s 494us/step - loss: 0.3121 - acc: 0.8600 - val_loss: 0.4007 - val_acc: 0.7800\n",
            "Epoch 2535/4500\n",
            "100/100 [==============================] - 0s 492us/step - loss: 0.3128 - acc: 0.8600 - val_loss: 0.4008 - val_acc: 0.7800\n",
            "Epoch 2536/4500\n",
            "100/100 [==============================] - 0s 491us/step - loss: 0.3127 - acc: 0.8600 - val_loss: 0.4029 - val_acc: 0.7800\n",
            "Epoch 2537/4500\n",
            "100/100 [==============================] - 0s 501us/step - loss: 0.3120 - acc: 0.8600 - val_loss: 0.4014 - val_acc: 0.7800\n",
            "Epoch 2538/4500\n",
            "100/100 [==============================] - 0s 609us/step - loss: 0.3115 - acc: 0.8600 - val_loss: 0.4019 - val_acc: 0.7800\n",
            "Epoch 2539/4500\n",
            "100/100 [==============================] - 0s 558us/step - loss: 0.3105 - acc: 0.8600 - val_loss: 0.4010 - val_acc: 0.7800\n",
            "Epoch 2540/4500\n",
            "100/100 [==============================] - 0s 532us/step - loss: 0.3143 - acc: 0.8600 - val_loss: 0.4013 - val_acc: 0.7800\n",
            "Epoch 2541/4500\n",
            "100/100 [==============================] - 0s 496us/step - loss: 0.3116 - acc: 0.8600 - val_loss: 0.3994 - val_acc: 0.7900\n",
            "Epoch 2542/4500\n",
            "100/100 [==============================] - 0s 541us/step - loss: 0.3122 - acc: 0.8600 - val_loss: 0.4009 - val_acc: 0.7800\n",
            "Epoch 2543/4500\n",
            "100/100 [==============================] - 0s 513us/step - loss: 0.3106 - acc: 0.8600 - val_loss: 0.4009 - val_acc: 0.7800\n",
            "Epoch 2544/4500\n",
            "100/100 [==============================] - 0s 512us/step - loss: 0.3102 - acc: 0.8600 - val_loss: 0.4001 - val_acc: 0.7900\n",
            "Epoch 2545/4500\n",
            "100/100 [==============================] - 0s 537us/step - loss: 0.3094 - acc: 0.8600 - val_loss: 0.4005 - val_acc: 0.7800\n",
            "Epoch 2546/4500\n",
            "100/100 [==============================] - 0s 601us/step - loss: 0.3105 - acc: 0.8600 - val_loss: 0.4013 - val_acc: 0.7800\n",
            "Epoch 2547/4500\n",
            "100/100 [==============================] - 0s 660us/step - loss: 0.3114 - acc: 0.8600 - val_loss: 0.3996 - val_acc: 0.7900\n",
            "Epoch 2548/4500\n",
            "100/100 [==============================] - 0s 600us/step - loss: 0.3117 - acc: 0.8600 - val_loss: 0.4015 - val_acc: 0.7800\n",
            "Epoch 2549/4500\n",
            "100/100 [==============================] - 0s 544us/step - loss: 0.3102 - acc: 0.8600 - val_loss: 0.3989 - val_acc: 0.7900\n",
            "Epoch 2550/4500\n",
            "100/100 [==============================] - 0s 493us/step - loss: 0.3114 - acc: 0.8600 - val_loss: 0.3992 - val_acc: 0.7900\n",
            "Epoch 2551/4500\n",
            "100/100 [==============================] - 0s 518us/step - loss: 0.3091 - acc: 0.8600 - val_loss: 0.3989 - val_acc: 0.7900\n",
            "Epoch 2552/4500\n",
            "100/100 [==============================] - 0s 478us/step - loss: 0.3092 - acc: 0.8600 - val_loss: 0.3999 - val_acc: 0.7800\n",
            "Epoch 2553/4500\n",
            "100/100 [==============================] - 0s 501us/step - loss: 0.3095 - acc: 0.8600 - val_loss: 0.4015 - val_acc: 0.7800\n",
            "Epoch 2554/4500\n",
            "100/100 [==============================] - 0s 505us/step - loss: 0.3115 - acc: 0.8600 - val_loss: 0.3990 - val_acc: 0.7900\n",
            "Epoch 2555/4500\n",
            "100/100 [==============================] - 0s 505us/step - loss: 0.3093 - acc: 0.8600 - val_loss: 0.3986 - val_acc: 0.7900\n",
            "Epoch 2556/4500\n",
            "100/100 [==============================] - 0s 491us/step - loss: 0.3092 - acc: 0.8600 - val_loss: 0.4000 - val_acc: 0.7800\n",
            "Epoch 2557/4500\n",
            "100/100 [==============================] - 0s 581us/step - loss: 0.3082 - acc: 0.8600 - val_loss: 0.3991 - val_acc: 0.7800\n",
            "Epoch 2558/4500\n",
            "100/100 [==============================] - 0s 503us/step - loss: 0.3090 - acc: 0.8600 - val_loss: 0.4000 - val_acc: 0.7800\n",
            "Epoch 2559/4500\n",
            "100/100 [==============================] - 0s 632us/step - loss: 0.3091 - acc: 0.8600 - val_loss: 0.3985 - val_acc: 0.7900\n",
            "Epoch 2560/4500\n",
            "100/100 [==============================] - 0s 497us/step - loss: 0.3083 - acc: 0.8600 - val_loss: 0.3994 - val_acc: 0.7900\n",
            "Epoch 2561/4500\n",
            "100/100 [==============================] - 0s 536us/step - loss: 0.3082 - acc: 0.8600 - val_loss: 0.3992 - val_acc: 0.7900\n",
            "Epoch 2562/4500\n",
            "100/100 [==============================] - 0s 551us/step - loss: 0.3074 - acc: 0.8600 - val_loss: 0.3985 - val_acc: 0.7900\n",
            "Epoch 2563/4500\n",
            "100/100 [==============================] - 0s 529us/step - loss: 0.3085 - acc: 0.8600 - val_loss: 0.3995 - val_acc: 0.7800\n",
            "Epoch 2564/4500\n",
            "100/100 [==============================] - 0s 539us/step - loss: 0.3084 - acc: 0.8600 - val_loss: 0.3984 - val_acc: 0.7900\n",
            "Epoch 2565/4500\n",
            "100/100 [==============================] - 0s 599us/step - loss: 0.3076 - acc: 0.8600 - val_loss: 0.3991 - val_acc: 0.7900\n",
            "Epoch 2566/4500\n",
            "100/100 [==============================] - 0s 501us/step - loss: 0.3073 - acc: 0.8600 - val_loss: 0.3988 - val_acc: 0.7900\n",
            "Epoch 2567/4500\n",
            "100/100 [==============================] - 0s 489us/step - loss: 0.3080 - acc: 0.8600 - val_loss: 0.3964 - val_acc: 0.7900\n",
            "Epoch 2568/4500\n",
            "100/100 [==============================] - 0s 492us/step - loss: 0.3103 - acc: 0.8600 - val_loss: 0.3983 - val_acc: 0.7900\n",
            "Epoch 2569/4500\n",
            "100/100 [==============================] - 0s 496us/step - loss: 0.3077 - acc: 0.8600 - val_loss: 0.3965 - val_acc: 0.7900\n",
            "Epoch 2570/4500\n",
            "100/100 [==============================] - 0s 526us/step - loss: 0.3079 - acc: 0.8600 - val_loss: 0.3964 - val_acc: 0.7900\n",
            "Epoch 2571/4500\n",
            "100/100 [==============================] - 0s 570us/step - loss: 0.3075 - acc: 0.8600 - val_loss: 0.3990 - val_acc: 0.7900\n",
            "Epoch 2572/4500\n",
            "100/100 [==============================] - 0s 509us/step - loss: 0.3102 - acc: 0.8600 - val_loss: 0.4020 - val_acc: 0.8000\n",
            "Epoch 2573/4500\n",
            "100/100 [==============================] - 0s 482us/step - loss: 0.3075 - acc: 0.8600 - val_loss: 0.3962 - val_acc: 0.7900\n",
            "Epoch 2574/4500\n",
            "100/100 [==============================] - 0s 488us/step - loss: 0.3079 - acc: 0.8500 - val_loss: 0.3973 - val_acc: 0.7900\n",
            "Epoch 2575/4500\n",
            "100/100 [==============================] - 0s 480us/step - loss: 0.3072 - acc: 0.8500 - val_loss: 0.3959 - val_acc: 0.7900\n",
            "Epoch 2576/4500\n",
            "100/100 [==============================] - 0s 579us/step - loss: 0.3077 - acc: 0.8500 - val_loss: 0.3968 - val_acc: 0.7900\n",
            "Epoch 2577/4500\n",
            "100/100 [==============================] - 0s 506us/step - loss: 0.3066 - acc: 0.8600 - val_loss: 0.3998 - val_acc: 0.7900\n",
            "Epoch 2578/4500\n",
            "100/100 [==============================] - 0s 507us/step - loss: 0.3073 - acc: 0.8600 - val_loss: 0.3995 - val_acc: 0.8000\n",
            "Epoch 2579/4500\n",
            "100/100 [==============================] - 0s 530us/step - loss: 0.3079 - acc: 0.8600 - val_loss: 0.4002 - val_acc: 0.8000\n",
            "Epoch 2580/4500\n",
            "100/100 [==============================] - 0s 514us/step - loss: 0.3086 - acc: 0.8600 - val_loss: 0.3955 - val_acc: 0.8100\n",
            "Epoch 2581/4500\n",
            "100/100 [==============================] - 0s 551us/step - loss: 0.3067 - acc: 0.8500 - val_loss: 0.3957 - val_acc: 0.7900\n",
            "Epoch 2582/4500\n",
            "100/100 [==============================] - 0s 496us/step - loss: 0.3066 - acc: 0.8600 - val_loss: 0.3973 - val_acc: 0.7900\n",
            "Epoch 2583/4500\n",
            "100/100 [==============================] - 0s 537us/step - loss: 0.3040 - acc: 0.8600 - val_loss: 0.3984 - val_acc: 0.8000\n",
            "Epoch 2584/4500\n",
            "100/100 [==============================] - 0s 580us/step - loss: 0.3050 - acc: 0.8600 - val_loss: 0.3972 - val_acc: 0.7900\n",
            "Epoch 2585/4500\n",
            "100/100 [==============================] - 0s 533us/step - loss: 0.3072 - acc: 0.8600 - val_loss: 0.4002 - val_acc: 0.8000\n",
            "Epoch 2586/4500\n",
            "100/100 [==============================] - 0s 540us/step - loss: 0.3054 - acc: 0.8600 - val_loss: 0.3959 - val_acc: 0.7900\n",
            "Epoch 2587/4500\n",
            "100/100 [==============================] - 0s 504us/step - loss: 0.3069 - acc: 0.8600 - val_loss: 0.3965 - val_acc: 0.7900\n",
            "Epoch 2588/4500\n",
            "100/100 [==============================] - 0s 524us/step - loss: 0.3061 - acc: 0.8500 - val_loss: 0.3949 - val_acc: 0.7900\n",
            "Epoch 2589/4500\n",
            "100/100 [==============================] - 0s 503us/step - loss: 0.3040 - acc: 0.8500 - val_loss: 0.3953 - val_acc: 0.7900\n",
            "Epoch 2590/4500\n",
            "100/100 [==============================] - 0s 540us/step - loss: 0.3061 - acc: 0.8600 - val_loss: 0.3983 - val_acc: 0.8100\n",
            "Epoch 2591/4500\n",
            "100/100 [==============================] - 0s 543us/step - loss: 0.3035 - acc: 0.8600 - val_loss: 0.3954 - val_acc: 0.7900\n",
            "Epoch 2592/4500\n",
            "100/100 [==============================] - 0s 514us/step - loss: 0.3050 - acc: 0.8500 - val_loss: 0.3942 - val_acc: 0.8000\n",
            "Epoch 2593/4500\n",
            "100/100 [==============================] - 0s 515us/step - loss: 0.3034 - acc: 0.8500 - val_loss: 0.3952 - val_acc: 0.7900\n",
            "Epoch 2594/4500\n",
            "100/100 [==============================] - 0s 526us/step - loss: 0.3038 - acc: 0.8500 - val_loss: 0.3960 - val_acc: 0.7900\n",
            "Epoch 2595/4500\n",
            "100/100 [==============================] - 0s 628us/step - loss: 0.3024 - acc: 0.8600 - val_loss: 0.3953 - val_acc: 0.7900\n",
            "Epoch 2596/4500\n",
            "100/100 [==============================] - 0s 520us/step - loss: 0.3038 - acc: 0.8600 - val_loss: 0.3967 - val_acc: 0.7900\n",
            "Epoch 2597/4500\n",
            "100/100 [==============================] - 0s 574us/step - loss: 0.3030 - acc: 0.8600 - val_loss: 0.3973 - val_acc: 0.8000\n",
            "Epoch 2598/4500\n",
            "100/100 [==============================] - 0s 538us/step - loss: 0.3023 - acc: 0.8600 - val_loss: 0.3953 - val_acc: 0.7900\n",
            "Epoch 2599/4500\n",
            "100/100 [==============================] - 0s 489us/step - loss: 0.3022 - acc: 0.8600 - val_loss: 0.3948 - val_acc: 0.7900\n",
            "Epoch 2600/4500\n",
            "100/100 [==============================] - 0s 525us/step - loss: 0.3031 - acc: 0.8600 - val_loss: 0.3967 - val_acc: 0.7900\n",
            "Epoch 2601/4500\n",
            "100/100 [==============================] - 0s 530us/step - loss: 0.3029 - acc: 0.8600 - val_loss: 0.3940 - val_acc: 0.7900\n",
            "Epoch 2602/4500\n",
            "100/100 [==============================] - 0s 496us/step - loss: 0.3041 - acc: 0.8600 - val_loss: 0.3937 - val_acc: 0.7900\n",
            "Epoch 2603/4500\n",
            "100/100 [==============================] - 0s 541us/step - loss: 0.3014 - acc: 0.8600 - val_loss: 0.3946 - val_acc: 0.7900\n",
            "Epoch 2604/4500\n",
            "100/100 [==============================] - 0s 543us/step - loss: 0.3012 - acc: 0.8600 - val_loss: 0.3947 - val_acc: 0.7900\n",
            "Epoch 2605/4500\n",
            "100/100 [==============================] - 0s 574us/step - loss: 0.3006 - acc: 0.8600 - val_loss: 0.3936 - val_acc: 0.7900\n",
            "Epoch 2606/4500\n",
            "100/100 [==============================] - 0s 552us/step - loss: 0.3013 - acc: 0.8500 - val_loss: 0.3940 - val_acc: 0.7900\n",
            "Epoch 2607/4500\n",
            "100/100 [==============================] - 0s 556us/step - loss: 0.3002 - acc: 0.8600 - val_loss: 0.3941 - val_acc: 0.7900\n",
            "Epoch 2608/4500\n",
            "100/100 [==============================] - 0s 538us/step - loss: 0.3005 - acc: 0.8600 - val_loss: 0.3937 - val_acc: 0.7900\n",
            "Epoch 2609/4500\n",
            "100/100 [==============================] - 0s 585us/step - loss: 0.3003 - acc: 0.8600 - val_loss: 0.3936 - val_acc: 0.7900\n",
            "Epoch 2610/4500\n",
            "100/100 [==============================] - 0s 569us/step - loss: 0.3027 - acc: 0.8600 - val_loss: 0.3968 - val_acc: 0.8100\n",
            "Epoch 2611/4500\n",
            "100/100 [==============================] - 0s 490us/step - loss: 0.3003 - acc: 0.8600 - val_loss: 0.3955 - val_acc: 0.8000\n",
            "Epoch 2612/4500\n",
            "100/100 [==============================] - 0s 532us/step - loss: 0.3001 - acc: 0.8600 - val_loss: 0.3922 - val_acc: 0.7900\n",
            "Epoch 2613/4500\n",
            "100/100 [==============================] - 0s 558us/step - loss: 0.3009 - acc: 0.8500 - val_loss: 0.3916 - val_acc: 0.8100\n",
            "Epoch 2614/4500\n",
            "100/100 [==============================] - 0s 543us/step - loss: 0.3012 - acc: 0.8500 - val_loss: 0.3934 - val_acc: 0.7900\n",
            "Epoch 2615/4500\n",
            "100/100 [==============================] - 0s 494us/step - loss: 0.2999 - acc: 0.8600 - val_loss: 0.3955 - val_acc: 0.8100\n",
            "Epoch 2616/4500\n",
            "100/100 [==============================] - 0s 488us/step - loss: 0.3026 - acc: 0.8600 - val_loss: 0.3937 - val_acc: 0.8000\n",
            "Epoch 2617/4500\n",
            "100/100 [==============================] - 0s 494us/step - loss: 0.2998 - acc: 0.8600 - val_loss: 0.3929 - val_acc: 0.8000\n",
            "Epoch 2618/4500\n",
            "100/100 [==============================] - 0s 509us/step - loss: 0.2998 - acc: 0.8600 - val_loss: 0.3928 - val_acc: 0.8000\n",
            "Epoch 2619/4500\n",
            "100/100 [==============================] - 0s 529us/step - loss: 0.2983 - acc: 0.8600 - val_loss: 0.3913 - val_acc: 0.7900\n",
            "Epoch 2620/4500\n",
            "100/100 [==============================] - 0s 521us/step - loss: 0.2992 - acc: 0.8600 - val_loss: 0.3923 - val_acc: 0.8000\n",
            "Epoch 2621/4500\n",
            "100/100 [==============================] - 0s 504us/step - loss: 0.2990 - acc: 0.8600 - val_loss: 0.3927 - val_acc: 0.7900\n",
            "Epoch 2622/4500\n",
            "100/100 [==============================] - 0s 503us/step - loss: 0.2978 - acc: 0.8600 - val_loss: 0.3930 - val_acc: 0.8000\n",
            "Epoch 2623/4500\n",
            "100/100 [==============================] - 0s 510us/step - loss: 0.2993 - acc: 0.8600 - val_loss: 0.3922 - val_acc: 0.8000\n",
            "Epoch 2624/4500\n",
            "100/100 [==============================] - 0s 493us/step - loss: 0.2996 - acc: 0.8600 - val_loss: 0.3938 - val_acc: 0.8100\n",
            "Epoch 2625/4500\n",
            "100/100 [==============================] - 0s 517us/step - loss: 0.2984 - acc: 0.8600 - val_loss: 0.3915 - val_acc: 0.8000\n",
            "Epoch 2626/4500\n",
            "100/100 [==============================] - 0s 483us/step - loss: 0.2985 - acc: 0.8600 - val_loss: 0.3913 - val_acc: 0.7900\n",
            "Epoch 2627/4500\n",
            "100/100 [==============================] - 0s 535us/step - loss: 0.2975 - acc: 0.8600 - val_loss: 0.3904 - val_acc: 0.8000\n",
            "Epoch 2628/4500\n",
            "100/100 [==============================] - 0s 494us/step - loss: 0.2980 - acc: 0.8600 - val_loss: 0.3920 - val_acc: 0.8000\n",
            "Epoch 2629/4500\n",
            "100/100 [==============================] - 0s 492us/step - loss: 0.2967 - acc: 0.8600 - val_loss: 0.3926 - val_acc: 0.8000\n",
            "Epoch 2630/4500\n",
            "100/100 [==============================] - 0s 531us/step - loss: 0.2988 - acc: 0.8500 - val_loss: 0.3889 - val_acc: 0.8000\n",
            "Epoch 2631/4500\n",
            "100/100 [==============================] - 0s 511us/step - loss: 0.2982 - acc: 0.8500 - val_loss: 0.3919 - val_acc: 0.8100\n",
            "Epoch 2632/4500\n",
            "100/100 [==============================] - 0s 557us/step - loss: 0.2971 - acc: 0.8600 - val_loss: 0.3910 - val_acc: 0.8000\n",
            "Epoch 2633/4500\n",
            "100/100 [==============================] - 0s 564us/step - loss: 0.2958 - acc: 0.8600 - val_loss: 0.3916 - val_acc: 0.8000\n",
            "Epoch 2634/4500\n",
            "100/100 [==============================] - 0s 537us/step - loss: 0.2961 - acc: 0.8600 - val_loss: 0.3923 - val_acc: 0.8000\n",
            "Epoch 2635/4500\n",
            "100/100 [==============================] - 0s 484us/step - loss: 0.2968 - acc: 0.8500 - val_loss: 0.3907 - val_acc: 0.8000\n",
            "Epoch 2636/4500\n",
            "100/100 [==============================] - 0s 499us/step - loss: 0.2970 - acc: 0.8600 - val_loss: 0.3893 - val_acc: 0.8000\n",
            "Epoch 2637/4500\n",
            "100/100 [==============================] - 0s 497us/step - loss: 0.2958 - acc: 0.8600 - val_loss: 0.3927 - val_acc: 0.8100\n",
            "Epoch 2638/4500\n",
            "100/100 [==============================] - 0s 494us/step - loss: 0.2965 - acc: 0.8600 - val_loss: 0.3910 - val_acc: 0.8000\n",
            "Epoch 2639/4500\n",
            "100/100 [==============================] - 0s 502us/step - loss: 0.2977 - acc: 0.8600 - val_loss: 0.3910 - val_acc: 0.7900\n",
            "Epoch 2640/4500\n",
            "100/100 [==============================] - 0s 521us/step - loss: 0.2965 - acc: 0.8600 - val_loss: 0.3908 - val_acc: 0.8100\n",
            "Epoch 2641/4500\n",
            "100/100 [==============================] - 0s 518us/step - loss: 0.2978 - acc: 0.8600 - val_loss: 0.3918 - val_acc: 0.8100\n",
            "Epoch 2642/4500\n",
            "100/100 [==============================] - 0s 516us/step - loss: 0.2943 - acc: 0.8600 - val_loss: 0.3886 - val_acc: 0.8000\n",
            "Epoch 2643/4500\n",
            "100/100 [==============================] - 0s 502us/step - loss: 0.2939 - acc: 0.8600 - val_loss: 0.3900 - val_acc: 0.8000\n",
            "Epoch 2644/4500\n",
            "100/100 [==============================] - 0s 476us/step - loss: 0.2957 - acc: 0.8600 - val_loss: 0.3920 - val_acc: 0.8000\n",
            "Epoch 2645/4500\n",
            "100/100 [==============================] - 0s 490us/step - loss: 0.2979 - acc: 0.8500 - val_loss: 0.3884 - val_acc: 0.8000\n",
            "Epoch 2646/4500\n",
            "100/100 [==============================] - 0s 528us/step - loss: 0.2948 - acc: 0.8600 - val_loss: 0.3925 - val_acc: 0.8100\n",
            "Epoch 2647/4500\n",
            "100/100 [==============================] - 0s 491us/step - loss: 0.2937 - acc: 0.8600 - val_loss: 0.3904 - val_acc: 0.8100\n",
            "Epoch 2648/4500\n",
            "100/100 [==============================] - 0s 496us/step - loss: 0.2940 - acc: 0.8600 - val_loss: 0.3900 - val_acc: 0.8000\n",
            "Epoch 2649/4500\n",
            "100/100 [==============================] - 0s 500us/step - loss: 0.3006 - acc: 0.8500 - val_loss: 0.3870 - val_acc: 0.8100\n",
            "Epoch 2650/4500\n",
            "100/100 [==============================] - 0s 505us/step - loss: 0.2930 - acc: 0.8600 - val_loss: 0.3927 - val_acc: 0.8100\n",
            "Epoch 2651/4500\n",
            "100/100 [==============================] - 0s 634us/step - loss: 0.2959 - acc: 0.8600 - val_loss: 0.3939 - val_acc: 0.8100\n",
            "Epoch 2652/4500\n",
            "100/100 [==============================] - 0s 582us/step - loss: 0.2933 - acc: 0.8600 - val_loss: 0.3908 - val_acc: 0.8100\n",
            "Epoch 2653/4500\n",
            "100/100 [==============================] - 0s 538us/step - loss: 0.2936 - acc: 0.8500 - val_loss: 0.3873 - val_acc: 0.8000\n",
            "Epoch 2654/4500\n",
            "100/100 [==============================] - 0s 499us/step - loss: 0.2937 - acc: 0.8600 - val_loss: 0.3889 - val_acc: 0.8000\n",
            "Epoch 2655/4500\n",
            "100/100 [==============================] - 0s 490us/step - loss: 0.2926 - acc: 0.8500 - val_loss: 0.3899 - val_acc: 0.8100\n",
            "Epoch 2656/4500\n",
            "100/100 [==============================] - 0s 474us/step - loss: 0.2936 - acc: 0.8600 - val_loss: 0.3918 - val_acc: 0.8100\n",
            "Epoch 2657/4500\n",
            "100/100 [==============================] - 0s 493us/step - loss: 0.2933 - acc: 0.8500 - val_loss: 0.3890 - val_acc: 0.8000\n",
            "Epoch 2658/4500\n",
            "100/100 [==============================] - 0s 514us/step - loss: 0.2931 - acc: 0.8600 - val_loss: 0.3890 - val_acc: 0.8100\n",
            "Epoch 2659/4500\n",
            "100/100 [==============================] - 0s 484us/step - loss: 0.2975 - acc: 0.8600 - val_loss: 0.3910 - val_acc: 0.8100\n",
            "Epoch 2660/4500\n",
            "100/100 [==============================] - 0s 537us/step - loss: 0.2919 - acc: 0.8500 - val_loss: 0.3887 - val_acc: 0.8100\n",
            "Epoch 2661/4500\n",
            "100/100 [==============================] - 0s 588us/step - loss: 0.2936 - acc: 0.8500 - val_loss: 0.3857 - val_acc: 0.8100\n",
            "Epoch 2662/4500\n",
            "100/100 [==============================] - 0s 573us/step - loss: 0.2923 - acc: 0.8500 - val_loss: 0.3882 - val_acc: 0.8100\n",
            "Epoch 2663/4500\n",
            "100/100 [==============================] - 0s 565us/step - loss: 0.2908 - acc: 0.8600 - val_loss: 0.3911 - val_acc: 0.8100\n",
            "Epoch 2664/4500\n",
            "100/100 [==============================] - 0s 552us/step - loss: 0.2917 - acc: 0.8600 - val_loss: 0.3913 - val_acc: 0.8100\n",
            "Epoch 2665/4500\n",
            "100/100 [==============================] - 0s 547us/step - loss: 0.2964 - acc: 0.8600 - val_loss: 0.3885 - val_acc: 0.8100\n",
            "Epoch 2666/4500\n",
            "100/100 [==============================] - 0s 514us/step - loss: 0.2905 - acc: 0.8500 - val_loss: 0.3900 - val_acc: 0.8100\n",
            "Epoch 2667/4500\n",
            "100/100 [==============================] - 0s 509us/step - loss: 0.2921 - acc: 0.8600 - val_loss: 0.3927 - val_acc: 0.8100\n",
            "Epoch 2668/4500\n",
            "100/100 [==============================] - 0s 502us/step - loss: 0.2902 - acc: 0.8600 - val_loss: 0.3887 - val_acc: 0.8100\n",
            "Epoch 2669/4500\n",
            "100/100 [==============================] - 0s 509us/step - loss: 0.2906 - acc: 0.8500 - val_loss: 0.3878 - val_acc: 0.8200\n",
            "Epoch 2670/4500\n",
            "100/100 [==============================] - 0s 538us/step - loss: 0.2898 - acc: 0.8600 - val_loss: 0.3902 - val_acc: 0.8100\n",
            "Epoch 2671/4500\n",
            "100/100 [==============================] - 0s 609us/step - loss: 0.2904 - acc: 0.8600 - val_loss: 0.3889 - val_acc: 0.8100\n",
            "Epoch 2672/4500\n",
            "100/100 [==============================] - 0s 498us/step - loss: 0.2894 - acc: 0.8500 - val_loss: 0.3868 - val_acc: 0.8100\n",
            "Epoch 2673/4500\n",
            "100/100 [==============================] - 0s 521us/step - loss: 0.2892 - acc: 0.8500 - val_loss: 0.3868 - val_acc: 0.8200\n",
            "Epoch 2674/4500\n",
            "100/100 [==============================] - 0s 498us/step - loss: 0.2902 - acc: 0.8500 - val_loss: 0.3880 - val_acc: 0.8100\n",
            "Epoch 2675/4500\n",
            "100/100 [==============================] - 0s 512us/step - loss: 0.2905 - acc: 0.8600 - val_loss: 0.3927 - val_acc: 0.8100\n",
            "Epoch 2676/4500\n",
            "100/100 [==============================] - 0s 514us/step - loss: 0.2892 - acc: 0.8600 - val_loss: 0.3904 - val_acc: 0.8100\n",
            "Epoch 2677/4500\n",
            "100/100 [==============================] - 0s 499us/step - loss: 0.2887 - acc: 0.8600 - val_loss: 0.3880 - val_acc: 0.8100\n",
            "Epoch 2678/4500\n",
            "100/100 [==============================] - 0s 581us/step - loss: 0.2891 - acc: 0.8500 - val_loss: 0.3858 - val_acc: 0.8200\n",
            "Epoch 2679/4500\n",
            "100/100 [==============================] - 0s 518us/step - loss: 0.2913 - acc: 0.8600 - val_loss: 0.3888 - val_acc: 0.8100\n",
            "Epoch 2680/4500\n",
            "100/100 [==============================] - 0s 589us/step - loss: 0.2886 - acc: 0.8600 - val_loss: 0.3879 - val_acc: 0.8100\n",
            "Epoch 2681/4500\n",
            "100/100 [==============================] - 0s 508us/step - loss: 0.2887 - acc: 0.8600 - val_loss: 0.3855 - val_acc: 0.8200\n",
            "Epoch 2682/4500\n",
            "100/100 [==============================] - 0s 499us/step - loss: 0.2906 - acc: 0.8500 - val_loss: 0.3844 - val_acc: 0.8200\n",
            "Epoch 2683/4500\n",
            "100/100 [==============================] - 0s 525us/step - loss: 0.2873 - acc: 0.8600 - val_loss: 0.3904 - val_acc: 0.8100\n",
            "Epoch 2684/4500\n",
            "100/100 [==============================] - 0s 488us/step - loss: 0.2895 - acc: 0.8600 - val_loss: 0.3899 - val_acc: 0.8100\n",
            "Epoch 2685/4500\n",
            "100/100 [==============================] - 0s 502us/step - loss: 0.2870 - acc: 0.8600 - val_loss: 0.3850 - val_acc: 0.8200\n",
            "Epoch 2686/4500\n",
            "100/100 [==============================] - 0s 522us/step - loss: 0.2884 - acc: 0.8500 - val_loss: 0.3852 - val_acc: 0.8200\n",
            "Epoch 2687/4500\n",
            "100/100 [==============================] - 0s 509us/step - loss: 0.2883 - acc: 0.8600 - val_loss: 0.3868 - val_acc: 0.8100\n",
            "Epoch 2688/4500\n",
            "100/100 [==============================] - 0s 482us/step - loss: 0.2883 - acc: 0.8600 - val_loss: 0.3885 - val_acc: 0.8100\n",
            "Epoch 2689/4500\n",
            "100/100 [==============================] - 0s 510us/step - loss: 0.2864 - acc: 0.8600 - val_loss: 0.3865 - val_acc: 0.8100\n",
            "Epoch 2690/4500\n",
            "100/100 [==============================] - 0s 659us/step - loss: 0.2874 - acc: 0.8500 - val_loss: 0.3850 - val_acc: 0.8100\n",
            "Epoch 2691/4500\n",
            "100/100 [==============================] - 0s 559us/step - loss: 0.2870 - acc: 0.8500 - val_loss: 0.3872 - val_acc: 0.8100\n",
            "Epoch 2692/4500\n",
            "100/100 [==============================] - 0s 482us/step - loss: 0.2875 - acc: 0.8500 - val_loss: 0.3849 - val_acc: 0.8200\n",
            "Epoch 2693/4500\n",
            "100/100 [==============================] - 0s 509us/step - loss: 0.2864 - acc: 0.8500 - val_loss: 0.3886 - val_acc: 0.8100\n",
            "Epoch 2694/4500\n",
            "100/100 [==============================] - 0s 489us/step - loss: 0.2862 - acc: 0.8600 - val_loss: 0.3870 - val_acc: 0.8100\n",
            "Epoch 2695/4500\n",
            "100/100 [==============================] - 0s 526us/step - loss: 0.2863 - acc: 0.8600 - val_loss: 0.3856 - val_acc: 0.8100\n",
            "Epoch 2696/4500\n",
            "100/100 [==============================] - 0s 524us/step - loss: 0.2851 - acc: 0.8600 - val_loss: 0.3851 - val_acc: 0.8200\n",
            "Epoch 2697/4500\n",
            "100/100 [==============================] - 0s 514us/step - loss: 0.2859 - acc: 0.8600 - val_loss: 0.3861 - val_acc: 0.8100\n",
            "Epoch 2698/4500\n",
            "100/100 [==============================] - 0s 511us/step - loss: 0.2856 - acc: 0.8600 - val_loss: 0.3878 - val_acc: 0.8100\n",
            "Epoch 2699/4500\n",
            "100/100 [==============================] - 0s 535us/step - loss: 0.2856 - acc: 0.8600 - val_loss: 0.3865 - val_acc: 0.8100\n",
            "Epoch 2700/4500\n",
            "100/100 [==============================] - 0s 693us/step - loss: 0.2830 - acc: 0.8600 - val_loss: 0.3836 - val_acc: 0.8200\n",
            "Epoch 2701/4500\n",
            "100/100 [==============================] - 0s 673us/step - loss: 0.2838 - acc: 0.8500 - val_loss: 0.3827 - val_acc: 0.8300\n",
            "Epoch 2702/4500\n",
            "100/100 [==============================] - 0s 542us/step - loss: 0.2944 - acc: 0.8500 - val_loss: 0.3901 - val_acc: 0.8100\n",
            "Epoch 2703/4500\n",
            "100/100 [==============================] - 0s 519us/step - loss: 0.2889 - acc: 0.8500 - val_loss: 0.3813 - val_acc: 0.8200\n",
            "Epoch 2704/4500\n",
            "100/100 [==============================] - 0s 498us/step - loss: 0.2864 - acc: 0.8500 - val_loss: 0.3837 - val_acc: 0.8300\n",
            "Epoch 2705/4500\n",
            "100/100 [==============================] - 0s 490us/step - loss: 0.2855 - acc: 0.8600 - val_loss: 0.3883 - val_acc: 0.8100\n",
            "Epoch 2706/4500\n",
            "100/100 [==============================] - 0s 536us/step - loss: 0.2835 - acc: 0.8600 - val_loss: 0.3873 - val_acc: 0.8100\n",
            "Epoch 2707/4500\n",
            "100/100 [==============================] - 0s 491us/step - loss: 0.2843 - acc: 0.8600 - val_loss: 0.3887 - val_acc: 0.8100\n",
            "Epoch 2708/4500\n",
            "100/100 [==============================] - 0s 558us/step - loss: 0.2838 - acc: 0.8600 - val_loss: 0.3835 - val_acc: 0.8100\n",
            "Epoch 2709/4500\n",
            "100/100 [==============================] - 0s 691us/step - loss: 0.2837 - acc: 0.8600 - val_loss: 0.3826 - val_acc: 0.8200\n",
            "Epoch 2710/4500\n",
            "100/100 [==============================] - 0s 520us/step - loss: 0.2871 - acc: 0.8600 - val_loss: 0.3894 - val_acc: 0.8100\n",
            "Epoch 2711/4500\n",
            "100/100 [==============================] - 0s 496us/step - loss: 0.2844 - acc: 0.8600 - val_loss: 0.3815 - val_acc: 0.8200\n",
            "Epoch 2712/4500\n",
            "100/100 [==============================] - 0s 498us/step - loss: 0.2833 - acc: 0.8500 - val_loss: 0.3848 - val_acc: 0.8100\n",
            "Epoch 2713/4500\n",
            "100/100 [==============================] - 0s 500us/step - loss: 0.2831 - acc: 0.8500 - val_loss: 0.3834 - val_acc: 0.8200\n",
            "Epoch 2714/4500\n",
            "100/100 [==============================] - 0s 586us/step - loss: 0.2863 - acc: 0.8500 - val_loss: 0.3845 - val_acc: 0.8100\n",
            "Epoch 2715/4500\n",
            "100/100 [==============================] - 0s 513us/step - loss: 0.2816 - acc: 0.8600 - val_loss: 0.3828 - val_acc: 0.8200\n",
            "Epoch 2716/4500\n",
            "100/100 [==============================] - 0s 513us/step - loss: 0.2831 - acc: 0.8500 - val_loss: 0.3821 - val_acc: 0.8200\n",
            "Epoch 2717/4500\n",
            "100/100 [==============================] - 0s 491us/step - loss: 0.2823 - acc: 0.8600 - val_loss: 0.3867 - val_acc: 0.8100\n",
            "Epoch 2718/4500\n",
            "100/100 [==============================] - 0s 492us/step - loss: 0.2810 - acc: 0.8600 - val_loss: 0.3835 - val_acc: 0.8100\n",
            "Epoch 2719/4500\n",
            "100/100 [==============================] - 0s 592us/step - loss: 0.2801 - acc: 0.8600 - val_loss: 0.3820 - val_acc: 0.8200\n",
            "Epoch 2720/4500\n",
            "100/100 [==============================] - 0s 584us/step - loss: 0.2818 - acc: 0.8500 - val_loss: 0.3810 - val_acc: 0.8200\n",
            "Epoch 2721/4500\n",
            "100/100 [==============================] - 0s 521us/step - loss: 0.2809 - acc: 0.8600 - val_loss: 0.3832 - val_acc: 0.8100\n",
            "Epoch 2722/4500\n",
            "100/100 [==============================] - 0s 545us/step - loss: 0.2812 - acc: 0.8500 - val_loss: 0.3836 - val_acc: 0.8100\n",
            "Epoch 2723/4500\n",
            "100/100 [==============================] - 0s 511us/step - loss: 0.2809 - acc: 0.8500 - val_loss: 0.3838 - val_acc: 0.8200\n",
            "Epoch 2724/4500\n",
            "100/100 [==============================] - 0s 518us/step - loss: 0.2802 - acc: 0.8600 - val_loss: 0.3817 - val_acc: 0.8200\n",
            "Epoch 2725/4500\n",
            "100/100 [==============================] - 0s 522us/step - loss: 0.2822 - acc: 0.8500 - val_loss: 0.3789 - val_acc: 0.8200\n",
            "Epoch 2726/4500\n",
            "100/100 [==============================] - 0s 543us/step - loss: 0.2785 - acc: 0.8600 - val_loss: 0.3826 - val_acc: 0.8100\n",
            "Epoch 2727/4500\n",
            "100/100 [==============================] - 0s 567us/step - loss: 0.2831 - acc: 0.8600 - val_loss: 0.3865 - val_acc: 0.8100\n",
            "Epoch 2728/4500\n",
            "100/100 [==============================] - 0s 669us/step - loss: 0.2785 - acc: 0.8500 - val_loss: 0.3789 - val_acc: 0.8300\n",
            "Epoch 2729/4500\n",
            "100/100 [==============================] - 0s 672us/step - loss: 0.2806 - acc: 0.8500 - val_loss: 0.3804 - val_acc: 0.8200\n",
            "Epoch 2730/4500\n",
            "100/100 [==============================] - 0s 673us/step - loss: 0.2826 - acc: 0.8600 - val_loss: 0.3862 - val_acc: 0.8100\n",
            "Epoch 2731/4500\n",
            "100/100 [==============================] - 0s 492us/step - loss: 0.2816 - acc: 0.8600 - val_loss: 0.3780 - val_acc: 0.8300\n",
            "Epoch 2732/4500\n",
            "100/100 [==============================] - 0s 490us/step - loss: 0.2775 - acc: 0.8500 - val_loss: 0.3801 - val_acc: 0.8200\n",
            "Epoch 2733/4500\n",
            "100/100 [==============================] - 0s 493us/step - loss: 0.2834 - acc: 0.8600 - val_loss: 0.3850 - val_acc: 0.8100\n",
            "Epoch 2734/4500\n",
            "100/100 [==============================] - 0s 504us/step - loss: 0.2780 - acc: 0.8600 - val_loss: 0.3802 - val_acc: 0.8200\n",
            "Epoch 2735/4500\n",
            "100/100 [==============================] - 0s 535us/step - loss: 0.2776 - acc: 0.8500 - val_loss: 0.3807 - val_acc: 0.8200\n",
            "Epoch 2736/4500\n",
            "100/100 [==============================] - 0s 485us/step - loss: 0.2782 - acc: 0.8600 - val_loss: 0.3816 - val_acc: 0.8100\n",
            "Epoch 2737/4500\n",
            "100/100 [==============================] - 0s 535us/step - loss: 0.2782 - acc: 0.8500 - val_loss: 0.3787 - val_acc: 0.8200\n",
            "Epoch 2738/4500\n",
            "100/100 [==============================] - 0s 605us/step - loss: 0.2771 - acc: 0.8600 - val_loss: 0.3829 - val_acc: 0.8100\n",
            "Epoch 2739/4500\n",
            "100/100 [==============================] - 0s 508us/step - loss: 0.2777 - acc: 0.8600 - val_loss: 0.3815 - val_acc: 0.8100\n",
            "Epoch 2740/4500\n",
            "100/100 [==============================] - 0s 516us/step - loss: 0.2797 - acc: 0.8500 - val_loss: 0.3768 - val_acc: 0.8300\n",
            "Epoch 2741/4500\n",
            "100/100 [==============================] - 0s 490us/step - loss: 0.2788 - acc: 0.8500 - val_loss: 0.3822 - val_acc: 0.8100\n",
            "Epoch 2742/4500\n",
            "100/100 [==============================] - 0s 508us/step - loss: 0.2752 - acc: 0.8600 - val_loss: 0.3815 - val_acc: 0.8100\n",
            "Epoch 2743/4500\n",
            "100/100 [==============================] - 0s 517us/step - loss: 0.2769 - acc: 0.8600 - val_loss: 0.3821 - val_acc: 0.8100\n",
            "Epoch 2744/4500\n",
            "100/100 [==============================] - 0s 531us/step - loss: 0.2767 - acc: 0.8500 - val_loss: 0.3760 - val_acc: 0.8200\n",
            "Epoch 2745/4500\n",
            "100/100 [==============================] - 0s 543us/step - loss: 0.2752 - acc: 0.8500 - val_loss: 0.3797 - val_acc: 0.8100\n",
            "Epoch 2746/4500\n",
            "100/100 [==============================] - 0s 622us/step - loss: 0.2742 - acc: 0.8600 - val_loss: 0.3825 - val_acc: 0.8100\n",
            "Epoch 2747/4500\n",
            "100/100 [==============================] - 0s 547us/step - loss: 0.2753 - acc: 0.8700 - val_loss: 0.3787 - val_acc: 0.8200\n",
            "Epoch 2748/4500\n",
            "100/100 [==============================] - 0s 499us/step - loss: 0.2758 - acc: 0.8500 - val_loss: 0.3806 - val_acc: 0.8200\n",
            "Epoch 2749/4500\n",
            "100/100 [==============================] - 0s 502us/step - loss: 0.2741 - acc: 0.8600 - val_loss: 0.3808 - val_acc: 0.8100\n",
            "Epoch 2750/4500\n",
            "100/100 [==============================] - 0s 490us/step - loss: 0.2737 - acc: 0.8600 - val_loss: 0.3826 - val_acc: 0.8100\n",
            "Epoch 2751/4500\n",
            "100/100 [==============================] - 0s 489us/step - loss: 0.2740 - acc: 0.8600 - val_loss: 0.3811 - val_acc: 0.8100\n",
            "Epoch 2752/4500\n",
            "100/100 [==============================] - 0s 507us/step - loss: 0.2736 - acc: 0.8600 - val_loss: 0.3809 - val_acc: 0.8100\n",
            "Epoch 2753/4500\n",
            "100/100 [==============================] - 0s 489us/step - loss: 0.2726 - acc: 0.8600 - val_loss: 0.3782 - val_acc: 0.8200\n",
            "Epoch 2754/4500\n",
            "100/100 [==============================] - 0s 536us/step - loss: 0.2739 - acc: 0.8600 - val_loss: 0.3785 - val_acc: 0.8200\n",
            "Epoch 2755/4500\n",
            "100/100 [==============================] - 0s 517us/step - loss: 0.2733 - acc: 0.8700 - val_loss: 0.3799 - val_acc: 0.8100\n",
            "Epoch 2756/4500\n",
            "100/100 [==============================] - 0s 529us/step - loss: 0.2731 - acc: 0.8600 - val_loss: 0.3792 - val_acc: 0.8200\n",
            "Epoch 2757/4500\n",
            "100/100 [==============================] - 0s 551us/step - loss: 0.2765 - acc: 0.8600 - val_loss: 0.3850 - val_acc: 0.8100\n",
            "Epoch 2758/4500\n",
            "100/100 [==============================] - 0s 589us/step - loss: 0.2717 - acc: 0.8500 - val_loss: 0.3782 - val_acc: 0.8200\n",
            "Epoch 2759/4500\n",
            "100/100 [==============================] - 0s 521us/step - loss: 0.2772 - acc: 0.8600 - val_loss: 0.3813 - val_acc: 0.8100\n",
            "Epoch 2760/4500\n",
            "100/100 [==============================] - 0s 534us/step - loss: 0.2715 - acc: 0.8700 - val_loss: 0.3752 - val_acc: 0.8200\n",
            "Epoch 2761/4500\n",
            "100/100 [==============================] - 0s 486us/step - loss: 0.2734 - acc: 0.8600 - val_loss: 0.3805 - val_acc: 0.8100\n",
            "Epoch 2762/4500\n",
            "100/100 [==============================] - 0s 508us/step - loss: 0.2733 - acc: 0.8600 - val_loss: 0.3791 - val_acc: 0.8200\n",
            "Epoch 2763/4500\n",
            "100/100 [==============================] - 0s 520us/step - loss: 0.2735 - acc: 0.8600 - val_loss: 0.3825 - val_acc: 0.8100\n",
            "Epoch 2764/4500\n",
            "100/100 [==============================] - 0s 539us/step - loss: 0.2711 - acc: 0.8600 - val_loss: 0.3809 - val_acc: 0.8100\n",
            "Epoch 2765/4500\n",
            "100/100 [==============================] - 0s 591us/step - loss: 0.2738 - acc: 0.8600 - val_loss: 0.3760 - val_acc: 0.8300\n",
            "Epoch 2766/4500\n",
            "100/100 [==============================] - 0s 518us/step - loss: 0.2698 - acc: 0.8600 - val_loss: 0.3806 - val_acc: 0.8100\n",
            "Epoch 2767/4500\n",
            "100/100 [==============================] - 0s 593us/step - loss: 0.2699 - acc: 0.8700 - val_loss: 0.3820 - val_acc: 0.8100\n",
            "Epoch 2768/4500\n",
            "100/100 [==============================] - 0s 574us/step - loss: 0.2736 - acc: 0.8600 - val_loss: 0.3826 - val_acc: 0.8100\n",
            "Epoch 2769/4500\n",
            "100/100 [==============================] - 0s 516us/step - loss: 0.2727 - acc: 0.8600 - val_loss: 0.3738 - val_acc: 0.8200\n",
            "Epoch 2770/4500\n",
            "100/100 [==============================] - 0s 505us/step - loss: 0.2730 - acc: 0.8600 - val_loss: 0.3773 - val_acc: 0.8200\n",
            "Epoch 2771/4500\n",
            "100/100 [==============================] - 0s 557us/step - loss: 0.2716 - acc: 0.8700 - val_loss: 0.3847 - val_acc: 0.8100\n",
            "Epoch 2772/4500\n",
            "100/100 [==============================] - 0s 501us/step - loss: 0.2700 - acc: 0.8600 - val_loss: 0.3786 - val_acc: 0.8100\n",
            "Epoch 2773/4500\n",
            "100/100 [==============================] - 0s 493us/step - loss: 0.2699 - acc: 0.8600 - val_loss: 0.3772 - val_acc: 0.8200\n",
            "Epoch 2774/4500\n",
            "100/100 [==============================] - 0s 508us/step - loss: 0.2695 - acc: 0.8600 - val_loss: 0.3813 - val_acc: 0.8100\n",
            "Epoch 2775/4500\n",
            "100/100 [==============================] - 0s 493us/step - loss: 0.2695 - acc: 0.8600 - val_loss: 0.3813 - val_acc: 0.8100\n",
            "Epoch 2776/4500\n",
            "100/100 [==============================] - 0s 508us/step - loss: 0.2691 - acc: 0.8600 - val_loss: 0.3787 - val_acc: 0.8200\n",
            "Epoch 2777/4500\n",
            "100/100 [==============================] - 0s 625us/step - loss: 0.2711 - acc: 0.8600 - val_loss: 0.3813 - val_acc: 0.8100\n",
            "Epoch 2778/4500\n",
            "100/100 [==============================] - 0s 614us/step - loss: 0.2690 - acc: 0.8700 - val_loss: 0.3784 - val_acc: 0.8100\n",
            "Epoch 2779/4500\n",
            "100/100 [==============================] - 0s 526us/step - loss: 0.2696 - acc: 0.8600 - val_loss: 0.3760 - val_acc: 0.8200\n",
            "Epoch 2780/4500\n",
            "100/100 [==============================] - 0s 498us/step - loss: 0.2674 - acc: 0.8600 - val_loss: 0.3805 - val_acc: 0.8100\n",
            "Epoch 2781/4500\n",
            "100/100 [==============================] - 0s 494us/step - loss: 0.2691 - acc: 0.8700 - val_loss: 0.3826 - val_acc: 0.8100\n",
            "Epoch 2782/4500\n",
            "100/100 [==============================] - 0s 530us/step - loss: 0.2704 - acc: 0.8700 - val_loss: 0.3815 - val_acc: 0.8100\n",
            "Epoch 2783/4500\n",
            "100/100 [==============================] - 0s 564us/step - loss: 0.2675 - acc: 0.8600 - val_loss: 0.3783 - val_acc: 0.8200\n",
            "Epoch 2784/4500\n",
            "100/100 [==============================] - 0s 526us/step - loss: 0.2698 - acc: 0.8700 - val_loss: 0.3812 - val_acc: 0.8100\n",
            "Epoch 2785/4500\n",
            "100/100 [==============================] - 0s 506us/step - loss: 0.2691 - acc: 0.8600 - val_loss: 0.3771 - val_acc: 0.8200\n",
            "Epoch 2786/4500\n",
            "100/100 [==============================] - 0s 490us/step - loss: 0.2671 - acc: 0.8600 - val_loss: 0.3774 - val_acc: 0.8200\n",
            "Epoch 2787/4500\n",
            "100/100 [==============================] - 0s 530us/step - loss: 0.2662 - acc: 0.8600 - val_loss: 0.3771 - val_acc: 0.8200\n",
            "Epoch 2788/4500\n",
            "100/100 [==============================] - 0s 541us/step - loss: 0.2686 - acc: 0.8600 - val_loss: 0.3776 - val_acc: 0.8200\n",
            "Epoch 2789/4500\n",
            "100/100 [==============================] - 0s 531us/step - loss: 0.2704 - acc: 0.8700 - val_loss: 0.3829 - val_acc: 0.8100\n",
            "Epoch 2790/4500\n",
            "100/100 [==============================] - 0s 604us/step - loss: 0.2648 - acc: 0.8800 - val_loss: 0.3763 - val_acc: 0.8200\n",
            "Epoch 2791/4500\n",
            "100/100 [==============================] - 0s 499us/step - loss: 0.2683 - acc: 0.8600 - val_loss: 0.3805 - val_acc: 0.8100\n",
            "Epoch 2792/4500\n",
            "100/100 [==============================] - 0s 498us/step - loss: 0.2694 - acc: 0.8600 - val_loss: 0.3755 - val_acc: 0.8200\n",
            "Epoch 2793/4500\n",
            "100/100 [==============================] - 0s 508us/step - loss: 0.2648 - acc: 0.8600 - val_loss: 0.3796 - val_acc: 0.8100\n",
            "Epoch 2794/4500\n",
            "100/100 [==============================] - 0s 502us/step - loss: 0.2658 - acc: 0.8700 - val_loss: 0.3780 - val_acc: 0.8200\n",
            "Epoch 2795/4500\n",
            "100/100 [==============================] - 0s 540us/step - loss: 0.2655 - acc: 0.8700 - val_loss: 0.3786 - val_acc: 0.8100\n",
            "Epoch 2796/4500\n",
            "100/100 [==============================] - 0s 493us/step - loss: 0.2654 - acc: 0.8800 - val_loss: 0.3801 - val_acc: 0.8100\n",
            "Epoch 2797/4500\n",
            "100/100 [==============================] - 0s 589us/step - loss: 0.2652 - acc: 0.8600 - val_loss: 0.3737 - val_acc: 0.8400\n",
            "Epoch 2798/4500\n",
            "100/100 [==============================] - 0s 517us/step - loss: 0.2648 - acc: 0.8600 - val_loss: 0.3785 - val_acc: 0.8200\n",
            "Epoch 2799/4500\n",
            "100/100 [==============================] - 0s 497us/step - loss: 0.2641 - acc: 0.8600 - val_loss: 0.3786 - val_acc: 0.8100\n",
            "Epoch 2800/4500\n",
            "100/100 [==============================] - 0s 498us/step - loss: 0.2660 - acc: 0.8800 - val_loss: 0.3795 - val_acc: 0.8100\n",
            "Epoch 2801/4500\n",
            "100/100 [==============================] - 0s 497us/step - loss: 0.2646 - acc: 0.8700 - val_loss: 0.3782 - val_acc: 0.8200\n",
            "Epoch 2802/4500\n",
            "100/100 [==============================] - 0s 567us/step - loss: 0.2631 - acc: 0.8700 - val_loss: 0.3809 - val_acc: 0.8100\n",
            "Epoch 2803/4500\n",
            "100/100 [==============================] - 0s 614us/step - loss: 0.2624 - acc: 0.8800 - val_loss: 0.3794 - val_acc: 0.8100\n",
            "Epoch 2804/4500\n",
            "100/100 [==============================] - 0s 543us/step - loss: 0.2635 - acc: 0.8800 - val_loss: 0.3807 - val_acc: 0.8100\n",
            "Epoch 2805/4500\n",
            "100/100 [==============================] - 0s 526us/step - loss: 0.2627 - acc: 0.8600 - val_loss: 0.3765 - val_acc: 0.8200\n",
            "Epoch 2806/4500\n",
            "100/100 [==============================] - 0s 520us/step - loss: 0.2632 - acc: 0.8800 - val_loss: 0.3768 - val_acc: 0.8200\n",
            "Epoch 2807/4500\n",
            "100/100 [==============================] - 0s 498us/step - loss: 0.2637 - acc: 0.8700 - val_loss: 0.3744 - val_acc: 0.8300\n",
            "Epoch 2808/4500\n",
            "100/100 [==============================] - 0s 494us/step - loss: 0.2638 - acc: 0.8600 - val_loss: 0.3770 - val_acc: 0.8300\n",
            "Epoch 2809/4500\n",
            "100/100 [==============================] - 0s 488us/step - loss: 0.2622 - acc: 0.8600 - val_loss: 0.3783 - val_acc: 0.8100\n",
            "Epoch 2810/4500\n",
            "100/100 [==============================] - 0s 509us/step - loss: 0.2611 - acc: 0.8600 - val_loss: 0.3795 - val_acc: 0.8100\n",
            "Epoch 2811/4500\n",
            "100/100 [==============================] - 0s 576us/step - loss: 0.2635 - acc: 0.8600 - val_loss: 0.3807 - val_acc: 0.8100\n",
            "Epoch 2812/4500\n",
            "100/100 [==============================] - 0s 527us/step - loss: 0.2624 - acc: 0.8700 - val_loss: 0.3786 - val_acc: 0.8100\n",
            "Epoch 2813/4500\n",
            "100/100 [==============================] - 0s 531us/step - loss: 0.2621 - acc: 0.8800 - val_loss: 0.3803 - val_acc: 0.8100\n",
            "Epoch 2814/4500\n",
            "100/100 [==============================] - 0s 508us/step - loss: 0.2611 - acc: 0.8700 - val_loss: 0.3767 - val_acc: 0.8200\n",
            "Epoch 2815/4500\n",
            "100/100 [==============================] - 0s 522us/step - loss: 0.2612 - acc: 0.8800 - val_loss: 0.3792 - val_acc: 0.8100\n",
            "Epoch 2816/4500\n",
            "100/100 [==============================] - 0s 525us/step - loss: 0.2639 - acc: 0.8600 - val_loss: 0.3792 - val_acc: 0.8200\n",
            "Epoch 2817/4500\n",
            "100/100 [==============================] - 0s 498us/step - loss: 0.2648 - acc: 0.8800 - val_loss: 0.3785 - val_acc: 0.8200\n",
            "Epoch 2818/4500\n",
            "100/100 [==============================] - 0s 515us/step - loss: 0.2615 - acc: 0.8700 - val_loss: 0.3763 - val_acc: 0.8200\n",
            "Epoch 2819/4500\n",
            "100/100 [==============================] - 0s 495us/step - loss: 0.2614 - acc: 0.8600 - val_loss: 0.3735 - val_acc: 0.8300\n",
            "Epoch 2820/4500\n",
            "100/100 [==============================] - 0s 533us/step - loss: 0.2661 - acc: 0.8800 - val_loss: 0.3771 - val_acc: 0.8100\n",
            "Epoch 2821/4500\n",
            "100/100 [==============================] - 0s 513us/step - loss: 0.2630 - acc: 0.8700 - val_loss: 0.3720 - val_acc: 0.8500\n",
            "Epoch 2822/4500\n",
            "100/100 [==============================] - 0s 569us/step - loss: 0.2601 - acc: 0.8600 - val_loss: 0.3763 - val_acc: 0.8300\n",
            "Epoch 2823/4500\n",
            "100/100 [==============================] - 0s 511us/step - loss: 0.2601 - acc: 0.8800 - val_loss: 0.3849 - val_acc: 0.8100\n",
            "Epoch 2824/4500\n",
            "100/100 [==============================] - 0s 536us/step - loss: 0.2596 - acc: 0.8800 - val_loss: 0.3765 - val_acc: 0.8200\n",
            "Epoch 2825/4500\n",
            "100/100 [==============================] - 0s 504us/step - loss: 0.2630 - acc: 0.8700 - val_loss: 0.3742 - val_acc: 0.8300\n",
            "Epoch 2826/4500\n",
            "100/100 [==============================] - 0s 570us/step - loss: 0.2588 - acc: 0.8800 - val_loss: 0.3790 - val_acc: 0.8100\n",
            "Epoch 2827/4500\n",
            "100/100 [==============================] - 0s 594us/step - loss: 0.2605 - acc: 0.8800 - val_loss: 0.3790 - val_acc: 0.8100\n",
            "Epoch 2828/4500\n",
            "100/100 [==============================] - 0s 497us/step - loss: 0.2623 - acc: 0.8800 - val_loss: 0.3783 - val_acc: 0.8200\n",
            "Epoch 2829/4500\n",
            "100/100 [==============================] - 0s 528us/step - loss: 0.2580 - acc: 0.8700 - val_loss: 0.3749 - val_acc: 0.8300\n",
            "Epoch 2830/4500\n",
            "100/100 [==============================] - 0s 499us/step - loss: 0.2579 - acc: 0.8700 - val_loss: 0.3748 - val_acc: 0.8300\n",
            "Epoch 2831/4500\n",
            "100/100 [==============================] - 0s 520us/step - loss: 0.2575 - acc: 0.8800 - val_loss: 0.3796 - val_acc: 0.8100\n",
            "Epoch 2832/4500\n",
            "100/100 [==============================] - 0s 488us/step - loss: 0.2579 - acc: 0.8700 - val_loss: 0.3790 - val_acc: 0.8300\n",
            "Epoch 2833/4500\n",
            "100/100 [==============================] - 0s 516us/step - loss: 0.2581 - acc: 0.8700 - val_loss: 0.3772 - val_acc: 0.8300\n",
            "Epoch 2834/4500\n",
            "100/100 [==============================] - 0s 494us/step - loss: 0.2596 - acc: 0.8700 - val_loss: 0.3756 - val_acc: 0.8300\n",
            "Epoch 2835/4500\n",
            "100/100 [==============================] - 0s 507us/step - loss: 0.2575 - acc: 0.8700 - val_loss: 0.3794 - val_acc: 0.8100\n",
            "Epoch 2836/4500\n",
            "100/100 [==============================] - 0s 623us/step - loss: 0.2590 - acc: 0.8600 - val_loss: 0.3777 - val_acc: 0.8300\n",
            "Epoch 2837/4500\n",
            "100/100 [==============================] - 0s 553us/step - loss: 0.2582 - acc: 0.8700 - val_loss: 0.3795 - val_acc: 0.8100\n",
            "Epoch 2838/4500\n",
            "100/100 [==============================] - 0s 526us/step - loss: 0.2601 - acc: 0.8800 - val_loss: 0.3854 - val_acc: 0.8100\n",
            "Epoch 2839/4500\n",
            "100/100 [==============================] - 0s 504us/step - loss: 0.2564 - acc: 0.8800 - val_loss: 0.3746 - val_acc: 0.8300\n",
            "Epoch 2840/4500\n",
            "100/100 [==============================] - 0s 561us/step - loss: 0.2599 - acc: 0.8800 - val_loss: 0.3774 - val_acc: 0.8300\n",
            "Epoch 2841/4500\n",
            "100/100 [==============================] - 0s 547us/step - loss: 0.2588 - acc: 0.8700 - val_loss: 0.3719 - val_acc: 0.8500\n",
            "Epoch 2842/4500\n",
            "100/100 [==============================] - 0s 526us/step - loss: 0.2573 - acc: 0.8700 - val_loss: 0.3769 - val_acc: 0.8200\n",
            "Epoch 2843/4500\n",
            "100/100 [==============================] - 0s 516us/step - loss: 0.2575 - acc: 0.8800 - val_loss: 0.3793 - val_acc: 0.8100\n",
            "Epoch 2844/4500\n",
            "100/100 [==============================] - 0s 523us/step - loss: 0.2559 - acc: 0.8800 - val_loss: 0.3786 - val_acc: 0.8300\n",
            "Epoch 2845/4500\n",
            "100/100 [==============================] - 0s 503us/step - loss: 0.2553 - acc: 0.8800 - val_loss: 0.3761 - val_acc: 0.8300\n",
            "Epoch 2846/4500\n",
            "100/100 [==============================] - 0s 549us/step - loss: 0.2576 - acc: 0.8700 - val_loss: 0.3783 - val_acc: 0.8300\n",
            "Epoch 2847/4500\n",
            "100/100 [==============================] - 0s 520us/step - loss: 0.2559 - acc: 0.8800 - val_loss: 0.3752 - val_acc: 0.8300\n",
            "Epoch 2848/4500\n",
            "100/100 [==============================] - 0s 513us/step - loss: 0.2580 - acc: 0.8800 - val_loss: 0.3811 - val_acc: 0.8100\n",
            "Epoch 2849/4500\n",
            "100/100 [==============================] - 0s 498us/step - loss: 0.2558 - acc: 0.8800 - val_loss: 0.3727 - val_acc: 0.8300\n",
            "Epoch 2850/4500\n",
            "100/100 [==============================] - 0s 515us/step - loss: 0.2583 - acc: 0.8800 - val_loss: 0.3786 - val_acc: 0.8100\n",
            "Epoch 2851/4500\n",
            "100/100 [==============================] - 0s 515us/step - loss: 0.2576 - acc: 0.8800 - val_loss: 0.3708 - val_acc: 0.8500\n",
            "Epoch 2852/4500\n",
            "100/100 [==============================] - 0s 536us/step - loss: 0.2545 - acc: 0.8700 - val_loss: 0.3742 - val_acc: 0.8300\n",
            "Epoch 2853/4500\n",
            "100/100 [==============================] - 0s 509us/step - loss: 0.2600 - acc: 0.8900 - val_loss: 0.3862 - val_acc: 0.8100\n",
            "Epoch 2854/4500\n",
            "100/100 [==============================] - 0s 522us/step - loss: 0.2556 - acc: 0.8800 - val_loss: 0.3716 - val_acc: 0.8500\n",
            "Epoch 2855/4500\n",
            "100/100 [==============================] - 0s 503us/step - loss: 0.2554 - acc: 0.8800 - val_loss: 0.3766 - val_acc: 0.8300\n",
            "Epoch 2856/4500\n",
            "100/100 [==============================] - 0s 618us/step - loss: 0.2532 - acc: 0.8700 - val_loss: 0.3752 - val_acc: 0.8300\n",
            "Epoch 2857/4500\n",
            "100/100 [==============================] - 0s 590us/step - loss: 0.2556 - acc: 0.8700 - val_loss: 0.3756 - val_acc: 0.8300\n",
            "Epoch 2858/4500\n",
            "100/100 [==============================] - 0s 526us/step - loss: 0.2536 - acc: 0.8700 - val_loss: 0.3755 - val_acc: 0.8300\n",
            "Epoch 2859/4500\n",
            "100/100 [==============================] - 0s 585us/step - loss: 0.2524 - acc: 0.8700 - val_loss: 0.3800 - val_acc: 0.8200\n",
            "Epoch 2860/4500\n",
            "100/100 [==============================] - 0s 695us/step - loss: 0.2521 - acc: 0.8800 - val_loss: 0.3779 - val_acc: 0.8300\n",
            "Epoch 2861/4500\n",
            "100/100 [==============================] - 0s 522us/step - loss: 0.2517 - acc: 0.8700 - val_loss: 0.3743 - val_acc: 0.8300\n",
            "Epoch 2862/4500\n",
            "100/100 [==============================] - 0s 526us/step - loss: 0.2531 - acc: 0.8700 - val_loss: 0.3760 - val_acc: 0.8300\n",
            "Epoch 2863/4500\n",
            "100/100 [==============================] - 0s 496us/step - loss: 0.2553 - acc: 0.8700 - val_loss: 0.3747 - val_acc: 0.8300\n",
            "Epoch 2864/4500\n",
            "100/100 [==============================] - 0s 488us/step - loss: 0.2548 - acc: 0.8700 - val_loss: 0.3713 - val_acc: 0.8400\n",
            "Epoch 2865/4500\n",
            "100/100 [==============================] - 0s 539us/step - loss: 0.2552 - acc: 0.8700 - val_loss: 0.3763 - val_acc: 0.8300\n",
            "Epoch 2866/4500\n",
            "100/100 [==============================] - 0s 544us/step - loss: 0.2521 - acc: 0.8700 - val_loss: 0.3759 - val_acc: 0.8300\n",
            "Epoch 2867/4500\n",
            "100/100 [==============================] - 0s 546us/step - loss: 0.2573 - acc: 0.8800 - val_loss: 0.3767 - val_acc: 0.8300\n",
            "Epoch 2868/4500\n",
            "100/100 [==============================] - 0s 502us/step - loss: 0.2529 - acc: 0.8700 - val_loss: 0.3746 - val_acc: 0.8400\n",
            "Epoch 2869/4500\n",
            "100/100 [==============================] - 0s 485us/step - loss: 0.2523 - acc: 0.8800 - val_loss: 0.3795 - val_acc: 0.8300\n",
            "Epoch 2870/4500\n",
            "100/100 [==============================] - 0s 501us/step - loss: 0.2531 - acc: 0.8700 - val_loss: 0.3719 - val_acc: 0.8400\n",
            "Epoch 2871/4500\n",
            "100/100 [==============================] - 0s 513us/step - loss: 0.2533 - acc: 0.8700 - val_loss: 0.3818 - val_acc: 0.8200\n",
            "Epoch 2872/4500\n",
            "100/100 [==============================] - 0s 637us/step - loss: 0.2553 - acc: 0.8900 - val_loss: 0.3768 - val_acc: 0.8300\n",
            "Epoch 2873/4500\n",
            "100/100 [==============================] - 0s 536us/step - loss: 0.2539 - acc: 0.8700 - val_loss: 0.3708 - val_acc: 0.8500\n",
            "Epoch 2874/4500\n",
            "100/100 [==============================] - 0s 504us/step - loss: 0.2521 - acc: 0.8700 - val_loss: 0.3750 - val_acc: 0.8300\n",
            "Epoch 2875/4500\n",
            "100/100 [==============================] - 0s 586us/step - loss: 0.2492 - acc: 0.8700 - val_loss: 0.3741 - val_acc: 0.8300\n",
            "Epoch 2876/4500\n",
            "100/100 [==============================] - 0s 509us/step - loss: 0.2589 - acc: 0.8700 - val_loss: 0.3763 - val_acc: 0.8300\n",
            "Epoch 2877/4500\n",
            "100/100 [==============================] - 0s 512us/step - loss: 0.2544 - acc: 0.8600 - val_loss: 0.3715 - val_acc: 0.8400\n",
            "Epoch 2878/4500\n",
            "100/100 [==============================] - 0s 582us/step - loss: 0.2547 - acc: 0.8700 - val_loss: 0.3753 - val_acc: 0.8400\n",
            "Epoch 2879/4500\n",
            "100/100 [==============================] - 0s 506us/step - loss: 0.2495 - acc: 0.8700 - val_loss: 0.3818 - val_acc: 0.8200\n",
            "Epoch 2880/4500\n",
            "100/100 [==============================] - 0s 506us/step - loss: 0.2521 - acc: 0.8900 - val_loss: 0.3847 - val_acc: 0.8200\n",
            "Epoch 2881/4500\n",
            "100/100 [==============================] - 0s 534us/step - loss: 0.2496 - acc: 0.8700 - val_loss: 0.3754 - val_acc: 0.8400\n",
            "Epoch 2882/4500\n",
            "100/100 [==============================] - 0s 525us/step - loss: 0.2511 - acc: 0.8800 - val_loss: 0.3753 - val_acc: 0.8300\n",
            "Epoch 2883/4500\n",
            "100/100 [==============================] - 0s 526us/step - loss: 0.2509 - acc: 0.8700 - val_loss: 0.3738 - val_acc: 0.8400\n",
            "Epoch 2884/4500\n",
            "100/100 [==============================] - 0s 569us/step - loss: 0.2493 - acc: 0.8700 - val_loss: 0.3757 - val_acc: 0.8300\n",
            "Epoch 2885/4500\n",
            "100/100 [==============================] - 0s 557us/step - loss: 0.2504 - acc: 0.8700 - val_loss: 0.3759 - val_acc: 0.8300\n",
            "Epoch 2886/4500\n",
            "100/100 [==============================] - 0s 527us/step - loss: 0.2485 - acc: 0.8700 - val_loss: 0.3763 - val_acc: 0.8400\n",
            "Epoch 2887/4500\n",
            "100/100 [==============================] - 0s 503us/step - loss: 0.2502 - acc: 0.8700 - val_loss: 0.3762 - val_acc: 0.8300\n",
            "Epoch 2888/4500\n",
            "100/100 [==============================] - 0s 504us/step - loss: 0.2489 - acc: 0.8700 - val_loss: 0.3787 - val_acc: 0.8300\n",
            "Epoch 2889/4500\n",
            "100/100 [==============================] - 0s 517us/step - loss: 0.2502 - acc: 0.8700 - val_loss: 0.3705 - val_acc: 0.8400\n",
            "Epoch 2890/4500\n",
            "100/100 [==============================] - 0s 505us/step - loss: 0.2470 - acc: 0.8700 - val_loss: 0.3771 - val_acc: 0.8300\n",
            "Epoch 2891/4500\n",
            "100/100 [==============================] - 0s 507us/step - loss: 0.2488 - acc: 0.8800 - val_loss: 0.3779 - val_acc: 0.8300\n",
            "Epoch 2892/4500\n",
            "100/100 [==============================] - 0s 511us/step - loss: 0.2459 - acc: 0.8800 - val_loss: 0.3758 - val_acc: 0.8400\n",
            "Epoch 2893/4500\n",
            "100/100 [==============================] - 0s 506us/step - loss: 0.2465 - acc: 0.8700 - val_loss: 0.3745 - val_acc: 0.8400\n",
            "Epoch 2894/4500\n",
            "100/100 [==============================] - 0s 490us/step - loss: 0.2471 - acc: 0.8700 - val_loss: 0.3744 - val_acc: 0.8400\n",
            "Epoch 2895/4500\n",
            "100/100 [==============================] - 0s 518us/step - loss: 0.2464 - acc: 0.8700 - val_loss: 0.3762 - val_acc: 0.8400\n",
            "Epoch 2896/4500\n",
            "100/100 [==============================] - 0s 480us/step - loss: 0.2452 - acc: 0.8700 - val_loss: 0.3774 - val_acc: 0.8300\n",
            "Epoch 2897/4500\n",
            "100/100 [==============================] - 0s 595us/step - loss: 0.2457 - acc: 0.8700 - val_loss: 0.3780 - val_acc: 0.8300\n",
            "Epoch 2898/4500\n",
            "100/100 [==============================] - 0s 541us/step - loss: 0.2469 - acc: 0.8800 - val_loss: 0.3798 - val_acc: 0.8300\n",
            "Epoch 2899/4500\n",
            "100/100 [==============================] - 0s 514us/step - loss: 0.2462 - acc: 0.8700 - val_loss: 0.3722 - val_acc: 0.8400\n",
            "Epoch 2900/4500\n",
            "100/100 [==============================] - 0s 513us/step - loss: 0.2466 - acc: 0.8800 - val_loss: 0.3738 - val_acc: 0.8400\n",
            "Epoch 2901/4500\n",
            "100/100 [==============================] - 0s 549us/step - loss: 0.2453 - acc: 0.8800 - val_loss: 0.3821 - val_acc: 0.8200\n",
            "Epoch 2902/4500\n",
            "100/100 [==============================] - 0s 510us/step - loss: 0.2438 - acc: 0.8900 - val_loss: 0.3762 - val_acc: 0.8400\n",
            "Epoch 2903/4500\n",
            "100/100 [==============================] - 0s 507us/step - loss: 0.2480 - acc: 0.8700 - val_loss: 0.3705 - val_acc: 0.8400\n",
            "Epoch 2904/4500\n",
            "100/100 [==============================] - 0s 504us/step - loss: 0.2460 - acc: 0.8700 - val_loss: 0.3776 - val_acc: 0.8300\n",
            "Epoch 2905/4500\n",
            "100/100 [==============================] - 0s 608us/step - loss: 0.2439 - acc: 0.8700 - val_loss: 0.3757 - val_acc: 0.8400\n",
            "Epoch 2906/4500\n",
            "100/100 [==============================] - 0s 530us/step - loss: 0.2437 - acc: 0.8700 - val_loss: 0.3769 - val_acc: 0.8400\n",
            "Epoch 2907/4500\n",
            "100/100 [==============================] - 0s 519us/step - loss: 0.2441 - acc: 0.8700 - val_loss: 0.3752 - val_acc: 0.8400\n",
            "Epoch 2908/4500\n",
            "100/100 [==============================] - 0s 513us/step - loss: 0.2439 - acc: 0.8700 - val_loss: 0.3730 - val_acc: 0.8400\n",
            "Epoch 2909/4500\n",
            "100/100 [==============================] - 0s 501us/step - loss: 0.2476 - acc: 0.8700 - val_loss: 0.3738 - val_acc: 0.8400\n",
            "Epoch 2910/4500\n",
            "100/100 [==============================] - 0s 536us/step - loss: 0.2452 - acc: 0.8900 - val_loss: 0.3810 - val_acc: 0.8200\n",
            "Epoch 2911/4500\n",
            "100/100 [==============================] - 0s 542us/step - loss: 0.2451 - acc: 0.8800 - val_loss: 0.3784 - val_acc: 0.8200\n",
            "Epoch 2912/4500\n",
            "100/100 [==============================] - 0s 545us/step - loss: 0.2439 - acc: 0.8900 - val_loss: 0.3772 - val_acc: 0.8400\n",
            "Epoch 2913/4500\n",
            "100/100 [==============================] - 0s 561us/step - loss: 0.2433 - acc: 0.8800 - val_loss: 0.3689 - val_acc: 0.8500\n",
            "Epoch 2914/4500\n",
            "100/100 [==============================] - 0s 609us/step - loss: 0.2449 - acc: 0.8700 - val_loss: 0.3773 - val_acc: 0.8400\n",
            "Epoch 2915/4500\n",
            "100/100 [==============================] - 0s 576us/step - loss: 0.2471 - acc: 0.9000 - val_loss: 0.3753 - val_acc: 0.8400\n",
            "Epoch 2916/4500\n",
            "100/100 [==============================] - 0s 578us/step - loss: 0.2448 - acc: 0.8800 - val_loss: 0.3677 - val_acc: 0.8500\n",
            "Epoch 2917/4500\n",
            "100/100 [==============================] - 0s 486us/step - loss: 0.2440 - acc: 0.8800 - val_loss: 0.3741 - val_acc: 0.8400\n",
            "Epoch 2918/4500\n",
            "100/100 [==============================] - 0s 496us/step - loss: 0.2438 - acc: 0.8800 - val_loss: 0.3793 - val_acc: 0.8300\n",
            "Epoch 2919/4500\n",
            "100/100 [==============================] - 0s 515us/step - loss: 0.2450 - acc: 0.8800 - val_loss: 0.3752 - val_acc: 0.8400\n",
            "Epoch 2920/4500\n",
            "100/100 [==============================] - 0s 501us/step - loss: 0.2492 - acc: 0.8700 - val_loss: 0.3840 - val_acc: 0.8200\n",
            "Epoch 2921/4500\n",
            "100/100 [==============================] - 0s 517us/step - loss: 0.2439 - acc: 0.8800 - val_loss: 0.3642 - val_acc: 0.8500\n",
            "Epoch 2922/4500\n",
            "100/100 [==============================] - 0s 517us/step - loss: 0.2451 - acc: 0.8800 - val_loss: 0.3739 - val_acc: 0.8400\n",
            "Epoch 2923/4500\n",
            "100/100 [==============================] - 0s 514us/step - loss: 0.2421 - acc: 0.8900 - val_loss: 0.3793 - val_acc: 0.8400\n",
            "Epoch 2924/4500\n",
            "100/100 [==============================] - 0s 641us/step - loss: 0.2421 - acc: 0.8800 - val_loss: 0.3714 - val_acc: 0.8400\n",
            "Epoch 2925/4500\n",
            "100/100 [==============================] - 0s 623us/step - loss: 0.2435 - acc: 0.8800 - val_loss: 0.3736 - val_acc: 0.8400\n",
            "Epoch 2926/4500\n",
            "100/100 [==============================] - 0s 546us/step - loss: 0.2422 - acc: 0.8800 - val_loss: 0.3724 - val_acc: 0.8400\n",
            "Epoch 2927/4500\n",
            "100/100 [==============================] - 0s 519us/step - loss: 0.2435 - acc: 0.8800 - val_loss: 0.3787 - val_acc: 0.8400\n",
            "Epoch 2928/4500\n",
            "100/100 [==============================] - 0s 490us/step - loss: 0.2440 - acc: 0.8800 - val_loss: 0.3696 - val_acc: 0.8500\n",
            "Epoch 2929/4500\n",
            "100/100 [==============================] - 0s 508us/step - loss: 0.2419 - acc: 0.8700 - val_loss: 0.3801 - val_acc: 0.8400\n",
            "Epoch 2930/4500\n",
            "100/100 [==============================] - 0s 500us/step - loss: 0.2411 - acc: 0.8700 - val_loss: 0.3736 - val_acc: 0.8400\n",
            "Epoch 2931/4500\n",
            "100/100 [==============================] - 0s 546us/step - loss: 0.2409 - acc: 0.8800 - val_loss: 0.3774 - val_acc: 0.8400\n",
            "Epoch 2932/4500\n",
            "100/100 [==============================] - 0s 549us/step - loss: 0.2400 - acc: 0.8800 - val_loss: 0.3725 - val_acc: 0.8400\n",
            "Epoch 2933/4500\n",
            "100/100 [==============================] - 0s 593us/step - loss: 0.2404 - acc: 0.8800 - val_loss: 0.3716 - val_acc: 0.8400\n",
            "Epoch 2934/4500\n",
            "100/100 [==============================] - 0s 611us/step - loss: 0.2396 - acc: 0.8800 - val_loss: 0.3757 - val_acc: 0.8400\n",
            "Epoch 2935/4500\n",
            "100/100 [==============================] - 0s 543us/step - loss: 0.2421 - acc: 0.8800 - val_loss: 0.3773 - val_acc: 0.8400\n",
            "Epoch 2936/4500\n",
            "100/100 [==============================] - 0s 518us/step - loss: 0.2390 - acc: 0.8800 - val_loss: 0.3815 - val_acc: 0.8400\n",
            "Epoch 2937/4500\n",
            "100/100 [==============================] - 0s 528us/step - loss: 0.2404 - acc: 0.8900 - val_loss: 0.3762 - val_acc: 0.8400\n",
            "Epoch 2938/4500\n",
            "100/100 [==============================] - 0s 495us/step - loss: 0.2404 - acc: 0.8800 - val_loss: 0.3674 - val_acc: 0.8500\n",
            "Epoch 2939/4500\n",
            "100/100 [==============================] - 0s 538us/step - loss: 0.2426 - acc: 0.8800 - val_loss: 0.3770 - val_acc: 0.8400\n",
            "Epoch 2940/4500\n",
            "100/100 [==============================] - 0s 507us/step - loss: 0.2414 - acc: 0.8800 - val_loss: 0.3736 - val_acc: 0.8400\n",
            "Epoch 2941/4500\n",
            "100/100 [==============================] - 0s 518us/step - loss: 0.2509 - acc: 0.8800 - val_loss: 0.3802 - val_acc: 0.8200\n",
            "Epoch 2942/4500\n",
            "100/100 [==============================] - 0s 495us/step - loss: 0.2458 - acc: 0.8900 - val_loss: 0.3873 - val_acc: 0.8000\n",
            "Epoch 2943/4500\n",
            "100/100 [==============================] - 0s 548us/step - loss: 0.2431 - acc: 0.8800 - val_loss: 0.3700 - val_acc: 0.8500\n",
            "Epoch 2944/4500\n",
            "100/100 [==============================] - 0s 495us/step - loss: 0.2434 - acc: 0.8700 - val_loss: 0.3819 - val_acc: 0.8300\n",
            "Epoch 2945/4500\n",
            "100/100 [==============================] - 0s 517us/step - loss: 0.2439 - acc: 0.8800 - val_loss: 0.3870 - val_acc: 0.8000\n",
            "Epoch 2946/4500\n",
            "100/100 [==============================] - 0s 488us/step - loss: 0.2423 - acc: 0.8700 - val_loss: 0.3665 - val_acc: 0.8500\n",
            "Epoch 2947/4500\n",
            "100/100 [==============================] - 0s 515us/step - loss: 0.2385 - acc: 0.8800 - val_loss: 0.3784 - val_acc: 0.8400\n",
            "Epoch 2948/4500\n",
            "100/100 [==============================] - 0s 491us/step - loss: 0.2439 - acc: 0.8800 - val_loss: 0.3782 - val_acc: 0.8300\n",
            "Epoch 2949/4500\n",
            "100/100 [==============================] - 0s 517us/step - loss: 0.2393 - acc: 0.8800 - val_loss: 0.3757 - val_acc: 0.8400\n",
            "Epoch 2950/4500\n",
            "100/100 [==============================] - 0s 497us/step - loss: 0.2376 - acc: 0.8900 - val_loss: 0.3713 - val_acc: 0.8400\n",
            "Epoch 2951/4500\n",
            "100/100 [==============================] - 0s 498us/step - loss: 0.2369 - acc: 0.8700 - val_loss: 0.3740 - val_acc: 0.8400\n",
            "Epoch 2952/4500\n",
            "100/100 [==============================] - 0s 496us/step - loss: 0.2366 - acc: 0.8800 - val_loss: 0.3754 - val_acc: 0.8400\n",
            "Epoch 2953/4500\n",
            "100/100 [==============================] - 0s 566us/step - loss: 0.2413 - acc: 0.8800 - val_loss: 0.3816 - val_acc: 0.8100\n",
            "Epoch 2954/4500\n",
            "100/100 [==============================] - 0s 572us/step - loss: 0.2399 - acc: 0.8800 - val_loss: 0.3735 - val_acc: 0.8400\n",
            "Epoch 2955/4500\n",
            "100/100 [==============================] - 0s 491us/step - loss: 0.2356 - acc: 0.8800 - val_loss: 0.3715 - val_acc: 0.8400\n",
            "Epoch 2956/4500\n",
            "100/100 [==============================] - 0s 503us/step - loss: 0.2384 - acc: 0.8700 - val_loss: 0.3824 - val_acc: 0.8100\n",
            "Epoch 2957/4500\n",
            "100/100 [==============================] - 0s 479us/step - loss: 0.2361 - acc: 0.8700 - val_loss: 0.3752 - val_acc: 0.8400\n",
            "Epoch 2958/4500\n",
            "100/100 [==============================] - 0s 506us/step - loss: 0.2372 - acc: 0.8800 - val_loss: 0.3727 - val_acc: 0.8400\n",
            "Epoch 2959/4500\n",
            "100/100 [==============================] - 0s 530us/step - loss: 0.2393 - acc: 0.8900 - val_loss: 0.3806 - val_acc: 0.8100\n",
            "Epoch 2960/4500\n",
            "100/100 [==============================] - 0s 477us/step - loss: 0.2351 - acc: 0.8800 - val_loss: 0.3741 - val_acc: 0.8300\n",
            "Epoch 2961/4500\n",
            "100/100 [==============================] - 0s 516us/step - loss: 0.2368 - acc: 0.8800 - val_loss: 0.3706 - val_acc: 0.8500\n",
            "Epoch 2962/4500\n",
            "100/100 [==============================] - 0s 499us/step - loss: 0.2369 - acc: 0.8700 - val_loss: 0.3811 - val_acc: 0.8200\n",
            "Epoch 2963/4500\n",
            "100/100 [==============================] - 0s 587us/step - loss: 0.2355 - acc: 0.8800 - val_loss: 0.3805 - val_acc: 0.8200\n",
            "Epoch 2964/4500\n",
            "100/100 [==============================] - 0s 633us/step - loss: 0.2381 - acc: 0.8800 - val_loss: 0.3706 - val_acc: 0.8500\n",
            "Epoch 2965/4500\n",
            "100/100 [==============================] - 0s 510us/step - loss: 0.2340 - acc: 0.8800 - val_loss: 0.3785 - val_acc: 0.8200\n",
            "Epoch 2966/4500\n",
            "100/100 [==============================] - 0s 521us/step - loss: 0.2348 - acc: 0.8900 - val_loss: 0.3739 - val_acc: 0.8200\n",
            "Epoch 2967/4500\n",
            "100/100 [==============================] - 0s 510us/step - loss: 0.2327 - acc: 0.8800 - val_loss: 0.3781 - val_acc: 0.8200\n",
            "Epoch 2968/4500\n",
            "100/100 [==============================] - 0s 500us/step - loss: 0.2390 - acc: 0.9000 - val_loss: 0.3810 - val_acc: 0.8200\n",
            "Epoch 2969/4500\n",
            "100/100 [==============================] - 0s 522us/step - loss: 0.2349 - acc: 0.8900 - val_loss: 0.3641 - val_acc: 0.8500\n",
            "Epoch 2970/4500\n",
            "100/100 [==============================] - 0s 511us/step - loss: 0.2346 - acc: 0.8800 - val_loss: 0.3732 - val_acc: 0.8400\n",
            "Epoch 2971/4500\n",
            "100/100 [==============================] - 0s 539us/step - loss: 0.2357 - acc: 0.8800 - val_loss: 0.3804 - val_acc: 0.8200\n",
            "Epoch 2972/4500\n",
            "100/100 [==============================] - 0s 573us/step - loss: 0.2329 - acc: 0.8900 - val_loss: 0.3842 - val_acc: 0.8100\n",
            "Epoch 2973/4500\n",
            "100/100 [==============================] - 0s 580us/step - loss: 0.2353 - acc: 0.8700 - val_loss: 0.3774 - val_acc: 0.8200\n",
            "Epoch 2974/4500\n",
            "100/100 [==============================] - 0s 487us/step - loss: 0.2345 - acc: 0.8800 - val_loss: 0.3772 - val_acc: 0.8200\n",
            "Epoch 2975/4500\n",
            "100/100 [==============================] - 0s 494us/step - loss: 0.2325 - acc: 0.8800 - val_loss: 0.3769 - val_acc: 0.8200\n",
            "Epoch 2976/4500\n",
            "100/100 [==============================] - 0s 491us/step - loss: 0.2328 - acc: 0.8700 - val_loss: 0.3774 - val_acc: 0.8200\n",
            "Epoch 2977/4500\n",
            "100/100 [==============================] - 0s 491us/step - loss: 0.2388 - acc: 0.8700 - val_loss: 0.3718 - val_acc: 0.8400\n",
            "Epoch 2978/4500\n",
            "100/100 [==============================] - 0s 557us/step - loss: 0.2362 - acc: 0.8800 - val_loss: 0.3685 - val_acc: 0.8500\n",
            "Epoch 2979/4500\n",
            "100/100 [==============================] - 0s 535us/step - loss: 0.2375 - acc: 0.8700 - val_loss: 0.3800 - val_acc: 0.8200\n",
            "Epoch 2980/4500\n",
            "100/100 [==============================] - 0s 492us/step - loss: 0.2348 - acc: 0.8800 - val_loss: 0.3698 - val_acc: 0.8200\n",
            "Epoch 2981/4500\n",
            "100/100 [==============================] - 0s 505us/step - loss: 0.2338 - acc: 0.8900 - val_loss: 0.3734 - val_acc: 0.8200\n",
            "Epoch 2982/4500\n",
            "100/100 [==============================] - 0s 499us/step - loss: 0.2315 - acc: 0.8800 - val_loss: 0.3696 - val_acc: 0.8500\n",
            "Epoch 2983/4500\n",
            "100/100 [==============================] - 0s 504us/step - loss: 0.2321 - acc: 0.8800 - val_loss: 0.3750 - val_acc: 0.8200\n",
            "Epoch 2984/4500\n",
            "100/100 [==============================] - 0s 524us/step - loss: 0.2322 - acc: 0.8800 - val_loss: 0.3761 - val_acc: 0.8200\n",
            "Epoch 2985/4500\n",
            "100/100 [==============================] - 0s 500us/step - loss: 0.2305 - acc: 0.8800 - val_loss: 0.3755 - val_acc: 0.8200\n",
            "Epoch 2986/4500\n",
            "100/100 [==============================] - 0s 521us/step - loss: 0.2359 - acc: 0.8800 - val_loss: 0.3731 - val_acc: 0.8200\n",
            "Epoch 2987/4500\n",
            "100/100 [==============================] - 0s 512us/step - loss: 0.2338 - acc: 0.9000 - val_loss: 0.3838 - val_acc: 0.8100\n",
            "Epoch 2988/4500\n",
            "100/100 [==============================] - 0s 552us/step - loss: 0.2300 - acc: 0.8900 - val_loss: 0.3716 - val_acc: 0.8200\n",
            "Epoch 2989/4500\n",
            "100/100 [==============================] - 0s 519us/step - loss: 0.2290 - acc: 0.8800 - val_loss: 0.3657 - val_acc: 0.8500\n",
            "Epoch 2990/4500\n",
            "100/100 [==============================] - 0s 498us/step - loss: 0.2321 - acc: 0.8800 - val_loss: 0.3737 - val_acc: 0.8200\n",
            "Epoch 2991/4500\n",
            "100/100 [==============================] - 0s 524us/step - loss: 0.2331 - acc: 0.8900 - val_loss: 0.3787 - val_acc: 0.8200\n",
            "Epoch 2992/4500\n",
            "100/100 [==============================] - 0s 588us/step - loss: 0.2297 - acc: 0.8800 - val_loss: 0.3679 - val_acc: 0.8300\n",
            "Epoch 2993/4500\n",
            "100/100 [==============================] - 0s 536us/step - loss: 0.2317 - acc: 0.8800 - val_loss: 0.3719 - val_acc: 0.8200\n",
            "Epoch 2994/4500\n",
            "100/100 [==============================] - 0s 510us/step - loss: 0.2294 - acc: 0.8800 - val_loss: 0.3720 - val_acc: 0.8200\n",
            "Epoch 2995/4500\n",
            "100/100 [==============================] - 0s 507us/step - loss: 0.2322 - acc: 0.8800 - val_loss: 0.3854 - val_acc: 0.8100\n",
            "Epoch 2996/4500\n",
            "100/100 [==============================] - 0s 509us/step - loss: 0.2344 - acc: 0.8800 - val_loss: 0.3708 - val_acc: 0.8200\n",
            "Epoch 2997/4500\n",
            "100/100 [==============================] - 0s 494us/step - loss: 0.2294 - acc: 0.8800 - val_loss: 0.3780 - val_acc: 0.8200\n",
            "Epoch 2998/4500\n",
            "100/100 [==============================] - 0s 493us/step - loss: 0.2301 - acc: 0.9000 - val_loss: 0.3879 - val_acc: 0.8100\n",
            "Epoch 2999/4500\n",
            "100/100 [==============================] - 0s 496us/step - loss: 0.2283 - acc: 0.9000 - val_loss: 0.3790 - val_acc: 0.8200\n",
            "Epoch 3000/4500\n",
            "100/100 [==============================] - 0s 507us/step - loss: 0.2333 - acc: 0.8800 - val_loss: 0.3681 - val_acc: 0.8500\n",
            "Epoch 3001/4500\n",
            "100/100 [==============================] - 0s 515us/step - loss: 0.2317 - acc: 0.8800 - val_loss: 0.3812 - val_acc: 0.8200\n",
            "Epoch 3002/4500\n",
            "100/100 [==============================] - 0s 498us/step - loss: 0.2297 - acc: 0.8900 - val_loss: 0.3744 - val_acc: 0.8200\n",
            "Epoch 3003/4500\n",
            "100/100 [==============================] - 0s 514us/step - loss: 0.2291 - acc: 0.9000 - val_loss: 0.3705 - val_acc: 0.8500\n",
            "Epoch 3004/4500\n",
            "100/100 [==============================] - 0s 595us/step - loss: 0.2280 - acc: 0.8800 - val_loss: 0.3777 - val_acc: 0.8200\n",
            "Epoch 3005/4500\n",
            "100/100 [==============================] - 0s 492us/step - loss: 0.2272 - acc: 0.8800 - val_loss: 0.3800 - val_acc: 0.8200\n",
            "Epoch 3006/4500\n",
            "100/100 [==============================] - 0s 489us/step - loss: 0.2277 - acc: 0.8800 - val_loss: 0.3777 - val_acc: 0.8200\n",
            "Epoch 3007/4500\n",
            "100/100 [==============================] - 0s 501us/step - loss: 0.2267 - acc: 0.8800 - val_loss: 0.3791 - val_acc: 0.8200\n",
            "Epoch 3008/4500\n",
            "100/100 [==============================] - 0s 505us/step - loss: 0.2274 - acc: 0.8900 - val_loss: 0.3764 - val_acc: 0.8200\n",
            "Epoch 3009/4500\n",
            "100/100 [==============================] - 0s 574us/step - loss: 0.2272 - acc: 0.8900 - val_loss: 0.3809 - val_acc: 0.8200\n",
            "Epoch 3010/4500\n",
            "100/100 [==============================] - 0s 514us/step - loss: 0.2288 - acc: 0.8900 - val_loss: 0.3780 - val_acc: 0.8200\n",
            "Epoch 3011/4500\n",
            "100/100 [==============================] - 0s 573us/step - loss: 0.2282 - acc: 0.8800 - val_loss: 0.3712 - val_acc: 0.8200\n",
            "Epoch 3012/4500\n",
            "100/100 [==============================] - 0s 488us/step - loss: 0.2242 - acc: 0.8800 - val_loss: 0.3677 - val_acc: 0.8300\n",
            "Epoch 3013/4500\n",
            "100/100 [==============================] - 0s 561us/step - loss: 0.2261 - acc: 0.8800 - val_loss: 0.3742 - val_acc: 0.8200\n",
            "Epoch 3014/4500\n",
            "100/100 [==============================] - 0s 502us/step - loss: 0.2271 - acc: 0.8800 - val_loss: 0.3765 - val_acc: 0.8200\n",
            "Epoch 3015/4500\n",
            "100/100 [==============================] - 0s 493us/step - loss: 0.2278 - acc: 0.9000 - val_loss: 0.3840 - val_acc: 0.8200\n",
            "Epoch 3016/4500\n",
            "100/100 [==============================] - 0s 504us/step - loss: 0.2269 - acc: 0.9000 - val_loss: 0.3742 - val_acc: 0.8200\n",
            "Epoch 3017/4500\n",
            "100/100 [==============================] - 0s 509us/step - loss: 0.2271 - acc: 0.8800 - val_loss: 0.3621 - val_acc: 0.8500\n",
            "Epoch 3018/4500\n",
            "100/100 [==============================] - 0s 496us/step - loss: 0.2253 - acc: 0.8800 - val_loss: 0.3749 - val_acc: 0.8200\n",
            "Epoch 3019/4500\n",
            "100/100 [==============================] - 0s 524us/step - loss: 0.2285 - acc: 0.8900 - val_loss: 0.3782 - val_acc: 0.8200\n",
            "Epoch 3020/4500\n",
            "100/100 [==============================] - 0s 486us/step - loss: 0.2266 - acc: 0.8800 - val_loss: 0.3664 - val_acc: 0.8300\n",
            "Epoch 3021/4500\n",
            "100/100 [==============================] - 0s 514us/step - loss: 0.2229 - acc: 0.8800 - val_loss: 0.3771 - val_acc: 0.8200\n",
            "Epoch 3022/4500\n",
            "100/100 [==============================] - 0s 509us/step - loss: 0.2237 - acc: 0.9100 - val_loss: 0.3828 - val_acc: 0.8200\n",
            "Epoch 3023/4500\n",
            "100/100 [==============================] - 0s 501us/step - loss: 0.2256 - acc: 0.9000 - val_loss: 0.3729 - val_acc: 0.8200\n",
            "Epoch 3024/4500\n",
            "100/100 [==============================] - 0s 588us/step - loss: 0.2281 - acc: 0.8800 - val_loss: 0.3772 - val_acc: 0.8200\n",
            "Epoch 3025/4500\n",
            "100/100 [==============================] - 0s 543us/step - loss: 0.2240 - acc: 0.8800 - val_loss: 0.3696 - val_acc: 0.8200\n",
            "Epoch 3026/4500\n",
            "100/100 [==============================] - 0s 497us/step - loss: 0.2251 - acc: 0.8800 - val_loss: 0.3733 - val_acc: 0.8200\n",
            "Epoch 3027/4500\n",
            "100/100 [==============================] - 0s 501us/step - loss: 0.2239 - acc: 0.8800 - val_loss: 0.3835 - val_acc: 0.8200\n",
            "Epoch 3028/4500\n",
            "100/100 [==============================] - 0s 523us/step - loss: 0.2276 - acc: 0.8800 - val_loss: 0.3756 - val_acc: 0.8200\n",
            "Epoch 3029/4500\n",
            "100/100 [==============================] - 0s 520us/step - loss: 0.2254 - acc: 0.9000 - val_loss: 0.3745 - val_acc: 0.8200\n",
            "Epoch 3030/4500\n",
            "100/100 [==============================] - 0s 500us/step - loss: 0.2249 - acc: 0.8800 - val_loss: 0.3691 - val_acc: 0.8200\n",
            "Epoch 3031/4500\n",
            "100/100 [==============================] - 0s 575us/step - loss: 0.2244 - acc: 0.8900 - val_loss: 0.3791 - val_acc: 0.8200\n",
            "Epoch 3032/4500\n",
            "100/100 [==============================] - 0s 520us/step - loss: 0.2228 - acc: 0.9000 - val_loss: 0.3739 - val_acc: 0.8200\n",
            "Epoch 3033/4500\n",
            "100/100 [==============================] - 0s 554us/step - loss: 0.2266 - acc: 0.8900 - val_loss: 0.3686 - val_acc: 0.8300\n",
            "Epoch 3034/4500\n",
            "100/100 [==============================] - 0s 523us/step - loss: 0.2273 - acc: 0.8800 - val_loss: 0.3856 - val_acc: 0.8100\n",
            "Epoch 3035/4500\n",
            "100/100 [==============================] - 0s 570us/step - loss: 0.2246 - acc: 0.9000 - val_loss: 0.3719 - val_acc: 0.8200\n",
            "Epoch 3036/4500\n",
            "100/100 [==============================] - 0s 569us/step - loss: 0.2253 - acc: 0.8800 - val_loss: 0.3679 - val_acc: 0.8300\n",
            "Epoch 3037/4500\n",
            "100/100 [==============================] - 0s 488us/step - loss: 0.2291 - acc: 0.8700 - val_loss: 0.3759 - val_acc: 0.8200\n",
            "Epoch 3038/4500\n",
            "100/100 [==============================] - 0s 487us/step - loss: 0.2214 - acc: 0.9100 - val_loss: 0.3736 - val_acc: 0.8200\n",
            "Epoch 3039/4500\n",
            "100/100 [==============================] - 0s 515us/step - loss: 0.2251 - acc: 0.8900 - val_loss: 0.3709 - val_acc: 0.8200\n",
            "Epoch 3040/4500\n",
            "100/100 [==============================] - 0s 514us/step - loss: 0.2207 - acc: 0.8900 - val_loss: 0.3827 - val_acc: 0.8200\n",
            "Epoch 3041/4500\n",
            "100/100 [==============================] - 0s 490us/step - loss: 0.2224 - acc: 0.8900 - val_loss: 0.3774 - val_acc: 0.8200\n",
            "Epoch 3042/4500\n",
            "100/100 [==============================] - 0s 504us/step - loss: 0.2209 - acc: 0.9000 - val_loss: 0.3772 - val_acc: 0.8200\n",
            "Epoch 3043/4500\n",
            "100/100 [==============================] - 0s 517us/step - loss: 0.2205 - acc: 0.8800 - val_loss: 0.3732 - val_acc: 0.8200\n",
            "Epoch 3044/4500\n",
            "100/100 [==============================] - 0s 565us/step - loss: 0.2233 - acc: 0.9100 - val_loss: 0.3751 - val_acc: 0.8200\n",
            "Epoch 3045/4500\n",
            "100/100 [==============================] - 0s 492us/step - loss: 0.2239 - acc: 0.8800 - val_loss: 0.3713 - val_acc: 0.8200\n",
            "Epoch 3046/4500\n",
            "100/100 [==============================] - 0s 501us/step - loss: 0.2196 - acc: 0.8800 - val_loss: 0.3736 - val_acc: 0.8200\n",
            "Epoch 3047/4500\n",
            "100/100 [==============================] - 0s 517us/step - loss: 0.2195 - acc: 0.9100 - val_loss: 0.3804 - val_acc: 0.8200\n",
            "Epoch 3048/4500\n",
            "100/100 [==============================] - 0s 492us/step - loss: 0.2203 - acc: 0.8900 - val_loss: 0.3745 - val_acc: 0.8200\n",
            "Epoch 3049/4500\n",
            "100/100 [==============================] - 0s 495us/step - loss: 0.2191 - acc: 0.8900 - val_loss: 0.3730 - val_acc: 0.8200\n",
            "Epoch 3050/4500\n",
            "100/100 [==============================] - 0s 572us/step - loss: 0.2188 - acc: 0.8900 - val_loss: 0.3724 - val_acc: 0.8200\n",
            "Epoch 3051/4500\n",
            "100/100 [==============================] - 0s 506us/step - loss: 0.2216 - acc: 0.8800 - val_loss: 0.3794 - val_acc: 0.8200\n",
            "Epoch 3052/4500\n",
            "100/100 [==============================] - 0s 482us/step - loss: 0.2187 - acc: 0.8900 - val_loss: 0.3716 - val_acc: 0.8200\n",
            "Epoch 3053/4500\n",
            "100/100 [==============================] - 0s 557us/step - loss: 0.2219 - acc: 0.8700 - val_loss: 0.3819 - val_acc: 0.8200\n",
            "Epoch 3054/4500\n",
            "100/100 [==============================] - 0s 501us/step - loss: 0.2263 - acc: 0.8800 - val_loss: 0.3707 - val_acc: 0.8200\n",
            "Epoch 3055/4500\n",
            "100/100 [==============================] - 0s 493us/step - loss: 0.2205 - acc: 0.9000 - val_loss: 0.3809 - val_acc: 0.8200\n",
            "Epoch 3056/4500\n",
            "100/100 [==============================] - 0s 532us/step - loss: 0.2227 - acc: 0.8900 - val_loss: 0.3719 - val_acc: 0.8200\n",
            "Epoch 3057/4500\n",
            "100/100 [==============================] - 0s 491us/step - loss: 0.2228 - acc: 0.8800 - val_loss: 0.3844 - val_acc: 0.8100\n",
            "Epoch 3058/4500\n",
            "100/100 [==============================] - 0s 499us/step - loss: 0.2182 - acc: 0.9100 - val_loss: 0.3779 - val_acc: 0.8200\n",
            "Epoch 3059/4500\n",
            "100/100 [==============================] - 0s 498us/step - loss: 0.2177 - acc: 0.8900 - val_loss: 0.3706 - val_acc: 0.8200\n",
            "Epoch 3060/4500\n",
            "100/100 [==============================] - 0s 499us/step - loss: 0.2182 - acc: 0.9000 - val_loss: 0.3810 - val_acc: 0.8200\n",
            "Epoch 3061/4500\n",
            "100/100 [==============================] - 0s 509us/step - loss: 0.2176 - acc: 0.9100 - val_loss: 0.3754 - val_acc: 0.8200\n",
            "Epoch 3062/4500\n",
            "100/100 [==============================] - 0s 527us/step - loss: 0.2200 - acc: 0.8800 - val_loss: 0.3684 - val_acc: 0.8300\n",
            "Epoch 3063/4500\n",
            "100/100 [==============================] - 0s 548us/step - loss: 0.2174 - acc: 0.8800 - val_loss: 0.3798 - val_acc: 0.8200\n",
            "Epoch 3064/4500\n",
            "100/100 [==============================] - 0s 498us/step - loss: 0.2178 - acc: 0.9100 - val_loss: 0.3769 - val_acc: 0.8200\n",
            "Epoch 3065/4500\n",
            "100/100 [==============================] - 0s 504us/step - loss: 0.2190 - acc: 0.8800 - val_loss: 0.3685 - val_acc: 0.8200\n",
            "Epoch 3066/4500\n",
            "100/100 [==============================] - 0s 495us/step - loss: 0.2176 - acc: 0.8800 - val_loss: 0.3737 - val_acc: 0.8200\n",
            "Epoch 3067/4500\n",
            "100/100 [==============================] - 0s 511us/step - loss: 0.2170 - acc: 0.9000 - val_loss: 0.3767 - val_acc: 0.8200\n",
            "Epoch 3068/4500\n",
            "100/100 [==============================] - 0s 494us/step - loss: 0.2175 - acc: 0.9100 - val_loss: 0.3761 - val_acc: 0.8200\n",
            "Epoch 3069/4500\n",
            "100/100 [==============================] - 0s 569us/step - loss: 0.2166 - acc: 0.8900 - val_loss: 0.3673 - val_acc: 0.8300\n",
            "Epoch 3070/4500\n",
            "100/100 [==============================] - 0s 503us/step - loss: 0.2168 - acc: 0.9000 - val_loss: 0.3770 - val_acc: 0.8200\n",
            "Epoch 3071/4500\n",
            "100/100 [==============================] - 0s 499us/step - loss: 0.2149 - acc: 0.9200 - val_loss: 0.3710 - val_acc: 0.8200\n",
            "Epoch 3072/4500\n",
            "100/100 [==============================] - 0s 489us/step - loss: 0.2160 - acc: 0.9000 - val_loss: 0.3757 - val_acc: 0.8200\n",
            "Epoch 3073/4500\n",
            "100/100 [==============================] - 0s 520us/step - loss: 0.2149 - acc: 0.9000 - val_loss: 0.3739 - val_acc: 0.8200\n",
            "Epoch 3074/4500\n",
            "100/100 [==============================] - 0s 589us/step - loss: 0.2152 - acc: 0.9000 - val_loss: 0.3790 - val_acc: 0.8200\n",
            "Epoch 3075/4500\n",
            "100/100 [==============================] - 0s 503us/step - loss: 0.2160 - acc: 0.8800 - val_loss: 0.3721 - val_acc: 0.8200\n",
            "Epoch 3076/4500\n",
            "100/100 [==============================] - 0s 485us/step - loss: 0.2156 - acc: 0.9000 - val_loss: 0.3742 - val_acc: 0.8200\n",
            "Epoch 3077/4500\n",
            "100/100 [==============================] - 0s 502us/step - loss: 0.2141 - acc: 0.8800 - val_loss: 0.3784 - val_acc: 0.8200\n",
            "Epoch 3078/4500\n",
            "100/100 [==============================] - 0s 487us/step - loss: 0.2183 - acc: 0.9000 - val_loss: 0.3776 - val_acc: 0.8200\n",
            "Epoch 3079/4500\n",
            "100/100 [==============================] - 0s 498us/step - loss: 0.2138 - acc: 0.9100 - val_loss: 0.3716 - val_acc: 0.8200\n",
            "Epoch 3080/4500\n",
            "100/100 [==============================] - 0s 525us/step - loss: 0.2140 - acc: 0.8900 - val_loss: 0.3692 - val_acc: 0.8200\n",
            "Epoch 3081/4500\n",
            "100/100 [==============================] - 0s 542us/step - loss: 0.2173 - acc: 0.9100 - val_loss: 0.3777 - val_acc: 0.8200\n",
            "Epoch 3082/4500\n",
            "100/100 [==============================] - 0s 566us/step - loss: 0.2151 - acc: 0.9100 - val_loss: 0.3725 - val_acc: 0.8200\n",
            "Epoch 3083/4500\n",
            "100/100 [==============================] - 0s 510us/step - loss: 0.2134 - acc: 0.9000 - val_loss: 0.3787 - val_acc: 0.8200\n",
            "Epoch 3084/4500\n",
            "100/100 [==============================] - 0s 576us/step - loss: 0.2193 - acc: 0.9100 - val_loss: 0.3803 - val_acc: 0.8200\n",
            "Epoch 3085/4500\n",
            "100/100 [==============================] - 0s 512us/step - loss: 0.2147 - acc: 0.9000 - val_loss: 0.3696 - val_acc: 0.8200\n",
            "Epoch 3086/4500\n",
            "100/100 [==============================] - 0s 529us/step - loss: 0.2170 - acc: 0.9000 - val_loss: 0.3836 - val_acc: 0.8200\n",
            "Epoch 3087/4500\n",
            "100/100 [==============================] - 0s 595us/step - loss: 0.2131 - acc: 0.9200 - val_loss: 0.3685 - val_acc: 0.8200\n",
            "Epoch 3088/4500\n",
            "100/100 [==============================] - 0s 555us/step - loss: 0.2178 - acc: 0.8900 - val_loss: 0.3729 - val_acc: 0.8200\n",
            "Epoch 3089/4500\n",
            "100/100 [==============================] - 0s 559us/step - loss: 0.2127 - acc: 0.8900 - val_loss: 0.3781 - val_acc: 0.8200\n",
            "Epoch 3090/4500\n",
            "100/100 [==============================] - 0s 482us/step - loss: 0.2131 - acc: 0.9000 - val_loss: 0.3788 - val_acc: 0.8200\n",
            "Epoch 3091/4500\n",
            "100/100 [==============================] - 0s 505us/step - loss: 0.2158 - acc: 0.9100 - val_loss: 0.3820 - val_acc: 0.8200\n",
            "Epoch 3092/4500\n",
            "100/100 [==============================] - 0s 484us/step - loss: 0.2113 - acc: 0.9100 - val_loss: 0.3744 - val_acc: 0.8200\n",
            "Epoch 3093/4500\n",
            "100/100 [==============================] - 0s 551us/step - loss: 0.2197 - acc: 0.8900 - val_loss: 0.3660 - val_acc: 0.8300\n",
            "Epoch 3094/4500\n",
            "100/100 [==============================] - 0s 528us/step - loss: 0.2133 - acc: 0.9100 - val_loss: 0.3842 - val_acc: 0.8200\n",
            "Epoch 3095/4500\n",
            "100/100 [==============================] - 0s 503us/step - loss: 0.2174 - acc: 0.8900 - val_loss: 0.3787 - val_acc: 0.8200\n",
            "Epoch 3096/4500\n",
            "100/100 [==============================] - 0s 524us/step - loss: 0.2117 - acc: 0.9200 - val_loss: 0.3702 - val_acc: 0.8300\n",
            "Epoch 3097/4500\n",
            "100/100 [==============================] - 0s 524us/step - loss: 0.2146 - acc: 0.8900 - val_loss: 0.3751 - val_acc: 0.8200\n",
            "Epoch 3098/4500\n",
            "100/100 [==============================] - 0s 491us/step - loss: 0.2119 - acc: 0.9100 - val_loss: 0.3746 - val_acc: 0.8200\n",
            "Epoch 3099/4500\n",
            "100/100 [==============================] - 0s 490us/step - loss: 0.2150 - acc: 0.8900 - val_loss: 0.3826 - val_acc: 0.8200\n",
            "Epoch 3100/4500\n",
            "100/100 [==============================] - 0s 500us/step - loss: 0.2161 - acc: 0.9100 - val_loss: 0.3797 - val_acc: 0.8200\n",
            "Epoch 3101/4500\n",
            "100/100 [==============================] - 0s 540us/step - loss: 0.2156 - acc: 0.8900 - val_loss: 0.3794 - val_acc: 0.8200\n",
            "Epoch 3102/4500\n",
            "100/100 [==============================] - 0s 582us/step - loss: 0.2131 - acc: 0.8800 - val_loss: 0.3804 - val_acc: 0.8200\n",
            "Epoch 3103/4500\n",
            "100/100 [==============================] - 0s 570us/step - loss: 0.2121 - acc: 0.9100 - val_loss: 0.3748 - val_acc: 0.8200\n",
            "Epoch 3104/4500\n",
            "100/100 [==============================] - 0s 560us/step - loss: 0.2119 - acc: 0.9100 - val_loss: 0.3802 - val_acc: 0.8200\n",
            "Epoch 3105/4500\n",
            "100/100 [==============================] - 0s 620us/step - loss: 0.2103 - acc: 0.9100 - val_loss: 0.3760 - val_acc: 0.8200\n",
            "Epoch 3106/4500\n",
            "100/100 [==============================] - 0s 536us/step - loss: 0.2204 - acc: 0.8800 - val_loss: 0.3747 - val_acc: 0.8200\n",
            "Epoch 3107/4500\n",
            "100/100 [==============================] - 0s 605us/step - loss: 0.2130 - acc: 0.9100 - val_loss: 0.3921 - val_acc: 0.8100\n",
            "Epoch 3108/4500\n",
            "100/100 [==============================] - 0s 506us/step - loss: 0.2097 - acc: 0.9100 - val_loss: 0.3683 - val_acc: 0.8200\n",
            "Epoch 3109/4500\n",
            "100/100 [==============================] - 0s 490us/step - loss: 0.2119 - acc: 0.8800 - val_loss: 0.3734 - val_acc: 0.8200\n",
            "Epoch 3110/4500\n",
            "100/100 [==============================] - 0s 533us/step - loss: 0.2102 - acc: 0.9200 - val_loss: 0.3779 - val_acc: 0.8200\n",
            "Epoch 3111/4500\n",
            "100/100 [==============================] - 0s 488us/step - loss: 0.2075 - acc: 0.9100 - val_loss: 0.3766 - val_acc: 0.8200\n",
            "Epoch 3112/4500\n",
            "100/100 [==============================] - 0s 497us/step - loss: 0.2103 - acc: 0.9000 - val_loss: 0.3748 - val_acc: 0.8200\n",
            "Epoch 3113/4500\n",
            "100/100 [==============================] - 0s 593us/step - loss: 0.2099 - acc: 0.9000 - val_loss: 0.3740 - val_acc: 0.8200\n",
            "Epoch 3114/4500\n",
            "100/100 [==============================] - 0s 500us/step - loss: 0.2134 - acc: 0.9000 - val_loss: 0.3773 - val_acc: 0.8200\n",
            "Epoch 3115/4500\n",
            "100/100 [==============================] - 0s 480us/step - loss: 0.2100 - acc: 0.9100 - val_loss: 0.3653 - val_acc: 0.8400\n",
            "Epoch 3116/4500\n",
            "100/100 [==============================] - 0s 498us/step - loss: 0.2109 - acc: 0.9000 - val_loss: 0.3803 - val_acc: 0.8200\n",
            "Epoch 3117/4500\n",
            "100/100 [==============================] - 0s 545us/step - loss: 0.2152 - acc: 0.8900 - val_loss: 0.3946 - val_acc: 0.8000\n",
            "Epoch 3118/4500\n",
            "100/100 [==============================] - 0s 500us/step - loss: 0.2082 - acc: 0.9100 - val_loss: 0.3785 - val_acc: 0.8200\n",
            "Epoch 3119/4500\n",
            "100/100 [==============================] - 0s 503us/step - loss: 0.2071 - acc: 0.9200 - val_loss: 0.3662 - val_acc: 0.8300\n",
            "Epoch 3120/4500\n",
            "100/100 [==============================] - 0s 492us/step - loss: 0.2110 - acc: 0.9100 - val_loss: 0.3813 - val_acc: 0.8200\n",
            "Epoch 3121/4500\n",
            "100/100 [==============================] - 0s 507us/step - loss: 0.2087 - acc: 0.8900 - val_loss: 0.3735 - val_acc: 0.8200\n",
            "Epoch 3122/4500\n",
            "100/100 [==============================] - 0s 490us/step - loss: 0.2079 - acc: 0.9100 - val_loss: 0.3758 - val_acc: 0.8200\n",
            "Epoch 3123/4500\n",
            "100/100 [==============================] - 0s 509us/step - loss: 0.2074 - acc: 0.9100 - val_loss: 0.3742 - val_acc: 0.8200\n",
            "Epoch 3124/4500\n",
            "100/100 [==============================] - 0s 483us/step - loss: 0.2063 - acc: 0.9000 - val_loss: 0.3780 - val_acc: 0.8200\n",
            "Epoch 3125/4500\n",
            "100/100 [==============================] - 0s 514us/step - loss: 0.2089 - acc: 0.9200 - val_loss: 0.3765 - val_acc: 0.8200\n",
            "Epoch 3126/4500\n",
            "100/100 [==============================] - 0s 507us/step - loss: 0.2078 - acc: 0.9100 - val_loss: 0.3735 - val_acc: 0.8200\n",
            "Epoch 3127/4500\n",
            "100/100 [==============================] - 0s 593us/step - loss: 0.2124 - acc: 0.9100 - val_loss: 0.3874 - val_acc: 0.8200\n",
            "Epoch 3128/4500\n",
            "100/100 [==============================] - 0s 510us/step - loss: 0.2061 - acc: 0.9000 - val_loss: 0.3692 - val_acc: 0.8300\n",
            "Epoch 3129/4500\n",
            "100/100 [==============================] - 0s 520us/step - loss: 0.2074 - acc: 0.8900 - val_loss: 0.3784 - val_acc: 0.8200\n",
            "Epoch 3130/4500\n",
            "100/100 [==============================] - 0s 541us/step - loss: 0.2111 - acc: 0.9100 - val_loss: 0.3738 - val_acc: 0.8200\n",
            "Epoch 3131/4500\n",
            "100/100 [==============================] - 0s 517us/step - loss: 0.2070 - acc: 0.9100 - val_loss: 0.3895 - val_acc: 0.8100\n",
            "Epoch 3132/4500\n",
            "100/100 [==============================] - 0s 509us/step - loss: 0.2116 - acc: 0.9100 - val_loss: 0.3748 - val_acc: 0.8200\n",
            "Epoch 3133/4500\n",
            "100/100 [==============================] - 0s 584us/step - loss: 0.2070 - acc: 0.9200 - val_loss: 0.3824 - val_acc: 0.8200\n",
            "Epoch 3134/4500\n",
            "100/100 [==============================] - 0s 577us/step - loss: 0.2058 - acc: 0.9100 - val_loss: 0.3691 - val_acc: 0.8400\n",
            "Epoch 3135/4500\n",
            "100/100 [==============================] - 0s 521us/step - loss: 0.2042 - acc: 0.9100 - val_loss: 0.3856 - val_acc: 0.8200\n",
            "Epoch 3136/4500\n",
            "100/100 [==============================] - 0s 510us/step - loss: 0.2060 - acc: 0.9100 - val_loss: 0.3811 - val_acc: 0.8200\n",
            "Epoch 3137/4500\n",
            "100/100 [==============================] - 0s 496us/step - loss: 0.2049 - acc: 0.9000 - val_loss: 0.3684 - val_acc: 0.8400\n",
            "Epoch 3138/4500\n",
            "100/100 [==============================] - 0s 489us/step - loss: 0.2063 - acc: 0.9000 - val_loss: 0.3730 - val_acc: 0.8200\n",
            "Epoch 3139/4500\n",
            "100/100 [==============================] - 0s 492us/step - loss: 0.2042 - acc: 0.9000 - val_loss: 0.3890 - val_acc: 0.8100\n",
            "Epoch 3140/4500\n",
            "100/100 [==============================] - 0s 490us/step - loss: 0.2050 - acc: 0.9100 - val_loss: 0.3738 - val_acc: 0.8200\n",
            "Epoch 3141/4500\n",
            "100/100 [==============================] - 0s 526us/step - loss: 0.2070 - acc: 0.9000 - val_loss: 0.3756 - val_acc: 0.8200\n",
            "Epoch 3142/4500\n",
            "100/100 [==============================] - 0s 524us/step - loss: 0.2127 - acc: 0.8900 - val_loss: 0.3686 - val_acc: 0.8400\n",
            "Epoch 3143/4500\n",
            "100/100 [==============================] - 0s 606us/step - loss: 0.2092 - acc: 0.8900 - val_loss: 0.3915 - val_acc: 0.8000\n",
            "Epoch 3144/4500\n",
            "100/100 [==============================] - 0s 500us/step - loss: 0.2039 - acc: 0.9000 - val_loss: 0.3685 - val_acc: 0.8200\n",
            "Epoch 3145/4500\n",
            "100/100 [==============================] - 0s 515us/step - loss: 0.2036 - acc: 0.9200 - val_loss: 0.3674 - val_acc: 0.8300\n",
            "Epoch 3146/4500\n",
            "100/100 [==============================] - 0s 582us/step - loss: 0.2023 - acc: 0.9100 - val_loss: 0.3799 - val_acc: 0.8200\n",
            "Epoch 3147/4500\n",
            "100/100 [==============================] - 0s 510us/step - loss: 0.2024 - acc: 0.9100 - val_loss: 0.3781 - val_acc: 0.8200\n",
            "Epoch 3148/4500\n",
            "100/100 [==============================] - 0s 515us/step - loss: 0.2036 - acc: 0.9000 - val_loss: 0.3720 - val_acc: 0.8300\n",
            "Epoch 3149/4500\n",
            "100/100 [==============================] - 0s 503us/step - loss: 0.2070 - acc: 0.9100 - val_loss: 0.3786 - val_acc: 0.8200\n",
            "Epoch 3150/4500\n",
            "100/100 [==============================] - 0s 499us/step - loss: 0.2031 - acc: 0.9200 - val_loss: 0.3705 - val_acc: 0.8200\n",
            "Epoch 3151/4500\n",
            "100/100 [==============================] - 0s 515us/step - loss: 0.2120 - acc: 0.9100 - val_loss: 0.3631 - val_acc: 0.8400\n",
            "Epoch 3152/4500\n",
            "100/100 [==============================] - 0s 522us/step - loss: 0.2025 - acc: 0.8900 - val_loss: 0.3949 - val_acc: 0.8100\n",
            "Epoch 3153/4500\n",
            "100/100 [==============================] - 0s 581us/step - loss: 0.2160 - acc: 0.8900 - val_loss: 0.3778 - val_acc: 0.8200\n",
            "Epoch 3154/4500\n",
            "100/100 [==============================] - 0s 492us/step - loss: 0.2036 - acc: 0.9200 - val_loss: 0.3602 - val_acc: 0.8400\n",
            "Epoch 3155/4500\n",
            "100/100 [==============================] - 0s 500us/step - loss: 0.2076 - acc: 0.9000 - val_loss: 0.3793 - val_acc: 0.8200\n",
            "Epoch 3156/4500\n",
            "100/100 [==============================] - 0s 496us/step - loss: 0.2077 - acc: 0.9000 - val_loss: 0.3847 - val_acc: 0.8200\n",
            "Epoch 3157/4500\n",
            "100/100 [==============================] - 0s 541us/step - loss: 0.2039 - acc: 0.9000 - val_loss: 0.3938 - val_acc: 0.8000\n",
            "Epoch 3158/4500\n",
            "100/100 [==============================] - 0s 654us/step - loss: 0.2081 - acc: 0.8800 - val_loss: 0.3759 - val_acc: 0.8200\n",
            "Epoch 3159/4500\n",
            "100/100 [==============================] - 0s 570us/step - loss: 0.2009 - acc: 0.9100 - val_loss: 0.3811 - val_acc: 0.8200\n",
            "Epoch 3160/4500\n",
            "100/100 [==============================] - 0s 544us/step - loss: 0.2021 - acc: 0.9100 - val_loss: 0.3807 - val_acc: 0.8200\n",
            "Epoch 3161/4500\n",
            "100/100 [==============================] - 0s 504us/step - loss: 0.2038 - acc: 0.9300 - val_loss: 0.3739 - val_acc: 0.8200\n",
            "Epoch 3162/4500\n",
            "100/100 [==============================] - 0s 525us/step - loss: 0.2021 - acc: 0.9200 - val_loss: 0.3685 - val_acc: 0.8300\n",
            "Epoch 3163/4500\n",
            "100/100 [==============================] - 0s 570us/step - loss: 0.1988 - acc: 0.9200 - val_loss: 0.3778 - val_acc: 0.8200\n",
            "Epoch 3164/4500\n",
            "100/100 [==============================] - 0s 592us/step - loss: 0.1984 - acc: 0.9200 - val_loss: 0.3775 - val_acc: 0.8200\n",
            "Epoch 3165/4500\n",
            "100/100 [==============================] - 0s 530us/step - loss: 0.1988 - acc: 0.9200 - val_loss: 0.3765 - val_acc: 0.8200\n",
            "Epoch 3166/4500\n",
            "100/100 [==============================] - 0s 511us/step - loss: 0.2016 - acc: 0.9100 - val_loss: 0.3756 - val_acc: 0.8200\n",
            "Epoch 3167/4500\n",
            "100/100 [==============================] - 0s 513us/step - loss: 0.1994 - acc: 0.9200 - val_loss: 0.3803 - val_acc: 0.8200\n",
            "Epoch 3168/4500\n",
            "100/100 [==============================] - 0s 506us/step - loss: 0.2006 - acc: 0.9100 - val_loss: 0.3749 - val_acc: 0.8200\n",
            "Epoch 3169/4500\n",
            "100/100 [==============================] - 0s 523us/step - loss: 0.1996 - acc: 0.9200 - val_loss: 0.3788 - val_acc: 0.8200\n",
            "Epoch 3170/4500\n",
            "100/100 [==============================] - 0s 556us/step - loss: 0.2035 - acc: 0.9100 - val_loss: 0.3715 - val_acc: 0.8300\n",
            "Epoch 3171/4500\n",
            "100/100 [==============================] - 0s 523us/step - loss: 0.2009 - acc: 0.9000 - val_loss: 0.3832 - val_acc: 0.8200\n",
            "Epoch 3172/4500\n",
            "100/100 [==============================] - 0s 617us/step - loss: 0.2033 - acc: 0.9100 - val_loss: 0.3815 - val_acc: 0.8200\n",
            "Epoch 3173/4500\n",
            "100/100 [==============================] - 0s 522us/step - loss: 0.1992 - acc: 0.9200 - val_loss: 0.3689 - val_acc: 0.8300\n",
            "Epoch 3174/4500\n",
            "100/100 [==============================] - 0s 486us/step - loss: 0.2017 - acc: 0.9100 - val_loss: 0.3836 - val_acc: 0.8200\n",
            "Epoch 3175/4500\n",
            "100/100 [==============================] - 0s 486us/step - loss: 0.2001 - acc: 0.9000 - val_loss: 0.3671 - val_acc: 0.8300\n",
            "Epoch 3176/4500\n",
            "100/100 [==============================] - 0s 497us/step - loss: 0.1972 - acc: 0.9200 - val_loss: 0.3780 - val_acc: 0.8200\n",
            "Epoch 3177/4500\n",
            "100/100 [==============================] - 0s 519us/step - loss: 0.1975 - acc: 0.9100 - val_loss: 0.3792 - val_acc: 0.8200\n",
            "Epoch 3178/4500\n",
            "100/100 [==============================] - 0s 518us/step - loss: 0.1979 - acc: 0.9100 - val_loss: 0.3790 - val_acc: 0.8300\n",
            "Epoch 3179/4500\n",
            "100/100 [==============================] - 0s 515us/step - loss: 0.1987 - acc: 0.9200 - val_loss: 0.3804 - val_acc: 0.8200\n",
            "Epoch 3180/4500\n",
            "100/100 [==============================] - 0s 504us/step - loss: 0.1954 - acc: 0.9200 - val_loss: 0.3664 - val_acc: 0.8400\n",
            "Epoch 3181/4500\n",
            "100/100 [==============================] - 0s 501us/step - loss: 0.1978 - acc: 0.9100 - val_loss: 0.3756 - val_acc: 0.8200\n",
            "Epoch 3182/4500\n",
            "100/100 [==============================] - 0s 565us/step - loss: 0.1972 - acc: 0.9200 - val_loss: 0.3693 - val_acc: 0.8300\n",
            "Epoch 3183/4500\n",
            "100/100 [==============================] - 0s 603us/step - loss: 0.2035 - acc: 0.9200 - val_loss: 0.3807 - val_acc: 0.8200\n",
            "Epoch 3184/4500\n",
            "100/100 [==============================] - 0s 504us/step - loss: 0.2048 - acc: 0.9000 - val_loss: 0.3635 - val_acc: 0.8400\n",
            "Epoch 3185/4500\n",
            "100/100 [==============================] - 0s 532us/step - loss: 0.2010 - acc: 0.9100 - val_loss: 0.3820 - val_acc: 0.8200\n",
            "Epoch 3186/4500\n",
            "100/100 [==============================] - 0s 518us/step - loss: 0.2007 - acc: 0.9200 - val_loss: 0.3789 - val_acc: 0.8200\n",
            "Epoch 3187/4500\n",
            "100/100 [==============================] - 0s 526us/step - loss: 0.1960 - acc: 0.9200 - val_loss: 0.3769 - val_acc: 0.8200\n",
            "Epoch 3188/4500\n",
            "100/100 [==============================] - 0s 534us/step - loss: 0.1982 - acc: 0.9000 - val_loss: 0.3717 - val_acc: 0.8300\n",
            "Epoch 3189/4500\n",
            "100/100 [==============================] - 0s 531us/step - loss: 0.2012 - acc: 0.9200 - val_loss: 0.3825 - val_acc: 0.8200\n",
            "Epoch 3190/4500\n",
            "100/100 [==============================] - 0s 493us/step - loss: 0.1995 - acc: 0.9200 - val_loss: 0.3719 - val_acc: 0.8300\n",
            "Epoch 3191/4500\n",
            "100/100 [==============================] - 0s 531us/step - loss: 0.1951 - acc: 0.9200 - val_loss: 0.3732 - val_acc: 0.8300\n",
            "Epoch 3192/4500\n",
            "100/100 [==============================] - 0s 571us/step - loss: 0.1948 - acc: 0.9300 - val_loss: 0.3789 - val_acc: 0.8300\n",
            "Epoch 3193/4500\n",
            "100/100 [==============================] - 0s 571us/step - loss: 0.1950 - acc: 0.9100 - val_loss: 0.3775 - val_acc: 0.8300\n",
            "Epoch 3194/4500\n",
            "100/100 [==============================] - 0s 583us/step - loss: 0.1961 - acc: 0.9200 - val_loss: 0.3760 - val_acc: 0.8300\n",
            "Epoch 3195/4500\n",
            "100/100 [==============================] - 0s 515us/step - loss: 0.1958 - acc: 0.9200 - val_loss: 0.3797 - val_acc: 0.8300\n",
            "Epoch 3196/4500\n",
            "100/100 [==============================] - 0s 582us/step - loss: 0.1943 - acc: 0.9200 - val_loss: 0.3858 - val_acc: 0.8200\n",
            "Epoch 3197/4500\n",
            "100/100 [==============================] - 0s 586us/step - loss: 0.1955 - acc: 0.9200 - val_loss: 0.3747 - val_acc: 0.8300\n",
            "Epoch 3198/4500\n",
            "100/100 [==============================] - 0s 550us/step - loss: 0.1951 - acc: 0.9100 - val_loss: 0.3773 - val_acc: 0.8300\n",
            "Epoch 3199/4500\n",
            "100/100 [==============================] - 0s 512us/step - loss: 0.2006 - acc: 0.9000 - val_loss: 0.3713 - val_acc: 0.8300\n",
            "Epoch 3200/4500\n",
            "100/100 [==============================] - 0s 547us/step - loss: 0.1953 - acc: 0.9200 - val_loss: 0.3849 - val_acc: 0.8100\n",
            "Epoch 3201/4500\n",
            "100/100 [==============================] - 0s 535us/step - loss: 0.1948 - acc: 0.9200 - val_loss: 0.3762 - val_acc: 0.8300\n",
            "Epoch 3202/4500\n",
            "100/100 [==============================] - 0s 541us/step - loss: 0.1964 - acc: 0.9100 - val_loss: 0.3749 - val_acc: 0.8300\n",
            "Epoch 3203/4500\n",
            "100/100 [==============================] - 0s 515us/step - loss: 0.1929 - acc: 0.9200 - val_loss: 0.3836 - val_acc: 0.8300\n",
            "Epoch 3204/4500\n",
            "100/100 [==============================] - 0s 500us/step - loss: 0.1948 - acc: 0.9100 - val_loss: 0.3841 - val_acc: 0.8300\n",
            "Epoch 3205/4500\n",
            "100/100 [==============================] - 0s 521us/step - loss: 0.1950 - acc: 0.9100 - val_loss: 0.3726 - val_acc: 0.8300\n",
            "Epoch 3206/4500\n",
            "100/100 [==============================] - 0s 562us/step - loss: 0.1922 - acc: 0.9200 - val_loss: 0.3712 - val_acc: 0.8300\n",
            "Epoch 3207/4500\n",
            "100/100 [==============================] - 0s 489us/step - loss: 0.1963 - acc: 0.9200 - val_loss: 0.3789 - val_acc: 0.8300\n",
            "Epoch 3208/4500\n",
            "100/100 [==============================] - 0s 490us/step - loss: 0.1916 - acc: 0.9200 - val_loss: 0.3668 - val_acc: 0.8300\n",
            "Epoch 3209/4500\n",
            "100/100 [==============================] - 0s 538us/step - loss: 0.2009 - acc: 0.9000 - val_loss: 0.3805 - val_acc: 0.8300\n",
            "Epoch 3210/4500\n",
            "100/100 [==============================] - 0s 500us/step - loss: 0.1951 - acc: 0.9200 - val_loss: 0.3788 - val_acc: 0.8300\n",
            "Epoch 3211/4500\n",
            "100/100 [==============================] - 0s 586us/step - loss: 0.1957 - acc: 0.9100 - val_loss: 0.3742 - val_acc: 0.8300\n",
            "Epoch 3212/4500\n",
            "100/100 [==============================] - 0s 590us/step - loss: 0.1927 - acc: 0.9200 - val_loss: 0.3812 - val_acc: 0.8300\n",
            "Epoch 3213/4500\n",
            "100/100 [==============================] - 0s 574us/step - loss: 0.1923 - acc: 0.9200 - val_loss: 0.3678 - val_acc: 0.8300\n",
            "Epoch 3214/4500\n",
            "100/100 [==============================] - 0s 495us/step - loss: 0.1952 - acc: 0.9100 - val_loss: 0.3765 - val_acc: 0.8300\n",
            "Epoch 3215/4500\n",
            "100/100 [==============================] - 0s 519us/step - loss: 0.1930 - acc: 0.9200 - val_loss: 0.3839 - val_acc: 0.8300\n",
            "Epoch 3216/4500\n",
            "100/100 [==============================] - 0s 493us/step - loss: 0.1953 - acc: 0.9200 - val_loss: 0.3762 - val_acc: 0.8300\n",
            "Epoch 3217/4500\n",
            "100/100 [==============================] - 0s 493us/step - loss: 0.1951 - acc: 0.9100 - val_loss: 0.3786 - val_acc: 0.8300\n",
            "Epoch 3218/4500\n",
            "100/100 [==============================] - 0s 502us/step - loss: 0.1977 - acc: 0.9200 - val_loss: 0.3903 - val_acc: 0.8000\n",
            "Epoch 3219/4500\n",
            "100/100 [==============================] - 0s 504us/step - loss: 0.1985 - acc: 0.9200 - val_loss: 0.3802 - val_acc: 0.8300\n",
            "Epoch 3220/4500\n",
            "100/100 [==============================] - 0s 547us/step - loss: 0.1972 - acc: 0.9000 - val_loss: 0.3914 - val_acc: 0.8100\n",
            "Epoch 3221/4500\n",
            "100/100 [==============================] - 0s 651us/step - loss: 0.1988 - acc: 0.9200 - val_loss: 0.3827 - val_acc: 0.8300\n",
            "Epoch 3222/4500\n",
            "100/100 [==============================] - 0s 509us/step - loss: 0.2026 - acc: 0.9200 - val_loss: 0.3704 - val_acc: 0.8300\n",
            "Epoch 3223/4500\n",
            "100/100 [==============================] - 0s 498us/step - loss: 0.1897 - acc: 0.9100 - val_loss: 0.3830 - val_acc: 0.8300\n",
            "Epoch 3224/4500\n",
            "100/100 [==============================] - 0s 499us/step - loss: 0.1955 - acc: 0.9200 - val_loss: 0.3763 - val_acc: 0.8300\n",
            "Epoch 3225/4500\n",
            "100/100 [==============================] - 0s 542us/step - loss: 0.1909 - acc: 0.9200 - val_loss: 0.3672 - val_acc: 0.8400\n",
            "Epoch 3226/4500\n",
            "100/100 [==============================] - 0s 517us/step - loss: 0.1942 - acc: 0.9100 - val_loss: 0.3788 - val_acc: 0.8300\n",
            "Epoch 3227/4500\n",
            "100/100 [==============================] - 0s 498us/step - loss: 0.1925 - acc: 0.9200 - val_loss: 0.3705 - val_acc: 0.8300\n",
            "Epoch 3228/4500\n",
            "100/100 [==============================] - 0s 503us/step - loss: 0.1911 - acc: 0.9200 - val_loss: 0.3757 - val_acc: 0.8300\n",
            "Epoch 3229/4500\n",
            "100/100 [==============================] - 0s 495us/step - loss: 0.1914 - acc: 0.9100 - val_loss: 0.3748 - val_acc: 0.8300\n",
            "Epoch 3230/4500\n",
            "100/100 [==============================] - 0s 501us/step - loss: 0.1911 - acc: 0.9100 - val_loss: 0.3735 - val_acc: 0.8300\n",
            "Epoch 3231/4500\n",
            "100/100 [==============================] - 0s 542us/step - loss: 0.1923 - acc: 0.9200 - val_loss: 0.3786 - val_acc: 0.8300\n",
            "Epoch 3232/4500\n",
            "100/100 [==============================] - 0s 507us/step - loss: 0.1875 - acc: 0.9200 - val_loss: 0.3719 - val_acc: 0.8300\n",
            "Epoch 3233/4500\n",
            "100/100 [==============================] - 0s 496us/step - loss: 0.1924 - acc: 0.9100 - val_loss: 0.3778 - val_acc: 0.8300\n",
            "Epoch 3234/4500\n",
            "100/100 [==============================] - 0s 494us/step - loss: 0.1916 - acc: 0.9200 - val_loss: 0.3845 - val_acc: 0.8200\n",
            "Epoch 3235/4500\n",
            "100/100 [==============================] - 0s 507us/step - loss: 0.1892 - acc: 0.9200 - val_loss: 0.3668 - val_acc: 0.8300\n",
            "Epoch 3236/4500\n",
            "100/100 [==============================] - 0s 514us/step - loss: 0.1929 - acc: 0.9200 - val_loss: 0.3817 - val_acc: 0.8300\n",
            "Epoch 3237/4500\n",
            "100/100 [==============================] - 0s 521us/step - loss: 0.2035 - acc: 0.8900 - val_loss: 0.3869 - val_acc: 0.8200\n",
            "Epoch 3238/4500\n",
            "100/100 [==============================] - 0s 533us/step - loss: 0.1894 - acc: 0.9200 - val_loss: 0.3592 - val_acc: 0.8500\n",
            "Epoch 3239/4500\n",
            "100/100 [==============================] - 0s 520us/step - loss: 0.1916 - acc: 0.9200 - val_loss: 0.3787 - val_acc: 0.8300\n",
            "Epoch 3240/4500\n",
            "100/100 [==============================] - 0s 599us/step - loss: 0.1969 - acc: 0.9000 - val_loss: 0.3746 - val_acc: 0.8300\n",
            "Epoch 3241/4500\n",
            "100/100 [==============================] - 0s 566us/step - loss: 0.1924 - acc: 0.9200 - val_loss: 0.3992 - val_acc: 0.8100\n",
            "Epoch 3242/4500\n",
            "100/100 [==============================] - 0s 507us/step - loss: 0.1913 - acc: 0.9100 - val_loss: 0.3737 - val_acc: 0.8300\n",
            "Epoch 3243/4500\n",
            "100/100 [==============================] - 0s 524us/step - loss: 0.1919 - acc: 0.9200 - val_loss: 0.3617 - val_acc: 0.8400\n",
            "Epoch 3244/4500\n",
            "100/100 [==============================] - 0s 477us/step - loss: 0.1890 - acc: 0.9200 - val_loss: 0.3783 - val_acc: 0.8300\n",
            "Epoch 3245/4500\n",
            "100/100 [==============================] - 0s 501us/step - loss: 0.1893 - acc: 0.9100 - val_loss: 0.3825 - val_acc: 0.8300\n",
            "Epoch 3246/4500\n",
            "100/100 [==============================] - 0s 513us/step - loss: 0.1892 - acc: 0.9200 - val_loss: 0.3756 - val_acc: 0.8300\n",
            "Epoch 3247/4500\n",
            "100/100 [==============================] - 0s 549us/step - loss: 0.1864 - acc: 0.9100 - val_loss: 0.3847 - val_acc: 0.8300\n",
            "Epoch 3248/4500\n",
            "100/100 [==============================] - 0s 492us/step - loss: 0.1928 - acc: 0.9200 - val_loss: 0.3846 - val_acc: 0.8200\n",
            "Epoch 3249/4500\n",
            "100/100 [==============================] - 0s 520us/step - loss: 0.1959 - acc: 0.9100 - val_loss: 0.3760 - val_acc: 0.8300\n",
            "Epoch 3250/4500\n",
            "100/100 [==============================] - 0s 503us/step - loss: 0.1853 - acc: 0.9200 - val_loss: 0.3757 - val_acc: 0.8300\n",
            "Epoch 3251/4500\n",
            "100/100 [==============================] - 0s 526us/step - loss: 0.1859 - acc: 0.9100 - val_loss: 0.3796 - val_acc: 0.8300\n",
            "Epoch 3252/4500\n",
            "100/100 [==============================] - 0s 527us/step - loss: 0.1857 - acc: 0.9200 - val_loss: 0.3770 - val_acc: 0.8300\n",
            "Epoch 3253/4500\n",
            "100/100 [==============================] - 0s 516us/step - loss: 0.1882 - acc: 0.9200 - val_loss: 0.3792 - val_acc: 0.8300\n",
            "Epoch 3254/4500\n",
            "100/100 [==============================] - 0s 474us/step - loss: 0.1845 - acc: 0.9100 - val_loss: 0.3752 - val_acc: 0.8300\n",
            "Epoch 3255/4500\n",
            "100/100 [==============================] - 0s 488us/step - loss: 0.1851 - acc: 0.9300 - val_loss: 0.3768 - val_acc: 0.8300\n",
            "Epoch 3256/4500\n",
            "100/100 [==============================] - 0s 507us/step - loss: 0.1858 - acc: 0.9300 - val_loss: 0.3907 - val_acc: 0.8100\n",
            "Epoch 3257/4500\n",
            "100/100 [==============================] - 0s 501us/step - loss: 0.1903 - acc: 0.9200 - val_loss: 0.3792 - val_acc: 0.8300\n",
            "Epoch 3258/4500\n",
            "100/100 [==============================] - 0s 618us/step - loss: 0.1881 - acc: 0.9100 - val_loss: 0.3781 - val_acc: 0.8300\n",
            "Epoch 3259/4500\n",
            "100/100 [==============================] - 0s 688us/step - loss: 0.1896 - acc: 0.9100 - val_loss: 0.3669 - val_acc: 0.8500\n",
            "Epoch 3260/4500\n",
            "100/100 [==============================] - 0s 514us/step - loss: 0.1833 - acc: 0.9200 - val_loss: 0.3858 - val_acc: 0.8200\n",
            "Epoch 3261/4500\n",
            "100/100 [==============================] - 0s 499us/step - loss: 0.1856 - acc: 0.9200 - val_loss: 0.3778 - val_acc: 0.8300\n",
            "Epoch 3262/4500\n",
            "100/100 [==============================] - 0s 488us/step - loss: 0.1820 - acc: 0.9200 - val_loss: 0.3712 - val_acc: 0.8300\n",
            "Epoch 3263/4500\n",
            "100/100 [==============================] - 0s 508us/step - loss: 0.1874 - acc: 0.9200 - val_loss: 0.3764 - val_acc: 0.8300\n",
            "Epoch 3264/4500\n",
            "100/100 [==============================] - 0s 493us/step - loss: 0.1835 - acc: 0.9100 - val_loss: 0.3947 - val_acc: 0.8000\n",
            "Epoch 3265/4500\n",
            "100/100 [==============================] - 0s 501us/step - loss: 0.1863 - acc: 0.9200 - val_loss: 0.3755 - val_acc: 0.8300\n",
            "Epoch 3266/4500\n",
            "100/100 [==============================] - 0s 497us/step - loss: 0.1851 - acc: 0.9200 - val_loss: 0.3765 - val_acc: 0.8300\n",
            "Epoch 3267/4500\n",
            "100/100 [==============================] - 0s 527us/step - loss: 0.1805 - acc: 0.9200 - val_loss: 0.3880 - val_acc: 0.8200\n",
            "Epoch 3268/4500\n",
            "100/100 [==============================] - 0s 503us/step - loss: 0.1875 - acc: 0.9100 - val_loss: 0.3757 - val_acc: 0.8300\n",
            "Epoch 3269/4500\n",
            "100/100 [==============================] - 0s 491us/step - loss: 0.1826 - acc: 0.9200 - val_loss: 0.3717 - val_acc: 0.8300\n",
            "Epoch 3270/4500\n",
            "100/100 [==============================] - 0s 483us/step - loss: 0.1901 - acc: 0.9100 - val_loss: 0.3764 - val_acc: 0.8300\n",
            "Epoch 3271/4500\n",
            "100/100 [==============================] - 0s 531us/step - loss: 0.1829 - acc: 0.9300 - val_loss: 0.3731 - val_acc: 0.8300\n",
            "Epoch 3272/4500\n",
            "100/100 [==============================] - 0s 498us/step - loss: 0.1823 - acc: 0.9200 - val_loss: 0.3796 - val_acc: 0.8300\n",
            "Epoch 3273/4500\n",
            "100/100 [==============================] - 0s 502us/step - loss: 0.1810 - acc: 0.9100 - val_loss: 0.3825 - val_acc: 0.8200\n",
            "Epoch 3274/4500\n",
            "100/100 [==============================] - 0s 518us/step - loss: 0.1866 - acc: 0.9100 - val_loss: 0.3738 - val_acc: 0.8300\n",
            "Epoch 3275/4500\n",
            "100/100 [==============================] - 0s 554us/step - loss: 0.1823 - acc: 0.9300 - val_loss: 0.3966 - val_acc: 0.8000\n",
            "Epoch 3276/4500\n",
            "100/100 [==============================] - 0s 522us/step - loss: 0.1829 - acc: 0.9200 - val_loss: 0.3878 - val_acc: 0.8100\n",
            "Epoch 3277/4500\n",
            "100/100 [==============================] - 0s 484us/step - loss: 0.1834 - acc: 0.9200 - val_loss: 0.3743 - val_acc: 0.8300\n",
            "Epoch 3278/4500\n",
            "100/100 [==============================] - 0s 511us/step - loss: 0.1910 - acc: 0.9100 - val_loss: 0.3808 - val_acc: 0.8300\n",
            "Epoch 3279/4500\n",
            "100/100 [==============================] - 0s 514us/step - loss: 0.1839 - acc: 0.9200 - val_loss: 0.3630 - val_acc: 0.8500\n",
            "Epoch 3280/4500\n",
            "100/100 [==============================] - 0s 527us/step - loss: 0.1848 - acc: 0.9100 - val_loss: 0.3790 - val_acc: 0.8300\n",
            "Epoch 3281/4500\n",
            "100/100 [==============================] - 0s 520us/step - loss: 0.1809 - acc: 0.9100 - val_loss: 0.3733 - val_acc: 0.8300\n",
            "Epoch 3282/4500\n",
            "100/100 [==============================] - 0s 490us/step - loss: 0.1839 - acc: 0.9200 - val_loss: 0.3817 - val_acc: 0.8300\n",
            "Epoch 3283/4500\n",
            "100/100 [==============================] - 0s 518us/step - loss: 0.1846 - acc: 0.9100 - val_loss: 0.3928 - val_acc: 0.8100\n",
            "Epoch 3284/4500\n",
            "100/100 [==============================] - 0s 524us/step - loss: 0.1879 - acc: 0.9200 - val_loss: 0.3715 - val_acc: 0.8400\n",
            "Epoch 3285/4500\n",
            "100/100 [==============================] - 0s 488us/step - loss: 0.1809 - acc: 0.9300 - val_loss: 0.3959 - val_acc: 0.8000\n",
            "Epoch 3286/4500\n",
            "100/100 [==============================] - 0s 489us/step - loss: 0.1854 - acc: 0.9200 - val_loss: 0.3893 - val_acc: 0.8200\n",
            "Epoch 3287/4500\n",
            "100/100 [==============================] - 0s 571us/step - loss: 0.1822 - acc: 0.9200 - val_loss: 0.3706 - val_acc: 0.8300\n",
            "Epoch 3288/4500\n",
            "100/100 [==============================] - 0s 644us/step - loss: 0.1889 - acc: 0.8900 - val_loss: 0.3663 - val_acc: 0.8400\n",
            "Epoch 3289/4500\n",
            "100/100 [==============================] - 0s 563us/step - loss: 0.1848 - acc: 0.9200 - val_loss: 0.3882 - val_acc: 0.8300\n",
            "Epoch 3290/4500\n",
            "100/100 [==============================] - 0s 631us/step - loss: 0.1825 - acc: 0.9100 - val_loss: 0.3784 - val_acc: 0.8300\n",
            "Epoch 3291/4500\n",
            "100/100 [==============================] - 0s 501us/step - loss: 0.1817 - acc: 0.9200 - val_loss: 0.3805 - val_acc: 0.8300\n",
            "Epoch 3292/4500\n",
            "100/100 [==============================] - 0s 500us/step - loss: 0.1843 - acc: 0.9100 - val_loss: 0.3781 - val_acc: 0.8300\n",
            "Epoch 3293/4500\n",
            "100/100 [==============================] - 0s 507us/step - loss: 0.1886 - acc: 0.9200 - val_loss: 0.3891 - val_acc: 0.8100\n",
            "Epoch 3294/4500\n",
            "100/100 [==============================] - 0s 490us/step - loss: 0.1803 - acc: 0.9100 - val_loss: 0.3652 - val_acc: 0.8500\n",
            "Epoch 3295/4500\n",
            "100/100 [==============================] - 0s 497us/step - loss: 0.1819 - acc: 0.9200 - val_loss: 0.3743 - val_acc: 0.8300\n",
            "Epoch 3296/4500\n",
            "100/100 [==============================] - 0s 516us/step - loss: 0.1801 - acc: 0.9300 - val_loss: 0.3870 - val_acc: 0.8200\n",
            "Epoch 3297/4500\n",
            "100/100 [==============================] - 0s 535us/step - loss: 0.1882 - acc: 0.9200 - val_loss: 0.3639 - val_acc: 0.8300\n",
            "Epoch 3298/4500\n",
            "100/100 [==============================] - 0s 522us/step - loss: 0.1809 - acc: 0.9100 - val_loss: 0.3736 - val_acc: 0.8300\n",
            "Epoch 3299/4500\n",
            "100/100 [==============================] - 0s 510us/step - loss: 0.1781 - acc: 0.9200 - val_loss: 0.3824 - val_acc: 0.8300\n",
            "Epoch 3300/4500\n",
            "100/100 [==============================] - 0s 485us/step - loss: 0.1799 - acc: 0.9200 - val_loss: 0.3794 - val_acc: 0.8300\n",
            "Epoch 3301/4500\n",
            "100/100 [==============================] - 0s 627us/step - loss: 0.1859 - acc: 0.9200 - val_loss: 0.3829 - val_acc: 0.8300\n",
            "Epoch 3302/4500\n",
            "100/100 [==============================] - 0s 534us/step - loss: 0.1812 - acc: 0.9200 - val_loss: 0.3746 - val_acc: 0.8300\n",
            "Epoch 3303/4500\n",
            "100/100 [==============================] - 0s 503us/step - loss: 0.1793 - acc: 0.9200 - val_loss: 0.3919 - val_acc: 0.8100\n",
            "Epoch 3304/4500\n",
            "100/100 [==============================] - 0s 503us/step - loss: 0.1755 - acc: 0.9100 - val_loss: 0.3773 - val_acc: 0.8400\n",
            "Epoch 3305/4500\n",
            "100/100 [==============================] - 0s 528us/step - loss: 0.1786 - acc: 0.9200 - val_loss: 0.3769 - val_acc: 0.8300\n",
            "Epoch 3306/4500\n",
            "100/100 [==============================] - 0s 523us/step - loss: 0.1791 - acc: 0.9300 - val_loss: 0.3663 - val_acc: 0.8400\n",
            "Epoch 3307/4500\n",
            "100/100 [==============================] - 0s 590us/step - loss: 0.1802 - acc: 0.9200 - val_loss: 0.3797 - val_acc: 0.8300\n",
            "Epoch 3308/4500\n",
            "100/100 [==============================] - 0s 624us/step - loss: 0.1911 - acc: 0.9100 - val_loss: 0.3939 - val_acc: 0.8200\n",
            "Epoch 3309/4500\n",
            "100/100 [==============================] - 0s 507us/step - loss: 0.1820 - acc: 0.9100 - val_loss: 0.3617 - val_acc: 0.8400\n",
            "Epoch 3310/4500\n",
            "100/100 [==============================] - 0s 519us/step - loss: 0.1836 - acc: 0.9200 - val_loss: 0.3744 - val_acc: 0.8400\n",
            "Epoch 3311/4500\n",
            "100/100 [==============================] - 0s 526us/step - loss: 0.1759 - acc: 0.9200 - val_loss: 0.3901 - val_acc: 0.8100\n",
            "Epoch 3312/4500\n",
            "100/100 [==============================] - 0s 512us/step - loss: 0.1761 - acc: 0.9300 - val_loss: 0.3847 - val_acc: 0.8200\n",
            "Epoch 3313/4500\n",
            "100/100 [==============================] - 0s 535us/step - loss: 0.1766 - acc: 0.9200 - val_loss: 0.3810 - val_acc: 0.8300\n",
            "Epoch 3314/4500\n",
            "100/100 [==============================] - 0s 495us/step - loss: 0.1772 - acc: 0.9100 - val_loss: 0.3884 - val_acc: 0.8100\n",
            "Epoch 3315/4500\n",
            "100/100 [==============================] - 0s 523us/step - loss: 0.1749 - acc: 0.9300 - val_loss: 0.3758 - val_acc: 0.8300\n",
            "Epoch 3316/4500\n",
            "100/100 [==============================] - 0s 595us/step - loss: 0.1805 - acc: 0.9100 - val_loss: 0.3824 - val_acc: 0.8300\n",
            "Epoch 3317/4500\n",
            "100/100 [==============================] - 0s 522us/step - loss: 0.1784 - acc: 0.9100 - val_loss: 0.3837 - val_acc: 0.8300\n",
            "Epoch 3318/4500\n",
            "100/100 [==============================] - 0s 516us/step - loss: 0.1775 - acc: 0.9200 - val_loss: 0.3721 - val_acc: 0.8300\n",
            "Epoch 3319/4500\n",
            "100/100 [==============================] - 0s 489us/step - loss: 0.1758 - acc: 0.9300 - val_loss: 0.3685 - val_acc: 0.8400\n",
            "Epoch 3320/4500\n",
            "100/100 [==============================] - 0s 556us/step - loss: 0.1722 - acc: 0.9400 - val_loss: 0.3874 - val_acc: 0.8200\n",
            "Epoch 3321/4500\n",
            "100/100 [==============================] - 0s 526us/step - loss: 0.1760 - acc: 0.9100 - val_loss: 0.3780 - val_acc: 0.8300\n",
            "Epoch 3322/4500\n",
            "100/100 [==============================] - 0s 515us/step - loss: 0.1759 - acc: 0.9300 - val_loss: 0.3849 - val_acc: 0.8300\n",
            "Epoch 3323/4500\n",
            "100/100 [==============================] - 0s 539us/step - loss: 0.1800 - acc: 0.9200 - val_loss: 0.3915 - val_acc: 0.8100\n",
            "Epoch 3324/4500\n",
            "100/100 [==============================] - 0s 511us/step - loss: 0.1754 - acc: 0.9300 - val_loss: 0.3661 - val_acc: 0.8400\n",
            "Epoch 3325/4500\n",
            "100/100 [==============================] - 0s 514us/step - loss: 0.1763 - acc: 0.9200 - val_loss: 0.3836 - val_acc: 0.8200\n",
            "Epoch 3326/4500\n",
            "100/100 [==============================] - 0s 544us/step - loss: 0.1760 - acc: 0.9200 - val_loss: 0.3705 - val_acc: 0.8400\n",
            "Epoch 3327/4500\n",
            "100/100 [==============================] - 0s 613us/step - loss: 0.1800 - acc: 0.9100 - val_loss: 0.3661 - val_acc: 0.8400\n",
            "Epoch 3328/4500\n",
            "100/100 [==============================] - 0s 497us/step - loss: 0.1741 - acc: 0.9300 - val_loss: 0.3951 - val_acc: 0.8000\n",
            "Epoch 3329/4500\n",
            "100/100 [==============================] - 0s 477us/step - loss: 0.1761 - acc: 0.9200 - val_loss: 0.3862 - val_acc: 0.8100\n",
            "Epoch 3330/4500\n",
            "100/100 [==============================] - 0s 517us/step - loss: 0.1756 - acc: 0.9200 - val_loss: 0.3760 - val_acc: 0.8400\n",
            "Epoch 3331/4500\n",
            "100/100 [==============================] - 0s 509us/step - loss: 0.1797 - acc: 0.9200 - val_loss: 0.3760 - val_acc: 0.8600\n",
            "Epoch 3332/4500\n",
            "100/100 [==============================] - 0s 506us/step - loss: 0.1813 - acc: 0.9300 - val_loss: 0.3784 - val_acc: 0.8400\n",
            "Epoch 3333/4500\n",
            "100/100 [==============================] - 0s 516us/step - loss: 0.1791 - acc: 0.9200 - val_loss: 0.3764 - val_acc: 0.8400\n",
            "Epoch 3334/4500\n",
            "100/100 [==============================] - 0s 502us/step - loss: 0.1940 - acc: 0.9000 - val_loss: 0.3856 - val_acc: 0.8200\n",
            "Epoch 3335/4500\n",
            "100/100 [==============================] - 0s 552us/step - loss: 0.1753 - acc: 0.9100 - val_loss: 0.3856 - val_acc: 0.8100\n",
            "Epoch 3336/4500\n",
            "100/100 [==============================] - 0s 514us/step - loss: 0.1821 - acc: 0.9200 - val_loss: 0.3721 - val_acc: 0.8600\n",
            "Epoch 3337/4500\n",
            "100/100 [==============================] - 0s 521us/step - loss: 0.1889 - acc: 0.9100 - val_loss: 0.3934 - val_acc: 0.8100\n",
            "Epoch 3338/4500\n",
            "100/100 [==============================] - 0s 528us/step - loss: 0.1732 - acc: 0.9300 - val_loss: 0.3718 - val_acc: 0.8400\n",
            "Epoch 3339/4500\n",
            "100/100 [==============================] - 0s 484us/step - loss: 0.1774 - acc: 0.9200 - val_loss: 0.3914 - val_acc: 0.8300\n",
            "Epoch 3340/4500\n",
            "100/100 [==============================] - 0s 539us/step - loss: 0.1752 - acc: 0.9100 - val_loss: 0.3858 - val_acc: 0.8400\n",
            "Epoch 3341/4500\n",
            "100/100 [==============================] - 0s 542us/step - loss: 0.1790 - acc: 0.9200 - val_loss: 0.3814 - val_acc: 0.8400\n",
            "Epoch 3342/4500\n",
            "100/100 [==============================] - 0s 481us/step - loss: 0.1725 - acc: 0.9300 - val_loss: 0.3963 - val_acc: 0.8100\n",
            "Epoch 3343/4500\n",
            "100/100 [==============================] - 0s 508us/step - loss: 0.1771 - acc: 0.9100 - val_loss: 0.3878 - val_acc: 0.8400\n",
            "Epoch 3344/4500\n",
            "100/100 [==============================] - 0s 496us/step - loss: 0.1724 - acc: 0.9300 - val_loss: 0.3765 - val_acc: 0.8400\n",
            "Epoch 3345/4500\n",
            "100/100 [==============================] - 0s 506us/step - loss: 0.1729 - acc: 0.9200 - val_loss: 0.3833 - val_acc: 0.8400\n",
            "Epoch 3346/4500\n",
            "100/100 [==============================] - 0s 597us/step - loss: 0.1719 - acc: 0.9300 - val_loss: 0.3727 - val_acc: 0.8400\n",
            "Epoch 3347/4500\n",
            "100/100 [==============================] - 0s 535us/step - loss: 0.1729 - acc: 0.9200 - val_loss: 0.3851 - val_acc: 0.8400\n",
            "Epoch 3348/4500\n",
            "100/100 [==============================] - 0s 524us/step - loss: 0.1775 - acc: 0.9200 - val_loss: 0.3781 - val_acc: 0.8400\n",
            "Epoch 3349/4500\n",
            "100/100 [==============================] - 0s 494us/step - loss: 0.1855 - acc: 0.9200 - val_loss: 0.3853 - val_acc: 0.8400\n",
            "Epoch 3350/4500\n",
            "100/100 [==============================] - 0s 516us/step - loss: 0.1944 - acc: 0.9100 - val_loss: 0.3837 - val_acc: 0.8400\n",
            "Epoch 3351/4500\n",
            "100/100 [==============================] - 0s 507us/step - loss: 0.1880 - acc: 0.9100 - val_loss: 0.3873 - val_acc: 0.8300\n",
            "Epoch 3352/4500\n",
            "100/100 [==============================] - 0s 506us/step - loss: 0.1787 - acc: 0.9100 - val_loss: 0.3876 - val_acc: 0.8300\n",
            "Epoch 3353/4500\n",
            "100/100 [==============================] - 0s 499us/step - loss: 0.1726 - acc: 0.9300 - val_loss: 0.3812 - val_acc: 0.8400\n",
            "Epoch 3354/4500\n",
            "100/100 [==============================] - 0s 492us/step - loss: 0.1711 - acc: 0.9100 - val_loss: 0.3783 - val_acc: 0.8400\n",
            "Epoch 3355/4500\n",
            "100/100 [==============================] - 0s 603us/step - loss: 0.1721 - acc: 0.9200 - val_loss: 0.3861 - val_acc: 0.8300\n",
            "Epoch 3356/4500\n",
            "100/100 [==============================] - 0s 492us/step - loss: 0.1751 - acc: 0.9200 - val_loss: 0.3839 - val_acc: 0.8400\n",
            "Epoch 3357/4500\n",
            "100/100 [==============================] - 0s 496us/step - loss: 0.1753 - acc: 0.9100 - val_loss: 0.3968 - val_acc: 0.8000\n",
            "Epoch 3358/4500\n",
            "100/100 [==============================] - 0s 492us/step - loss: 0.1739 - acc: 0.9200 - val_loss: 0.3819 - val_acc: 0.8400\n",
            "Epoch 3359/4500\n",
            "100/100 [==============================] - 0s 488us/step - loss: 0.1742 - acc: 0.9200 - val_loss: 0.3748 - val_acc: 0.8400\n",
            "Epoch 3360/4500\n",
            "100/100 [==============================] - 0s 547us/step - loss: 0.1717 - acc: 0.9100 - val_loss: 0.3860 - val_acc: 0.8100\n",
            "Epoch 3361/4500\n",
            "100/100 [==============================] - 0s 496us/step - loss: 0.1670 - acc: 0.9200 - val_loss: 0.3724 - val_acc: 0.8400\n",
            "Epoch 3362/4500\n",
            "100/100 [==============================] - 0s 516us/step - loss: 0.1722 - acc: 0.9200 - val_loss: 0.3777 - val_acc: 0.8400\n",
            "Epoch 3363/4500\n",
            "100/100 [==============================] - 0s 520us/step - loss: 0.1714 - acc: 0.9100 - val_loss: 0.3883 - val_acc: 0.8300\n",
            "Epoch 3364/4500\n",
            "100/100 [==============================] - 0s 563us/step - loss: 0.1749 - acc: 0.9100 - val_loss: 0.3734 - val_acc: 0.8400\n",
            "Epoch 3365/4500\n",
            "100/100 [==============================] - 0s 557us/step - loss: 0.1677 - acc: 0.9100 - val_loss: 0.3876 - val_acc: 0.8200\n",
            "Epoch 3366/4500\n",
            "100/100 [==============================] - 0s 524us/step - loss: 0.1726 - acc: 0.9100 - val_loss: 0.3818 - val_acc: 0.8400\n",
            "Epoch 3367/4500\n",
            "100/100 [==============================] - 0s 481us/step - loss: 0.1745 - acc: 0.9200 - val_loss: 0.3705 - val_acc: 0.8400\n",
            "Epoch 3368/4500\n",
            "100/100 [==============================] - 0s 494us/step - loss: 0.1664 - acc: 0.9100 - val_loss: 0.3924 - val_acc: 0.8100\n",
            "Epoch 3369/4500\n",
            "100/100 [==============================] - 0s 505us/step - loss: 0.1684 - acc: 0.9200 - val_loss: 0.3756 - val_acc: 0.8400\n",
            "Epoch 3370/4500\n",
            "100/100 [==============================] - 0s 604us/step - loss: 0.1682 - acc: 0.9300 - val_loss: 0.3688 - val_acc: 0.8400\n",
            "Epoch 3371/4500\n",
            "100/100 [==============================] - 0s 485us/step - loss: 0.1690 - acc: 0.9200 - val_loss: 0.3766 - val_acc: 0.8300\n",
            "Epoch 3372/4500\n",
            "100/100 [==============================] - 0s 528us/step - loss: 0.1663 - acc: 0.9200 - val_loss: 0.3753 - val_acc: 0.8400\n",
            "Epoch 3373/4500\n",
            "100/100 [==============================] - 0s 510us/step - loss: 0.1742 - acc: 0.9300 - val_loss: 0.3783 - val_acc: 0.8400\n",
            "Epoch 3374/4500\n",
            "100/100 [==============================] - 0s 572us/step - loss: 0.1717 - acc: 0.9100 - val_loss: 0.3869 - val_acc: 0.8200\n",
            "Epoch 3375/4500\n",
            "100/100 [==============================] - 0s 484us/step - loss: 0.1688 - acc: 0.9200 - val_loss: 0.3692 - val_acc: 0.8400\n",
            "Epoch 3376/4500\n",
            "100/100 [==============================] - 0s 493us/step - loss: 0.1678 - acc: 0.9300 - val_loss: 0.3853 - val_acc: 0.8400\n",
            "Epoch 3377/4500\n",
            "100/100 [==============================] - 0s 484us/step - loss: 0.1701 - acc: 0.9200 - val_loss: 0.3825 - val_acc: 0.8400\n",
            "Epoch 3378/4500\n",
            "100/100 [==============================] - 0s 477us/step - loss: 0.1677 - acc: 0.9200 - val_loss: 0.3810 - val_acc: 0.8400\n",
            "Epoch 3379/4500\n",
            "100/100 [==============================] - 0s 505us/step - loss: 0.1669 - acc: 0.9100 - val_loss: 0.3750 - val_acc: 0.8400\n",
            "Epoch 3380/4500\n",
            "100/100 [==============================] - 0s 617us/step - loss: 0.1666 - acc: 0.9200 - val_loss: 0.3765 - val_acc: 0.8400\n",
            "Epoch 3381/4500\n",
            "100/100 [==============================] - 0s 523us/step - loss: 0.1656 - acc: 0.9200 - val_loss: 0.3807 - val_acc: 0.8400\n",
            "Epoch 3382/4500\n",
            "100/100 [==============================] - 0s 503us/step - loss: 0.1674 - acc: 0.9200 - val_loss: 0.3876 - val_acc: 0.8200\n",
            "Epoch 3383/4500\n",
            "100/100 [==============================] - 0s 499us/step - loss: 0.1663 - acc: 0.9100 - val_loss: 0.3783 - val_acc: 0.8400\n",
            "Epoch 3384/4500\n",
            "100/100 [==============================] - 0s 510us/step - loss: 0.1679 - acc: 0.9200 - val_loss: 0.3819 - val_acc: 0.8200\n",
            "Epoch 3385/4500\n",
            "100/100 [==============================] - 0s 486us/step - loss: 0.1646 - acc: 0.9300 - val_loss: 0.3796 - val_acc: 0.8300\n",
            "Epoch 3386/4500\n",
            "100/100 [==============================] - 0s 488us/step - loss: 0.1639 - acc: 0.9200 - val_loss: 0.3769 - val_acc: 0.8400\n",
            "Epoch 3387/4500\n",
            "100/100 [==============================] - 0s 515us/step - loss: 0.1687 - acc: 0.9200 - val_loss: 0.3872 - val_acc: 0.8200\n",
            "Epoch 3388/4500\n",
            "100/100 [==============================] - 0s 496us/step - loss: 0.1700 - acc: 0.9200 - val_loss: 0.3792 - val_acc: 0.8300\n",
            "Epoch 3389/4500\n",
            "100/100 [==============================] - 0s 498us/step - loss: 0.1737 - acc: 0.9200 - val_loss: 0.3931 - val_acc: 0.8100\n",
            "Epoch 3390/4500\n",
            "100/100 [==============================] - 0s 546us/step - loss: 0.1662 - acc: 0.9200 - val_loss: 0.3648 - val_acc: 0.8400\n",
            "Epoch 3391/4500\n",
            "100/100 [==============================] - 0s 534us/step - loss: 0.1768 - acc: 0.9100 - val_loss: 0.3724 - val_acc: 0.8400\n",
            "Epoch 3392/4500\n",
            "100/100 [==============================] - 0s 527us/step - loss: 0.1721 - acc: 0.9300 - val_loss: 0.3893 - val_acc: 0.8100\n",
            "Epoch 3393/4500\n",
            "100/100 [==============================] - 0s 586us/step - loss: 0.1689 - acc: 0.9300 - val_loss: 0.3778 - val_acc: 0.8400\n",
            "Epoch 3394/4500\n",
            "100/100 [==============================] - 0s 526us/step - loss: 0.1697 - acc: 0.9300 - val_loss: 0.3878 - val_acc: 0.8400\n",
            "Epoch 3395/4500\n",
            "100/100 [==============================] - 0s 535us/step - loss: 0.1748 - acc: 0.9200 - val_loss: 0.4025 - val_acc: 0.8100\n",
            "Epoch 3396/4500\n",
            "100/100 [==============================] - 0s 496us/step - loss: 0.1794 - acc: 0.9200 - val_loss: 0.3742 - val_acc: 0.8600\n",
            "Epoch 3397/4500\n",
            "100/100 [==============================] - 0s 535us/step - loss: 0.1917 - acc: 0.9200 - val_loss: 0.3994 - val_acc: 0.7900\n",
            "Epoch 3398/4500\n",
            "100/100 [==============================] - 0s 532us/step - loss: 0.1750 - acc: 0.9200 - val_loss: 0.3680 - val_acc: 0.8400\n",
            "Epoch 3399/4500\n",
            "100/100 [==============================] - 0s 527us/step - loss: 0.1655 - acc: 0.9300 - val_loss: 0.3768 - val_acc: 0.8700\n",
            "Epoch 3400/4500\n",
            "100/100 [==============================] - 0s 526us/step - loss: 0.1696 - acc: 0.9200 - val_loss: 0.4068 - val_acc: 0.8000\n",
            "Epoch 3401/4500\n",
            "100/100 [==============================] - 0s 551us/step - loss: 0.1767 - acc: 0.9200 - val_loss: 0.4099 - val_acc: 0.8200\n",
            "Epoch 3402/4500\n",
            "100/100 [==============================] - 0s 503us/step - loss: 0.1748 - acc: 0.9100 - val_loss: 0.4107 - val_acc: 0.8100\n",
            "Epoch 3403/4500\n",
            "100/100 [==============================] - 0s 489us/step - loss: 0.1794 - acc: 0.9200 - val_loss: 0.3981 - val_acc: 0.8100\n",
            "Epoch 3404/4500\n",
            "100/100 [==============================] - 0s 498us/step - loss: 0.1779 - acc: 0.9200 - val_loss: 0.3796 - val_acc: 0.8400\n",
            "Epoch 3405/4500\n",
            "100/100 [==============================] - 0s 562us/step - loss: 0.1708 - acc: 0.9200 - val_loss: 0.3912 - val_acc: 0.8400\n",
            "Epoch 3406/4500\n",
            "100/100 [==============================] - 0s 526us/step - loss: 0.1655 - acc: 0.9300 - val_loss: 0.3936 - val_acc: 0.8300\n",
            "Epoch 3407/4500\n",
            "100/100 [==============================] - 0s 498us/step - loss: 0.1635 - acc: 0.9300 - val_loss: 0.4092 - val_acc: 0.8100\n",
            "Epoch 3408/4500\n",
            "100/100 [==============================] - 0s 510us/step - loss: 0.1693 - acc: 0.9200 - val_loss: 0.3935 - val_acc: 0.8300\n",
            "Epoch 3409/4500\n",
            "100/100 [==============================] - 0s 486us/step - loss: 0.1622 - acc: 0.9300 - val_loss: 0.3942 - val_acc: 0.8300\n",
            "Epoch 3410/4500\n",
            "100/100 [==============================] - 0s 557us/step - loss: 0.1624 - acc: 0.9200 - val_loss: 0.3881 - val_acc: 0.8400\n",
            "Epoch 3411/4500\n",
            "100/100 [==============================] - 0s 578us/step - loss: 0.1657 - acc: 0.9300 - val_loss: 0.3974 - val_acc: 0.8200\n",
            "Epoch 3412/4500\n",
            "100/100 [==============================] - 0s 621us/step - loss: 0.1667 - acc: 0.9200 - val_loss: 0.4026 - val_acc: 0.8200\n",
            "Epoch 3413/4500\n",
            "100/100 [==============================] - 0s 550us/step - loss: 0.1614 - acc: 0.9400 - val_loss: 0.3772 - val_acc: 0.8400\n",
            "Epoch 3414/4500\n",
            "100/100 [==============================] - 0s 511us/step - loss: 0.1616 - acc: 0.9200 - val_loss: 0.3942 - val_acc: 0.8200\n",
            "Epoch 3415/4500\n",
            "100/100 [==============================] - 0s 500us/step - loss: 0.1597 - acc: 0.9300 - val_loss: 0.4007 - val_acc: 0.8100\n",
            "Epoch 3416/4500\n",
            "100/100 [==============================] - 0s 490us/step - loss: 0.1633 - acc: 0.9300 - val_loss: 0.3796 - val_acc: 0.8400\n",
            "Epoch 3417/4500\n",
            "100/100 [==============================] - 0s 530us/step - loss: 0.1617 - acc: 0.9400 - val_loss: 0.3749 - val_acc: 0.8300\n",
            "Epoch 3418/4500\n",
            "100/100 [==============================] - 0s 541us/step - loss: 0.1613 - acc: 0.9200 - val_loss: 0.3729 - val_acc: 0.8500\n",
            "Epoch 3419/4500\n",
            "100/100 [==============================] - 0s 555us/step - loss: 0.1639 - acc: 0.9300 - val_loss: 0.3828 - val_acc: 0.8400\n",
            "Epoch 3420/4500\n",
            "100/100 [==============================] - 0s 593us/step - loss: 0.1643 - acc: 0.9100 - val_loss: 0.3887 - val_acc: 0.8400\n",
            "Epoch 3421/4500\n",
            "100/100 [==============================] - 0s 536us/step - loss: 0.1628 - acc: 0.9100 - val_loss: 0.3924 - val_acc: 0.8200\n",
            "Epoch 3422/4500\n",
            "100/100 [==============================] - 0s 517us/step - loss: 0.1628 - acc: 0.9300 - val_loss: 0.3894 - val_acc: 0.8300\n",
            "Epoch 3423/4500\n",
            "100/100 [==============================] - 0s 557us/step - loss: 0.1633 - acc: 0.9100 - val_loss: 0.3870 - val_acc: 0.8300\n",
            "Epoch 3424/4500\n",
            "100/100 [==============================] - 0s 505us/step - loss: 0.1599 - acc: 0.9200 - val_loss: 0.3904 - val_acc: 0.8200\n",
            "Epoch 3425/4500\n",
            "100/100 [==============================] - 0s 504us/step - loss: 0.1629 - acc: 0.9300 - val_loss: 0.3823 - val_acc: 0.8400\n",
            "Epoch 3426/4500\n",
            "100/100 [==============================] - 0s 491us/step - loss: 0.1722 - acc: 0.9200 - val_loss: 0.3772 - val_acc: 0.8400\n",
            "Epoch 3427/4500\n",
            "100/100 [==============================] - 0s 485us/step - loss: 0.1716 - acc: 0.9100 - val_loss: 0.4034 - val_acc: 0.8200\n",
            "Epoch 3428/4500\n",
            "100/100 [==============================] - 0s 488us/step - loss: 0.1767 - acc: 0.9100 - val_loss: 0.3742 - val_acc: 0.8300\n",
            "Epoch 3429/4500\n",
            "100/100 [==============================] - 0s 585us/step - loss: 0.1583 - acc: 0.9300 - val_loss: 0.3724 - val_acc: 0.8400\n",
            "Epoch 3430/4500\n",
            "100/100 [==============================] - 0s 526us/step - loss: 0.1618 - acc: 0.9200 - val_loss: 0.3996 - val_acc: 0.8200\n",
            "Epoch 3431/4500\n",
            "100/100 [==============================] - 0s 607us/step - loss: 0.1585 - acc: 0.9200 - val_loss: 0.3985 - val_acc: 0.8200\n",
            "Epoch 3432/4500\n",
            "100/100 [==============================] - 0s 582us/step - loss: 0.1596 - acc: 0.9200 - val_loss: 0.3685 - val_acc: 0.8400\n",
            "Epoch 3433/4500\n",
            "100/100 [==============================] - 0s 565us/step - loss: 0.1623 - acc: 0.9400 - val_loss: 0.3818 - val_acc: 0.8300\n",
            "Epoch 3434/4500\n",
            "100/100 [==============================] - 0s 498us/step - loss: 0.1626 - acc: 0.9200 - val_loss: 0.3921 - val_acc: 0.8200\n",
            "Epoch 3435/4500\n",
            "100/100 [==============================] - 0s 494us/step - loss: 0.1606 - acc: 0.9200 - val_loss: 0.3884 - val_acc: 0.8200\n",
            "Epoch 3436/4500\n",
            "100/100 [==============================] - 0s 500us/step - loss: 0.1689 - acc: 0.9200 - val_loss: 0.3789 - val_acc: 0.8300\n",
            "Epoch 3437/4500\n",
            "100/100 [==============================] - 0s 497us/step - loss: 0.1599 - acc: 0.9500 - val_loss: 0.3738 - val_acc: 0.8400\n",
            "Epoch 3438/4500\n",
            "100/100 [==============================] - 0s 526us/step - loss: 0.1668 - acc: 0.9100 - val_loss: 0.3849 - val_acc: 0.8200\n",
            "Epoch 3439/4500\n",
            "100/100 [==============================] - 0s 543us/step - loss: 0.1528 - acc: 0.9300 - val_loss: 0.3713 - val_acc: 0.8400\n",
            "Epoch 3440/4500\n",
            "100/100 [==============================] - 0s 542us/step - loss: 0.1576 - acc: 0.9300 - val_loss: 0.3757 - val_acc: 0.8400\n",
            "Epoch 3441/4500\n",
            "100/100 [==============================] - 0s 545us/step - loss: 0.1588 - acc: 0.9300 - val_loss: 0.3883 - val_acc: 0.8300\n",
            "Epoch 3442/4500\n",
            "100/100 [==============================] - 0s 508us/step - loss: 0.1612 - acc: 0.9300 - val_loss: 0.4025 - val_acc: 0.7900\n",
            "Epoch 3443/4500\n",
            "100/100 [==============================] - 0s 475us/step - loss: 0.1556 - acc: 0.9300 - val_loss: 0.3703 - val_acc: 0.8400\n",
            "Epoch 3444/4500\n",
            "100/100 [==============================] - 0s 499us/step - loss: 0.1590 - acc: 0.9300 - val_loss: 0.3747 - val_acc: 0.8400\n",
            "Epoch 3445/4500\n",
            "100/100 [==============================] - 0s 493us/step - loss: 0.1579 - acc: 0.9300 - val_loss: 0.3908 - val_acc: 0.8200\n",
            "Epoch 3446/4500\n",
            "100/100 [==============================] - 0s 497us/step - loss: 0.1571 - acc: 0.9300 - val_loss: 0.3788 - val_acc: 0.8400\n",
            "Epoch 3447/4500\n",
            "100/100 [==============================] - 0s 492us/step - loss: 0.1553 - acc: 0.9300 - val_loss: 0.3842 - val_acc: 0.8200\n",
            "Epoch 3448/4500\n",
            "100/100 [==============================] - 0s 527us/step - loss: 0.1562 - acc: 0.9400 - val_loss: 0.3894 - val_acc: 0.8200\n",
            "Epoch 3449/4500\n",
            "100/100 [==============================] - 0s 585us/step - loss: 0.1550 - acc: 0.9400 - val_loss: 0.3804 - val_acc: 0.8400\n",
            "Epoch 3450/4500\n",
            "100/100 [==============================] - 0s 645us/step - loss: 0.1542 - acc: 0.9400 - val_loss: 0.3830 - val_acc: 0.8300\n",
            "Epoch 3451/4500\n",
            "100/100 [==============================] - 0s 528us/step - loss: 0.1529 - acc: 0.9300 - val_loss: 0.3866 - val_acc: 0.8200\n",
            "Epoch 3452/4500\n",
            "100/100 [==============================] - 0s 496us/step - loss: 0.1557 - acc: 0.9400 - val_loss: 0.3767 - val_acc: 0.8400\n",
            "Epoch 3453/4500\n",
            "100/100 [==============================] - 0s 499us/step - loss: 0.1551 - acc: 0.9300 - val_loss: 0.3747 - val_acc: 0.8400\n",
            "Epoch 3454/4500\n",
            "100/100 [==============================] - 0s 542us/step - loss: 0.1614 - acc: 0.9200 - val_loss: 0.3892 - val_acc: 0.8200\n",
            "Epoch 3455/4500\n",
            "100/100 [==============================] - 0s 511us/step - loss: 0.1602 - acc: 0.9200 - val_loss: 0.3885 - val_acc: 0.8400\n",
            "Epoch 3456/4500\n",
            "100/100 [==============================] - 0s 526us/step - loss: 0.1655 - acc: 0.9200 - val_loss: 0.3774 - val_acc: 0.8300\n",
            "Epoch 3457/4500\n",
            "100/100 [==============================] - 0s 511us/step - loss: 0.1571 - acc: 0.9300 - val_loss: 0.3695 - val_acc: 0.8400\n",
            "Epoch 3458/4500\n",
            "100/100 [==============================] - 0s 496us/step - loss: 0.1557 - acc: 0.9400 - val_loss: 0.3877 - val_acc: 0.8200\n",
            "Epoch 3459/4500\n",
            "100/100 [==============================] - 0s 530us/step - loss: 0.1560 - acc: 0.9200 - val_loss: 0.3773 - val_acc: 0.8400\n",
            "Epoch 3460/4500\n",
            "100/100 [==============================] - 0s 515us/step - loss: 0.1510 - acc: 0.9200 - val_loss: 0.3891 - val_acc: 0.8200\n",
            "Epoch 3461/4500\n",
            "100/100 [==============================] - 0s 501us/step - loss: 0.1535 - acc: 0.9400 - val_loss: 0.3790 - val_acc: 0.8300\n",
            "Epoch 3462/4500\n",
            "100/100 [==============================] - 0s 504us/step - loss: 0.1586 - acc: 0.9300 - val_loss: 0.3830 - val_acc: 0.8300\n",
            "Epoch 3463/4500\n",
            "100/100 [==============================] - 0s 495us/step - loss: 0.1532 - acc: 0.9300 - val_loss: 0.3793 - val_acc: 0.8300\n",
            "Epoch 3464/4500\n",
            "100/100 [==============================] - 0s 501us/step - loss: 0.1558 - acc: 0.9400 - val_loss: 0.3831 - val_acc: 0.8300\n",
            "Epoch 3465/4500\n",
            "100/100 [==============================] - 0s 538us/step - loss: 0.1563 - acc: 0.9200 - val_loss: 0.3809 - val_acc: 0.8400\n",
            "Epoch 3466/4500\n",
            "100/100 [==============================] - 0s 553us/step - loss: 0.1582 - acc: 0.9300 - val_loss: 0.3818 - val_acc: 0.8300\n",
            "Epoch 3467/4500\n",
            "100/100 [==============================] - 0s 520us/step - loss: 0.1622 - acc: 0.9400 - val_loss: 0.3797 - val_acc: 0.8300\n",
            "Epoch 3468/4500\n",
            "100/100 [==============================] - 0s 498us/step - loss: 0.1572 - acc: 0.9400 - val_loss: 0.3690 - val_acc: 0.8600\n",
            "Epoch 3469/4500\n",
            "100/100 [==============================] - 0s 609us/step - loss: 0.1576 - acc: 0.9300 - val_loss: 0.3737 - val_acc: 0.8400\n",
            "Epoch 3470/4500\n",
            "100/100 [==============================] - 0s 501us/step - loss: 0.1556 - acc: 0.9300 - val_loss: 0.3862 - val_acc: 0.8200\n",
            "Epoch 3471/4500\n",
            "100/100 [==============================] - 0s 505us/step - loss: 0.1548 - acc: 0.9400 - val_loss: 0.3728 - val_acc: 0.8400\n",
            "Epoch 3472/4500\n",
            "100/100 [==============================] - 0s 549us/step - loss: 0.1512 - acc: 0.9300 - val_loss: 0.3988 - val_acc: 0.8100\n",
            "Epoch 3473/4500\n",
            "100/100 [==============================] - 0s 507us/step - loss: 0.1509 - acc: 0.9400 - val_loss: 0.3821 - val_acc: 0.8300\n",
            "Epoch 3474/4500\n",
            "100/100 [==============================] - 0s 509us/step - loss: 0.1499 - acc: 0.9300 - val_loss: 0.3825 - val_acc: 0.8400\n",
            "Epoch 3475/4500\n",
            "100/100 [==============================] - 0s 502us/step - loss: 0.1502 - acc: 0.9200 - val_loss: 0.3854 - val_acc: 0.8200\n",
            "Epoch 3476/4500\n",
            "100/100 [==============================] - 0s 515us/step - loss: 0.1556 - acc: 0.9300 - val_loss: 0.3816 - val_acc: 0.8400\n",
            "Epoch 3477/4500\n",
            "100/100 [==============================] - 0s 524us/step - loss: 0.1487 - acc: 0.9300 - val_loss: 0.3919 - val_acc: 0.8100\n",
            "Epoch 3478/4500\n",
            "100/100 [==============================] - 0s 530us/step - loss: 0.1587 - acc: 0.9300 - val_loss: 0.3810 - val_acc: 0.8300\n",
            "Epoch 3479/4500\n",
            "100/100 [==============================] - 0s 582us/step - loss: 0.1797 - acc: 0.9200 - val_loss: 0.3707 - val_acc: 0.8300\n",
            "Epoch 3480/4500\n",
            "100/100 [==============================] - 0s 532us/step - loss: 0.1667 - acc: 0.9000 - val_loss: 0.3900 - val_acc: 0.8200\n",
            "Epoch 3481/4500\n",
            "100/100 [==============================] - 0s 517us/step - loss: 0.1711 - acc: 0.9200 - val_loss: 0.4008 - val_acc: 0.8000\n",
            "Epoch 3482/4500\n",
            "100/100 [==============================] - 0s 499us/step - loss: 0.1584 - acc: 0.9200 - val_loss: 0.3716 - val_acc: 0.8800\n",
            "Epoch 3483/4500\n",
            "100/100 [==============================] - 0s 523us/step - loss: 0.1658 - acc: 0.9300 - val_loss: 0.3860 - val_acc: 0.8300\n",
            "Epoch 3484/4500\n",
            "100/100 [==============================] - 0s 533us/step - loss: 0.1633 - acc: 0.9400 - val_loss: 0.3827 - val_acc: 0.8300\n",
            "Epoch 3485/4500\n",
            "100/100 [==============================] - 0s 514us/step - loss: 0.1510 - acc: 0.9500 - val_loss: 0.3781 - val_acc: 0.8400\n",
            "Epoch 3486/4500\n",
            "100/100 [==============================] - 0s 645us/step - loss: 0.1516 - acc: 0.9400 - val_loss: 0.3963 - val_acc: 0.8200\n",
            "Epoch 3487/4500\n",
            "100/100 [==============================] - 0s 578us/step - loss: 0.1608 - acc: 0.9200 - val_loss: 0.4156 - val_acc: 0.8100\n",
            "Epoch 3488/4500\n",
            "100/100 [==============================] - 0s 644us/step - loss: 0.1546 - acc: 0.9300 - val_loss: 0.4035 - val_acc: 0.8000\n",
            "Epoch 3489/4500\n",
            "100/100 [==============================] - 0s 555us/step - loss: 0.1566 - acc: 0.9300 - val_loss: 0.3946 - val_acc: 0.8200\n",
            "Epoch 3490/4500\n",
            "100/100 [==============================] - 0s 520us/step - loss: 0.1523 - acc: 0.9300 - val_loss: 0.3793 - val_acc: 0.8400\n",
            "Epoch 3491/4500\n",
            "100/100 [==============================] - 0s 503us/step - loss: 0.1500 - acc: 0.9400 - val_loss: 0.3929 - val_acc: 0.8400\n",
            "Epoch 3492/4500\n",
            "100/100 [==============================] - 0s 563us/step - loss: 0.1554 - acc: 0.9400 - val_loss: 0.3895 - val_acc: 0.8400\n",
            "Epoch 3493/4500\n",
            "100/100 [==============================] - 0s 553us/step - loss: 0.1586 - acc: 0.9100 - val_loss: 0.4099 - val_acc: 0.8000\n",
            "Epoch 3494/4500\n",
            "100/100 [==============================] - 0s 584us/step - loss: 0.1629 - acc: 0.9200 - val_loss: 0.3888 - val_acc: 0.8400\n",
            "Epoch 3495/4500\n",
            "100/100 [==============================] - 0s 507us/step - loss: 0.1592 - acc: 0.9200 - val_loss: 0.4031 - val_acc: 0.8200\n",
            "Epoch 3496/4500\n",
            "100/100 [==============================] - 0s 520us/step - loss: 0.1585 - acc: 0.9300 - val_loss: 0.4286 - val_acc: 0.7900\n",
            "Epoch 3497/4500\n",
            "100/100 [==============================] - 0s 514us/step - loss: 0.1638 - acc: 0.9300 - val_loss: 0.3778 - val_acc: 0.8500\n",
            "Epoch 3498/4500\n",
            "100/100 [==============================] - 0s 540us/step - loss: 0.1588 - acc: 0.9400 - val_loss: 0.3906 - val_acc: 0.8400\n",
            "Epoch 3499/4500\n",
            "100/100 [==============================] - 0s 516us/step - loss: 0.1504 - acc: 0.9400 - val_loss: 0.4014 - val_acc: 0.8300\n",
            "Epoch 3500/4500\n",
            "100/100 [==============================] - 0s 558us/step - loss: 0.1493 - acc: 0.9400 - val_loss: 0.3909 - val_acc: 0.8200\n",
            "Epoch 3501/4500\n",
            "100/100 [==============================] - 0s 502us/step - loss: 0.1516 - acc: 0.9400 - val_loss: 0.3797 - val_acc: 0.8300\n",
            "Epoch 3502/4500\n",
            "100/100 [==============================] - 0s 504us/step - loss: 0.1492 - acc: 0.9300 - val_loss: 0.4004 - val_acc: 0.8100\n",
            "Epoch 3503/4500\n",
            "100/100 [==============================] - 0s 509us/step - loss: 0.1610 - acc: 0.9300 - val_loss: 0.3848 - val_acc: 0.8300\n",
            "Epoch 3504/4500\n",
            "100/100 [==============================] - 0s 506us/step - loss: 0.1488 - acc: 0.9400 - val_loss: 0.3792 - val_acc: 0.8300\n",
            "Epoch 3505/4500\n",
            "100/100 [==============================] - 0s 501us/step - loss: 0.1491 - acc: 0.9400 - val_loss: 0.3934 - val_acc: 0.8300\n",
            "Epoch 3506/4500\n",
            "100/100 [==============================] - 0s 500us/step - loss: 0.1474 - acc: 0.9200 - val_loss: 0.3867 - val_acc: 0.8300\n",
            "Epoch 3507/4500\n",
            "100/100 [==============================] - 0s 588us/step - loss: 0.1466 - acc: 0.9400 - val_loss: 0.3861 - val_acc: 0.8300\n",
            "Epoch 3508/4500\n",
            "100/100 [==============================] - 0s 608us/step - loss: 0.1519 - acc: 0.9300 - val_loss: 0.3819 - val_acc: 0.8400\n",
            "Epoch 3509/4500\n",
            "100/100 [==============================] - 0s 554us/step - loss: 0.1471 - acc: 0.9400 - val_loss: 0.3869 - val_acc: 0.8200\n",
            "Epoch 3510/4500\n",
            "100/100 [==============================] - 0s 532us/step - loss: 0.1568 - acc: 0.9400 - val_loss: 0.3870 - val_acc: 0.8200\n",
            "Epoch 3511/4500\n",
            "100/100 [==============================] - 0s 502us/step - loss: 0.1496 - acc: 0.9200 - val_loss: 0.3618 - val_acc: 0.8900\n",
            "Epoch 3512/4500\n",
            "100/100 [==============================] - 0s 507us/step - loss: 0.1523 - acc: 0.9500 - val_loss: 0.3934 - val_acc: 0.8200\n",
            "Epoch 3513/4500\n",
            "100/100 [==============================] - 0s 494us/step - loss: 0.1460 - acc: 0.9400 - val_loss: 0.3840 - val_acc: 0.8400\n",
            "Epoch 3514/4500\n",
            "100/100 [==============================] - 0s 505us/step - loss: 0.1484 - acc: 0.9300 - val_loss: 0.3875 - val_acc: 0.8200\n",
            "Epoch 3515/4500\n",
            "100/100 [==============================] - 0s 507us/step - loss: 0.1551 - acc: 0.9100 - val_loss: 0.3921 - val_acc: 0.8300\n",
            "Epoch 3516/4500\n",
            "100/100 [==============================] - 0s 518us/step - loss: 0.1463 - acc: 0.9300 - val_loss: 0.3868 - val_acc: 0.8200\n",
            "Epoch 3517/4500\n",
            "100/100 [==============================] - 0s 510us/step - loss: 0.1486 - acc: 0.9400 - val_loss: 0.3783 - val_acc: 0.8400\n",
            "Epoch 3518/4500\n",
            "100/100 [==============================] - 0s 542us/step - loss: 0.1492 - acc: 0.9300 - val_loss: 0.3803 - val_acc: 0.8200\n",
            "Epoch 3519/4500\n",
            "100/100 [==============================] - 0s 497us/step - loss: 0.1447 - acc: 0.9400 - val_loss: 0.3961 - val_acc: 0.8100\n",
            "Epoch 3520/4500\n",
            "100/100 [==============================] - 0s 487us/step - loss: 0.1417 - acc: 0.9500 - val_loss: 0.3743 - val_acc: 0.8400\n",
            "Epoch 3521/4500\n",
            "100/100 [==============================] - 0s 561us/step - loss: 0.1463 - acc: 0.9400 - val_loss: 0.3755 - val_acc: 0.8300\n",
            "Epoch 3522/4500\n",
            "100/100 [==============================] - 0s 517us/step - loss: 0.1445 - acc: 0.9400 - val_loss: 0.3744 - val_acc: 0.8600\n",
            "Epoch 3523/4500\n",
            "100/100 [==============================] - 0s 500us/step - loss: 0.1488 - acc: 0.9400 - val_loss: 0.4010 - val_acc: 0.8200\n",
            "Epoch 3524/4500\n",
            "100/100 [==============================] - 0s 525us/step - loss: 0.1454 - acc: 0.9400 - val_loss: 0.3989 - val_acc: 0.8100\n",
            "Epoch 3525/4500\n",
            "100/100 [==============================] - 0s 514us/step - loss: 0.1463 - acc: 0.9300 - val_loss: 0.3855 - val_acc: 0.8300\n",
            "Epoch 3526/4500\n",
            "100/100 [==============================] - 0s 587us/step - loss: 0.1454 - acc: 0.9300 - val_loss: 0.3778 - val_acc: 0.8400\n",
            "Epoch 3527/4500\n",
            "100/100 [==============================] - 0s 504us/step - loss: 0.1449 - acc: 0.9300 - val_loss: 0.3871 - val_acc: 0.8200\n",
            "Epoch 3528/4500\n",
            "100/100 [==============================] - 0s 546us/step - loss: 0.1447 - acc: 0.9200 - val_loss: 0.3835 - val_acc: 0.8400\n",
            "Epoch 3529/4500\n",
            "100/100 [==============================] - 0s 574us/step - loss: 0.1427 - acc: 0.9300 - val_loss: 0.3872 - val_acc: 0.8200\n",
            "Epoch 3530/4500\n",
            "100/100 [==============================] - 0s 544us/step - loss: 0.1433 - acc: 0.9400 - val_loss: 0.3879 - val_acc: 0.8200\n",
            "Epoch 3531/4500\n",
            "100/100 [==============================] - 0s 529us/step - loss: 0.1451 - acc: 0.9400 - val_loss: 0.3703 - val_acc: 0.8700\n",
            "Epoch 3532/4500\n",
            "100/100 [==============================] - 0s 498us/step - loss: 0.1485 - acc: 0.9300 - val_loss: 0.3945 - val_acc: 0.8200\n",
            "Epoch 3533/4500\n",
            "100/100 [==============================] - 0s 494us/step - loss: 0.1449 - acc: 0.9300 - val_loss: 0.3939 - val_acc: 0.8200\n",
            "Epoch 3534/4500\n",
            "100/100 [==============================] - 0s 512us/step - loss: 0.1417 - acc: 0.9400 - val_loss: 0.3788 - val_acc: 0.8300\n",
            "Epoch 3535/4500\n",
            "100/100 [==============================] - 0s 480us/step - loss: 0.1423 - acc: 0.9500 - val_loss: 0.3734 - val_acc: 0.8700\n",
            "Epoch 3536/4500\n",
            "100/100 [==============================] - 0s 482us/step - loss: 0.1403 - acc: 0.9400 - val_loss: 0.3948 - val_acc: 0.8200\n",
            "Epoch 3537/4500\n",
            "100/100 [==============================] - 0s 528us/step - loss: 0.1445 - acc: 0.9400 - val_loss: 0.3877 - val_acc: 0.8600\n",
            "Epoch 3538/4500\n",
            "100/100 [==============================] - 0s 579us/step - loss: 0.1414 - acc: 0.9300 - val_loss: 0.3843 - val_acc: 0.8300\n",
            "Epoch 3539/4500\n",
            "100/100 [==============================] - 0s 496us/step - loss: 0.1402 - acc: 0.9500 - val_loss: 0.3796 - val_acc: 0.8300\n",
            "Epoch 3540/4500\n",
            "100/100 [==============================] - 0s 577us/step - loss: 0.1475 - acc: 0.9500 - val_loss: 0.3700 - val_acc: 0.8500\n",
            "Epoch 3541/4500\n",
            "100/100 [==============================] - 0s 495us/step - loss: 0.1430 - acc: 0.9400 - val_loss: 0.3659 - val_acc: 0.8800\n",
            "Epoch 3542/4500\n",
            "100/100 [==============================] - 0s 505us/step - loss: 0.1402 - acc: 0.9500 - val_loss: 0.3886 - val_acc: 0.8200\n",
            "Epoch 3543/4500\n",
            "100/100 [==============================] - 0s 515us/step - loss: 0.1422 - acc: 0.9300 - val_loss: 0.3988 - val_acc: 0.8100\n",
            "Epoch 3544/4500\n",
            "100/100 [==============================] - 0s 511us/step - loss: 0.1485 - acc: 0.9300 - val_loss: 0.3801 - val_acc: 0.8300\n",
            "Epoch 3545/4500\n",
            "100/100 [==============================] - 0s 611us/step - loss: 0.1404 - acc: 0.9400 - val_loss: 0.3926 - val_acc: 0.8200\n",
            "Epoch 3546/4500\n",
            "100/100 [==============================] - 0s 506us/step - loss: 0.1490 - acc: 0.9300 - val_loss: 0.3872 - val_acc: 0.8400\n",
            "Epoch 3547/4500\n",
            "100/100 [==============================] - 0s 509us/step - loss: 0.1393 - acc: 0.9400 - val_loss: 0.3954 - val_acc: 0.8100\n",
            "Epoch 3548/4500\n",
            "100/100 [==============================] - 0s 521us/step - loss: 0.1450 - acc: 0.9200 - val_loss: 0.3770 - val_acc: 0.8600\n",
            "Epoch 3549/4500\n",
            "100/100 [==============================] - 0s 503us/step - loss: 0.1392 - acc: 0.9400 - val_loss: 0.3765 - val_acc: 0.8300\n",
            "Epoch 3550/4500\n",
            "100/100 [==============================] - 0s 477us/step - loss: 0.1444 - acc: 0.9400 - val_loss: 0.3907 - val_acc: 0.8400\n",
            "Epoch 3551/4500\n",
            "100/100 [==============================] - 0s 506us/step - loss: 0.1401 - acc: 0.9400 - val_loss: 0.3839 - val_acc: 0.8400\n",
            "Epoch 3552/4500\n",
            "100/100 [==============================] - 0s 503us/step - loss: 0.1416 - acc: 0.9500 - val_loss: 0.3839 - val_acc: 0.8300\n",
            "Epoch 3553/4500\n",
            "100/100 [==============================] - 0s 510us/step - loss: 0.1424 - acc: 0.9500 - val_loss: 0.3747 - val_acc: 0.8700\n",
            "Epoch 3554/4500\n",
            "100/100 [==============================] - 0s 513us/step - loss: 0.1408 - acc: 0.9500 - val_loss: 0.4090 - val_acc: 0.8100\n",
            "Epoch 3555/4500\n",
            "100/100 [==============================] - 0s 519us/step - loss: 0.1377 - acc: 0.9500 - val_loss: 0.3794 - val_acc: 0.8600\n",
            "Epoch 3556/4500\n",
            "100/100 [==============================] - 0s 492us/step - loss: 0.1408 - acc: 0.9500 - val_loss: 0.3796 - val_acc: 0.8500\n",
            "Epoch 3557/4500\n",
            "100/100 [==============================] - 0s 522us/step - loss: 0.1458 - acc: 0.9300 - val_loss: 0.3922 - val_acc: 0.8200\n",
            "Epoch 3558/4500\n",
            "100/100 [==============================] - 0s 585us/step - loss: 0.1406 - acc: 0.9400 - val_loss: 0.3857 - val_acc: 0.8300\n",
            "Epoch 3559/4500\n",
            "100/100 [==============================] - 0s 499us/step - loss: 0.1370 - acc: 0.9400 - val_loss: 0.3940 - val_acc: 0.8200\n",
            "Epoch 3560/4500\n",
            "100/100 [==============================] - 0s 524us/step - loss: 0.1387 - acc: 0.9500 - val_loss: 0.3901 - val_acc: 0.8200\n",
            "Epoch 3561/4500\n",
            "100/100 [==============================] - 0s 576us/step - loss: 0.1384 - acc: 0.9400 - val_loss: 0.3826 - val_acc: 0.8500\n",
            "Epoch 3562/4500\n",
            "100/100 [==============================] - 0s 557us/step - loss: 0.1391 - acc: 0.9300 - val_loss: 0.3814 - val_acc: 0.8300\n",
            "Epoch 3563/4500\n",
            "100/100 [==============================] - 0s 509us/step - loss: 0.1380 - acc: 0.9500 - val_loss: 0.3794 - val_acc: 0.8600\n",
            "Epoch 3564/4500\n",
            "100/100 [==============================] - 0s 587us/step - loss: 0.1455 - acc: 0.9400 - val_loss: 0.3867 - val_acc: 0.8600\n",
            "Epoch 3565/4500\n",
            "100/100 [==============================] - 0s 476us/step - loss: 0.1412 - acc: 0.9600 - val_loss: 0.3964 - val_acc: 0.8100\n",
            "Epoch 3566/4500\n",
            "100/100 [==============================] - 0s 490us/step - loss: 0.1419 - acc: 0.9400 - val_loss: 0.3727 - val_acc: 0.8600\n",
            "Epoch 3567/4500\n",
            "100/100 [==============================] - 0s 519us/step - loss: 0.1414 - acc: 0.9400 - val_loss: 0.3796 - val_acc: 0.8600\n",
            "Epoch 3568/4500\n",
            "100/100 [==============================] - 0s 503us/step - loss: 0.1413 - acc: 0.9400 - val_loss: 0.3921 - val_acc: 0.8200\n",
            "Epoch 3569/4500\n",
            "100/100 [==============================] - 0s 485us/step - loss: 0.1359 - acc: 0.9400 - val_loss: 0.3982 - val_acc: 0.8100\n",
            "Epoch 3570/4500\n",
            "100/100 [==============================] - 0s 504us/step - loss: 0.1411 - acc: 0.9300 - val_loss: 0.3865 - val_acc: 0.8300\n",
            "Epoch 3571/4500\n",
            "100/100 [==============================] - 0s 513us/step - loss: 0.1377 - acc: 0.9500 - val_loss: 0.3898 - val_acc: 0.8200\n",
            "Epoch 3572/4500\n",
            "100/100 [==============================] - 0s 530us/step - loss: 0.1390 - acc: 0.9300 - val_loss: 0.3750 - val_acc: 0.8500\n",
            "Epoch 3573/4500\n",
            "100/100 [==============================] - 0s 492us/step - loss: 0.1370 - acc: 0.9500 - val_loss: 0.3861 - val_acc: 0.8500\n",
            "Epoch 3574/4500\n",
            "100/100 [==============================] - 0s 523us/step - loss: 0.1376 - acc: 0.9300 - val_loss: 0.3931 - val_acc: 0.8300\n",
            "Epoch 3575/4500\n",
            "100/100 [==============================] - 0s 501us/step - loss: 0.1369 - acc: 0.9300 - val_loss: 0.3832 - val_acc: 0.8500\n",
            "Epoch 3576/4500\n",
            "100/100 [==============================] - 0s 471us/step - loss: 0.1369 - acc: 0.9500 - val_loss: 0.3825 - val_acc: 0.8400\n",
            "Epoch 3577/4500\n",
            "100/100 [==============================] - 0s 494us/step - loss: 0.1352 - acc: 0.9400 - val_loss: 0.3943 - val_acc: 0.8200\n",
            "Epoch 3578/4500\n",
            "100/100 [==============================] - 0s 619us/step - loss: 0.1394 - acc: 0.9500 - val_loss: 0.3945 - val_acc: 0.8200\n",
            "Epoch 3579/4500\n",
            "100/100 [==============================] - 0s 576us/step - loss: 0.1359 - acc: 0.9400 - val_loss: 0.3835 - val_acc: 0.8400\n",
            "Epoch 3580/4500\n",
            "100/100 [==============================] - 0s 514us/step - loss: 0.1344 - acc: 0.9500 - val_loss: 0.3958 - val_acc: 0.8200\n",
            "Epoch 3581/4500\n",
            "100/100 [==============================] - 0s 502us/step - loss: 0.1391 - acc: 0.9400 - val_loss: 0.3806 - val_acc: 0.8600\n",
            "Epoch 3582/4500\n",
            "100/100 [==============================] - 0s 499us/step - loss: 0.1369 - acc: 0.9400 - val_loss: 0.3784 - val_acc: 0.8700\n",
            "Epoch 3583/4500\n",
            "100/100 [==============================] - 0s 550us/step - loss: 0.1381 - acc: 0.9500 - val_loss: 0.3981 - val_acc: 0.8100\n",
            "Epoch 3584/4500\n",
            "100/100 [==============================] - 0s 509us/step - loss: 0.1365 - acc: 0.9500 - val_loss: 0.3923 - val_acc: 0.8400\n",
            "Epoch 3585/4500\n",
            "100/100 [==============================] - 0s 538us/step - loss: 0.1354 - acc: 0.9500 - val_loss: 0.3722 - val_acc: 0.8600\n",
            "Epoch 3586/4500\n",
            "100/100 [==============================] - 0s 506us/step - loss: 0.1371 - acc: 0.9400 - val_loss: 0.3776 - val_acc: 0.8500\n",
            "Epoch 3587/4500\n",
            "100/100 [==============================] - 0s 529us/step - loss: 0.1365 - acc: 0.9400 - val_loss: 0.4000 - val_acc: 0.8100\n",
            "Epoch 3588/4500\n",
            "100/100 [==============================] - 0s 512us/step - loss: 0.1363 - acc: 0.9500 - val_loss: 0.3868 - val_acc: 0.8200\n",
            "Epoch 3589/4500\n",
            "100/100 [==============================] - 0s 583us/step - loss: 0.1346 - acc: 0.9600 - val_loss: 0.3766 - val_acc: 0.8600\n",
            "Epoch 3590/4500\n",
            "100/100 [==============================] - 0s 511us/step - loss: 0.1352 - acc: 0.9500 - val_loss: 0.3945 - val_acc: 0.8100\n",
            "Epoch 3591/4500\n",
            "100/100 [==============================] - 0s 510us/step - loss: 0.1366 - acc: 0.9300 - val_loss: 0.3916 - val_acc: 0.8300\n",
            "Epoch 3592/4500\n",
            "100/100 [==============================] - 0s 512us/step - loss: 0.1356 - acc: 0.9300 - val_loss: 0.3890 - val_acc: 0.8200\n",
            "Epoch 3593/4500\n",
            "100/100 [==============================] - 0s 519us/step - loss: 0.1341 - acc: 0.9500 - val_loss: 0.3772 - val_acc: 0.8600\n",
            "Epoch 3594/4500\n",
            "100/100 [==============================] - 0s 539us/step - loss: 0.1375 - acc: 0.9500 - val_loss: 0.3785 - val_acc: 0.8500\n",
            "Epoch 3595/4500\n",
            "100/100 [==============================] - 0s 496us/step - loss: 0.1319 - acc: 0.9500 - val_loss: 0.3825 - val_acc: 0.8600\n",
            "Epoch 3596/4500\n",
            "100/100 [==============================] - 0s 501us/step - loss: 0.1384 - acc: 0.9400 - val_loss: 0.3976 - val_acc: 0.8500\n",
            "Epoch 3597/4500\n",
            "100/100 [==============================] - 0s 534us/step - loss: 0.1429 - acc: 0.9300 - val_loss: 0.3837 - val_acc: 0.8500\n",
            "Epoch 3598/4500\n",
            "100/100 [==============================] - 0s 509us/step - loss: 0.1316 - acc: 0.9600 - val_loss: 0.3792 - val_acc: 0.8500\n",
            "Epoch 3599/4500\n",
            "100/100 [==============================] - 0s 504us/step - loss: 0.1335 - acc: 0.9500 - val_loss: 0.3971 - val_acc: 0.8200\n",
            "Epoch 3600/4500\n",
            "100/100 [==============================] - 0s 495us/step - loss: 0.1329 - acc: 0.9500 - val_loss: 0.3841 - val_acc: 0.8500\n",
            "Epoch 3601/4500\n",
            "100/100 [==============================] - 0s 499us/step - loss: 0.1358 - acc: 0.9400 - val_loss: 0.3753 - val_acc: 0.8700\n",
            "Epoch 3602/4500\n",
            "100/100 [==============================] - 0s 487us/step - loss: 0.1342 - acc: 0.9400 - val_loss: 0.3870 - val_acc: 0.8600\n",
            "Epoch 3603/4500\n",
            "100/100 [==============================] - 0s 599us/step - loss: 0.1341 - acc: 0.9500 - val_loss: 0.4034 - val_acc: 0.8100\n",
            "Epoch 3604/4500\n",
            "100/100 [==============================] - 0s 501us/step - loss: 0.1406 - acc: 0.9400 - val_loss: 0.3960 - val_acc: 0.8000\n",
            "Epoch 3605/4500\n",
            "100/100 [==============================] - 0s 523us/step - loss: 0.1344 - acc: 0.9500 - val_loss: 0.3909 - val_acc: 0.8500\n",
            "Epoch 3606/4500\n",
            "100/100 [==============================] - 0s 518us/step - loss: 0.1377 - acc: 0.9500 - val_loss: 0.3972 - val_acc: 0.8400\n",
            "Epoch 3607/4500\n",
            "100/100 [==============================] - 0s 512us/step - loss: 0.1329 - acc: 0.9500 - val_loss: 0.3931 - val_acc: 0.8400\n",
            "Epoch 3608/4500\n",
            "100/100 [==============================] - 0s 581us/step - loss: 0.1338 - acc: 0.9600 - val_loss: 0.3966 - val_acc: 0.8200\n",
            "Epoch 3609/4500\n",
            "100/100 [==============================] - 0s 558us/step - loss: 0.1330 - acc: 0.9500 - val_loss: 0.3899 - val_acc: 0.8400\n",
            "Epoch 3610/4500\n",
            "100/100 [==============================] - 0s 489us/step - loss: 0.1339 - acc: 0.9400 - val_loss: 0.3887 - val_acc: 0.8600\n",
            "Epoch 3611/4500\n",
            "100/100 [==============================] - 0s 495us/step - loss: 0.1313 - acc: 0.9500 - val_loss: 0.3854 - val_acc: 0.8500\n",
            "Epoch 3612/4500\n",
            "100/100 [==============================] - 0s 510us/step - loss: 0.1328 - acc: 0.9500 - val_loss: 0.3849 - val_acc: 0.8500\n",
            "Epoch 3613/4500\n",
            "100/100 [==============================] - 0s 493us/step - loss: 0.1327 - acc: 0.9400 - val_loss: 0.3890 - val_acc: 0.8600\n",
            "Epoch 3614/4500\n",
            "100/100 [==============================] - 0s 511us/step - loss: 0.1330 - acc: 0.9500 - val_loss: 0.3982 - val_acc: 0.8400\n",
            "Epoch 3615/4500\n",
            "100/100 [==============================] - 0s 482us/step - loss: 0.1344 - acc: 0.9500 - val_loss: 0.3872 - val_acc: 0.8500\n",
            "Epoch 3616/4500\n",
            "100/100 [==============================] - 0s 486us/step - loss: 0.1332 - acc: 0.9500 - val_loss: 0.4021 - val_acc: 0.8100\n",
            "Epoch 3617/4500\n",
            "100/100 [==============================] - 0s 501us/step - loss: 0.1392 - acc: 0.9400 - val_loss: 0.3768 - val_acc: 0.8600\n",
            "Epoch 3618/4500\n",
            "100/100 [==============================] - 0s 618us/step - loss: 0.1295 - acc: 0.9500 - val_loss: 0.3895 - val_acc: 0.8500\n",
            "Epoch 3619/4500\n",
            "100/100 [==============================] - 0s 502us/step - loss: 0.1312 - acc: 0.9400 - val_loss: 0.4044 - val_acc: 0.8400\n",
            "Epoch 3620/4500\n",
            "100/100 [==============================] - 0s 513us/step - loss: 0.1358 - acc: 0.9400 - val_loss: 0.4032 - val_acc: 0.8100\n",
            "Epoch 3621/4500\n",
            "100/100 [==============================] - 0s 532us/step - loss: 0.1423 - acc: 0.9400 - val_loss: 0.3821 - val_acc: 0.8500\n",
            "Epoch 3622/4500\n",
            "100/100 [==============================] - 0s 595us/step - loss: 0.1413 - acc: 0.9500 - val_loss: 0.3900 - val_acc: 0.8600\n",
            "Epoch 3623/4500\n",
            "100/100 [==============================] - 0s 496us/step - loss: 0.1337 - acc: 0.9400 - val_loss: 0.4014 - val_acc: 0.8200\n",
            "Epoch 3624/4500\n",
            "100/100 [==============================] - 0s 502us/step - loss: 0.1289 - acc: 0.9500 - val_loss: 0.3933 - val_acc: 0.8600\n",
            "Epoch 3625/4500\n",
            "100/100 [==============================] - 0s 504us/step - loss: 0.1328 - acc: 0.9500 - val_loss: 0.3874 - val_acc: 0.8500\n",
            "Epoch 3626/4500\n",
            "100/100 [==============================] - 0s 543us/step - loss: 0.1337 - acc: 0.9500 - val_loss: 0.3977 - val_acc: 0.8500\n",
            "Epoch 3627/4500\n",
            "100/100 [==============================] - 0s 576us/step - loss: 0.1339 - acc: 0.9500 - val_loss: 0.3916 - val_acc: 0.8400\n",
            "Epoch 3628/4500\n",
            "100/100 [==============================] - 0s 553us/step - loss: 0.1296 - acc: 0.9500 - val_loss: 0.3829 - val_acc: 0.8600\n",
            "Epoch 3629/4500\n",
            "100/100 [==============================] - 0s 590us/step - loss: 0.1339 - acc: 0.9500 - val_loss: 0.3819 - val_acc: 0.8500\n",
            "Epoch 3630/4500\n",
            "100/100 [==============================] - 0s 502us/step - loss: 0.1331 - acc: 0.9400 - val_loss: 0.3897 - val_acc: 0.8600\n",
            "Epoch 3631/4500\n",
            "100/100 [==============================] - 0s 495us/step - loss: 0.1312 - acc: 0.9400 - val_loss: 0.3881 - val_acc: 0.8500\n",
            "Epoch 3632/4500\n",
            "100/100 [==============================] - 0s 523us/step - loss: 0.1404 - acc: 0.9400 - val_loss: 0.4084 - val_acc: 0.8100\n",
            "Epoch 3633/4500\n",
            "100/100 [==============================] - 0s 504us/step - loss: 0.1292 - acc: 0.9500 - val_loss: 0.4171 - val_acc: 0.8100\n",
            "Epoch 3634/4500\n",
            "100/100 [==============================] - 0s 505us/step - loss: 0.1302 - acc: 0.9500 - val_loss: 0.3817 - val_acc: 0.8800\n",
            "Epoch 3635/4500\n",
            "100/100 [==============================] - 0s 523us/step - loss: 0.1330 - acc: 0.9500 - val_loss: 0.3928 - val_acc: 0.8300\n",
            "Epoch 3636/4500\n",
            "100/100 [==============================] - 0s 513us/step - loss: 0.1371 - acc: 0.9400 - val_loss: 0.4023 - val_acc: 0.8300\n",
            "Epoch 3637/4500\n",
            "100/100 [==============================] - 0s 520us/step - loss: 0.1318 - acc: 0.9500 - val_loss: 0.3986 - val_acc: 0.8200\n",
            "Epoch 3638/4500\n",
            "100/100 [==============================] - 0s 514us/step - loss: 0.1321 - acc: 0.9500 - val_loss: 0.3939 - val_acc: 0.8600\n",
            "Epoch 3639/4500\n",
            "100/100 [==============================] - 0s 495us/step - loss: 0.1300 - acc: 0.9500 - val_loss: 0.4031 - val_acc: 0.8200\n",
            "Epoch 3640/4500\n",
            "100/100 [==============================] - 0s 518us/step - loss: 0.1283 - acc: 0.9500 - val_loss: 0.3781 - val_acc: 0.8700\n",
            "Epoch 3641/4500\n",
            "100/100 [==============================] - 0s 557us/step - loss: 0.1272 - acc: 0.9600 - val_loss: 0.3962 - val_acc: 0.8400\n",
            "Epoch 3642/4500\n",
            "100/100 [==============================] - 0s 529us/step - loss: 0.1271 - acc: 0.9500 - val_loss: 0.3940 - val_acc: 0.8400\n",
            "Epoch 3643/4500\n",
            "100/100 [==============================] - 0s 514us/step - loss: 0.1268 - acc: 0.9500 - val_loss: 0.3908 - val_acc: 0.8600\n",
            "Epoch 3644/4500\n",
            "100/100 [==============================] - 0s 500us/step - loss: 0.1273 - acc: 0.9600 - val_loss: 0.3956 - val_acc: 0.8400\n",
            "Epoch 3645/4500\n",
            "100/100 [==============================] - 0s 496us/step - loss: 0.1281 - acc: 0.9500 - val_loss: 0.3918 - val_acc: 0.8500\n",
            "Epoch 3646/4500\n",
            "100/100 [==============================] - 0s 494us/step - loss: 0.1317 - acc: 0.9500 - val_loss: 0.3911 - val_acc: 0.8400\n",
            "Epoch 3647/4500\n",
            "100/100 [==============================] - 0s 530us/step - loss: 0.1294 - acc: 0.9500 - val_loss: 0.3828 - val_acc: 0.8700\n",
            "Epoch 3648/4500\n",
            "100/100 [==============================] - 0s 602us/step - loss: 0.1290 - acc: 0.9500 - val_loss: 0.4030 - val_acc: 0.8200\n",
            "Epoch 3649/4500\n",
            "100/100 [==============================] - 0s 473us/step - loss: 0.1308 - acc: 0.9400 - val_loss: 0.3907 - val_acc: 0.8600\n",
            "Epoch 3650/4500\n",
            "100/100 [==============================] - 0s 479us/step - loss: 0.1336 - acc: 0.9500 - val_loss: 0.3948 - val_acc: 0.8600\n",
            "Epoch 3651/4500\n",
            "100/100 [==============================] - 0s 485us/step - loss: 0.1375 - acc: 0.9600 - val_loss: 0.4192 - val_acc: 0.8000\n",
            "Epoch 3652/4500\n",
            "100/100 [==============================] - 0s 498us/step - loss: 0.1299 - acc: 0.9500 - val_loss: 0.3945 - val_acc: 0.8500\n",
            "Epoch 3653/4500\n",
            "100/100 [==============================] - 0s 533us/step - loss: 0.1359 - acc: 0.9400 - val_loss: 0.3913 - val_acc: 0.8700\n",
            "Epoch 3654/4500\n",
            "100/100 [==============================] - 0s 511us/step - loss: 0.1376 - acc: 0.9300 - val_loss: 0.3823 - val_acc: 0.8800\n",
            "Epoch 3655/4500\n",
            "100/100 [==============================] - 0s 559us/step - loss: 0.1398 - acc: 0.9400 - val_loss: 0.4165 - val_acc: 0.8300\n",
            "Epoch 3656/4500\n",
            "100/100 [==============================] - 0s 586us/step - loss: 0.1352 - acc: 0.9500 - val_loss: 0.3924 - val_acc: 0.8700\n",
            "Epoch 3657/4500\n",
            "100/100 [==============================] - 0s 527us/step - loss: 0.1290 - acc: 0.9300 - val_loss: 0.4164 - val_acc: 0.8200\n",
            "Epoch 3658/4500\n",
            "100/100 [==============================] - 0s 511us/step - loss: 0.1256 - acc: 0.9500 - val_loss: 0.4033 - val_acc: 0.8400\n",
            "Epoch 3659/4500\n",
            "100/100 [==============================] - 0s 515us/step - loss: 0.1269 - acc: 0.9600 - val_loss: 0.4124 - val_acc: 0.8300\n",
            "Epoch 3660/4500\n",
            "100/100 [==============================] - 0s 574us/step - loss: 0.1456 - acc: 0.9200 - val_loss: 0.4220 - val_acc: 0.8300\n",
            "Epoch 3661/4500\n",
            "100/100 [==============================] - 0s 519us/step - loss: 0.1577 - acc: 0.9500 - val_loss: 0.3932 - val_acc: 0.8400\n",
            "Epoch 3662/4500\n",
            "100/100 [==============================] - 0s 545us/step - loss: 0.1383 - acc: 0.9600 - val_loss: 0.3817 - val_acc: 0.8600\n",
            "Epoch 3663/4500\n",
            "100/100 [==============================] - 0s 521us/step - loss: 0.1308 - acc: 0.9600 - val_loss: 0.4043 - val_acc: 0.8500\n",
            "Epoch 3664/4500\n",
            "100/100 [==============================] - 0s 490us/step - loss: 0.1287 - acc: 0.9500 - val_loss: 0.3910 - val_acc: 0.8600\n",
            "Epoch 3665/4500\n",
            "100/100 [==============================] - 0s 565us/step - loss: 0.1419 - acc: 0.9300 - val_loss: 0.4153 - val_acc: 0.8100\n",
            "Epoch 3666/4500\n",
            "100/100 [==============================] - 0s 603us/step - loss: 0.1248 - acc: 0.9500 - val_loss: 0.4043 - val_acc: 0.8500\n",
            "Epoch 3667/4500\n",
            "100/100 [==============================] - 0s 579us/step - loss: 0.1276 - acc: 0.9500 - val_loss: 0.4150 - val_acc: 0.8100\n",
            "Epoch 3668/4500\n",
            "100/100 [==============================] - 0s 499us/step - loss: 0.1252 - acc: 0.9600 - val_loss: 0.4125 - val_acc: 0.8300\n",
            "Epoch 3669/4500\n",
            "100/100 [==============================] - 0s 567us/step - loss: 0.1296 - acc: 0.9500 - val_loss: 0.4036 - val_acc: 0.8200\n",
            "Epoch 3670/4500\n",
            "100/100 [==============================] - 0s 520us/step - loss: 0.1244 - acc: 0.9500 - val_loss: 0.3934 - val_acc: 0.8600\n",
            "Epoch 3671/4500\n",
            "100/100 [==============================] - 0s 499us/step - loss: 0.1288 - acc: 0.9600 - val_loss: 0.3845 - val_acc: 0.8700\n",
            "Epoch 3672/4500\n",
            "100/100 [==============================] - 0s 481us/step - loss: 0.1253 - acc: 0.9500 - val_loss: 0.4135 - val_acc: 0.8200\n",
            "Epoch 3673/4500\n",
            "100/100 [==============================] - 0s 518us/step - loss: 0.1335 - acc: 0.9400 - val_loss: 0.3980 - val_acc: 0.8600\n",
            "Epoch 3674/4500\n",
            "100/100 [==============================] - 0s 510us/step - loss: 0.1296 - acc: 0.9600 - val_loss: 0.3965 - val_acc: 0.8400\n",
            "Epoch 3675/4500\n",
            "100/100 [==============================] - 0s 488us/step - loss: 0.1238 - acc: 0.9500 - val_loss: 0.4027 - val_acc: 0.8100\n",
            "Epoch 3676/4500\n",
            "100/100 [==============================] - 0s 497us/step - loss: 0.1283 - acc: 0.9500 - val_loss: 0.3965 - val_acc: 0.8400\n",
            "Epoch 3677/4500\n",
            "100/100 [==============================] - 0s 557us/step - loss: 0.1264 - acc: 0.9500 - val_loss: 0.4013 - val_acc: 0.8300\n",
            "Epoch 3678/4500\n",
            "100/100 [==============================] - 0s 559us/step - loss: 0.1245 - acc: 0.9500 - val_loss: 0.4006 - val_acc: 0.8400\n",
            "Epoch 3679/4500\n",
            "100/100 [==============================] - 0s 594us/step - loss: 0.1285 - acc: 0.9500 - val_loss: 0.3977 - val_acc: 0.8500\n",
            "Epoch 3680/4500\n",
            "100/100 [==============================] - 0s 626us/step - loss: 0.1275 - acc: 0.9400 - val_loss: 0.4078 - val_acc: 0.8200\n",
            "Epoch 3681/4500\n",
            "100/100 [==============================] - 0s 534us/step - loss: 0.1237 - acc: 0.9600 - val_loss: 0.3904 - val_acc: 0.8500\n",
            "Epoch 3682/4500\n",
            "100/100 [==============================] - 0s 559us/step - loss: 0.1261 - acc: 0.9600 - val_loss: 0.4059 - val_acc: 0.8300\n",
            "Epoch 3683/4500\n",
            "100/100 [==============================] - 0s 513us/step - loss: 0.1212 - acc: 0.9500 - val_loss: 0.4117 - val_acc: 0.8200\n",
            "Epoch 3684/4500\n",
            "100/100 [==============================] - 0s 496us/step - loss: 0.1226 - acc: 0.9600 - val_loss: 0.3939 - val_acc: 0.8600\n",
            "Epoch 3685/4500\n",
            "100/100 [==============================] - 0s 506us/step - loss: 0.1287 - acc: 0.9400 - val_loss: 0.4043 - val_acc: 0.8200\n",
            "Epoch 3686/4500\n",
            "100/100 [==============================] - 0s 518us/step - loss: 0.1335 - acc: 0.9400 - val_loss: 0.3940 - val_acc: 0.8400\n",
            "Epoch 3687/4500\n",
            "100/100 [==============================] - 0s 502us/step - loss: 0.1244 - acc: 0.9500 - val_loss: 0.3977 - val_acc: 0.8500\n",
            "Epoch 3688/4500\n",
            "100/100 [==============================] - 0s 491us/step - loss: 0.1232 - acc: 0.9500 - val_loss: 0.3970 - val_acc: 0.8600\n",
            "Epoch 3689/4500\n",
            "100/100 [==============================] - 0s 499us/step - loss: 0.1271 - acc: 0.9600 - val_loss: 0.4034 - val_acc: 0.8300\n",
            "Epoch 3690/4500\n",
            "100/100 [==============================] - 0s 499us/step - loss: 0.1210 - acc: 0.9600 - val_loss: 0.4012 - val_acc: 0.8400\n",
            "Epoch 3691/4500\n",
            "100/100 [==============================] - 0s 522us/step - loss: 0.1242 - acc: 0.9500 - val_loss: 0.3884 - val_acc: 0.8700\n",
            "Epoch 3692/4500\n",
            "100/100 [==============================] - 0s 525us/step - loss: 0.1259 - acc: 0.9500 - val_loss: 0.3931 - val_acc: 0.8600\n",
            "Epoch 3693/4500\n",
            "100/100 [==============================] - 0s 499us/step - loss: 0.1251 - acc: 0.9600 - val_loss: 0.4057 - val_acc: 0.8200\n",
            "Epoch 3694/4500\n",
            "100/100 [==============================] - 0s 504us/step - loss: 0.1209 - acc: 0.9600 - val_loss: 0.3965 - val_acc: 0.8500\n",
            "Epoch 3695/4500\n",
            "100/100 [==============================] - 0s 505us/step - loss: 0.1227 - acc: 0.9500 - val_loss: 0.3931 - val_acc: 0.8600\n",
            "Epoch 3696/4500\n",
            "100/100 [==============================] - 0s 538us/step - loss: 0.1255 - acc: 0.9600 - val_loss: 0.3992 - val_acc: 0.8400\n",
            "Epoch 3697/4500\n",
            "100/100 [==============================] - 0s 537us/step - loss: 0.1202 - acc: 0.9600 - val_loss: 0.4065 - val_acc: 0.8200\n",
            "Epoch 3698/4500\n",
            "100/100 [==============================] - 0s 584us/step - loss: 0.1269 - acc: 0.9400 - val_loss: 0.3870 - val_acc: 0.8800\n",
            "Epoch 3699/4500\n",
            "100/100 [==============================] - 0s 507us/step - loss: 0.1254 - acc: 0.9500 - val_loss: 0.3933 - val_acc: 0.8800\n",
            "Epoch 3700/4500\n",
            "100/100 [==============================] - 0s 489us/step - loss: 0.1242 - acc: 0.9500 - val_loss: 0.4121 - val_acc: 0.8100\n",
            "Epoch 3701/4500\n",
            "100/100 [==============================] - 0s 494us/step - loss: 0.1233 - acc: 0.9500 - val_loss: 0.3856 - val_acc: 0.8800\n",
            "Epoch 3702/4500\n",
            "100/100 [==============================] - 0s 514us/step - loss: 0.1201 - acc: 0.9500 - val_loss: 0.4099 - val_acc: 0.8300\n",
            "Epoch 3703/4500\n",
            "100/100 [==============================] - 0s 514us/step - loss: 0.1201 - acc: 0.9500 - val_loss: 0.3946 - val_acc: 0.8600\n",
            "Epoch 3704/4500\n",
            "100/100 [==============================] - 0s 491us/step - loss: 0.1228 - acc: 0.9500 - val_loss: 0.4023 - val_acc: 0.8400\n",
            "Epoch 3705/4500\n",
            "100/100 [==============================] - 0s 525us/step - loss: 0.1211 - acc: 0.9600 - val_loss: 0.3975 - val_acc: 0.8500\n",
            "Epoch 3706/4500\n",
            "100/100 [==============================] - 0s 504us/step - loss: 0.1196 - acc: 0.9500 - val_loss: 0.4013 - val_acc: 0.8400\n",
            "Epoch 3707/4500\n",
            "100/100 [==============================] - 0s 532us/step - loss: 0.1254 - acc: 0.9500 - val_loss: 0.3956 - val_acc: 0.8400\n",
            "Epoch 3708/4500\n",
            "100/100 [==============================] - 0s 496us/step - loss: 0.1221 - acc: 0.9500 - val_loss: 0.3986 - val_acc: 0.8500\n",
            "Epoch 3709/4500\n",
            "100/100 [==============================] - 0s 497us/step - loss: 0.1203 - acc: 0.9500 - val_loss: 0.3957 - val_acc: 0.8700\n",
            "Epoch 3710/4500\n",
            "100/100 [==============================] - 0s 497us/step - loss: 0.1236 - acc: 0.9600 - val_loss: 0.4054 - val_acc: 0.8400\n",
            "Epoch 3711/4500\n",
            "100/100 [==============================] - 0s 515us/step - loss: 0.1291 - acc: 0.9500 - val_loss: 0.4219 - val_acc: 0.8100\n",
            "Epoch 3712/4500\n",
            "100/100 [==============================] - 0s 517us/step - loss: 0.1240 - acc: 0.9600 - val_loss: 0.3850 - val_acc: 0.8800\n",
            "Epoch 3713/4500\n",
            "100/100 [==============================] - 0s 514us/step - loss: 0.1298 - acc: 0.9400 - val_loss: 0.4040 - val_acc: 0.8500\n",
            "Epoch 3714/4500\n",
            "100/100 [==============================] - 0s 507us/step - loss: 0.1218 - acc: 0.9600 - val_loss: 0.4010 - val_acc: 0.8800\n",
            "Epoch 3715/4500\n",
            "100/100 [==============================] - 0s 492us/step - loss: 0.1179 - acc: 0.9600 - val_loss: 0.4108 - val_acc: 0.8300\n",
            "Epoch 3716/4500\n",
            "100/100 [==============================] - 0s 485us/step - loss: 0.1233 - acc: 0.9600 - val_loss: 0.4007 - val_acc: 0.8600\n",
            "Epoch 3717/4500\n",
            "100/100 [==============================] - 0s 539us/step - loss: 0.1194 - acc: 0.9600 - val_loss: 0.4086 - val_acc: 0.8300\n",
            "Epoch 3718/4500\n",
            "100/100 [==============================] - 0s 669us/step - loss: 0.1259 - acc: 0.9600 - val_loss: 0.4087 - val_acc: 0.8300\n",
            "Epoch 3719/4500\n",
            "100/100 [==============================] - 0s 561us/step - loss: 0.1204 - acc: 0.9500 - val_loss: 0.3923 - val_acc: 0.8700\n",
            "Epoch 3720/4500\n",
            "100/100 [==============================] - 0s 529us/step - loss: 0.1256 - acc: 0.9400 - val_loss: 0.3934 - val_acc: 0.8800\n",
            "Epoch 3721/4500\n",
            "100/100 [==============================] - 0s 519us/step - loss: 0.1224 - acc: 0.9500 - val_loss: 0.3860 - val_acc: 0.8800\n",
            "Epoch 3722/4500\n",
            "100/100 [==============================] - 0s 496us/step - loss: 0.1227 - acc: 0.9600 - val_loss: 0.3934 - val_acc: 0.8700\n",
            "Epoch 3723/4500\n",
            "100/100 [==============================] - 0s 504us/step - loss: 0.1177 - acc: 0.9500 - val_loss: 0.4057 - val_acc: 0.8300\n",
            "Epoch 3724/4500\n",
            "100/100 [==============================] - 0s 523us/step - loss: 0.1193 - acc: 0.9500 - val_loss: 0.4030 - val_acc: 0.8400\n",
            "Epoch 3725/4500\n",
            "100/100 [==============================] - 0s 521us/step - loss: 0.1179 - acc: 0.9700 - val_loss: 0.4028 - val_acc: 0.8500\n",
            "Epoch 3726/4500\n",
            "100/100 [==============================] - 0s 556us/step - loss: 0.1179 - acc: 0.9600 - val_loss: 0.4043 - val_acc: 0.8300\n",
            "Epoch 3727/4500\n",
            "100/100 [==============================] - 0s 508us/step - loss: 0.1167 - acc: 0.9600 - val_loss: 0.4027 - val_acc: 0.8600\n",
            "Epoch 3728/4500\n",
            "100/100 [==============================] - 0s 524us/step - loss: 0.1155 - acc: 0.9600 - val_loss: 0.4025 - val_acc: 0.8500\n",
            "Epoch 3729/4500\n",
            "100/100 [==============================] - 0s 516us/step - loss: 0.1217 - acc: 0.9600 - val_loss: 0.4046 - val_acc: 0.8500\n",
            "Epoch 3730/4500\n",
            "100/100 [==============================] - 0s 540us/step - loss: 0.1223 - acc: 0.9500 - val_loss: 0.4007 - val_acc: 0.8400\n",
            "Epoch 3731/4500\n",
            "100/100 [==============================] - 0s 497us/step - loss: 0.1174 - acc: 0.9500 - val_loss: 0.3857 - val_acc: 0.8800\n",
            "Epoch 3732/4500\n",
            "100/100 [==============================] - 0s 496us/step - loss: 0.1176 - acc: 0.9600 - val_loss: 0.4054 - val_acc: 0.8300\n",
            "Epoch 3733/4500\n",
            "100/100 [==============================] - 0s 498us/step - loss: 0.1192 - acc: 0.9600 - val_loss: 0.3937 - val_acc: 0.8700\n",
            "Epoch 3734/4500\n",
            "100/100 [==============================] - 0s 502us/step - loss: 0.1172 - acc: 0.9700 - val_loss: 0.4143 - val_acc: 0.8300\n",
            "Epoch 3735/4500\n",
            "100/100 [==============================] - 0s 497us/step - loss: 0.1212 - acc: 0.9500 - val_loss: 0.4070 - val_acc: 0.8400\n",
            "Epoch 3736/4500\n",
            "100/100 [==============================] - 0s 497us/step - loss: 0.1212 - acc: 0.9600 - val_loss: 0.3851 - val_acc: 0.8700\n",
            "Epoch 3737/4500\n",
            "100/100 [==============================] - 0s 633us/step - loss: 0.1186 - acc: 0.9500 - val_loss: 0.3891 - val_acc: 0.8700\n",
            "Epoch 3738/4500\n",
            "100/100 [==============================] - 0s 522us/step - loss: 0.1187 - acc: 0.9600 - val_loss: 0.4225 - val_acc: 0.8300\n",
            "Epoch 3739/4500\n",
            "100/100 [==============================] - 0s 522us/step - loss: 0.1186 - acc: 0.9500 - val_loss: 0.4038 - val_acc: 0.8500\n",
            "Epoch 3740/4500\n",
            "100/100 [==============================] - 0s 496us/step - loss: 0.1166 - acc: 0.9600 - val_loss: 0.3976 - val_acc: 0.8600\n",
            "Epoch 3741/4500\n",
            "100/100 [==============================] - 0s 498us/step - loss: 0.1163 - acc: 0.9600 - val_loss: 0.4078 - val_acc: 0.8300\n",
            "Epoch 3742/4500\n",
            "100/100 [==============================] - 0s 503us/step - loss: 0.1179 - acc: 0.9600 - val_loss: 0.4012 - val_acc: 0.8500\n",
            "Epoch 3743/4500\n",
            "100/100 [==============================] - 0s 499us/step - loss: 0.1260 - acc: 0.9600 - val_loss: 0.3993 - val_acc: 0.8800\n",
            "Epoch 3744/4500\n",
            "100/100 [==============================] - 0s 533us/step - loss: 0.1157 - acc: 0.9500 - val_loss: 0.4165 - val_acc: 0.8200\n",
            "Epoch 3745/4500\n",
            "100/100 [==============================] - 0s 508us/step - loss: 0.1239 - acc: 0.9500 - val_loss: 0.4121 - val_acc: 0.8300\n",
            "Epoch 3746/4500\n",
            "100/100 [==============================] - 0s 490us/step - loss: 0.1228 - acc: 0.9400 - val_loss: 0.3939 - val_acc: 0.8700\n",
            "Epoch 3747/4500\n",
            "100/100 [==============================] - 0s 598us/step - loss: 0.1149 - acc: 0.9600 - val_loss: 0.3798 - val_acc: 0.8800\n",
            "Epoch 3748/4500\n",
            "100/100 [==============================] - 0s 542us/step - loss: 0.1159 - acc: 0.9600 - val_loss: 0.4070 - val_acc: 0.8400\n",
            "Epoch 3749/4500\n",
            "100/100 [==============================] - 0s 512us/step - loss: 0.1144 - acc: 0.9600 - val_loss: 0.4087 - val_acc: 0.8300\n",
            "Epoch 3750/4500\n",
            "100/100 [==============================] - 0s 504us/step - loss: 0.1149 - acc: 0.9600 - val_loss: 0.4066 - val_acc: 0.8500\n",
            "Epoch 3751/4500\n",
            "100/100 [==============================] - 0s 525us/step - loss: 0.1170 - acc: 0.9600 - val_loss: 0.4181 - val_acc: 0.8300\n",
            "Epoch 3752/4500\n",
            "100/100 [==============================] - 0s 524us/step - loss: 0.1155 - acc: 0.9700 - val_loss: 0.4016 - val_acc: 0.8700\n",
            "Epoch 3753/4500\n",
            "100/100 [==============================] - 0s 489us/step - loss: 0.1155 - acc: 0.9600 - val_loss: 0.4096 - val_acc: 0.8500\n",
            "Epoch 3754/4500\n",
            "100/100 [==============================] - 0s 565us/step - loss: 0.1182 - acc: 0.9500 - val_loss: 0.4144 - val_acc: 0.8300\n",
            "Epoch 3755/4500\n",
            "100/100 [==============================] - 0s 506us/step - loss: 0.1143 - acc: 0.9500 - val_loss: 0.4139 - val_acc: 0.8300\n",
            "Epoch 3756/4500\n",
            "100/100 [==============================] - 0s 597us/step - loss: 0.1121 - acc: 0.9600 - val_loss: 0.3951 - val_acc: 0.8700\n",
            "Epoch 3757/4500\n",
            "100/100 [==============================] - 0s 505us/step - loss: 0.1140 - acc: 0.9600 - val_loss: 0.4012 - val_acc: 0.8600\n",
            "Epoch 3758/4500\n",
            "100/100 [==============================] - 0s 513us/step - loss: 0.1219 - acc: 0.9500 - val_loss: 0.3989 - val_acc: 0.8700\n",
            "Epoch 3759/4500\n",
            "100/100 [==============================] - 0s 528us/step - loss: 0.1160 - acc: 0.9600 - val_loss: 0.3951 - val_acc: 0.8700\n",
            "Epoch 3760/4500\n",
            "100/100 [==============================] - 0s 511us/step - loss: 0.1206 - acc: 0.9600 - val_loss: 0.4101 - val_acc: 0.8400\n",
            "Epoch 3761/4500\n",
            "100/100 [==============================] - 0s 568us/step - loss: 0.1185 - acc: 0.9500 - val_loss: 0.4146 - val_acc: 0.8300\n",
            "Epoch 3762/4500\n",
            "100/100 [==============================] - 0s 543us/step - loss: 0.1128 - acc: 0.9600 - val_loss: 0.3830 - val_acc: 0.8800\n",
            "Epoch 3763/4500\n",
            "100/100 [==============================] - 0s 511us/step - loss: 0.1230 - acc: 0.9500 - val_loss: 0.4013 - val_acc: 0.8500\n",
            "Epoch 3764/4500\n",
            "100/100 [==============================] - 0s 548us/step - loss: 0.1121 - acc: 0.9600 - val_loss: 0.3923 - val_acc: 0.8800\n",
            "Epoch 3765/4500\n",
            "100/100 [==============================] - 0s 535us/step - loss: 0.1138 - acc: 0.9500 - val_loss: 0.4042 - val_acc: 0.8600\n",
            "Epoch 3766/4500\n",
            "100/100 [==============================] - 0s 583us/step - loss: 0.1143 - acc: 0.9700 - val_loss: 0.4159 - val_acc: 0.8300\n",
            "Epoch 3767/4500\n",
            "100/100 [==============================] - 0s 535us/step - loss: 0.1136 - acc: 0.9700 - val_loss: 0.4078 - val_acc: 0.8600\n",
            "Epoch 3768/4500\n",
            "100/100 [==============================] - 0s 534us/step - loss: 0.1117 - acc: 0.9600 - val_loss: 0.4098 - val_acc: 0.8300\n",
            "Epoch 3769/4500\n",
            "100/100 [==============================] - 0s 501us/step - loss: 0.1226 - acc: 0.9500 - val_loss: 0.4229 - val_acc: 0.8300\n",
            "Epoch 3770/4500\n",
            "100/100 [==============================] - 0s 570us/step - loss: 0.1216 - acc: 0.9500 - val_loss: 0.3802 - val_acc: 0.8800\n",
            "Epoch 3771/4500\n",
            "100/100 [==============================] - 0s 528us/step - loss: 0.1226 - acc: 0.9700 - val_loss: 0.4161 - val_acc: 0.8300\n",
            "Epoch 3772/4500\n",
            "100/100 [==============================] - 0s 483us/step - loss: 0.1178 - acc: 0.9500 - val_loss: 0.4256 - val_acc: 0.8300\n",
            "Epoch 3773/4500\n",
            "100/100 [==============================] - 0s 503us/step - loss: 0.1161 - acc: 0.9600 - val_loss: 0.3939 - val_acc: 0.8700\n",
            "Epoch 3774/4500\n",
            "100/100 [==============================] - 0s 544us/step - loss: 0.1130 - acc: 0.9600 - val_loss: 0.4093 - val_acc: 0.8300\n",
            "Epoch 3775/4500\n",
            "100/100 [==============================] - 0s 560us/step - loss: 0.1147 - acc: 0.9500 - val_loss: 0.4031 - val_acc: 0.8600\n",
            "Epoch 3776/4500\n",
            "100/100 [==============================] - 0s 552us/step - loss: 0.1143 - acc: 0.9600 - val_loss: 0.4141 - val_acc: 0.8500\n",
            "Epoch 3777/4500\n",
            "100/100 [==============================] - 0s 518us/step - loss: 0.1134 - acc: 0.9600 - val_loss: 0.4093 - val_acc: 0.8500\n",
            "Epoch 3778/4500\n",
            "100/100 [==============================] - 0s 496us/step - loss: 0.1156 - acc: 0.9500 - val_loss: 0.4233 - val_acc: 0.8300\n",
            "Epoch 3779/4500\n",
            "100/100 [==============================] - 0s 534us/step - loss: 0.1176 - acc: 0.9500 - val_loss: 0.4125 - val_acc: 0.8400\n",
            "Epoch 3780/4500\n",
            "100/100 [==============================] - 0s 479us/step - loss: 0.1134 - acc: 0.9500 - val_loss: 0.4141 - val_acc: 0.8200\n",
            "Epoch 3781/4500\n",
            "100/100 [==============================] - 0s 496us/step - loss: 0.1140 - acc: 0.9500 - val_loss: 0.4143 - val_acc: 0.8300\n",
            "Epoch 3782/4500\n",
            "100/100 [==============================] - 0s 491us/step - loss: 0.1157 - acc: 0.9600 - val_loss: 0.3980 - val_acc: 0.8700\n",
            "Epoch 3783/4500\n",
            "100/100 [==============================] - 0s 484us/step - loss: 0.1125 - acc: 0.9700 - val_loss: 0.4053 - val_acc: 0.8800\n",
            "Epoch 3784/4500\n",
            "100/100 [==============================] - 0s 606us/step - loss: 0.1093 - acc: 0.9600 - val_loss: 0.4142 - val_acc: 0.8300\n",
            "Epoch 3785/4500\n",
            "100/100 [==============================] - 0s 492us/step - loss: 0.1118 - acc: 0.9500 - val_loss: 0.4032 - val_acc: 0.8700\n",
            "Epoch 3786/4500\n",
            "100/100 [==============================] - 0s 581us/step - loss: 0.1101 - acc: 0.9600 - val_loss: 0.3953 - val_acc: 0.8700\n",
            "Epoch 3787/4500\n",
            "100/100 [==============================] - 0s 526us/step - loss: 0.1119 - acc: 0.9600 - val_loss: 0.4073 - val_acc: 0.8700\n",
            "Epoch 3788/4500\n",
            "100/100 [==============================] - 0s 519us/step - loss: 0.1140 - acc: 0.9700 - val_loss: 0.4147 - val_acc: 0.8300\n",
            "Epoch 3789/4500\n",
            "100/100 [==============================] - 0s 534us/step - loss: 0.1080 - acc: 0.9600 - val_loss: 0.4000 - val_acc: 0.8800\n",
            "Epoch 3790/4500\n",
            "100/100 [==============================] - 0s 566us/step - loss: 0.1124 - acc: 0.9700 - val_loss: 0.4181 - val_acc: 0.8300\n",
            "Epoch 3791/4500\n",
            "100/100 [==============================] - 0s 493us/step - loss: 0.1114 - acc: 0.9500 - val_loss: 0.4027 - val_acc: 0.8700\n",
            "Epoch 3792/4500\n",
            "100/100 [==============================] - 0s 498us/step - loss: 0.1120 - acc: 0.9600 - val_loss: 0.4006 - val_acc: 0.8700\n",
            "Epoch 3793/4500\n",
            "100/100 [==============================] - 0s 481us/step - loss: 0.1108 - acc: 0.9600 - val_loss: 0.4079 - val_acc: 0.8600\n",
            "Epoch 3794/4500\n",
            "100/100 [==============================] - 0s 592us/step - loss: 0.1123 - acc: 0.9600 - val_loss: 0.4139 - val_acc: 0.8500\n",
            "Epoch 3795/4500\n",
            "100/100 [==============================] - 0s 512us/step - loss: 0.1151 - acc: 0.9600 - val_loss: 0.4196 - val_acc: 0.8300\n",
            "Epoch 3796/4500\n",
            "100/100 [==============================] - 0s 522us/step - loss: 0.1211 - acc: 0.9600 - val_loss: 0.4269 - val_acc: 0.8300\n",
            "Epoch 3797/4500\n",
            "100/100 [==============================] - 0s 525us/step - loss: 0.1180 - acc: 0.9500 - val_loss: 0.4098 - val_acc: 0.8600\n",
            "Epoch 3798/4500\n",
            "100/100 [==============================] - 0s 535us/step - loss: 0.1165 - acc: 0.9500 - val_loss: 0.4068 - val_acc: 0.8700\n",
            "Epoch 3799/4500\n",
            "100/100 [==============================] - 0s 529us/step - loss: 0.1110 - acc: 0.9500 - val_loss: 0.4176 - val_acc: 0.8500\n",
            "Epoch 3800/4500\n",
            "100/100 [==============================] - 0s 515us/step - loss: 0.1115 - acc: 0.9600 - val_loss: 0.4227 - val_acc: 0.8600\n",
            "Epoch 3801/4500\n",
            "100/100 [==============================] - 0s 514us/step - loss: 0.1205 - acc: 0.9400 - val_loss: 0.4161 - val_acc: 0.8800\n",
            "Epoch 3802/4500\n",
            "100/100 [==============================] - 0s 486us/step - loss: 0.1440 - acc: 0.9600 - val_loss: 0.4183 - val_acc: 0.8100\n",
            "Epoch 3803/4500\n",
            "100/100 [==============================] - 0s 561us/step - loss: 0.1306 - acc: 0.9500 - val_loss: 0.4048 - val_acc: 0.8600\n",
            "Epoch 3804/4500\n",
            "100/100 [==============================] - 0s 508us/step - loss: 0.1215 - acc: 0.9500 - val_loss: 0.3964 - val_acc: 0.8700\n",
            "Epoch 3805/4500\n",
            "100/100 [==============================] - 0s 493us/step - loss: 0.1135 - acc: 0.9600 - val_loss: 0.4126 - val_acc: 0.8600\n",
            "Epoch 3806/4500\n",
            "100/100 [==============================] - 0s 603us/step - loss: 0.1072 - acc: 0.9600 - val_loss: 0.4295 - val_acc: 0.8300\n",
            "Epoch 3807/4500\n",
            "100/100 [==============================] - 0s 480us/step - loss: 0.1097 - acc: 0.9600 - val_loss: 0.4244 - val_acc: 0.8300\n",
            "Epoch 3808/4500\n",
            "100/100 [==============================] - 0s 483us/step - loss: 0.1181 - acc: 0.9500 - val_loss: 0.4100 - val_acc: 0.8600\n",
            "Epoch 3809/4500\n",
            "100/100 [==============================] - 0s 516us/step - loss: 0.1106 - acc: 0.9600 - val_loss: 0.4137 - val_acc: 0.8400\n",
            "Epoch 3810/4500\n",
            "100/100 [==============================] - 0s 490us/step - loss: 0.1083 - acc: 0.9600 - val_loss: 0.4198 - val_acc: 0.8300\n",
            "Epoch 3811/4500\n",
            "100/100 [==============================] - 0s 474us/step - loss: 0.1085 - acc: 0.9600 - val_loss: 0.4136 - val_acc: 0.8400\n",
            "Epoch 3812/4500\n",
            "100/100 [==============================] - 0s 507us/step - loss: 0.1122 - acc: 0.9500 - val_loss: 0.4181 - val_acc: 0.8400\n",
            "Epoch 3813/4500\n",
            "100/100 [==============================] - 0s 582us/step - loss: 0.1135 - acc: 0.9500 - val_loss: 0.4103 - val_acc: 0.8700\n",
            "Epoch 3814/4500\n",
            "100/100 [==============================] - 0s 509us/step - loss: 0.1092 - acc: 0.9500 - val_loss: 0.4113 - val_acc: 0.8700\n",
            "Epoch 3815/4500\n",
            "100/100 [==============================] - 0s 517us/step - loss: 0.1140 - acc: 0.9700 - val_loss: 0.4089 - val_acc: 0.8700\n",
            "Epoch 3816/4500\n",
            "100/100 [==============================] - 0s 566us/step - loss: 0.1049 - acc: 0.9700 - val_loss: 0.4215 - val_acc: 0.8300\n",
            "Epoch 3817/4500\n",
            "100/100 [==============================] - 0s 606us/step - loss: 0.1079 - acc: 0.9500 - val_loss: 0.4128 - val_acc: 0.8600\n",
            "Epoch 3818/4500\n",
            "100/100 [==============================] - 0s 542us/step - loss: 0.1136 - acc: 0.9600 - val_loss: 0.4038 - val_acc: 0.8700\n",
            "Epoch 3819/4500\n",
            "100/100 [==============================] - 0s 550us/step - loss: 0.1144 - acc: 0.9600 - val_loss: 0.4151 - val_acc: 0.8400\n",
            "Epoch 3820/4500\n",
            "100/100 [==============================] - 0s 659us/step - loss: 0.1059 - acc: 0.9600 - val_loss: 0.4297 - val_acc: 0.8300\n",
            "Epoch 3821/4500\n",
            "100/100 [==============================] - 0s 519us/step - loss: 0.1100 - acc: 0.9600 - val_loss: 0.4139 - val_acc: 0.8400\n",
            "Epoch 3822/4500\n",
            "100/100 [==============================] - 0s 525us/step - loss: 0.1065 - acc: 0.9600 - val_loss: 0.4197 - val_acc: 0.8300\n",
            "Epoch 3823/4500\n",
            "100/100 [==============================] - 0s 526us/step - loss: 0.1096 - acc: 0.9600 - val_loss: 0.4118 - val_acc: 0.8400\n",
            "Epoch 3824/4500\n",
            "100/100 [==============================] - 0s 502us/step - loss: 0.1097 - acc: 0.9600 - val_loss: 0.4292 - val_acc: 0.8300\n",
            "Epoch 3825/4500\n",
            "100/100 [==============================] - 0s 544us/step - loss: 0.1116 - acc: 0.9500 - val_loss: 0.4295 - val_acc: 0.8400\n",
            "Epoch 3826/4500\n",
            "100/100 [==============================] - 0s 528us/step - loss: 0.1113 - acc: 0.9600 - val_loss: 0.4084 - val_acc: 0.8700\n",
            "Epoch 3827/4500\n",
            "100/100 [==============================] - 0s 485us/step - loss: 0.1075 - acc: 0.9600 - val_loss: 0.4169 - val_acc: 0.8700\n",
            "Epoch 3828/4500\n",
            "100/100 [==============================] - 0s 486us/step - loss: 0.1149 - acc: 0.9500 - val_loss: 0.4170 - val_acc: 0.8800\n",
            "Epoch 3829/4500\n",
            "100/100 [==============================] - 0s 488us/step - loss: 0.1117 - acc: 0.9600 - val_loss: 0.4129 - val_acc: 0.8800\n",
            "Epoch 3830/4500\n",
            "100/100 [==============================] - 0s 532us/step - loss: 0.1083 - acc: 0.9700 - val_loss: 0.4356 - val_acc: 0.8300\n",
            "Epoch 3831/4500\n",
            "100/100 [==============================] - 0s 483us/step - loss: 0.1134 - acc: 0.9500 - val_loss: 0.4136 - val_acc: 0.8400\n",
            "Epoch 3832/4500\n",
            "100/100 [==============================] - 0s 616us/step - loss: 0.1171 - acc: 0.9600 - val_loss: 0.4207 - val_acc: 0.8400\n",
            "Epoch 3833/4500\n",
            "100/100 [==============================] - 0s 488us/step - loss: 0.1069 - acc: 0.9600 - val_loss: 0.4141 - val_acc: 0.8500\n",
            "Epoch 3834/4500\n",
            "100/100 [==============================] - 0s 493us/step - loss: 0.1028 - acc: 0.9600 - val_loss: 0.4236 - val_acc: 0.8800\n",
            "Epoch 3835/4500\n",
            "100/100 [==============================] - 0s 492us/step - loss: 0.1507 - acc: 0.9400 - val_loss: 0.4393 - val_acc: 0.8300\n",
            "Epoch 3836/4500\n",
            "100/100 [==============================] - 0s 560us/step - loss: 0.1310 - acc: 0.9300 - val_loss: 0.3958 - val_acc: 0.8600\n",
            "Epoch 3837/4500\n",
            "100/100 [==============================] - 0s 488us/step - loss: 0.1164 - acc: 0.9500 - val_loss: 0.4118 - val_acc: 0.8400\n",
            "Epoch 3838/4500\n",
            "100/100 [==============================] - 0s 502us/step - loss: 0.1092 - acc: 0.9600 - val_loss: 0.4311 - val_acc: 0.8400\n",
            "Epoch 3839/4500\n",
            "100/100 [==============================] - 0s 495us/step - loss: 0.1144 - acc: 0.9500 - val_loss: 0.4432 - val_acc: 0.8300\n",
            "Epoch 3840/4500\n",
            "100/100 [==============================] - 0s 536us/step - loss: 0.1103 - acc: 0.9600 - val_loss: 0.4536 - val_acc: 0.8100\n",
            "Epoch 3841/4500\n",
            "100/100 [==============================] - 0s 510us/step - loss: 0.1169 - acc: 0.9600 - val_loss: 0.4332 - val_acc: 0.8400\n",
            "Epoch 3842/4500\n",
            "100/100 [==============================] - 0s 515us/step - loss: 0.1145 - acc: 0.9600 - val_loss: 0.4188 - val_acc: 0.8600\n",
            "Epoch 3843/4500\n",
            "100/100 [==============================] - 0s 507us/step - loss: 0.1148 - acc: 0.9400 - val_loss: 0.4060 - val_acc: 0.8700\n",
            "Epoch 3844/4500\n",
            "100/100 [==============================] - 0s 509us/step - loss: 0.1094 - acc: 0.9600 - val_loss: 0.4161 - val_acc: 0.8700\n",
            "Epoch 3845/4500\n",
            "100/100 [==============================] - 0s 482us/step - loss: 0.1072 - acc: 0.9600 - val_loss: 0.4279 - val_acc: 0.8300\n",
            "Epoch 3846/4500\n",
            "100/100 [==============================] - 0s 490us/step - loss: 0.1059 - acc: 0.9600 - val_loss: 0.4330 - val_acc: 0.8300\n",
            "Epoch 3847/4500\n",
            "100/100 [==============================] - 0s 491us/step - loss: 0.1062 - acc: 0.9600 - val_loss: 0.4392 - val_acc: 0.8200\n",
            "Epoch 3848/4500\n",
            "100/100 [==============================] - 0s 530us/step - loss: 0.1046 - acc: 0.9600 - val_loss: 0.4042 - val_acc: 0.8700\n",
            "Epoch 3849/4500\n",
            "100/100 [==============================] - 0s 634us/step - loss: 0.1087 - acc: 0.9500 - val_loss: 0.4141 - val_acc: 0.8700\n",
            "Epoch 3850/4500\n",
            "100/100 [==============================] - 0s 596us/step - loss: 0.1039 - acc: 0.9600 - val_loss: 0.4478 - val_acc: 0.8200\n",
            "Epoch 3851/4500\n",
            "100/100 [==============================] - 0s 581us/step - loss: 0.1100 - acc: 0.9400 - val_loss: 0.4247 - val_acc: 0.8700\n",
            "Epoch 3852/4500\n",
            "100/100 [==============================] - 0s 522us/step - loss: 0.1230 - acc: 0.9400 - val_loss: 0.4239 - val_acc: 0.8600\n",
            "Epoch 3853/4500\n",
            "100/100 [==============================] - 0s 511us/step - loss: 0.1099 - acc: 0.9600 - val_loss: 0.4132 - val_acc: 0.8800\n",
            "Epoch 3854/4500\n",
            "100/100 [==============================] - 0s 512us/step - loss: 0.1174 - acc: 0.9600 - val_loss: 0.4271 - val_acc: 0.8700\n",
            "Epoch 3855/4500\n",
            "100/100 [==============================] - 0s 561us/step - loss: 0.1041 - acc: 0.9700 - val_loss: 0.4381 - val_acc: 0.8200\n",
            "Epoch 3856/4500\n",
            "100/100 [==============================] - 0s 576us/step - loss: 0.1105 - acc: 0.9500 - val_loss: 0.4074 - val_acc: 0.8700\n",
            "Epoch 3857/4500\n",
            "100/100 [==============================] - 0s 496us/step - loss: 0.1086 - acc: 0.9600 - val_loss: 0.4102 - val_acc: 0.8700\n",
            "Epoch 3858/4500\n",
            "100/100 [==============================] - 0s 479us/step - loss: 0.1074 - acc: 0.9500 - val_loss: 0.4297 - val_acc: 0.8300\n",
            "Epoch 3859/4500\n",
            "100/100 [==============================] - 0s 493us/step - loss: 0.1024 - acc: 0.9600 - val_loss: 0.4214 - val_acc: 0.8700\n",
            "Epoch 3860/4500\n",
            "100/100 [==============================] - 0s 490us/step - loss: 0.1061 - acc: 0.9600 - val_loss: 0.4256 - val_acc: 0.8500\n",
            "Epoch 3861/4500\n",
            "100/100 [==============================] - 0s 525us/step - loss: 0.1024 - acc: 0.9600 - val_loss: 0.4167 - val_acc: 0.8700\n",
            "Epoch 3862/4500\n",
            "100/100 [==============================] - 0s 519us/step - loss: 0.1062 - acc: 0.9700 - val_loss: 0.4315 - val_acc: 0.8300\n",
            "Epoch 3863/4500\n",
            "100/100 [==============================] - 0s 492us/step - loss: 0.1056 - acc: 0.9600 - val_loss: 0.4274 - val_acc: 0.8300\n",
            "Epoch 3864/4500\n",
            "100/100 [==============================] - 0s 529us/step - loss: 0.1196 - acc: 0.9500 - val_loss: 0.4268 - val_acc: 0.8500\n",
            "Epoch 3865/4500\n",
            "100/100 [==============================] - 0s 519us/step - loss: 0.1319 - acc: 0.9400 - val_loss: 0.4060 - val_acc: 0.8700\n",
            "Epoch 3866/4500\n",
            "100/100 [==============================] - 0s 521us/step - loss: 0.1072 - acc: 0.9600 - val_loss: 0.4443 - val_acc: 0.8000\n",
            "Epoch 3867/4500\n",
            "100/100 [==============================] - 0s 498us/step - loss: 0.1146 - acc: 0.9500 - val_loss: 0.4136 - val_acc: 0.8800\n",
            "Epoch 3868/4500\n",
            "100/100 [==============================] - 0s 504us/step - loss: 0.1021 - acc: 0.9600 - val_loss: 0.4319 - val_acc: 0.8300\n",
            "Epoch 3869/4500\n",
            "100/100 [==============================] - 0s 514us/step - loss: 0.1016 - acc: 0.9600 - val_loss: 0.4262 - val_acc: 0.8400\n",
            "Epoch 3870/4500\n",
            "100/100 [==============================] - 0s 562us/step - loss: 0.1020 - acc: 0.9700 - val_loss: 0.4140 - val_acc: 0.8800\n",
            "Epoch 3871/4500\n",
            "100/100 [==============================] - 0s 532us/step - loss: 0.1052 - acc: 0.9800 - val_loss: 0.4279 - val_acc: 0.8400\n",
            "Epoch 3872/4500\n",
            "100/100 [==============================] - 0s 531us/step - loss: 0.1145 - acc: 0.9600 - val_loss: 0.4074 - val_acc: 0.8700\n",
            "Epoch 3873/4500\n",
            "100/100 [==============================] - 0s 492us/step - loss: 0.1042 - acc: 0.9800 - val_loss: 0.4087 - val_acc: 0.8700\n",
            "Epoch 3874/4500\n",
            "100/100 [==============================] - 0s 488us/step - loss: 0.1076 - acc: 0.9500 - val_loss: 0.4241 - val_acc: 0.8500\n",
            "Epoch 3875/4500\n",
            "100/100 [==============================] - 0s 527us/step - loss: 0.1045 - acc: 0.9600 - val_loss: 0.4156 - val_acc: 0.8700\n",
            "Epoch 3876/4500\n",
            "100/100 [==============================] - 0s 509us/step - loss: 0.1096 - acc: 0.9600 - val_loss: 0.4349 - val_acc: 0.8300\n",
            "Epoch 3877/4500\n",
            "100/100 [==============================] - 0s 500us/step - loss: 0.1072 - acc: 0.9600 - val_loss: 0.4270 - val_acc: 0.8300\n",
            "Epoch 3878/4500\n",
            "100/100 [==============================] - 0s 495us/step - loss: 0.1015 - acc: 0.9600 - val_loss: 0.4080 - val_acc: 0.8700\n",
            "Epoch 3879/4500\n",
            "100/100 [==============================] - 0s 494us/step - loss: 0.1041 - acc: 0.9600 - val_loss: 0.4363 - val_acc: 0.8300\n",
            "Epoch 3880/4500\n",
            "100/100 [==============================] - 0s 511us/step - loss: 0.1129 - acc: 0.9600 - val_loss: 0.4187 - val_acc: 0.8800\n",
            "Epoch 3881/4500\n",
            "100/100 [==============================] - 0s 515us/step - loss: 0.1060 - acc: 0.9600 - val_loss: 0.4239 - val_acc: 0.8500\n",
            "Epoch 3882/4500\n",
            "100/100 [==============================] - 0s 500us/step - loss: 0.1071 - acc: 0.9600 - val_loss: 0.4265 - val_acc: 0.8600\n",
            "Epoch 3883/4500\n",
            "100/100 [==============================] - 0s 486us/step - loss: 0.1274 - acc: 0.9500 - val_loss: 0.4407 - val_acc: 0.8100\n",
            "Epoch 3884/4500\n",
            "100/100 [==============================] - 0s 482us/step - loss: 0.1075 - acc: 0.9600 - val_loss: 0.4162 - val_acc: 0.8700\n",
            "Epoch 3885/4500\n",
            "100/100 [==============================] - 0s 513us/step - loss: 0.1045 - acc: 0.9500 - val_loss: 0.4249 - val_acc: 0.8500\n",
            "Epoch 3886/4500\n",
            "100/100 [==============================] - 0s 621us/step - loss: 0.1058 - acc: 0.9600 - val_loss: 0.4442 - val_acc: 0.8200\n",
            "Epoch 3887/4500\n",
            "100/100 [==============================] - 0s 570us/step - loss: 0.1108 - acc: 0.9600 - val_loss: 0.4366 - val_acc: 0.8200\n",
            "Epoch 3888/4500\n",
            "100/100 [==============================] - 0s 539us/step - loss: 0.1011 - acc: 0.9600 - val_loss: 0.4390 - val_acc: 0.8200\n",
            "Epoch 3889/4500\n",
            "100/100 [==============================] - 0s 656us/step - loss: 0.1069 - acc: 0.9500 - val_loss: 0.4368 - val_acc: 0.8300\n",
            "Epoch 3890/4500\n",
            "100/100 [==============================] - 0s 554us/step - loss: 0.1089 - acc: 0.9600 - val_loss: 0.4301 - val_acc: 0.8500\n",
            "Epoch 3891/4500\n",
            "100/100 [==============================] - 0s 488us/step - loss: 0.1037 - acc: 0.9600 - val_loss: 0.4350 - val_acc: 0.8400\n",
            "Epoch 3892/4500\n",
            "100/100 [==============================] - 0s 513us/step - loss: 0.1015 - acc: 0.9600 - val_loss: 0.4179 - val_acc: 0.8700\n",
            "Epoch 3893/4500\n",
            "100/100 [==============================] - 0s 473us/step - loss: 0.1050 - acc: 0.9600 - val_loss: 0.4146 - val_acc: 0.8800\n",
            "Epoch 3894/4500\n",
            "100/100 [==============================] - 0s 502us/step - loss: 0.1045 - acc: 0.9600 - val_loss: 0.4434 - val_acc: 0.8200\n",
            "Epoch 3895/4500\n",
            "100/100 [==============================] - 0s 522us/step - loss: 0.1051 - acc: 0.9500 - val_loss: 0.4244 - val_acc: 0.8500\n",
            "Epoch 3896/4500\n",
            "100/100 [==============================] - 0s 579us/step - loss: 0.1032 - acc: 0.9500 - val_loss: 0.4229 - val_acc: 0.8600\n",
            "Epoch 3897/4500\n",
            "100/100 [==============================] - 0s 538us/step - loss: 0.1041 - acc: 0.9500 - val_loss: 0.4193 - val_acc: 0.8800\n",
            "Epoch 3898/4500\n",
            "100/100 [==============================] - 0s 548us/step - loss: 0.1005 - acc: 0.9700 - val_loss: 0.4232 - val_acc: 0.8600\n",
            "Epoch 3899/4500\n",
            "100/100 [==============================] - 0s 534us/step - loss: 0.1042 - acc: 0.9600 - val_loss: 0.4302 - val_acc: 0.8400\n",
            "Epoch 3900/4500\n",
            "100/100 [==============================] - 0s 534us/step - loss: 0.0982 - acc: 0.9700 - val_loss: 0.4086 - val_acc: 0.8800\n",
            "Epoch 3901/4500\n",
            "100/100 [==============================] - 0s 546us/step - loss: 0.1034 - acc: 0.9700 - val_loss: 0.4270 - val_acc: 0.8500\n",
            "Epoch 3902/4500\n",
            "100/100 [==============================] - 0s 537us/step - loss: 0.1043 - acc: 0.9500 - val_loss: 0.4191 - val_acc: 0.8700\n",
            "Epoch 3903/4500\n",
            "100/100 [==============================] - 0s 547us/step - loss: 0.1041 - acc: 0.9700 - val_loss: 0.4282 - val_acc: 0.8700\n",
            "Epoch 3904/4500\n",
            "100/100 [==============================] - 0s 531us/step - loss: 0.1016 - acc: 0.9600 - val_loss: 0.4349 - val_acc: 0.8200\n",
            "Epoch 3905/4500\n",
            "100/100 [==============================] - 0s 539us/step - loss: 0.1000 - acc: 0.9700 - val_loss: 0.4158 - val_acc: 0.8700\n",
            "Epoch 3906/4500\n",
            "100/100 [==============================] - 0s 494us/step - loss: 0.0982 - acc: 0.9800 - val_loss: 0.4397 - val_acc: 0.8200\n",
            "Epoch 3907/4500\n",
            "100/100 [==============================] - 0s 502us/step - loss: 0.1021 - acc: 0.9600 - val_loss: 0.4327 - val_acc: 0.8400\n",
            "Epoch 3908/4500\n",
            "100/100 [==============================] - 0s 552us/step - loss: 0.0977 - acc: 0.9600 - val_loss: 0.4369 - val_acc: 0.8300\n",
            "Epoch 3909/4500\n",
            "100/100 [==============================] - 0s 534us/step - loss: 0.0986 - acc: 0.9600 - val_loss: 0.4285 - val_acc: 0.8400\n",
            "Epoch 3910/4500\n",
            "100/100 [==============================] - 0s 506us/step - loss: 0.1002 - acc: 0.9500 - val_loss: 0.4334 - val_acc: 0.8500\n",
            "Epoch 3911/4500\n",
            "100/100 [==============================] - 0s 547us/step - loss: 0.1039 - acc: 0.9700 - val_loss: 0.4422 - val_acc: 0.8400\n",
            "Epoch 3912/4500\n",
            "100/100 [==============================] - 0s 514us/step - loss: 0.1216 - acc: 0.9400 - val_loss: 0.4377 - val_acc: 0.8100\n",
            "Epoch 3913/4500\n",
            "100/100 [==============================] - 0s 517us/step - loss: 0.1222 - acc: 0.9500 - val_loss: 0.4163 - val_acc: 0.8800\n",
            "Epoch 3914/4500\n",
            "100/100 [==============================] - 0s 510us/step - loss: 0.1012 - acc: 0.9700 - val_loss: 0.4420 - val_acc: 0.8700\n",
            "Epoch 3915/4500\n",
            "100/100 [==============================] - 0s 542us/step - loss: 0.1251 - acc: 0.9500 - val_loss: 0.4407 - val_acc: 0.8400\n",
            "Epoch 3916/4500\n",
            "100/100 [==============================] - 0s 535us/step - loss: 0.1237 - acc: 0.9500 - val_loss: 0.4352 - val_acc: 0.8400\n",
            "Epoch 3917/4500\n",
            "100/100 [==============================] - 0s 505us/step - loss: 0.1107 - acc: 0.9600 - val_loss: 0.4240 - val_acc: 0.8200\n",
            "Epoch 3918/4500\n",
            "100/100 [==============================] - 0s 514us/step - loss: 0.1071 - acc: 0.9700 - val_loss: 0.4273 - val_acc: 0.8300\n",
            "Epoch 3919/4500\n",
            "100/100 [==============================] - 0s 495us/step - loss: 0.1070 - acc: 0.9500 - val_loss: 0.4400 - val_acc: 0.8400\n",
            "Epoch 3920/4500\n",
            "100/100 [==============================] - 0s 484us/step - loss: 0.1031 - acc: 0.9600 - val_loss: 0.4246 - val_acc: 0.8700\n",
            "Epoch 3921/4500\n",
            "100/100 [==============================] - 0s 504us/step - loss: 0.1015 - acc: 0.9600 - val_loss: 0.4339 - val_acc: 0.8400\n",
            "Epoch 3922/4500\n",
            "100/100 [==============================] - 0s 493us/step - loss: 0.0974 - acc: 0.9700 - val_loss: 0.4418 - val_acc: 0.8300\n",
            "Epoch 3923/4500\n",
            "100/100 [==============================] - 0s 539us/step - loss: 0.0970 - acc: 0.9600 - val_loss: 0.4486 - val_acc: 0.8200\n",
            "Epoch 3924/4500\n",
            "100/100 [==============================] - 0s 503us/step - loss: 0.0984 - acc: 0.9600 - val_loss: 0.4315 - val_acc: 0.8600\n",
            "Epoch 3925/4500\n",
            "100/100 [==============================] - 0s 589us/step - loss: 0.0985 - acc: 0.9700 - val_loss: 0.4331 - val_acc: 0.8500\n",
            "Epoch 3926/4500\n",
            "100/100 [==============================] - 0s 553us/step - loss: 0.0985 - acc: 0.9600 - val_loss: 0.4216 - val_acc: 0.8700\n",
            "Epoch 3927/4500\n",
            "100/100 [==============================] - 0s 535us/step - loss: 0.0960 - acc: 0.9800 - val_loss: 0.4530 - val_acc: 0.8100\n",
            "Epoch 3928/4500\n",
            "100/100 [==============================] - 0s 624us/step - loss: 0.1023 - acc: 0.9600 - val_loss: 0.4261 - val_acc: 0.8600\n",
            "Epoch 3929/4500\n",
            "100/100 [==============================] - 0s 507us/step - loss: 0.1024 - acc: 0.9700 - val_loss: 0.4301 - val_acc: 0.8400\n",
            "Epoch 3930/4500\n",
            "100/100 [==============================] - 0s 482us/step - loss: 0.1001 - acc: 0.9600 - val_loss: 0.4391 - val_acc: 0.8300\n",
            "Epoch 3931/4500\n",
            "100/100 [==============================] - 0s 476us/step - loss: 0.0972 - acc: 0.9600 - val_loss: 0.4310 - val_acc: 0.8500\n",
            "Epoch 3932/4500\n",
            "100/100 [==============================] - 0s 488us/step - loss: 0.1065 - acc: 0.9700 - val_loss: 0.4598 - val_acc: 0.8200\n",
            "Epoch 3933/4500\n",
            "100/100 [==============================] - 0s 527us/step - loss: 0.1523 - acc: 0.9200 - val_loss: 0.4743 - val_acc: 0.8000\n",
            "Epoch 3934/4500\n",
            "100/100 [==============================] - 0s 521us/step - loss: 0.1172 - acc: 0.9600 - val_loss: 0.4024 - val_acc: 0.8700\n",
            "Epoch 3935/4500\n",
            "100/100 [==============================] - 0s 638us/step - loss: 0.1028 - acc: 0.9600 - val_loss: 0.4509 - val_acc: 0.8100\n",
            "Epoch 3936/4500\n",
            "100/100 [==============================] - 0s 525us/step - loss: 0.0972 - acc: 0.9600 - val_loss: 0.4342 - val_acc: 0.8500\n",
            "Epoch 3937/4500\n",
            "100/100 [==============================] - 0s 498us/step - loss: 0.0998 - acc: 0.9600 - val_loss: 0.4405 - val_acc: 0.8600\n",
            "Epoch 3938/4500\n",
            "100/100 [==============================] - 0s 506us/step - loss: 0.1183 - acc: 0.9500 - val_loss: 0.4429 - val_acc: 0.8400\n",
            "Epoch 3939/4500\n",
            "100/100 [==============================] - 0s 480us/step - loss: 0.1205 - acc: 0.9400 - val_loss: 0.4524 - val_acc: 0.7900\n",
            "Epoch 3940/4500\n",
            "100/100 [==============================] - 0s 487us/step - loss: 0.1021 - acc: 0.9700 - val_loss: 0.4136 - val_acc: 0.8700\n",
            "Epoch 3941/4500\n",
            "100/100 [==============================] - 0s 527us/step - loss: 0.0999 - acc: 0.9800 - val_loss: 0.4299 - val_acc: 0.8300\n",
            "Epoch 3942/4500\n",
            "100/100 [==============================] - 0s 545us/step - loss: 0.0975 - acc: 0.9700 - val_loss: 0.4384 - val_acc: 0.8300\n",
            "Epoch 3943/4500\n",
            "100/100 [==============================] - 0s 505us/step - loss: 0.0980 - acc: 0.9700 - val_loss: 0.4533 - val_acc: 0.8200\n",
            "Epoch 3944/4500\n",
            "100/100 [==============================] - 0s 499us/step - loss: 0.0970 - acc: 0.9600 - val_loss: 0.4469 - val_acc: 0.8200\n",
            "Epoch 3945/4500\n",
            "100/100 [==============================] - 0s 583us/step - loss: 0.0973 - acc: 0.9600 - val_loss: 0.4479 - val_acc: 0.8300\n",
            "Epoch 3946/4500\n",
            "100/100 [==============================] - 0s 524us/step - loss: 0.1008 - acc: 0.9600 - val_loss: 0.4302 - val_acc: 0.8500\n",
            "Epoch 3947/4500\n",
            "100/100 [==============================] - 0s 602us/step - loss: 0.0992 - acc: 0.9600 - val_loss: 0.4218 - val_acc: 0.8700\n",
            "Epoch 3948/4500\n",
            "100/100 [==============================] - 0s 500us/step - loss: 0.0995 - acc: 0.9700 - val_loss: 0.4391 - val_acc: 0.8500\n",
            "Epoch 3949/4500\n",
            "100/100 [==============================] - 0s 482us/step - loss: 0.0952 - acc: 0.9600 - val_loss: 0.4424 - val_acc: 0.8500\n",
            "Epoch 3950/4500\n",
            "100/100 [==============================] - 0s 516us/step - loss: 0.0985 - acc: 0.9600 - val_loss: 0.4399 - val_acc: 0.8500\n",
            "Epoch 3951/4500\n",
            "100/100 [==============================] - 0s 501us/step - loss: 0.1083 - acc: 0.9600 - val_loss: 0.4366 - val_acc: 0.8300\n",
            "Epoch 3952/4500\n",
            "100/100 [==============================] - 0s 515us/step - loss: 0.0918 - acc: 0.9800 - val_loss: 0.4134 - val_acc: 0.8800\n",
            "Epoch 3953/4500\n",
            "100/100 [==============================] - 0s 511us/step - loss: 0.0976 - acc: 0.9600 - val_loss: 0.4407 - val_acc: 0.8300\n",
            "Epoch 3954/4500\n",
            "100/100 [==============================] - 0s 499us/step - loss: 0.0953 - acc: 0.9600 - val_loss: 0.4397 - val_acc: 0.8500\n",
            "Epoch 3955/4500\n",
            "100/100 [==============================] - 0s 533us/step - loss: 0.0997 - acc: 0.9700 - val_loss: 0.4348 - val_acc: 0.8500\n",
            "Epoch 3956/4500\n",
            "100/100 [==============================] - 0s 510us/step - loss: 0.0971 - acc: 0.9700 - val_loss: 0.4464 - val_acc: 0.8200\n",
            "Epoch 3957/4500\n",
            "100/100 [==============================] - 0s 498us/step - loss: 0.0976 - acc: 0.9600 - val_loss: 0.4312 - val_acc: 0.8600\n",
            "Epoch 3958/4500\n",
            "100/100 [==============================] - 0s 482us/step - loss: 0.1016 - acc: 0.9600 - val_loss: 0.4404 - val_acc: 0.8500\n",
            "Epoch 3959/4500\n",
            "100/100 [==============================] - 0s 526us/step - loss: 0.1006 - acc: 0.9500 - val_loss: 0.4291 - val_acc: 0.8600\n",
            "Epoch 3960/4500\n",
            "100/100 [==============================] - 0s 529us/step - loss: 0.0929 - acc: 0.9800 - val_loss: 0.4244 - val_acc: 0.8800\n",
            "Epoch 3961/4500\n",
            "100/100 [==============================] - 0s 494us/step - loss: 0.1084 - acc: 0.9600 - val_loss: 0.4589 - val_acc: 0.8100\n",
            "Epoch 3962/4500\n",
            "100/100 [==============================] - 0s 501us/step - loss: 0.1184 - acc: 0.9600 - val_loss: 0.4571 - val_acc: 0.8600\n",
            "Epoch 3963/4500\n",
            "100/100 [==============================] - 0s 520us/step - loss: 0.1854 - acc: 0.9100 - val_loss: 0.3850 - val_acc: 0.8600\n",
            "Epoch 3964/4500\n",
            "100/100 [==============================] - 0s 527us/step - loss: 0.1340 - acc: 0.9400 - val_loss: 0.4144 - val_acc: 0.8500\n",
            "Epoch 3965/4500\n",
            "100/100 [==============================] - 0s 600us/step - loss: 0.1316 - acc: 0.9600 - val_loss: 0.4167 - val_acc: 0.8600\n",
            "Epoch 3966/4500\n",
            "100/100 [==============================] - 0s 576us/step - loss: 0.1176 - acc: 0.9600 - val_loss: 0.4226 - val_acc: 0.8800\n",
            "Epoch 3967/4500\n",
            "100/100 [==============================] - 0s 503us/step - loss: 0.0915 - acc: 0.9700 - val_loss: 0.5128 - val_acc: 0.8100\n",
            "Epoch 3968/4500\n",
            "100/100 [==============================] - 0s 515us/step - loss: 0.1022 - acc: 0.9500 - val_loss: 0.4539 - val_acc: 0.8500\n",
            "Epoch 3969/4500\n",
            "100/100 [==============================] - 0s 516us/step - loss: 0.0977 - acc: 0.9700 - val_loss: 0.4521 - val_acc: 0.8200\n",
            "Epoch 3970/4500\n",
            "100/100 [==============================] - 0s 503us/step - loss: 0.0980 - acc: 0.9600 - val_loss: 0.4406 - val_acc: 0.8700\n",
            "Epoch 3971/4500\n",
            "100/100 [==============================] - 0s 509us/step - loss: 0.0964 - acc: 0.9700 - val_loss: 0.4497 - val_acc: 0.8400\n",
            "Epoch 3972/4500\n",
            "100/100 [==============================] - 0s 488us/step - loss: 0.0930 - acc: 0.9600 - val_loss: 0.4583 - val_acc: 0.8700\n",
            "Epoch 3973/4500\n",
            "100/100 [==============================] - 0s 497us/step - loss: 0.1112 - acc: 0.9600 - val_loss: 0.4638 - val_acc: 0.8100\n",
            "Epoch 3974/4500\n",
            "100/100 [==============================] - 0s 491us/step - loss: 0.0984 - acc: 0.9700 - val_loss: 0.4370 - val_acc: 0.8800\n",
            "Epoch 3975/4500\n",
            "100/100 [==============================] - 0s 532us/step - loss: 0.1128 - acc: 0.9600 - val_loss: 0.4419 - val_acc: 0.8500\n",
            "Epoch 3976/4500\n",
            "100/100 [==============================] - 0s 510us/step - loss: 0.1041 - acc: 0.9500 - val_loss: 0.4835 - val_acc: 0.8100\n",
            "Epoch 3977/4500\n",
            "100/100 [==============================] - 0s 553us/step - loss: 0.1042 - acc: 0.9500 - val_loss: 0.4554 - val_acc: 0.8200\n",
            "Epoch 3978/4500\n",
            "100/100 [==============================] - 0s 488us/step - loss: 0.0988 - acc: 0.9500 - val_loss: 0.4534 - val_acc: 0.8300\n",
            "Epoch 3979/4500\n",
            "100/100 [==============================] - 0s 485us/step - loss: 0.0955 - acc: 0.9600 - val_loss: 0.4424 - val_acc: 0.8600\n",
            "Epoch 3980/4500\n",
            "100/100 [==============================] - 0s 513us/step - loss: 0.0932 - acc: 0.9700 - val_loss: 0.4610 - val_acc: 0.8200\n",
            "Epoch 3981/4500\n",
            "100/100 [==============================] - 0s 504us/step - loss: 0.0937 - acc: 0.9600 - val_loss: 0.4573 - val_acc: 0.8300\n",
            "Epoch 3982/4500\n",
            "100/100 [==============================] - 0s 502us/step - loss: 0.0926 - acc: 0.9600 - val_loss: 0.4462 - val_acc: 0.8500\n",
            "Epoch 3983/4500\n",
            "100/100 [==============================] - 0s 498us/step - loss: 0.0941 - acc: 0.9700 - val_loss: 0.4552 - val_acc: 0.8300\n",
            "Epoch 3984/4500\n",
            "100/100 [==============================] - 0s 489us/step - loss: 0.0945 - acc: 0.9600 - val_loss: 0.4561 - val_acc: 0.8300\n",
            "Epoch 3985/4500\n",
            "100/100 [==============================] - 0s 541us/step - loss: 0.0919 - acc: 0.9700 - val_loss: 0.4475 - val_acc: 0.8300\n",
            "Epoch 3986/4500\n",
            "100/100 [==============================] - 0s 576us/step - loss: 0.0985 - acc: 0.9600 - val_loss: 0.4499 - val_acc: 0.8300\n",
            "Epoch 3987/4500\n",
            "100/100 [==============================] - 0s 507us/step - loss: 0.0979 - acc: 0.9600 - val_loss: 0.4384 - val_acc: 0.8800\n",
            "Epoch 3988/4500\n",
            "100/100 [==============================] - 0s 492us/step - loss: 0.1020 - acc: 0.9700 - val_loss: 0.4573 - val_acc: 0.8200\n",
            "Epoch 3989/4500\n",
            "100/100 [==============================] - 0s 504us/step - loss: 0.0915 - acc: 0.9600 - val_loss: 0.4353 - val_acc: 0.8700\n",
            "Epoch 3990/4500\n",
            "100/100 [==============================] - 0s 489us/step - loss: 0.0909 - acc: 0.9800 - val_loss: 0.4467 - val_acc: 0.8500\n",
            "Epoch 3991/4500\n",
            "100/100 [==============================] - 0s 497us/step - loss: 0.0919 - acc: 0.9600 - val_loss: 0.4467 - val_acc: 0.8400\n",
            "Epoch 3992/4500\n",
            "100/100 [==============================] - 0s 510us/step - loss: 0.0912 - acc: 0.9700 - val_loss: 0.4436 - val_acc: 0.8500\n",
            "Epoch 3993/4500\n",
            "100/100 [==============================] - 0s 514us/step - loss: 0.0925 - acc: 0.9700 - val_loss: 0.4463 - val_acc: 0.8500\n",
            "Epoch 3994/4500\n",
            "100/100 [==============================] - 0s 510us/step - loss: 0.0937 - acc: 0.9600 - val_loss: 0.4544 - val_acc: 0.8200\n",
            "Epoch 3995/4500\n",
            "100/100 [==============================] - 0s 620us/step - loss: 0.0940 - acc: 0.9700 - val_loss: 0.4433 - val_acc: 0.8300\n",
            "Epoch 3996/4500\n",
            "100/100 [==============================] - 0s 518us/step - loss: 0.0949 - acc: 0.9600 - val_loss: 0.4401 - val_acc: 0.8500\n",
            "Epoch 3997/4500\n",
            "100/100 [==============================] - 0s 495us/step - loss: 0.0907 - acc: 0.9700 - val_loss: 0.4445 - val_acc: 0.8400\n",
            "Epoch 3998/4500\n",
            "100/100 [==============================] - 0s 499us/step - loss: 0.0931 - acc: 0.9600 - val_loss: 0.4430 - val_acc: 0.8600\n",
            "Epoch 3999/4500\n",
            "100/100 [==============================] - 0s 497us/step - loss: 0.0913 - acc: 0.9700 - val_loss: 0.4346 - val_acc: 0.8600\n",
            "Epoch 4000/4500\n",
            "100/100 [==============================] - 0s 490us/step - loss: 0.0918 - acc: 0.9700 - val_loss: 0.4576 - val_acc: 0.8300\n",
            "Epoch 4001/4500\n",
            "100/100 [==============================] - 0s 509us/step - loss: 0.0888 - acc: 0.9600 - val_loss: 0.4421 - val_acc: 0.8600\n",
            "Epoch 4002/4500\n",
            "100/100 [==============================] - 0s 518us/step - loss: 0.0910 - acc: 0.9700 - val_loss: 0.4525 - val_acc: 0.8200\n",
            "Epoch 4003/4500\n",
            "100/100 [==============================] - 0s 500us/step - loss: 0.0933 - acc: 0.9600 - val_loss: 0.4442 - val_acc: 0.8400\n",
            "Epoch 4004/4500\n",
            "100/100 [==============================] - 0s 495us/step - loss: 0.0919 - acc: 0.9600 - val_loss: 0.4420 - val_acc: 0.8700\n",
            "Epoch 4005/4500\n",
            "100/100 [==============================] - 0s 637us/step - loss: 0.1007 - acc: 0.9700 - val_loss: 0.4420 - val_acc: 0.8600\n",
            "Epoch 4006/4500\n",
            "100/100 [==============================] - 0s 520us/step - loss: 0.0902 - acc: 0.9700 - val_loss: 0.4426 - val_acc: 0.8600\n",
            "Epoch 4007/4500\n",
            "100/100 [==============================] - 0s 505us/step - loss: 0.0925 - acc: 0.9700 - val_loss: 0.4464 - val_acc: 0.8500\n",
            "Epoch 4008/4500\n",
            "100/100 [==============================] - 0s 521us/step - loss: 0.0882 - acc: 0.9700 - val_loss: 0.4527 - val_acc: 0.8400\n",
            "Epoch 4009/4500\n",
            "100/100 [==============================] - 0s 530us/step - loss: 0.0904 - acc: 0.9800 - val_loss: 0.4384 - val_acc: 0.8600\n",
            "Epoch 4010/4500\n",
            "100/100 [==============================] - 0s 504us/step - loss: 0.0973 - acc: 0.9600 - val_loss: 0.4387 - val_acc: 0.8600\n",
            "Epoch 4011/4500\n",
            "100/100 [==============================] - 0s 497us/step - loss: 0.0933 - acc: 0.9700 - val_loss: 0.4445 - val_acc: 0.8500\n",
            "Epoch 4012/4500\n",
            "100/100 [==============================] - 0s 480us/step - loss: 0.0959 - acc: 0.9600 - val_loss: 0.4444 - val_acc: 0.8500\n",
            "Epoch 4013/4500\n",
            "100/100 [==============================] - 0s 492us/step - loss: 0.0900 - acc: 0.9800 - val_loss: 0.4455 - val_acc: 0.8600\n",
            "Epoch 4014/4500\n",
            "100/100 [==============================] - 0s 540us/step - loss: 0.0912 - acc: 0.9600 - val_loss: 0.4526 - val_acc: 0.8400\n",
            "Epoch 4015/4500\n",
            "100/100 [==============================] - 0s 559us/step - loss: 0.0902 - acc: 0.9800 - val_loss: 0.4478 - val_acc: 0.8500\n",
            "Epoch 4016/4500\n",
            "100/100 [==============================] - 0s 484us/step - loss: 0.0903 - acc: 0.9600 - val_loss: 0.4583 - val_acc: 0.8200\n",
            "Epoch 4017/4500\n",
            "100/100 [==============================] - 0s 518us/step - loss: 0.0918 - acc: 0.9600 - val_loss: 0.4380 - val_acc: 0.8700\n",
            "Epoch 4018/4500\n",
            "100/100 [==============================] - 0s 532us/step - loss: 0.0922 - acc: 0.9800 - val_loss: 0.4489 - val_acc: 0.8500\n",
            "Epoch 4019/4500\n",
            "100/100 [==============================] - 0s 524us/step - loss: 0.0895 - acc: 0.9700 - val_loss: 0.4681 - val_acc: 0.8100\n",
            "Epoch 4020/4500\n",
            "100/100 [==============================] - 0s 535us/step - loss: 0.0891 - acc: 0.9700 - val_loss: 0.4399 - val_acc: 0.8700\n",
            "Epoch 4021/4500\n",
            "100/100 [==============================] - 0s 529us/step - loss: 0.0911 - acc: 0.9600 - val_loss: 0.4526 - val_acc: 0.8400\n",
            "Epoch 4022/4500\n",
            "100/100 [==============================] - 0s 494us/step - loss: 0.0894 - acc: 0.9600 - val_loss: 0.4420 - val_acc: 0.8600\n",
            "Epoch 4023/4500\n",
            "100/100 [==============================] - 0s 531us/step - loss: 0.0944 - acc: 0.9600 - val_loss: 0.4463 - val_acc: 0.8500\n",
            "Epoch 4024/4500\n",
            "100/100 [==============================] - 0s 602us/step - loss: 0.0871 - acc: 0.9800 - val_loss: 0.4374 - val_acc: 0.8700\n",
            "Epoch 4025/4500\n",
            "100/100 [==============================] - 0s 518us/step - loss: 0.0898 - acc: 0.9700 - val_loss: 0.4639 - val_acc: 0.8200\n",
            "Epoch 4026/4500\n",
            "100/100 [==============================] - 0s 523us/step - loss: 0.0882 - acc: 0.9700 - val_loss: 0.4565 - val_acc: 0.8300\n",
            "Epoch 4027/4500\n",
            "100/100 [==============================] - 0s 502us/step - loss: 0.0910 - acc: 0.9600 - val_loss: 0.4482 - val_acc: 0.8400\n",
            "Epoch 4028/4500\n",
            "100/100 [==============================] - 0s 512us/step - loss: 0.0873 - acc: 0.9600 - val_loss: 0.4453 - val_acc: 0.8600\n",
            "Epoch 4029/4500\n",
            "100/100 [==============================] - 0s 514us/step - loss: 0.0990 - acc: 0.9700 - val_loss: 0.4484 - val_acc: 0.8500\n",
            "Epoch 4030/4500\n",
            "100/100 [==============================] - 0s 499us/step - loss: 0.0872 - acc: 0.9700 - val_loss: 0.4623 - val_acc: 0.8200\n",
            "Epoch 4031/4500\n",
            "100/100 [==============================] - 0s 504us/step - loss: 0.0934 - acc: 0.9800 - val_loss: 0.4576 - val_acc: 0.8400\n",
            "Epoch 4032/4500\n",
            "100/100 [==============================] - 0s 520us/step - loss: 0.0911 - acc: 0.9700 - val_loss: 0.4556 - val_acc: 0.8300\n",
            "Epoch 4033/4500\n",
            "100/100 [==============================] - 0s 519us/step - loss: 0.0867 - acc: 0.9600 - val_loss: 0.4463 - val_acc: 0.8400\n",
            "Epoch 4034/4500\n",
            "100/100 [==============================] - 0s 502us/step - loss: 0.0912 - acc: 0.9600 - val_loss: 0.4717 - val_acc: 0.8400\n",
            "Epoch 4035/4500\n",
            "100/100 [==============================] - 0s 596us/step - loss: 0.0936 - acc: 0.9500 - val_loss: 0.4555 - val_acc: 0.8600\n",
            "Epoch 4036/4500\n",
            "100/100 [==============================] - 0s 528us/step - loss: 0.1169 - acc: 0.9200 - val_loss: 0.4476 - val_acc: 0.8300\n",
            "Epoch 4037/4500\n",
            "100/100 [==============================] - 0s 510us/step - loss: 0.0931 - acc: 0.9700 - val_loss: 0.4378 - val_acc: 0.8400\n",
            "Epoch 4038/4500\n",
            "100/100 [==============================] - 0s 505us/step - loss: 0.0903 - acc: 0.9700 - val_loss: 0.4780 - val_acc: 0.8000\n",
            "Epoch 4039/4500\n",
            "100/100 [==============================] - 0s 553us/step - loss: 0.1141 - acc: 0.9400 - val_loss: 0.4660 - val_acc: 0.8300\n",
            "Epoch 4040/4500\n",
            "100/100 [==============================] - 0s 530us/step - loss: 0.1126 - acc: 0.9700 - val_loss: 0.4282 - val_acc: 0.8800\n",
            "Epoch 4041/4500\n",
            "100/100 [==============================] - 0s 502us/step - loss: 0.1095 - acc: 0.9500 - val_loss: 0.4505 - val_acc: 0.8700\n",
            "Epoch 4042/4500\n",
            "100/100 [==============================] - 0s 509us/step - loss: 0.0946 - acc: 0.9600 - val_loss: 0.4586 - val_acc: 0.8400\n",
            "Epoch 4043/4500\n",
            "100/100 [==============================] - 0s 621us/step - loss: 0.0879 - acc: 0.9600 - val_loss: 0.4725 - val_acc: 0.8400\n",
            "Epoch 4044/4500\n",
            "100/100 [==============================] - 0s 499us/step - loss: 0.0891 - acc: 0.9600 - val_loss: 0.4653 - val_acc: 0.8300\n",
            "Epoch 4045/4500\n",
            "100/100 [==============================] - 0s 546us/step - loss: 0.0923 - acc: 0.9600 - val_loss: 0.4563 - val_acc: 0.8400\n",
            "Epoch 4046/4500\n",
            "100/100 [==============================] - 0s 500us/step - loss: 0.0932 - acc: 0.9600 - val_loss: 0.4477 - val_acc: 0.8800\n",
            "Epoch 4047/4500\n",
            "100/100 [==============================] - 0s 511us/step - loss: 0.0945 - acc: 0.9600 - val_loss: 0.4660 - val_acc: 0.8300\n",
            "Epoch 4048/4500\n",
            "100/100 [==============================] - 0s 594us/step - loss: 0.0912 - acc: 0.9800 - val_loss: 0.4578 - val_acc: 0.8400\n",
            "Epoch 4049/4500\n",
            "100/100 [==============================] - 0s 572us/step - loss: 0.0865 - acc: 0.9700 - val_loss: 0.4539 - val_acc: 0.8400\n",
            "Epoch 4050/4500\n",
            "100/100 [==============================] - 0s 495us/step - loss: 0.1044 - acc: 0.9700 - val_loss: 0.4701 - val_acc: 0.8100\n",
            "Epoch 4051/4500\n",
            "100/100 [==============================] - 0s 497us/step - loss: 0.0867 - acc: 0.9600 - val_loss: 0.4716 - val_acc: 0.8000\n",
            "Epoch 4052/4500\n",
            "100/100 [==============================] - 0s 502us/step - loss: 0.0915 - acc: 0.9600 - val_loss: 0.4544 - val_acc: 0.8500\n",
            "Epoch 4053/4500\n",
            "100/100 [==============================] - 0s 509us/step - loss: 0.0908 - acc: 0.9600 - val_loss: 0.4486 - val_acc: 0.8500\n",
            "Epoch 4054/4500\n",
            "100/100 [==============================] - 0s 525us/step - loss: 0.0874 - acc: 0.9800 - val_loss: 0.4525 - val_acc: 0.8600\n",
            "Epoch 4055/4500\n",
            "100/100 [==============================] - 0s 598us/step - loss: 0.0858 - acc: 0.9800 - val_loss: 0.4551 - val_acc: 0.8400\n",
            "Epoch 4056/4500\n",
            "100/100 [==============================] - 0s 502us/step - loss: 0.0902 - acc: 0.9700 - val_loss: 0.4853 - val_acc: 0.8100\n",
            "Epoch 4057/4500\n",
            "100/100 [==============================] - 0s 500us/step - loss: 0.0885 - acc: 0.9600 - val_loss: 0.4587 - val_acc: 0.8400\n",
            "Epoch 4058/4500\n",
            "100/100 [==============================] - 0s 532us/step - loss: 0.0854 - acc: 0.9800 - val_loss: 0.4557 - val_acc: 0.8600\n",
            "Epoch 4059/4500\n",
            "100/100 [==============================] - 0s 499us/step - loss: 0.0853 - acc: 0.9800 - val_loss: 0.4581 - val_acc: 0.8400\n",
            "Epoch 4060/4500\n",
            "100/100 [==============================] - 0s 480us/step - loss: 0.0942 - acc: 0.9600 - val_loss: 0.4404 - val_acc: 0.8500\n",
            "Epoch 4061/4500\n",
            "100/100 [==============================] - 0s 517us/step - loss: 0.0902 - acc: 0.9600 - val_loss: 0.4600 - val_acc: 0.8500\n",
            "Epoch 4062/4500\n",
            "100/100 [==============================] - 0s 578us/step - loss: 0.0947 - acc: 0.9700 - val_loss: 0.4535 - val_acc: 0.8500\n",
            "Epoch 4063/4500\n",
            "100/100 [==============================] - 0s 540us/step - loss: 0.0890 - acc: 0.9800 - val_loss: 0.4505 - val_acc: 0.8600\n",
            "Epoch 4064/4500\n",
            "100/100 [==============================] - 0s 579us/step - loss: 0.0869 - acc: 0.9800 - val_loss: 0.4712 - val_acc: 0.8400\n",
            "Epoch 4065/4500\n",
            "100/100 [==============================] - 0s 622us/step - loss: 0.0939 - acc: 0.9500 - val_loss: 0.4578 - val_acc: 0.8400\n",
            "Epoch 4066/4500\n",
            "100/100 [==============================] - 0s 510us/step - loss: 0.0870 - acc: 0.9700 - val_loss: 0.4754 - val_acc: 0.8100\n",
            "Epoch 4067/4500\n",
            "100/100 [==============================] - 0s 478us/step - loss: 0.0857 - acc: 0.9800 - val_loss: 0.4644 - val_acc: 0.8400\n",
            "Epoch 4068/4500\n",
            "100/100 [==============================] - 0s 490us/step - loss: 0.0841 - acc: 0.9700 - val_loss: 0.4602 - val_acc: 0.8400\n",
            "Epoch 4069/4500\n",
            "100/100 [==============================] - 0s 585us/step - loss: 0.0867 - acc: 0.9800 - val_loss: 0.4628 - val_acc: 0.8400\n",
            "Epoch 4070/4500\n",
            "100/100 [==============================] - 0s 506us/step - loss: 0.0848 - acc: 0.9700 - val_loss: 0.4632 - val_acc: 0.8300\n",
            "Epoch 4071/4500\n",
            "100/100 [==============================] - 0s 515us/step - loss: 0.0845 - acc: 0.9600 - val_loss: 0.4601 - val_acc: 0.8400\n",
            "Epoch 4072/4500\n",
            "100/100 [==============================] - 0s 512us/step - loss: 0.0841 - acc: 0.9700 - val_loss: 0.4564 - val_acc: 0.8400\n",
            "Epoch 4073/4500\n",
            "100/100 [==============================] - 0s 496us/step - loss: 0.0833 - acc: 0.9700 - val_loss: 0.4605 - val_acc: 0.8400\n",
            "Epoch 4074/4500\n",
            "100/100 [==============================] - 0s 522us/step - loss: 0.0850 - acc: 0.9800 - val_loss: 0.4728 - val_acc: 0.8200\n",
            "Epoch 4075/4500\n",
            "100/100 [==============================] - 0s 509us/step - loss: 0.0849 - acc: 0.9600 - val_loss: 0.4613 - val_acc: 0.8400\n",
            "Epoch 4076/4500\n",
            "100/100 [==============================] - 0s 537us/step - loss: 0.0845 - acc: 0.9600 - val_loss: 0.4484 - val_acc: 0.8700\n",
            "Epoch 4077/4500\n",
            "100/100 [==============================] - 0s 541us/step - loss: 0.0885 - acc: 0.9700 - val_loss: 0.4705 - val_acc: 0.8400\n",
            "Epoch 4078/4500\n",
            "100/100 [==============================] - 0s 503us/step - loss: 0.0835 - acc: 0.9800 - val_loss: 0.4775 - val_acc: 0.8100\n",
            "Epoch 4079/4500\n",
            "100/100 [==============================] - 0s 493us/step - loss: 0.0828 - acc: 0.9600 - val_loss: 0.4555 - val_acc: 0.8400\n",
            "Epoch 4080/4500\n",
            "100/100 [==============================] - 0s 506us/step - loss: 0.0843 - acc: 0.9800 - val_loss: 0.4437 - val_acc: 0.8700\n",
            "Epoch 4081/4500\n",
            "100/100 [==============================] - 0s 558us/step - loss: 0.0870 - acc: 0.9600 - val_loss: 0.4800 - val_acc: 0.8100\n",
            "Epoch 4082/4500\n",
            "100/100 [==============================] - 0s 519us/step - loss: 0.0863 - acc: 0.9600 - val_loss: 0.4636 - val_acc: 0.8400\n",
            "Epoch 4083/4500\n",
            "100/100 [==============================] - 0s 481us/step - loss: 0.0841 - acc: 0.9700 - val_loss: 0.4600 - val_acc: 0.8500\n",
            "Epoch 4084/4500\n",
            "100/100 [==============================] - 0s 536us/step - loss: 0.0877 - acc: 0.9700 - val_loss: 0.4757 - val_acc: 0.8300\n",
            "Epoch 4085/4500\n",
            "100/100 [==============================] - 0s 500us/step - loss: 0.0867 - acc: 0.9600 - val_loss: 0.4644 - val_acc: 0.8400\n",
            "Epoch 4086/4500\n",
            "100/100 [==============================] - 0s 495us/step - loss: 0.0836 - acc: 0.9700 - val_loss: 0.4571 - val_acc: 0.8500\n",
            "Epoch 4087/4500\n",
            "100/100 [==============================] - 0s 485us/step - loss: 0.0840 - acc: 0.9800 - val_loss: 0.4718 - val_acc: 0.8400\n",
            "Epoch 4088/4500\n",
            "100/100 [==============================] - 0s 485us/step - loss: 0.0825 - acc: 0.9800 - val_loss: 0.4758 - val_acc: 0.8300\n",
            "Epoch 4089/4500\n",
            "100/100 [==============================] - 0s 514us/step - loss: 0.0890 - acc: 0.9700 - val_loss: 0.4446 - val_acc: 0.8700\n",
            "Epoch 4090/4500\n",
            "100/100 [==============================] - 0s 497us/step - loss: 0.0873 - acc: 0.9700 - val_loss: 0.4689 - val_acc: 0.8300\n",
            "Epoch 4091/4500\n",
            "100/100 [==============================] - 0s 500us/step - loss: 0.0869 - acc: 0.9800 - val_loss: 0.4658 - val_acc: 0.8400\n",
            "Epoch 4092/4500\n",
            "100/100 [==============================] - 0s 505us/step - loss: 0.0804 - acc: 0.9700 - val_loss: 0.4724 - val_acc: 0.8300\n",
            "Epoch 4093/4500\n",
            "100/100 [==============================] - 0s 509us/step - loss: 0.0831 - acc: 0.9700 - val_loss: 0.4583 - val_acc: 0.8500\n",
            "Epoch 4094/4500\n",
            "100/100 [==============================] - 0s 528us/step - loss: 0.0878 - acc: 0.9700 - val_loss: 0.4739 - val_acc: 0.8300\n",
            "Epoch 4095/4500\n",
            "100/100 [==============================] - 0s 506us/step - loss: 0.0839 - acc: 0.9700 - val_loss: 0.4697 - val_acc: 0.8400\n",
            "Epoch 4096/4500\n",
            "100/100 [==============================] - 0s 489us/step - loss: 0.0888 - acc: 0.9600 - val_loss: 0.4475 - val_acc: 0.8700\n",
            "Epoch 4097/4500\n",
            "100/100 [==============================] - 0s 519us/step - loss: 0.0894 - acc: 0.9600 - val_loss: 0.4706 - val_acc: 0.8400\n",
            "Epoch 4098/4500\n",
            "100/100 [==============================] - 0s 486us/step - loss: 0.0828 - acc: 0.9700 - val_loss: 0.4672 - val_acc: 0.8300\n",
            "Epoch 4099/4500\n",
            "100/100 [==============================] - 0s 472us/step - loss: 0.0816 - acc: 0.9800 - val_loss: 0.4593 - val_acc: 0.8400\n",
            "Epoch 4100/4500\n",
            "100/100 [==============================] - 0s 496us/step - loss: 0.0821 - acc: 0.9800 - val_loss: 0.4754 - val_acc: 0.8400\n",
            "Epoch 4101/4500\n",
            "100/100 [==============================] - 0s 612us/step - loss: 0.0819 - acc: 0.9600 - val_loss: 0.4686 - val_acc: 0.8400\n",
            "Epoch 4102/4500\n",
            "100/100 [==============================] - 0s 495us/step - loss: 0.0817 - acc: 0.9800 - val_loss: 0.4683 - val_acc: 0.8600\n",
            "Epoch 4103/4500\n",
            "100/100 [==============================] - 0s 485us/step - loss: 0.0841 - acc: 0.9600 - val_loss: 0.4719 - val_acc: 0.8400\n",
            "Epoch 4104/4500\n",
            "100/100 [==============================] - 0s 514us/step - loss: 0.0824 - acc: 0.9700 - val_loss: 0.4649 - val_acc: 0.8400\n",
            "Epoch 4105/4500\n",
            "100/100 [==============================] - 0s 520us/step - loss: 0.0832 - acc: 0.9800 - val_loss: 0.4640 - val_acc: 0.8500\n",
            "Epoch 4106/4500\n",
            "100/100 [==============================] - 0s 496us/step - loss: 0.0856 - acc: 0.9600 - val_loss: 0.4836 - val_acc: 0.8100\n",
            "Epoch 4107/4500\n",
            "100/100 [==============================] - 0s 501us/step - loss: 0.0960 - acc: 0.9600 - val_loss: 0.4639 - val_acc: 0.8600\n",
            "Epoch 4108/4500\n",
            "100/100 [==============================] - 0s 502us/step - loss: 0.1058 - acc: 0.9500 - val_loss: 0.4803 - val_acc: 0.8300\n",
            "Epoch 4109/4500\n",
            "100/100 [==============================] - 0s 524us/step - loss: 0.0982 - acc: 0.9600 - val_loss: 0.4776 - val_acc: 0.8300\n",
            "Epoch 4110/4500\n",
            "100/100 [==============================] - 0s 491us/step - loss: 0.0912 - acc: 0.9700 - val_loss: 0.4534 - val_acc: 0.8600\n",
            "Epoch 4111/4500\n",
            "100/100 [==============================] - 0s 507us/step - loss: 0.0864 - acc: 0.9700 - val_loss: 0.4883 - val_acc: 0.8200\n",
            "Epoch 4112/4500\n",
            "100/100 [==============================] - 0s 505us/step - loss: 0.0888 - acc: 0.9600 - val_loss: 0.4780 - val_acc: 0.8300\n",
            "Epoch 4113/4500\n",
            "100/100 [==============================] - 0s 498us/step - loss: 0.1027 - acc: 0.9500 - val_loss: 0.4877 - val_acc: 0.8400\n",
            "Epoch 4114/4500\n",
            "100/100 [==============================] - 0s 529us/step - loss: 0.0942 - acc: 0.9600 - val_loss: 0.4744 - val_acc: 0.8300\n",
            "Epoch 4115/4500\n",
            "100/100 [==============================] - 0s 568us/step - loss: 0.0975 - acc: 0.9600 - val_loss: 0.4731 - val_acc: 0.8300\n",
            "Epoch 4116/4500\n",
            "100/100 [==============================] - 0s 496us/step - loss: 0.0836 - acc: 0.9700 - val_loss: 0.4675 - val_acc: 0.8600\n",
            "Epoch 4117/4500\n",
            "100/100 [==============================] - 0s 499us/step - loss: 0.0828 - acc: 0.9700 - val_loss: 0.4875 - val_acc: 0.8200\n",
            "Epoch 4118/4500\n",
            "100/100 [==============================] - 0s 480us/step - loss: 0.0831 - acc: 0.9700 - val_loss: 0.4951 - val_acc: 0.8200\n",
            "Epoch 4119/4500\n",
            "100/100 [==============================] - 0s 529us/step - loss: 0.0847 - acc: 0.9800 - val_loss: 0.4889 - val_acc: 0.8200\n",
            "Epoch 4120/4500\n",
            "100/100 [==============================] - 0s 535us/step - loss: 0.0846 - acc: 0.9600 - val_loss: 0.4685 - val_acc: 0.8600\n",
            "Epoch 4121/4500\n",
            "100/100 [==============================] - 0s 534us/step - loss: 0.0882 - acc: 0.9700 - val_loss: 0.4774 - val_acc: 0.8200\n",
            "Epoch 4122/4500\n",
            "100/100 [==============================] - 0s 554us/step - loss: 0.0832 - acc: 0.9600 - val_loss: 0.4818 - val_acc: 0.8200\n",
            "Epoch 4123/4500\n",
            "100/100 [==============================] - 0s 502us/step - loss: 0.0799 - acc: 0.9700 - val_loss: 0.4738 - val_acc: 0.8300\n",
            "Epoch 4124/4500\n",
            "100/100 [==============================] - 0s 492us/step - loss: 0.0818 - acc: 0.9800 - val_loss: 0.4789 - val_acc: 0.8200\n",
            "Epoch 4125/4500\n",
            "100/100 [==============================] - 0s 584us/step - loss: 0.0911 - acc: 0.9500 - val_loss: 0.4677 - val_acc: 0.8500\n",
            "Epoch 4126/4500\n",
            "100/100 [==============================] - 0s 563us/step - loss: 0.0858 - acc: 0.9700 - val_loss: 0.4820 - val_acc: 0.8300\n",
            "Epoch 4127/4500\n",
            "100/100 [==============================] - 0s 494us/step - loss: 0.0789 - acc: 0.9800 - val_loss: 0.4790 - val_acc: 0.8200\n",
            "Epoch 4128/4500\n",
            "100/100 [==============================] - 0s 476us/step - loss: 0.0808 - acc: 0.9700 - val_loss: 0.4701 - val_acc: 0.8400\n",
            "Epoch 4129/4500\n",
            "100/100 [==============================] - 0s 499us/step - loss: 0.0820 - acc: 0.9800 - val_loss: 0.4756 - val_acc: 0.8400\n",
            "Epoch 4130/4500\n",
            "100/100 [==============================] - 0s 497us/step - loss: 0.0798 - acc: 0.9700 - val_loss: 0.4622 - val_acc: 0.8500\n",
            "Epoch 4131/4500\n",
            "100/100 [==============================] - 0s 523us/step - loss: 0.0792 - acc: 0.9700 - val_loss: 0.4745 - val_acc: 0.8400\n",
            "Epoch 4132/4500\n",
            "100/100 [==============================] - 0s 495us/step - loss: 0.0790 - acc: 0.9800 - val_loss: 0.4731 - val_acc: 0.8400\n",
            "Epoch 4133/4500\n",
            "100/100 [==============================] - 0s 512us/step - loss: 0.0797 - acc: 0.9800 - val_loss: 0.4838 - val_acc: 0.8100\n",
            "Epoch 4134/4500\n",
            "100/100 [==============================] - 0s 493us/step - loss: 0.0820 - acc: 0.9700 - val_loss: 0.4842 - val_acc: 0.8300\n",
            "Epoch 4135/4500\n",
            "100/100 [==============================] - 0s 584us/step - loss: 0.0808 - acc: 0.9700 - val_loss: 0.4699 - val_acc: 0.8400\n",
            "Epoch 4136/4500\n",
            "100/100 [==============================] - 0s 514us/step - loss: 0.0793 - acc: 0.9800 - val_loss: 0.4778 - val_acc: 0.8400\n",
            "Epoch 4137/4500\n",
            "100/100 [==============================] - 0s 495us/step - loss: 0.0787 - acc: 0.9600 - val_loss: 0.4714 - val_acc: 0.8400\n",
            "Epoch 4138/4500\n",
            "100/100 [==============================] - 0s 498us/step - loss: 0.0790 - acc: 0.9800 - val_loss: 0.4700 - val_acc: 0.8400\n",
            "Epoch 4139/4500\n",
            "100/100 [==============================] - 0s 494us/step - loss: 0.0790 - acc: 0.9800 - val_loss: 0.4887 - val_acc: 0.8200\n",
            "Epoch 4140/4500\n",
            "100/100 [==============================] - 0s 580us/step - loss: 0.0843 - acc: 0.9700 - val_loss: 0.4842 - val_acc: 0.8200\n",
            "Epoch 4141/4500\n",
            "100/100 [==============================] - 0s 515us/step - loss: 0.0823 - acc: 0.9600 - val_loss: 0.4616 - val_acc: 0.8400\n",
            "Epoch 4142/4500\n",
            "100/100 [==============================] - 0s 506us/step - loss: 0.0786 - acc: 0.9800 - val_loss: 0.4673 - val_acc: 0.8400\n",
            "Epoch 4143/4500\n",
            "100/100 [==============================] - 0s 494us/step - loss: 0.0782 - acc: 0.9800 - val_loss: 0.4820 - val_acc: 0.8400\n",
            "Epoch 4144/4500\n",
            "100/100 [==============================] - 0s 507us/step - loss: 0.0797 - acc: 0.9700 - val_loss: 0.4680 - val_acc: 0.8400\n",
            "Epoch 4145/4500\n",
            "100/100 [==============================] - 0s 598us/step - loss: 0.0776 - acc: 0.9700 - val_loss: 0.4737 - val_acc: 0.8400\n",
            "Epoch 4146/4500\n",
            "100/100 [==============================] - 0s 499us/step - loss: 0.0786 - acc: 0.9800 - val_loss: 0.4722 - val_acc: 0.8400\n",
            "Epoch 4147/4500\n",
            "100/100 [==============================] - 0s 498us/step - loss: 0.0767 - acc: 0.9800 - val_loss: 0.4657 - val_acc: 0.8400\n",
            "Epoch 4148/4500\n",
            "100/100 [==============================] - 0s 496us/step - loss: 0.0786 - acc: 0.9700 - val_loss: 0.4770 - val_acc: 0.8400\n",
            "Epoch 4149/4500\n",
            "100/100 [==============================] - 0s 480us/step - loss: 0.0804 - acc: 0.9700 - val_loss: 0.4772 - val_acc: 0.8400\n",
            "Epoch 4150/4500\n",
            "100/100 [==============================] - 0s 507us/step - loss: 0.0783 - acc: 0.9700 - val_loss: 0.4782 - val_acc: 0.8400\n",
            "Epoch 4151/4500\n",
            "100/100 [==============================] - 0s 484us/step - loss: 0.0800 - acc: 0.9700 - val_loss: 0.4726 - val_acc: 0.8400\n",
            "Epoch 4152/4500\n",
            "100/100 [==============================] - 0s 495us/step - loss: 0.0892 - acc: 0.9600 - val_loss: 0.4704 - val_acc: 0.8400\n",
            "Epoch 4153/4500\n",
            "100/100 [==============================] - 0s 481us/step - loss: 0.0827 - acc: 0.9700 - val_loss: 0.4698 - val_acc: 0.8500\n",
            "Epoch 4154/4500\n",
            "100/100 [==============================] - 0s 526us/step - loss: 0.0800 - acc: 0.9700 - val_loss: 0.4848 - val_acc: 0.8400\n",
            "Epoch 4155/4500\n",
            "100/100 [==============================] - 0s 552us/step - loss: 0.0780 - acc: 0.9800 - val_loss: 0.4787 - val_acc: 0.8400\n",
            "Epoch 4156/4500\n",
            "100/100 [==============================] - 0s 509us/step - loss: 0.0786 - acc: 0.9800 - val_loss: 0.4821 - val_acc: 0.8200\n",
            "Epoch 4157/4500\n",
            "100/100 [==============================] - 0s 497us/step - loss: 0.0800 - acc: 0.9600 - val_loss: 0.4798 - val_acc: 0.8400\n",
            "Epoch 4158/4500\n",
            "100/100 [==============================] - 0s 484us/step - loss: 0.0833 - acc: 0.9700 - val_loss: 0.4847 - val_acc: 0.8300\n",
            "Epoch 4159/4500\n",
            "100/100 [==============================] - 0s 588us/step - loss: 0.0769 - acc: 0.9700 - val_loss: 0.4793 - val_acc: 0.8400\n",
            "Epoch 4160/4500\n",
            "100/100 [==============================] - 0s 488us/step - loss: 0.0812 - acc: 0.9700 - val_loss: 0.4695 - val_acc: 0.8500\n",
            "Epoch 4161/4500\n",
            "100/100 [==============================] - 0s 506us/step - loss: 0.0791 - acc: 0.9700 - val_loss: 0.4758 - val_acc: 0.8400\n",
            "Epoch 4162/4500\n",
            "100/100 [==============================] - 0s 503us/step - loss: 0.0762 - acc: 0.9800 - val_loss: 0.4749 - val_acc: 0.8400\n",
            "Epoch 4163/4500\n",
            "100/100 [==============================] - 0s 490us/step - loss: 0.0781 - acc: 0.9700 - val_loss: 0.4823 - val_acc: 0.8400\n",
            "Epoch 4164/4500\n",
            "100/100 [==============================] - 0s 512us/step - loss: 0.0790 - acc: 0.9700 - val_loss: 0.4699 - val_acc: 0.8500\n",
            "Epoch 4165/4500\n",
            "100/100 [==============================] - 0s 531us/step - loss: 0.0768 - acc: 0.9800 - val_loss: 0.4754 - val_acc: 0.8400\n",
            "Epoch 4166/4500\n",
            "100/100 [==============================] - 0s 533us/step - loss: 0.0772 - acc: 0.9700 - val_loss: 0.4807 - val_acc: 0.8400\n",
            "Epoch 4167/4500\n",
            "100/100 [==============================] - 0s 508us/step - loss: 0.0765 - acc: 0.9800 - val_loss: 0.4831 - val_acc: 0.8400\n",
            "Epoch 4168/4500\n",
            "100/100 [==============================] - 0s 484us/step - loss: 0.0776 - acc: 0.9700 - val_loss: 0.4786 - val_acc: 0.8300\n",
            "Epoch 4169/4500\n",
            "100/100 [==============================] - 0s 531us/step - loss: 0.0784 - acc: 0.9800 - val_loss: 0.4902 - val_acc: 0.8300\n",
            "Epoch 4170/4500\n",
            "100/100 [==============================] - 0s 497us/step - loss: 0.0814 - acc: 0.9600 - val_loss: 0.4717 - val_acc: 0.8400\n",
            "Epoch 4171/4500\n",
            "100/100 [==============================] - 0s 524us/step - loss: 0.0763 - acc: 0.9700 - val_loss: 0.4833 - val_acc: 0.8400\n",
            "Epoch 4172/4500\n",
            "100/100 [==============================] - 0s 501us/step - loss: 0.0808 - acc: 0.9700 - val_loss: 0.4844 - val_acc: 0.8400\n",
            "Epoch 4173/4500\n",
            "100/100 [==============================] - 0s 543us/step - loss: 0.0918 - acc: 0.9600 - val_loss: 0.5305 - val_acc: 0.8200\n",
            "Epoch 4174/4500\n",
            "100/100 [==============================] - 0s 503us/step - loss: 0.0865 - acc: 0.9600 - val_loss: 0.4767 - val_acc: 0.8400\n",
            "Epoch 4175/4500\n",
            "100/100 [==============================] - 0s 483us/step - loss: 0.0829 - acc: 0.9700 - val_loss: 0.4783 - val_acc: 0.8400\n",
            "Epoch 4176/4500\n",
            "100/100 [==============================] - 0s 574us/step - loss: 0.0776 - acc: 0.9700 - val_loss: 0.4896 - val_acc: 0.8400\n",
            "Epoch 4177/4500\n",
            "100/100 [==============================] - 0s 487us/step - loss: 0.0789 - acc: 0.9700 - val_loss: 0.4810 - val_acc: 0.8600\n",
            "Epoch 4178/4500\n",
            "100/100 [==============================] - 0s 487us/step - loss: 0.0869 - acc: 0.9600 - val_loss: 0.5123 - val_acc: 0.8100\n",
            "Epoch 4179/4500\n",
            "100/100 [==============================] - 0s 573us/step - loss: 0.0803 - acc: 0.9700 - val_loss: 0.4916 - val_acc: 0.8000\n",
            "Epoch 4180/4500\n",
            "100/100 [==============================] - 0s 491us/step - loss: 0.0770 - acc: 0.9700 - val_loss: 0.4667 - val_acc: 0.8500\n",
            "Epoch 4181/4500\n",
            "100/100 [==============================] - 0s 497us/step - loss: 0.0761 - acc: 0.9800 - val_loss: 0.4878 - val_acc: 0.8200\n",
            "Epoch 4182/4500\n",
            "100/100 [==============================] - 0s 521us/step - loss: 0.0772 - acc: 0.9600 - val_loss: 0.4955 - val_acc: 0.8200\n",
            "Epoch 4183/4500\n",
            "100/100 [==============================] - 0s 504us/step - loss: 0.0828 - acc: 0.9800 - val_loss: 0.4897 - val_acc: 0.8300\n",
            "Epoch 4184/4500\n",
            "100/100 [==============================] - 0s 490us/step - loss: 0.0784 - acc: 0.9800 - val_loss: 0.5115 - val_acc: 0.8100\n",
            "Epoch 4185/4500\n",
            "100/100 [==============================] - 0s 509us/step - loss: 0.0862 - acc: 0.9500 - val_loss: 0.4770 - val_acc: 0.8700\n",
            "Epoch 4186/4500\n",
            "100/100 [==============================] - 0s 507us/step - loss: 0.0979 - acc: 0.9800 - val_loss: 0.4889 - val_acc: 0.8300\n",
            "Epoch 4187/4500\n",
            "100/100 [==============================] - 0s 501us/step - loss: 0.0786 - acc: 0.9800 - val_loss: 0.4870 - val_acc: 0.8500\n",
            "Epoch 4188/4500\n",
            "100/100 [==============================] - 0s 502us/step - loss: 0.0769 - acc: 0.9800 - val_loss: 0.5217 - val_acc: 0.8200\n",
            "Epoch 4189/4500\n",
            "100/100 [==============================] - 0s 495us/step - loss: 0.0805 - acc: 0.9700 - val_loss: 0.5166 - val_acc: 0.7900\n",
            "Epoch 4190/4500\n",
            "100/100 [==============================] - 0s 488us/step - loss: 0.0787 - acc: 0.9600 - val_loss: 0.4777 - val_acc: 0.8800\n",
            "Epoch 4191/4500\n",
            "100/100 [==============================] - 0s 506us/step - loss: 0.1065 - acc: 0.9400 - val_loss: 0.4891 - val_acc: 0.8300\n",
            "Epoch 4192/4500\n",
            "100/100 [==============================] - 0s 507us/step - loss: 0.0770 - acc: 0.9800 - val_loss: 0.5074 - val_acc: 0.8200\n",
            "Epoch 4193/4500\n",
            "100/100 [==============================] - 0s 500us/step - loss: 0.0792 - acc: 0.9700 - val_loss: 0.4887 - val_acc: 0.8300\n",
            "Epoch 4194/4500\n",
            "100/100 [==============================] - 0s 588us/step - loss: 0.0788 - acc: 0.9600 - val_loss: 0.4990 - val_acc: 0.8300\n",
            "Epoch 4195/4500\n",
            "100/100 [==============================] - 0s 539us/step - loss: 0.0803 - acc: 0.9700 - val_loss: 0.4854 - val_acc: 0.8700\n",
            "Epoch 4196/4500\n",
            "100/100 [==============================] - 0s 587us/step - loss: 0.0899 - acc: 0.9600 - val_loss: 0.4986 - val_acc: 0.8300\n",
            "Epoch 4197/4500\n",
            "100/100 [==============================] - 0s 549us/step - loss: 0.0851 - acc: 0.9600 - val_loss: 0.5041 - val_acc: 0.8200\n",
            "Epoch 4198/4500\n",
            "100/100 [==============================] - 0s 619us/step - loss: 0.0869 - acc: 0.9600 - val_loss: 0.5090 - val_acc: 0.8100\n",
            "Epoch 4199/4500\n",
            "100/100 [==============================] - 0s 499us/step - loss: 0.0769 - acc: 0.9700 - val_loss: 0.4786 - val_acc: 0.8600\n",
            "Epoch 4200/4500\n",
            "100/100 [==============================] - 0s 511us/step - loss: 0.0764 - acc: 0.9800 - val_loss: 0.4928 - val_acc: 0.8200\n",
            "Epoch 4201/4500\n",
            "100/100 [==============================] - 0s 501us/step - loss: 0.0747 - acc: 0.9700 - val_loss: 0.4936 - val_acc: 0.8200\n",
            "Epoch 4202/4500\n",
            "100/100 [==============================] - 0s 506us/step - loss: 0.0744 - acc: 0.9700 - val_loss: 0.5043 - val_acc: 0.8300\n",
            "Epoch 4203/4500\n",
            "100/100 [==============================] - 0s 493us/step - loss: 0.0852 - acc: 0.9700 - val_loss: 0.4963 - val_acc: 0.8200\n",
            "Epoch 4204/4500\n",
            "100/100 [==============================] - 0s 502us/step - loss: 0.0830 - acc: 0.9600 - val_loss: 0.4778 - val_acc: 0.8800\n",
            "Epoch 4205/4500\n",
            "100/100 [==============================] - 0s 498us/step - loss: 0.0983 - acc: 0.9500 - val_loss: 0.5383 - val_acc: 0.8200\n",
            "Epoch 4206/4500\n",
            "100/100 [==============================] - 0s 531us/step - loss: 0.0937 - acc: 0.9500 - val_loss: 0.4957 - val_acc: 0.8300\n",
            "Epoch 4207/4500\n",
            "100/100 [==============================] - 0s 505us/step - loss: 0.0857 - acc: 0.9600 - val_loss: 0.4752 - val_acc: 0.8400\n",
            "Epoch 4208/4500\n",
            "100/100 [==============================] - 0s 497us/step - loss: 0.0775 - acc: 0.9800 - val_loss: 0.4954 - val_acc: 0.8200\n",
            "Epoch 4209/4500\n",
            "100/100 [==============================] - 0s 490us/step - loss: 0.0743 - acc: 0.9800 - val_loss: 0.5192 - val_acc: 0.8100\n",
            "Epoch 4210/4500\n",
            "100/100 [==============================] - 0s 521us/step - loss: 0.0754 - acc: 0.9800 - val_loss: 0.5024 - val_acc: 0.8200\n",
            "Epoch 4211/4500\n",
            "100/100 [==============================] - 0s 517us/step - loss: 0.0854 - acc: 0.9700 - val_loss: 0.5351 - val_acc: 0.8000\n",
            "Epoch 4212/4500\n",
            "100/100 [==============================] - 0s 547us/step - loss: 0.0863 - acc: 0.9600 - val_loss: 0.5077 - val_acc: 0.8200\n",
            "Epoch 4213/4500\n",
            "100/100 [==============================] - 0s 519us/step - loss: 0.0770 - acc: 0.9700 - val_loss: 0.5084 - val_acc: 0.8200\n",
            "Epoch 4214/4500\n",
            "100/100 [==============================] - 0s 501us/step - loss: 0.0751 - acc: 0.9700 - val_loss: 0.4894 - val_acc: 0.8400\n",
            "Epoch 4215/4500\n",
            "100/100 [==============================] - 0s 507us/step - loss: 0.0765 - acc: 0.9800 - val_loss: 0.4885 - val_acc: 0.8400\n",
            "Epoch 4216/4500\n",
            "100/100 [==============================] - 0s 513us/step - loss: 0.1115 - acc: 0.9500 - val_loss: 0.4901 - val_acc: 0.8300\n",
            "Epoch 4217/4500\n",
            "100/100 [==============================] - 0s 556us/step - loss: 0.0827 - acc: 0.9700 - val_loss: 0.4792 - val_acc: 0.8300\n",
            "Epoch 4218/4500\n",
            "100/100 [==============================] - 0s 535us/step - loss: 0.0852 - acc: 0.9600 - val_loss: 0.5122 - val_acc: 0.8100\n",
            "Epoch 4219/4500\n",
            "100/100 [==============================] - 0s 512us/step - loss: 0.0845 - acc: 0.9600 - val_loss: 0.5058 - val_acc: 0.8200\n",
            "Epoch 4220/4500\n",
            "100/100 [==============================] - 0s 522us/step - loss: 0.0735 - acc: 0.9800 - val_loss: 0.5034 - val_acc: 0.8200\n",
            "Epoch 4221/4500\n",
            "100/100 [==============================] - 0s 508us/step - loss: 0.0750 - acc: 0.9700 - val_loss: 0.5110 - val_acc: 0.8100\n",
            "Epoch 4222/4500\n",
            "100/100 [==============================] - 0s 492us/step - loss: 0.0739 - acc: 0.9800 - val_loss: 0.4921 - val_acc: 0.8400\n",
            "Epoch 4223/4500\n",
            "100/100 [==============================] - 0s 496us/step - loss: 0.0797 - acc: 0.9700 - val_loss: 0.4993 - val_acc: 0.8300\n",
            "Epoch 4224/4500\n",
            "100/100 [==============================] - 0s 492us/step - loss: 0.0774 - acc: 0.9800 - val_loss: 0.5444 - val_acc: 0.8200\n",
            "Epoch 4225/4500\n",
            "100/100 [==============================] - 0s 498us/step - loss: 0.0896 - acc: 0.9500 - val_loss: 0.4978 - val_acc: 0.8400\n",
            "Epoch 4226/4500\n",
            "100/100 [==============================] - 0s 545us/step - loss: 0.0782 - acc: 0.9800 - val_loss: 0.5152 - val_acc: 0.8300\n",
            "Epoch 4227/4500\n",
            "100/100 [==============================] - 0s 494us/step - loss: 0.0815 - acc: 0.9700 - val_loss: 0.4980 - val_acc: 0.8100\n",
            "Epoch 4228/4500\n",
            "100/100 [==============================] - 0s 507us/step - loss: 0.0765 - acc: 0.9700 - val_loss: 0.5237 - val_acc: 0.8100\n",
            "Epoch 4229/4500\n",
            "100/100 [==============================] - 0s 510us/step - loss: 0.0717 - acc: 0.9600 - val_loss: 0.4770 - val_acc: 0.8700\n",
            "Epoch 4230/4500\n",
            "100/100 [==============================] - 0s 531us/step - loss: 0.0781 - acc: 0.9800 - val_loss: 0.5056 - val_acc: 0.8200\n",
            "Epoch 4231/4500\n",
            "100/100 [==============================] - 0s 620us/step - loss: 0.0745 - acc: 0.9800 - val_loss: 0.5122 - val_acc: 0.8300\n",
            "Epoch 4232/4500\n",
            "100/100 [==============================] - 0s 486us/step - loss: 0.0742 - acc: 0.9700 - val_loss: 0.5110 - val_acc: 0.8400\n",
            "Epoch 4233/4500\n",
            "100/100 [==============================] - 0s 503us/step - loss: 0.0742 - acc: 0.9800 - val_loss: 0.4960 - val_acc: 0.8300\n",
            "Epoch 4234/4500\n",
            "100/100 [==============================] - 0s 503us/step - loss: 0.0751 - acc: 0.9700 - val_loss: 0.5073 - val_acc: 0.8200\n",
            "Epoch 4235/4500\n",
            "100/100 [==============================] - 0s 507us/step - loss: 0.0751 - acc: 0.9800 - val_loss: 0.5265 - val_acc: 0.8200\n",
            "Epoch 4236/4500\n",
            "100/100 [==============================] - 0s 563us/step - loss: 0.0791 - acc: 0.9700 - val_loss: 0.5113 - val_acc: 0.8200\n",
            "Epoch 4237/4500\n",
            "100/100 [==============================] - 0s 623us/step - loss: 0.0763 - acc: 0.9800 - val_loss: 0.5022 - val_acc: 0.8200\n",
            "Epoch 4238/4500\n",
            "100/100 [==============================] - 0s 509us/step - loss: 0.0745 - acc: 0.9700 - val_loss: 0.4928 - val_acc: 0.8400\n",
            "Epoch 4239/4500\n",
            "100/100 [==============================] - 0s 499us/step - loss: 0.0738 - acc: 0.9700 - val_loss: 0.5172 - val_acc: 0.8200\n",
            "Epoch 4240/4500\n",
            "100/100 [==============================] - 0s 494us/step - loss: 0.0723 - acc: 0.9700 - val_loss: 0.4851 - val_acc: 0.8500\n",
            "Epoch 4241/4500\n",
            "100/100 [==============================] - 0s 507us/step - loss: 0.0770 - acc: 0.9700 - val_loss: 0.4965 - val_acc: 0.8200\n",
            "Epoch 4242/4500\n",
            "100/100 [==============================] - 0s 491us/step - loss: 0.0744 - acc: 0.9700 - val_loss: 0.4965 - val_acc: 0.8300\n",
            "Epoch 4243/4500\n",
            "100/100 [==============================] - 0s 501us/step - loss: 0.0745 - acc: 0.9800 - val_loss: 0.4944 - val_acc: 0.8400\n",
            "Epoch 4244/4500\n",
            "100/100 [==============================] - 0s 491us/step - loss: 0.0694 - acc: 0.9700 - val_loss: 0.5168 - val_acc: 0.8000\n",
            "Epoch 4245/4500\n",
            "100/100 [==============================] - 0s 567us/step - loss: 0.0725 - acc: 0.9700 - val_loss: 0.4997 - val_acc: 0.8300\n",
            "Epoch 4246/4500\n",
            "100/100 [==============================] - 0s 526us/step - loss: 0.0747 - acc: 0.9800 - val_loss: 0.4910 - val_acc: 0.8400\n",
            "Epoch 4247/4500\n",
            "100/100 [==============================] - 0s 544us/step - loss: 0.0738 - acc: 0.9600 - val_loss: 0.4798 - val_acc: 0.8400\n",
            "Epoch 4248/4500\n",
            "100/100 [==============================] - 0s 633us/step - loss: 0.0743 - acc: 0.9800 - val_loss: 0.4947 - val_acc: 0.8400\n",
            "Epoch 4249/4500\n",
            "100/100 [==============================] - 0s 604us/step - loss: 0.0744 - acc: 0.9700 - val_loss: 0.5075 - val_acc: 0.8300\n",
            "Epoch 4250/4500\n",
            "100/100 [==============================] - 0s 511us/step - loss: 0.0726 - acc: 0.9800 - val_loss: 0.4811 - val_acc: 0.8500\n",
            "Epoch 4251/4500\n",
            "100/100 [==============================] - 0s 495us/step - loss: 0.0708 - acc: 0.9800 - val_loss: 0.4976 - val_acc: 0.8300\n",
            "Epoch 4252/4500\n",
            "100/100 [==============================] - 0s 507us/step - loss: 0.0734 - acc: 0.9800 - val_loss: 0.4982 - val_acc: 0.8300\n",
            "Epoch 4253/4500\n",
            "100/100 [==============================] - 0s 493us/step - loss: 0.0699 - acc: 0.9700 - val_loss: 0.5081 - val_acc: 0.8100\n",
            "Epoch 4254/4500\n",
            "100/100 [==============================] - 0s 492us/step - loss: 0.0727 - acc: 0.9700 - val_loss: 0.4890 - val_acc: 0.8400\n",
            "Epoch 4255/4500\n",
            "100/100 [==============================] - 0s 515us/step - loss: 0.0699 - acc: 0.9800 - val_loss: 0.4964 - val_acc: 0.8400\n",
            "Epoch 4256/4500\n",
            "100/100 [==============================] - 0s 629us/step - loss: 0.0703 - acc: 0.9800 - val_loss: 0.5097 - val_acc: 0.8200\n",
            "Epoch 4257/4500\n",
            "100/100 [==============================] - 0s 493us/step - loss: 0.0775 - acc: 0.9700 - val_loss: 0.5111 - val_acc: 0.8200\n",
            "Epoch 4258/4500\n",
            "100/100 [==============================] - 0s 566us/step - loss: 0.0722 - acc: 0.9700 - val_loss: 0.4975 - val_acc: 0.8400\n",
            "Epoch 4259/4500\n",
            "100/100 [==============================] - 0s 585us/step - loss: 0.0731 - acc: 0.9800 - val_loss: 0.5052 - val_acc: 0.8300\n",
            "Epoch 4260/4500\n",
            "100/100 [==============================] - 0s 506us/step - loss: 0.0730 - acc: 0.9700 - val_loss: 0.4930 - val_acc: 0.8500\n",
            "Epoch 4261/4500\n",
            "100/100 [==============================] - 0s 521us/step - loss: 0.0716 - acc: 0.9800 - val_loss: 0.5121 - val_acc: 0.8200\n",
            "Epoch 4262/4500\n",
            "100/100 [==============================] - 0s 523us/step - loss: 0.0734 - acc: 0.9700 - val_loss: 0.5060 - val_acc: 0.8300\n",
            "Epoch 4263/4500\n",
            "100/100 [==============================] - 0s 510us/step - loss: 0.0685 - acc: 0.9700 - val_loss: 0.4997 - val_acc: 0.8400\n",
            "Epoch 4264/4500\n",
            "100/100 [==============================] - 0s 500us/step - loss: 0.0795 - acc: 0.9700 - val_loss: 0.5087 - val_acc: 0.8300\n",
            "Epoch 4265/4500\n",
            "100/100 [==============================] - 0s 526us/step - loss: 0.0713 - acc: 0.9800 - val_loss: 0.4992 - val_acc: 0.8300\n",
            "Epoch 4266/4500\n",
            "100/100 [==============================] - 0s 496us/step - loss: 0.0715 - acc: 0.9800 - val_loss: 0.5068 - val_acc: 0.8300\n",
            "Epoch 4267/4500\n",
            "100/100 [==============================] - 0s 567us/step - loss: 0.0749 - acc: 0.9800 - val_loss: 0.5031 - val_acc: 0.8400\n",
            "Epoch 4268/4500\n",
            "100/100 [==============================] - 0s 535us/step - loss: 0.0737 - acc: 0.9600 - val_loss: 0.4991 - val_acc: 0.8500\n",
            "Epoch 4269/4500\n",
            "100/100 [==============================] - 0s 502us/step - loss: 0.0783 - acc: 0.9600 - val_loss: 0.5298 - val_acc: 0.8300\n",
            "Epoch 4270/4500\n",
            "100/100 [==============================] - 0s 506us/step - loss: 0.0753 - acc: 0.9700 - val_loss: 0.4981 - val_acc: 0.8500\n",
            "Epoch 4271/4500\n",
            "100/100 [==============================] - 0s 516us/step - loss: 0.0804 - acc: 0.9700 - val_loss: 0.4889 - val_acc: 0.8300\n",
            "Epoch 4272/4500\n",
            "100/100 [==============================] - 0s 529us/step - loss: 0.0770 - acc: 0.9800 - val_loss: 0.5160 - val_acc: 0.8200\n",
            "Epoch 4273/4500\n",
            "100/100 [==============================] - 0s 504us/step - loss: 0.0741 - acc: 0.9700 - val_loss: 0.4934 - val_acc: 0.8500\n",
            "Epoch 4274/4500\n",
            "100/100 [==============================] - 0s 507us/step - loss: 0.0772 - acc: 0.9800 - val_loss: 0.5081 - val_acc: 0.8300\n",
            "Epoch 4275/4500\n",
            "100/100 [==============================] - 0s 621us/step - loss: 0.0705 - acc: 0.9700 - val_loss: 0.5140 - val_acc: 0.8200\n",
            "Epoch 4276/4500\n",
            "100/100 [==============================] - 0s 582us/step - loss: 0.0714 - acc: 0.9700 - val_loss: 0.5082 - val_acc: 0.8300\n",
            "Epoch 4277/4500\n",
            "100/100 [==============================] - 0s 499us/step - loss: 0.0693 - acc: 0.9800 - val_loss: 0.5101 - val_acc: 0.8300\n",
            "Epoch 4278/4500\n",
            "100/100 [==============================] - 0s 530us/step - loss: 0.0719 - acc: 0.9700 - val_loss: 0.5086 - val_acc: 0.8200\n",
            "Epoch 4279/4500\n",
            "100/100 [==============================] - 0s 501us/step - loss: 0.0711 - acc: 0.9700 - val_loss: 0.4970 - val_acc: 0.8300\n",
            "Epoch 4280/4500\n",
            "100/100 [==============================] - 0s 490us/step - loss: 0.0711 - acc: 0.9800 - val_loss: 0.4996 - val_acc: 0.8400\n",
            "Epoch 4281/4500\n",
            "100/100 [==============================] - 0s 504us/step - loss: 0.0705 - acc: 0.9800 - val_loss: 0.5151 - val_acc: 0.8200\n",
            "Epoch 4282/4500\n",
            "100/100 [==============================] - 0s 519us/step - loss: 0.0721 - acc: 0.9700 - val_loss: 0.4963 - val_acc: 0.8400\n",
            "Epoch 4283/4500\n",
            "100/100 [==============================] - 0s 512us/step - loss: 0.0755 - acc: 0.9800 - val_loss: 0.5035 - val_acc: 0.8400\n",
            "Epoch 4284/4500\n",
            "100/100 [==============================] - 0s 577us/step - loss: 0.0662 - acc: 0.9800 - val_loss: 0.5150 - val_acc: 0.8100\n",
            "Epoch 4285/4500\n",
            "100/100 [==============================] - 0s 589us/step - loss: 0.0716 - acc: 0.9700 - val_loss: 0.5203 - val_acc: 0.8200\n",
            "Epoch 4286/4500\n",
            "100/100 [==============================] - 0s 571us/step - loss: 0.0689 - acc: 0.9800 - val_loss: 0.4965 - val_acc: 0.8400\n",
            "Epoch 4287/4500\n",
            "100/100 [==============================] - 0s 540us/step - loss: 0.0690 - acc: 0.9700 - val_loss: 0.5024 - val_acc: 0.8400\n",
            "Epoch 4288/4500\n",
            "100/100 [==============================] - 0s 503us/step - loss: 0.0702 - acc: 0.9800 - val_loss: 0.5090 - val_acc: 0.8300\n",
            "Epoch 4289/4500\n",
            "100/100 [==============================] - 0s 542us/step - loss: 0.0703 - acc: 0.9700 - val_loss: 0.4950 - val_acc: 0.8300\n",
            "Epoch 4290/4500\n",
            "100/100 [==============================] - 0s 537us/step - loss: 0.0691 - acc: 0.9800 - val_loss: 0.4795 - val_acc: 0.8600\n",
            "Epoch 4291/4500\n",
            "100/100 [==============================] - 0s 522us/step - loss: 0.0733 - acc: 0.9800 - val_loss: 0.5034 - val_acc: 0.8400\n",
            "Epoch 4292/4500\n",
            "100/100 [==============================] - 0s 520us/step - loss: 0.0693 - acc: 0.9800 - val_loss: 0.5240 - val_acc: 0.8200\n",
            "Epoch 4293/4500\n",
            "100/100 [==============================] - 0s 504us/step - loss: 0.0732 - acc: 0.9700 - val_loss: 0.4995 - val_acc: 0.8400\n",
            "Epoch 4294/4500\n",
            "100/100 [==============================] - 0s 583us/step - loss: 0.0729 - acc: 0.9700 - val_loss: 0.5011 - val_acc: 0.8300\n",
            "Epoch 4295/4500\n",
            "100/100 [==============================] - 0s 597us/step - loss: 0.0696 - acc: 0.9800 - val_loss: 0.5100 - val_acc: 0.8300\n",
            "Epoch 4296/4500\n",
            "100/100 [==============================] - 0s 563us/step - loss: 0.0726 - acc: 0.9800 - val_loss: 0.5268 - val_acc: 0.8300\n",
            "Epoch 4297/4500\n",
            "100/100 [==============================] - 0s 552us/step - loss: 0.0711 - acc: 0.9800 - val_loss: 0.5132 - val_acc: 0.8300\n",
            "Epoch 4298/4500\n",
            "100/100 [==============================] - 0s 539us/step - loss: 0.0703 - acc: 0.9800 - val_loss: 0.5154 - val_acc: 0.8300\n",
            "Epoch 4299/4500\n",
            "100/100 [==============================] - 0s 504us/step - loss: 0.0777 - acc: 0.9700 - val_loss: 0.5109 - val_acc: 0.8300\n",
            "Epoch 4300/4500\n",
            "100/100 [==============================] - 0s 494us/step - loss: 0.0849 - acc: 0.9500 - val_loss: 0.5080 - val_acc: 0.8300\n",
            "Epoch 4301/4500\n",
            "100/100 [==============================] - 0s 510us/step - loss: 0.0780 - acc: 0.9600 - val_loss: 0.4859 - val_acc: 0.8500\n",
            "Epoch 4302/4500\n",
            "100/100 [==============================] - 0s 511us/step - loss: 0.0924 - acc: 0.9500 - val_loss: 0.4946 - val_acc: 0.8500\n",
            "Epoch 4303/4500\n",
            "100/100 [==============================] - 0s 519us/step - loss: 0.0704 - acc: 0.9800 - val_loss: 0.5035 - val_acc: 0.8300\n",
            "Epoch 4304/4500\n",
            "100/100 [==============================] - 0s 543us/step - loss: 0.0686 - acc: 0.9800 - val_loss: 0.5113 - val_acc: 0.8300\n",
            "Epoch 4305/4500\n",
            "100/100 [==============================] - 0s 531us/step - loss: 0.0690 - acc: 0.9700 - val_loss: 0.5111 - val_acc: 0.8300\n",
            "Epoch 4306/4500\n",
            "100/100 [==============================] - 0s 489us/step - loss: 0.0702 - acc: 0.9800 - val_loss: 0.5035 - val_acc: 0.8400\n",
            "Epoch 4307/4500\n",
            "100/100 [==============================] - 0s 493us/step - loss: 0.0670 - acc: 0.9800 - val_loss: 0.5134 - val_acc: 0.8300\n",
            "Epoch 4308/4500\n",
            "100/100 [==============================] - 0s 509us/step - loss: 0.0679 - acc: 0.9700 - val_loss: 0.5113 - val_acc: 0.8300\n",
            "Epoch 4309/4500\n",
            "100/100 [==============================] - 0s 504us/step - loss: 0.0666 - acc: 0.9800 - val_loss: 0.5147 - val_acc: 0.8300\n",
            "Epoch 4310/4500\n",
            "100/100 [==============================] - 0s 498us/step - loss: 0.0655 - acc: 0.9800 - val_loss: 0.5196 - val_acc: 0.8200\n",
            "Epoch 4311/4500\n",
            "100/100 [==============================] - 0s 495us/step - loss: 0.0657 - acc: 0.9800 - val_loss: 0.5235 - val_acc: 0.8200\n",
            "Epoch 4312/4500\n",
            "100/100 [==============================] - 0s 500us/step - loss: 0.0662 - acc: 0.9700 - val_loss: 0.5087 - val_acc: 0.8300\n",
            "Epoch 4313/4500\n",
            "100/100 [==============================] - 0s 593us/step - loss: 0.0671 - acc: 0.9800 - val_loss: 0.5157 - val_acc: 0.8300\n",
            "Epoch 4314/4500\n",
            "100/100 [==============================] - 0s 524us/step - loss: 0.0704 - acc: 0.9700 - val_loss: 0.5045 - val_acc: 0.8400\n",
            "Epoch 4315/4500\n",
            "100/100 [==============================] - 0s 616us/step - loss: 0.0702 - acc: 0.9700 - val_loss: 0.4977 - val_acc: 0.8400\n",
            "Epoch 4316/4500\n",
            "100/100 [==============================] - 0s 547us/step - loss: 0.0661 - acc: 0.9800 - val_loss: 0.5127 - val_acc: 0.8300\n",
            "Epoch 4317/4500\n",
            "100/100 [==============================] - 0s 531us/step - loss: 0.0684 - acc: 0.9800 - val_loss: 0.5365 - val_acc: 0.8200\n",
            "Epoch 4318/4500\n",
            "100/100 [==============================] - 0s 511us/step - loss: 0.0689 - acc: 0.9700 - val_loss: 0.4975 - val_acc: 0.8400\n",
            "Epoch 4319/4500\n",
            "100/100 [==============================] - 0s 509us/step - loss: 0.0697 - acc: 0.9800 - val_loss: 0.5077 - val_acc: 0.8300\n",
            "Epoch 4320/4500\n",
            "100/100 [==============================] - 0s 523us/step - loss: 0.0720 - acc: 0.9900 - val_loss: 0.5028 - val_acc: 0.8400\n",
            "Epoch 4321/4500\n",
            "100/100 [==============================] - 0s 512us/step - loss: 0.0629 - acc: 0.9800 - val_loss: 0.4950 - val_acc: 0.8500\n",
            "Epoch 4322/4500\n",
            "100/100 [==============================] - 0s 548us/step - loss: 0.0738 - acc: 0.9700 - val_loss: 0.5174 - val_acc: 0.8300\n",
            "Epoch 4323/4500\n",
            "100/100 [==============================] - 0s 541us/step - loss: 0.0688 - acc: 0.9800 - val_loss: 0.5227 - val_acc: 0.8300\n",
            "Epoch 4324/4500\n",
            "100/100 [==============================] - 0s 559us/step - loss: 0.0660 - acc: 0.9800 - val_loss: 0.5228 - val_acc: 0.8100\n",
            "Epoch 4325/4500\n",
            "100/100 [==============================] - 0s 497us/step - loss: 0.0682 - acc: 0.9800 - val_loss: 0.5048 - val_acc: 0.8400\n",
            "Epoch 4326/4500\n",
            "100/100 [==============================] - 0s 511us/step - loss: 0.0683 - acc: 0.9700 - val_loss: 0.5119 - val_acc: 0.8300\n",
            "Epoch 4327/4500\n",
            "100/100 [==============================] - 0s 480us/step - loss: 0.0721 - acc: 0.9800 - val_loss: 0.5223 - val_acc: 0.8300\n",
            "Epoch 4328/4500\n",
            "100/100 [==============================] - 0s 508us/step - loss: 0.0689 - acc: 0.9700 - val_loss: 0.5131 - val_acc: 0.8300\n",
            "Epoch 4329/4500\n",
            "100/100 [==============================] - 0s 492us/step - loss: 0.0644 - acc: 0.9800 - val_loss: 0.5064 - val_acc: 0.8400\n",
            "Epoch 4330/4500\n",
            "100/100 [==============================] - 0s 506us/step - loss: 0.0706 - acc: 0.9800 - val_loss: 0.5153 - val_acc: 0.8300\n",
            "Epoch 4331/4500\n",
            "100/100 [==============================] - 0s 566us/step - loss: 0.0680 - acc: 0.9800 - val_loss: 0.5434 - val_acc: 0.8100\n",
            "Epoch 4332/4500\n",
            "100/100 [==============================] - 0s 618us/step - loss: 0.0664 - acc: 0.9700 - val_loss: 0.5396 - val_acc: 0.8200\n",
            "Epoch 4333/4500\n",
            "100/100 [==============================] - 0s 574us/step - loss: 0.0658 - acc: 0.9700 - val_loss: 0.5130 - val_acc: 0.8300\n",
            "Epoch 4334/4500\n",
            "100/100 [==============================] - 0s 535us/step - loss: 0.0634 - acc: 0.9800 - val_loss: 0.5074 - val_acc: 0.8400\n",
            "Epoch 4335/4500\n",
            "100/100 [==============================] - 0s 524us/step - loss: 0.0666 - acc: 0.9800 - val_loss: 0.5311 - val_acc: 0.8100\n",
            "Epoch 4336/4500\n",
            "100/100 [==============================] - 0s 548us/step - loss: 0.0653 - acc: 0.9700 - val_loss: 0.5335 - val_acc: 0.8100\n",
            "Epoch 4337/4500\n",
            "100/100 [==============================] - 0s 543us/step - loss: 0.0649 - acc: 0.9700 - val_loss: 0.5137 - val_acc: 0.8300\n",
            "Epoch 4338/4500\n",
            "100/100 [==============================] - 0s 513us/step - loss: 0.0628 - acc: 0.9800 - val_loss: 0.5082 - val_acc: 0.8400\n",
            "Epoch 4339/4500\n",
            "100/100 [==============================] - 0s 499us/step - loss: 0.0649 - acc: 0.9700 - val_loss: 0.5277 - val_acc: 0.8300\n",
            "Epoch 4340/4500\n",
            "100/100 [==============================] - 0s 501us/step - loss: 0.0659 - acc: 0.9800 - val_loss: 0.5259 - val_acc: 0.8300\n",
            "Epoch 4341/4500\n",
            "100/100 [==============================] - 0s 531us/step - loss: 0.0652 - acc: 0.9800 - val_loss: 0.5092 - val_acc: 0.8300\n",
            "Epoch 4342/4500\n",
            "100/100 [==============================] - 0s 520us/step - loss: 0.0649 - acc: 0.9700 - val_loss: 0.5055 - val_acc: 0.8400\n",
            "Epoch 4343/4500\n",
            "100/100 [==============================] - 0s 555us/step - loss: 0.0639 - acc: 0.9800 - val_loss: 0.5203 - val_acc: 0.8300\n",
            "Epoch 4344/4500\n",
            "100/100 [==============================] - 0s 614us/step - loss: 0.0618 - acc: 0.9800 - val_loss: 0.5326 - val_acc: 0.8300\n",
            "Epoch 4345/4500\n",
            "100/100 [==============================] - 0s 495us/step - loss: 0.0666 - acc: 0.9800 - val_loss: 0.5366 - val_acc: 0.8100\n",
            "Epoch 4346/4500\n",
            "100/100 [==============================] - 0s 501us/step - loss: 0.0658 - acc: 0.9900 - val_loss: 0.5063 - val_acc: 0.8400\n",
            "Epoch 4347/4500\n",
            "100/100 [==============================] - 0s 511us/step - loss: 0.0694 - acc: 0.9800 - val_loss: 0.5230 - val_acc: 0.8300\n",
            "Epoch 4348/4500\n",
            "100/100 [==============================] - 0s 513us/step - loss: 0.0638 - acc: 0.9800 - val_loss: 0.5348 - val_acc: 0.8200\n",
            "Epoch 4349/4500\n",
            "100/100 [==============================] - 0s 514us/step - loss: 0.0630 - acc: 0.9700 - val_loss: 0.5183 - val_acc: 0.8300\n",
            "Epoch 4350/4500\n",
            "100/100 [==============================] - 0s 600us/step - loss: 0.0648 - acc: 0.9800 - val_loss: 0.5181 - val_acc: 0.8300\n",
            "Epoch 4351/4500\n",
            "100/100 [==============================] - 0s 509us/step - loss: 0.0684 - acc: 0.9800 - val_loss: 0.5314 - val_acc: 0.8200\n",
            "Epoch 4352/4500\n",
            "100/100 [==============================] - 0s 506us/step - loss: 0.0683 - acc: 0.9700 - val_loss: 0.5084 - val_acc: 0.8400\n",
            "Epoch 4353/4500\n",
            "100/100 [==============================] - 0s 508us/step - loss: 0.0762 - acc: 0.9600 - val_loss: 0.5245 - val_acc: 0.8300\n",
            "Epoch 4354/4500\n",
            "100/100 [==============================] - 0s 542us/step - loss: 0.0699 - acc: 0.9700 - val_loss: 0.5287 - val_acc: 0.8300\n",
            "Epoch 4355/4500\n",
            "100/100 [==============================] - 0s 498us/step - loss: 0.0620 - acc: 0.9800 - val_loss: 0.5066 - val_acc: 0.8400\n",
            "Epoch 4356/4500\n",
            "100/100 [==============================] - 0s 508us/step - loss: 0.0710 - acc: 0.9800 - val_loss: 0.5484 - val_acc: 0.8200\n",
            "Epoch 4357/4500\n",
            "100/100 [==============================] - 0s 522us/step - loss: 0.0811 - acc: 0.9500 - val_loss: 0.5226 - val_acc: 0.8300\n",
            "Epoch 4358/4500\n",
            "100/100 [==============================] - 0s 531us/step - loss: 0.0660 - acc: 0.9700 - val_loss: 0.5222 - val_acc: 0.8200\n",
            "Epoch 4359/4500\n",
            "100/100 [==============================] - 0s 571us/step - loss: 0.0798 - acc: 0.9700 - val_loss: 0.5261 - val_acc: 0.8300\n",
            "Epoch 4360/4500\n",
            "100/100 [==============================] - 0s 501us/step - loss: 0.0691 - acc: 0.9700 - val_loss: 0.5337 - val_acc: 0.8100\n",
            "Epoch 4361/4500\n",
            "100/100 [==============================] - 0s 509us/step - loss: 0.0672 - acc: 0.9800 - val_loss: 0.5103 - val_acc: 0.8400\n",
            "Epoch 4362/4500\n",
            "100/100 [==============================] - 0s 521us/step - loss: 0.0615 - acc: 0.9800 - val_loss: 0.5264 - val_acc: 0.8300\n",
            "Epoch 4363/4500\n",
            "100/100 [==============================] - 0s 696us/step - loss: 0.0643 - acc: 0.9700 - val_loss: 0.5332 - val_acc: 0.8200\n",
            "Epoch 4364/4500\n",
            "100/100 [==============================] - 0s 532us/step - loss: 0.0615 - acc: 0.9800 - val_loss: 0.5112 - val_acc: 0.8400\n",
            "Epoch 4365/4500\n",
            "100/100 [==============================] - 0s 511us/step - loss: 0.0638 - acc: 0.9800 - val_loss: 0.5361 - val_acc: 0.8200\n",
            "Epoch 4366/4500\n",
            "100/100 [==============================] - 0s 506us/step - loss: 0.0707 - acc: 0.9800 - val_loss: 0.5080 - val_acc: 0.8400\n",
            "Epoch 4367/4500\n",
            "100/100 [==============================] - 0s 504us/step - loss: 0.0666 - acc: 0.9800 - val_loss: 0.5252 - val_acc: 0.8300\n",
            "Epoch 4368/4500\n",
            "100/100 [==============================] - 0s 499us/step - loss: 0.0671 - acc: 0.9800 - val_loss: 0.5359 - val_acc: 0.8100\n",
            "Epoch 4369/4500\n",
            "100/100 [==============================] - 0s 572us/step - loss: 0.0710 - acc: 0.9700 - val_loss: 0.5249 - val_acc: 0.8300\n",
            "Epoch 4370/4500\n",
            "100/100 [==============================] - 0s 561us/step - loss: 0.0677 - acc: 0.9700 - val_loss: 0.5293 - val_acc: 0.8300\n",
            "Epoch 4371/4500\n",
            "100/100 [==============================] - 0s 501us/step - loss: 0.0646 - acc: 0.9800 - val_loss: 0.5073 - val_acc: 0.8400\n",
            "Epoch 4372/4500\n",
            "100/100 [==============================] - 0s 500us/step - loss: 0.0614 - acc: 0.9800 - val_loss: 0.5314 - val_acc: 0.8300\n",
            "Epoch 4373/4500\n",
            "100/100 [==============================] - 0s 564us/step - loss: 0.0607 - acc: 0.9800 - val_loss: 0.5176 - val_acc: 0.8400\n",
            "Epoch 4374/4500\n",
            "100/100 [==============================] - 0s 557us/step - loss: 0.0634 - acc: 0.9800 - val_loss: 0.5201 - val_acc: 0.8300\n",
            "Epoch 4375/4500\n",
            "100/100 [==============================] - 0s 507us/step - loss: 0.0636 - acc: 0.9800 - val_loss: 0.5245 - val_acc: 0.8300\n",
            "Epoch 4376/4500\n",
            "100/100 [==============================] - 0s 497us/step - loss: 0.0626 - acc: 0.9800 - val_loss: 0.5234 - val_acc: 0.8300\n",
            "Epoch 4377/4500\n",
            "100/100 [==============================] - 0s 496us/step - loss: 0.0656 - acc: 0.9800 - val_loss: 0.5126 - val_acc: 0.8400\n",
            "Epoch 4378/4500\n",
            "100/100 [==============================] - 0s 525us/step - loss: 0.0672 - acc: 0.9800 - val_loss: 0.5457 - val_acc: 0.8100\n",
            "Epoch 4379/4500\n",
            "100/100 [==============================] - 0s 493us/step - loss: 0.0647 - acc: 1.0000 - val_loss: 0.5386 - val_acc: 0.8000\n",
            "Epoch 4380/4500\n",
            "100/100 [==============================] - 0s 505us/step - loss: 0.0618 - acc: 0.9800 - val_loss: 0.5185 - val_acc: 0.8400\n",
            "Epoch 4381/4500\n",
            "100/100 [==============================] - 0s 529us/step - loss: 0.0599 - acc: 0.9800 - val_loss: 0.5276 - val_acc: 0.8200\n",
            "Epoch 4382/4500\n",
            "100/100 [==============================] - 0s 508us/step - loss: 0.0617 - acc: 0.9800 - val_loss: 0.5314 - val_acc: 0.8200\n",
            "Epoch 4383/4500\n",
            "100/100 [==============================] - 0s 575us/step - loss: 0.0620 - acc: 0.9800 - val_loss: 0.5335 - val_acc: 0.8300\n",
            "Epoch 4384/4500\n",
            "100/100 [==============================] - 0s 621us/step - loss: 0.0644 - acc: 0.9800 - val_loss: 0.5141 - val_acc: 0.8400\n",
            "Epoch 4385/4500\n",
            "100/100 [==============================] - 0s 501us/step - loss: 0.0624 - acc: 0.9800 - val_loss: 0.5290 - val_acc: 0.8300\n",
            "Epoch 4386/4500\n",
            "100/100 [==============================] - 0s 499us/step - loss: 0.0621 - acc: 0.9800 - val_loss: 0.5375 - val_acc: 0.8300\n",
            "Epoch 4387/4500\n",
            "100/100 [==============================] - 0s 495us/step - loss: 0.0630 - acc: 0.9800 - val_loss: 0.5311 - val_acc: 0.8300\n",
            "Epoch 4388/4500\n",
            "100/100 [==============================] - 0s 602us/step - loss: 0.0628 - acc: 0.9800 - val_loss: 0.5022 - val_acc: 0.8500\n",
            "Epoch 4389/4500\n",
            "100/100 [==============================] - 0s 515us/step - loss: 0.0610 - acc: 0.9800 - val_loss: 0.5391 - val_acc: 0.8200\n",
            "Epoch 4390/4500\n",
            "100/100 [==============================] - 0s 479us/step - loss: 0.0618 - acc: 0.9800 - val_loss: 0.5443 - val_acc: 0.8300\n",
            "Epoch 4391/4500\n",
            "100/100 [==============================] - 0s 561us/step - loss: 0.0622 - acc: 0.9800 - val_loss: 0.5176 - val_acc: 0.8400\n",
            "Epoch 4392/4500\n",
            "100/100 [==============================] - 0s 538us/step - loss: 0.0642 - acc: 0.9800 - val_loss: 0.5272 - val_acc: 0.8300\n",
            "Epoch 4393/4500\n",
            "100/100 [==============================] - 0s 554us/step - loss: 0.0658 - acc: 0.9700 - val_loss: 0.5373 - val_acc: 0.8300\n",
            "Epoch 4394/4500\n",
            "100/100 [==============================] - 0s 527us/step - loss: 0.0681 - acc: 0.9800 - val_loss: 0.5287 - val_acc: 0.8300\n",
            "Epoch 4395/4500\n",
            "100/100 [==============================] - 0s 513us/step - loss: 0.0778 - acc: 0.9600 - val_loss: 0.5445 - val_acc: 0.8100\n",
            "Epoch 4396/4500\n",
            "100/100 [==============================] - 0s 496us/step - loss: 0.0641 - acc: 0.9700 - val_loss: 0.5030 - val_acc: 0.8600\n",
            "Epoch 4397/4500\n",
            "100/100 [==============================] - 0s 522us/step - loss: 0.0614 - acc: 0.9800 - val_loss: 0.5360 - val_acc: 0.8200\n",
            "Epoch 4398/4500\n",
            "100/100 [==============================] - 0s 538us/step - loss: 0.0607 - acc: 0.9800 - val_loss: 0.5247 - val_acc: 0.8300\n",
            "Epoch 4399/4500\n",
            "100/100 [==============================] - 0s 508us/step - loss: 0.0646 - acc: 0.9700 - val_loss: 0.5247 - val_acc: 0.8300\n",
            "Epoch 4400/4500\n",
            "100/100 [==============================] - 0s 523us/step - loss: 0.0697 - acc: 0.9600 - val_loss: 0.5373 - val_acc: 0.8300\n",
            "Epoch 4401/4500\n",
            "100/100 [==============================] - 0s 479us/step - loss: 0.0700 - acc: 0.9800 - val_loss: 0.5478 - val_acc: 0.8300\n",
            "Epoch 4402/4500\n",
            "100/100 [==============================] - 0s 535us/step - loss: 0.0617 - acc: 0.9800 - val_loss: 0.5303 - val_acc: 0.8300\n",
            "Epoch 4403/4500\n",
            "100/100 [==============================] - 0s 635us/step - loss: 0.0593 - acc: 0.9800 - val_loss: 0.5313 - val_acc: 0.8300\n",
            "Epoch 4404/4500\n",
            "100/100 [==============================] - 0s 530us/step - loss: 0.0606 - acc: 0.9800 - val_loss: 0.5361 - val_acc: 0.8300\n",
            "Epoch 4405/4500\n",
            "100/100 [==============================] - 0s 491us/step - loss: 0.0604 - acc: 0.9800 - val_loss: 0.5422 - val_acc: 0.8200\n",
            "Epoch 4406/4500\n",
            "100/100 [==============================] - 0s 502us/step - loss: 0.0591 - acc: 0.9800 - val_loss: 0.5314 - val_acc: 0.8300\n",
            "Epoch 4407/4500\n",
            "100/100 [==============================] - 0s 597us/step - loss: 0.0610 - acc: 0.9800 - val_loss: 0.5297 - val_acc: 0.8300\n",
            "Epoch 4408/4500\n",
            "100/100 [==============================] - 0s 492us/step - loss: 0.0674 - acc: 0.9800 - val_loss: 0.5093 - val_acc: 0.8500\n",
            "Epoch 4409/4500\n",
            "100/100 [==============================] - 0s 520us/step - loss: 0.0658 - acc: 0.9800 - val_loss: 0.5378 - val_acc: 0.8300\n",
            "Epoch 4410/4500\n",
            "100/100 [==============================] - 0s 498us/step - loss: 0.0713 - acc: 0.9800 - val_loss: 0.5285 - val_acc: 0.8300\n",
            "Epoch 4411/4500\n",
            "100/100 [==============================] - 0s 471us/step - loss: 0.0680 - acc: 0.9800 - val_loss: 0.5179 - val_acc: 0.8300\n",
            "Epoch 4412/4500\n",
            "100/100 [==============================] - 0s 665us/step - loss: 0.0644 - acc: 0.9700 - val_loss: 0.5308 - val_acc: 0.8300\n",
            "Epoch 4413/4500\n",
            "100/100 [==============================] - 0s 660us/step - loss: 0.0615 - acc: 0.9800 - val_loss: 0.5241 - val_acc: 0.8300\n",
            "Epoch 4414/4500\n",
            "100/100 [==============================] - 0s 506us/step - loss: 0.0595 - acc: 0.9800 - val_loss: 0.5633 - val_acc: 0.8100\n",
            "Epoch 4415/4500\n",
            "100/100 [==============================] - 0s 525us/step - loss: 0.0650 - acc: 0.9900 - val_loss: 0.5121 - val_acc: 0.8500\n",
            "Epoch 4416/4500\n",
            "100/100 [==============================] - 0s 512us/step - loss: 0.0614 - acc: 0.9800 - val_loss: 0.5331 - val_acc: 0.8300\n",
            "Epoch 4417/4500\n",
            "100/100 [==============================] - 0s 496us/step - loss: 0.0629 - acc: 0.9800 - val_loss: 0.5346 - val_acc: 0.8300\n",
            "Epoch 4418/4500\n",
            "100/100 [==============================] - 0s 513us/step - loss: 0.0613 - acc: 0.9700 - val_loss: 0.5493 - val_acc: 0.8100\n",
            "Epoch 4419/4500\n",
            "100/100 [==============================] - 0s 496us/step - loss: 0.0602 - acc: 0.9800 - val_loss: 0.5263 - val_acc: 0.8300\n",
            "Epoch 4420/4500\n",
            "100/100 [==============================] - 0s 513us/step - loss: 0.0589 - acc: 0.9800 - val_loss: 0.5404 - val_acc: 0.8300\n",
            "Epoch 4421/4500\n",
            "100/100 [==============================] - 0s 510us/step - loss: 0.0616 - acc: 0.9800 - val_loss: 0.5399 - val_acc: 0.8300\n",
            "Epoch 4422/4500\n",
            "100/100 [==============================] - 0s 582us/step - loss: 0.0583 - acc: 0.9800 - val_loss: 0.5346 - val_acc: 0.8100\n",
            "Epoch 4423/4500\n",
            "100/100 [==============================] - 0s 481us/step - loss: 0.0595 - acc: 0.9800 - val_loss: 0.5411 - val_acc: 0.8100\n",
            "Epoch 4424/4500\n",
            "100/100 [==============================] - 0s 526us/step - loss: 0.0582 - acc: 0.9800 - val_loss: 0.5289 - val_acc: 0.8400\n",
            "Epoch 4425/4500\n",
            "100/100 [==============================] - 0s 511us/step - loss: 0.0606 - acc: 0.9800 - val_loss: 0.5403 - val_acc: 0.8300\n",
            "Epoch 4426/4500\n",
            "100/100 [==============================] - 0s 569us/step - loss: 0.0640 - acc: 0.9700 - val_loss: 0.5577 - val_acc: 0.8000\n",
            "Epoch 4427/4500\n",
            "100/100 [==============================] - 0s 491us/step - loss: 0.0586 - acc: 0.9800 - val_loss: 0.5282 - val_acc: 0.8300\n",
            "Epoch 4428/4500\n",
            "100/100 [==============================] - 0s 490us/step - loss: 0.0605 - acc: 0.9800 - val_loss: 0.5370 - val_acc: 0.8300\n",
            "Epoch 4429/4500\n",
            "100/100 [==============================] - 0s 483us/step - loss: 0.0711 - acc: 0.9700 - val_loss: 0.5466 - val_acc: 0.8300\n",
            "Epoch 4430/4500\n",
            "100/100 [==============================] - 0s 498us/step - loss: 0.0617 - acc: 0.9900 - val_loss: 0.5542 - val_acc: 0.8100\n",
            "Epoch 4431/4500\n",
            "100/100 [==============================] - 0s 496us/step - loss: 0.0609 - acc: 0.9700 - val_loss: 0.5448 - val_acc: 0.8300\n",
            "Epoch 4432/4500\n",
            "100/100 [==============================] - 0s 533us/step - loss: 0.0592 - acc: 0.9800 - val_loss: 0.5365 - val_acc: 0.8300\n",
            "Epoch 4433/4500\n",
            "100/100 [==============================] - 0s 516us/step - loss: 0.0663 - acc: 0.9900 - val_loss: 0.5298 - val_acc: 0.8300\n",
            "Epoch 4434/4500\n",
            "100/100 [==============================] - 0s 532us/step - loss: 0.0595 - acc: 0.9700 - val_loss: 0.5286 - val_acc: 0.8300\n",
            "Epoch 4435/4500\n",
            "100/100 [==============================] - 0s 485us/step - loss: 0.0644 - acc: 0.9800 - val_loss: 0.5593 - val_acc: 0.8100\n",
            "Epoch 4436/4500\n",
            "100/100 [==============================] - 0s 531us/step - loss: 0.0626 - acc: 0.9700 - val_loss: 0.5578 - val_acc: 0.8000\n",
            "Epoch 4437/4500\n",
            "100/100 [==============================] - 0s 529us/step - loss: 0.0597 - acc: 0.9900 - val_loss: 0.5179 - val_acc: 0.8500\n",
            "Epoch 4438/4500\n",
            "100/100 [==============================] - 0s 519us/step - loss: 0.0620 - acc: 0.9800 - val_loss: 0.5592 - val_acc: 0.8100\n",
            "Epoch 4439/4500\n",
            "100/100 [==============================] - 0s 544us/step - loss: 0.0613 - acc: 0.9900 - val_loss: 0.5419 - val_acc: 0.8300\n",
            "Epoch 4440/4500\n",
            "100/100 [==============================] - 0s 521us/step - loss: 0.0611 - acc: 0.9700 - val_loss: 0.5288 - val_acc: 0.8300\n",
            "Epoch 4441/4500\n",
            "100/100 [==============================] - 0s 510us/step - loss: 0.0582 - acc: 0.9800 - val_loss: 0.5256 - val_acc: 0.8400\n",
            "Epoch 4442/4500\n",
            "100/100 [==============================] - 0s 571us/step - loss: 0.0601 - acc: 0.9800 - val_loss: 0.5595 - val_acc: 0.8100\n",
            "Epoch 4443/4500\n",
            "100/100 [==============================] - 0s 564us/step - loss: 0.0594 - acc: 0.9800 - val_loss: 0.5473 - val_acc: 0.8300\n",
            "Epoch 4444/4500\n",
            "100/100 [==============================] - 0s 522us/step - loss: 0.0593 - acc: 0.9800 - val_loss: 0.5437 - val_acc: 0.8100\n",
            "Epoch 4445/4500\n",
            "100/100 [==============================] - 0s 584us/step - loss: 0.0568 - acc: 0.9900 - val_loss: 0.5285 - val_acc: 0.8300\n",
            "Epoch 4446/4500\n",
            "100/100 [==============================] - 0s 469us/step - loss: 0.0588 - acc: 0.9800 - val_loss: 0.5575 - val_acc: 0.8000\n",
            "Epoch 4447/4500\n",
            "100/100 [==============================] - 0s 507us/step - loss: 0.0594 - acc: 0.9900 - val_loss: 0.5440 - val_acc: 0.8300\n",
            "Epoch 4448/4500\n",
            "100/100 [==============================] - 0s 492us/step - loss: 0.0569 - acc: 0.9800 - val_loss: 0.5309 - val_acc: 0.8400\n",
            "Epoch 4449/4500\n",
            "100/100 [==============================] - 0s 501us/step - loss: 0.0572 - acc: 0.9800 - val_loss: 0.5495 - val_acc: 0.8300\n",
            "Epoch 4450/4500\n",
            "100/100 [==============================] - 0s 512us/step - loss: 0.0585 - acc: 0.9900 - val_loss: 0.5376 - val_acc: 0.8300\n",
            "Epoch 4451/4500\n",
            "100/100 [==============================] - 0s 464us/step - loss: 0.0572 - acc: 0.9800 - val_loss: 0.5234 - val_acc: 0.8400\n",
            "Epoch 4452/4500\n",
            "100/100 [==============================] - 0s 714us/step - loss: 0.0591 - acc: 0.9800 - val_loss: 0.5607 - val_acc: 0.8200\n",
            "Epoch 4453/4500\n",
            "100/100 [==============================] - 0s 530us/step - loss: 0.0589 - acc: 0.9800 - val_loss: 0.5418 - val_acc: 0.8100\n",
            "Epoch 4454/4500\n",
            "100/100 [==============================] - 0s 545us/step - loss: 0.0577 - acc: 0.9800 - val_loss: 0.5401 - val_acc: 0.8100\n",
            "Epoch 4455/4500\n",
            "100/100 [==============================] - 0s 515us/step - loss: 0.0572 - acc: 0.9800 - val_loss: 0.5482 - val_acc: 0.8300\n",
            "Epoch 4456/4500\n",
            "100/100 [==============================] - 0s 554us/step - loss: 0.0556 - acc: 0.9800 - val_loss: 0.5319 - val_acc: 0.8400\n",
            "Epoch 4457/4500\n",
            "100/100 [==============================] - 0s 501us/step - loss: 0.0583 - acc: 0.9800 - val_loss: 0.5608 - val_acc: 0.8000\n",
            "Epoch 4458/4500\n",
            "100/100 [==============================] - 0s 560us/step - loss: 0.0587 - acc: 0.9800 - val_loss: 0.5370 - val_acc: 0.8300\n",
            "Epoch 4459/4500\n",
            "100/100 [==============================] - 0s 521us/step - loss: 0.0603 - acc: 0.9800 - val_loss: 0.5429 - val_acc: 0.8300\n",
            "Epoch 4460/4500\n",
            "100/100 [==============================] - 0s 505us/step - loss: 0.0595 - acc: 0.9900 - val_loss: 0.5415 - val_acc: 0.8300\n",
            "Epoch 4461/4500\n",
            "100/100 [==============================] - 0s 527us/step - loss: 0.0619 - acc: 0.9800 - val_loss: 0.5431 - val_acc: 0.8300\n",
            "Epoch 4462/4500\n",
            "100/100 [==============================] - 0s 498us/step - loss: 0.0566 - acc: 0.9800 - val_loss: 0.5444 - val_acc: 0.8300\n",
            "Epoch 4463/4500\n",
            "100/100 [==============================] - 0s 545us/step - loss: 0.0611 - acc: 0.9800 - val_loss: 0.5385 - val_acc: 0.8300\n",
            "Epoch 4464/4500\n",
            "100/100 [==============================] - 0s 595us/step - loss: 0.0649 - acc: 0.9800 - val_loss: 0.5476 - val_acc: 0.8300\n",
            "Epoch 4465/4500\n",
            "100/100 [==============================] - 0s 500us/step - loss: 0.0656 - acc: 0.9600 - val_loss: 0.5493 - val_acc: 0.8300\n",
            "Epoch 4466/4500\n",
            "100/100 [==============================] - 0s 495us/step - loss: 0.0716 - acc: 0.9600 - val_loss: 0.5424 - val_acc: 0.8300\n",
            "Epoch 4467/4500\n",
            "100/100 [==============================] - 0s 490us/step - loss: 0.0631 - acc: 0.9800 - val_loss: 0.5440 - val_acc: 0.8300\n",
            "Epoch 4468/4500\n",
            "100/100 [==============================] - 0s 506us/step - loss: 0.0579 - acc: 0.9800 - val_loss: 0.5374 - val_acc: 0.8300\n",
            "Epoch 4469/4500\n",
            "100/100 [==============================] - 0s 490us/step - loss: 0.0601 - acc: 0.9900 - val_loss: 0.5389 - val_acc: 0.8300\n",
            "Epoch 4470/4500\n",
            "100/100 [==============================] - 0s 513us/step - loss: 0.0610 - acc: 0.9800 - val_loss: 0.5504 - val_acc: 0.8300\n",
            "Epoch 4471/4500\n",
            "100/100 [==============================] - 0s 551us/step - loss: 0.0603 - acc: 0.9900 - val_loss: 0.5520 - val_acc: 0.8100\n",
            "Epoch 4472/4500\n",
            "100/100 [==============================] - 0s 525us/step - loss: 0.0558 - acc: 1.0000 - val_loss: 0.5292 - val_acc: 0.8300\n",
            "Epoch 4473/4500\n",
            "100/100 [==============================] - 0s 528us/step - loss: 0.0580 - acc: 0.9800 - val_loss: 0.5533 - val_acc: 0.8300\n",
            "Epoch 4474/4500\n",
            "100/100 [==============================] - 0s 545us/step - loss: 0.0576 - acc: 0.9800 - val_loss: 0.5616 - val_acc: 0.8100\n",
            "Epoch 4475/4500\n",
            "100/100 [==============================] - 0s 509us/step - loss: 0.0587 - acc: 1.0000 - val_loss: 0.5365 - val_acc: 0.8300\n",
            "Epoch 4476/4500\n",
            "100/100 [==============================] - 0s 508us/step - loss: 0.0549 - acc: 0.9800 - val_loss: 0.5443 - val_acc: 0.8300\n",
            "Epoch 4477/4500\n",
            "100/100 [==============================] - 0s 519us/step - loss: 0.0620 - acc: 0.9800 - val_loss: 0.5369 - val_acc: 0.8300\n",
            "Epoch 4478/4500\n",
            "100/100 [==============================] - 0s 538us/step - loss: 0.0662 - acc: 0.9700 - val_loss: 0.5435 - val_acc: 0.8300\n",
            "Epoch 4479/4500\n",
            "100/100 [==============================] - 0s 510us/step - loss: 0.0544 - acc: 0.9800 - val_loss: 0.5571 - val_acc: 0.8100\n",
            "Epoch 4480/4500\n",
            "100/100 [==============================] - 0s 547us/step - loss: 0.0560 - acc: 0.9800 - val_loss: 0.5540 - val_acc: 0.8200\n",
            "Epoch 4481/4500\n",
            "100/100 [==============================] - 0s 536us/step - loss: 0.0552 - acc: 0.9800 - val_loss: 0.5486 - val_acc: 0.8200\n",
            "Epoch 4482/4500\n",
            "100/100 [==============================] - 0s 490us/step - loss: 0.0601 - acc: 0.9800 - val_loss: 0.5411 - val_acc: 0.8300\n",
            "Epoch 4483/4500\n",
            "100/100 [==============================] - 0s 603us/step - loss: 0.0558 - acc: 0.9900 - val_loss: 0.5653 - val_acc: 0.8100\n",
            "Epoch 4484/4500\n",
            "100/100 [==============================] - 0s 503us/step - loss: 0.0561 - acc: 0.9800 - val_loss: 0.5476 - val_acc: 0.8300\n",
            "Epoch 4485/4500\n",
            "100/100 [==============================] - 0s 502us/step - loss: 0.0571 - acc: 0.9800 - val_loss: 0.5432 - val_acc: 0.8300\n",
            "Epoch 4486/4500\n",
            "100/100 [==============================] - 0s 484us/step - loss: 0.0578 - acc: 0.9800 - val_loss: 0.5558 - val_acc: 0.8300\n",
            "Epoch 4487/4500\n",
            "100/100 [==============================] - 0s 484us/step - loss: 0.0631 - acc: 0.9800 - val_loss: 0.5665 - val_acc: 0.8100\n",
            "Epoch 4488/4500\n",
            "100/100 [==============================] - 0s 474us/step - loss: 0.0587 - acc: 0.9900 - val_loss: 0.5445 - val_acc: 0.8200\n",
            "Epoch 4489/4500\n",
            "100/100 [==============================] - 0s 502us/step - loss: 0.0559 - acc: 0.9800 - val_loss: 0.5304 - val_acc: 0.8300\n",
            "Epoch 4490/4500\n",
            "100/100 [==============================] - 0s 508us/step - loss: 0.0609 - acc: 0.9800 - val_loss: 0.5474 - val_acc: 0.8300\n",
            "Epoch 4491/4500\n",
            "100/100 [==============================] - 0s 519us/step - loss: 0.0534 - acc: 0.9800 - val_loss: 0.5570 - val_acc: 0.8200\n",
            "Epoch 4492/4500\n",
            "100/100 [==============================] - 0s 545us/step - loss: 0.0557 - acc: 0.9700 - val_loss: 0.5583 - val_acc: 0.8200\n",
            "Epoch 4493/4500\n",
            "100/100 [==============================] - 0s 494us/step - loss: 0.0551 - acc: 0.9800 - val_loss: 0.5424 - val_acc: 0.8300\n",
            "Epoch 4494/4500\n",
            "100/100 [==============================] - 0s 490us/step - loss: 0.0536 - acc: 0.9800 - val_loss: 0.5568 - val_acc: 0.8200\n",
            "Epoch 4495/4500\n",
            "100/100 [==============================] - 0s 487us/step - loss: 0.0581 - acc: 0.9900 - val_loss: 0.5404 - val_acc: 0.8300\n",
            "Epoch 4496/4500\n",
            "100/100 [==============================] - 0s 478us/step - loss: 0.0566 - acc: 0.9900 - val_loss: 0.5367 - val_acc: 0.8300\n",
            "Epoch 4497/4500\n",
            "100/100 [==============================] - 0s 484us/step - loss: 0.0558 - acc: 0.9900 - val_loss: 0.5477 - val_acc: 0.8300\n",
            "Epoch 4498/4500\n",
            "100/100 [==============================] - 0s 547us/step - loss: 0.0580 - acc: 0.9800 - val_loss: 0.5486 - val_acc: 0.8300\n",
            "Epoch 4499/4500\n",
            "100/100 [==============================] - 0s 528us/step - loss: 0.0576 - acc: 0.9800 - val_loss: 0.5432 - val_acc: 0.8300\n",
            "Epoch 4500/4500\n",
            "100/100 [==============================] - 0s 504us/step - loss: 0.0585 - acc: 0.9800 - val_loss: 0.5676 - val_acc: 0.8100\n",
            "Test loss: 0.5675883364677429\n",
            "Test accuracy: 0.81\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZKtpfYZGVx__",
        "colab_type": "text"
      },
      "source": [
        "#GADF 31x31\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Xsiw1LtkbCH",
        "colab_type": "code",
        "outputId": "af53c4a4-cc29-4a87-98f9-6af2f336c7e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "print(max(history.history['val_acc']))\n",
        "print(max(history.history['acc']))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8899999916553497\n",
            "1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ivnU2cUxmH7j",
        "colab_type": "code",
        "outputId": "8004e31a-4868-408d-c0dd-1aff589fa645",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b1j8Yf6ZmKhz",
        "colab_type": "code",
        "outputId": "179017c6-162b-43d3-86b3-6db4e5f7041c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "plt.title('Model Accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nBQhjjDERWYAwxhgTkQUIY4wxEf0/wdYMAhxX+joAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vATD7hOvvu8S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}